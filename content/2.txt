<p>


Leonardus Lessius (1554–1623)



</p><p>
	 Main article: Leonardus Lessius</p><p>In 1605 Flemish Jesuit theologian Leonardus Lessius (1554–1623) published On Justice and Law, the deepest moral-theological study of economics since Aquinas, whose just price approach he claimed was no longer workable. After comparing money's growth via avarice to the propagation of hares, he made the first statement of the price of insurance as being based on risk.</p><h3>Edward Misselden and Gerard Malynes</h3><p> Main articles: Edward Misselden and Gerard Malynes</p><p>In 1622 English merchants Edward Misselden and Gerard Malynes began a dispute over free trade and the desirability of government regulation of companies, with Malynes arguing against foreign exchange as under the control of bankers[clarification needed], and Misselden arguing that international money exchange and fluctuations in the exchange rate depend upon international trade and not bankers, and that the state should regulate trade to insure export surpluses.</p><h3>Thomas Mun</h3><p> Main article: Thomas Mun</p><p>English economist Thomas Mun (1571–1641) describes early mercantilist policy in his book England's Treasure by Foreign Trade, which was not published until 1664, although it was widely circulated in manuscript form during his lifetime. A member of the East India Company, he wrote about his experiences in A Discourse of Trade from England unto the East Indies (1621).</p><h3>Sir William Petty</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/8/84/Sir_William_Petty.jpg/100px-Sir_William_Petty.jpg" width="100" height="135"><p>


Sir William Petty (1623–1687)



</p><p>
	 Main article: William Petty</p><p>In 1662 English economist Sir William Petty (1623–1687) began publishing short works applying the rational scientific tradition of Francis Bacon to economics, requiring that it only use measurable phenomena and seek quantitative precision, coining the term political arithmetic, introducing statistical mathematics, and becoming the first scientific economist.</p><h3>Philipp von Hörnigk</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/5/50/%C3%96sterreich_uber_alles_wann_es_nur_will.jpg/100px-%C3%96sterreich_uber_alles_wann_es_nur_will.jpg" width="100" height="170"><p>


The title page to Philipp von Hörnigk's statement of mercantilist philosophy.



</p><p>
	 Main article: Philipp von Hörnigk</p><p>Philipp von Hörnigk (1640–1712, sometimes spelt Hornick or Horneck) was born in Frankfurt and became an Austrian civil servant writing in a time when his country was constantly threatened by Ottoman invasion. In Österreich Über Alles, Wann es Nur Will (1684, Austria Over All, If She Only Will) he laid out one of the clearest statements of mercantile policy, listing nine principal rules of national economy:</p><p>To inspect the country's soil with the greatest care, and not to leave the agricultural possibilities of a single corner or clod of earth unconsidered... All commodities found in a country, which cannot be used in their natural state, should be worked up within the country... Attention should be given to the population, that it may be as large as the country can support... gold and silver once in the country are under no circumstances to be taken out for any purpose... The inhabitants should make every effort to get along with their domestic products... [Foreign commodities] should be obtained not for gold or silver, but in exchange for other domestic wares... and should be imported in unfinished form, and worked up within the country... Opportunities should be sought night and day for selling the country's superfluous goods to these foreigners in manufactured form... No importation should be allowed under any circumstances of which there is a sufficient supply of suitable quality at home.</p><p>Nationalism, self-sufficiency and national power were the basic policies proposed.[18]</p><h3>Jean-Baptiste Colbert and Pierre Le Pesant, Sieur de Boisguilbert</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/4/49/Colbert_mg_8447_cropped.jpg/100px-Colbert_mg_8447_cropped.jpg" width="100" height="118"><p>


Jean-Baptiste Colbert (1619–1683)



</p><p>
	 Main articles: Jean-Baptiste Colbert and Pierre Le Pesant, sieur de Boisguilbert</p><p>In 1665–1683 Jean-Baptiste Colbert (1619–1683) was minister of finance under King Louis XIV of France, and set up national guilds to regulate major industries. Silk, linen, tapestry, furniture manufacture and wine were examples of the crafts in which France specialized, all of which came to require membership in a guild to operate in until the French Revolution. According to Colbert, It is simply and solely the abundance of money within a state [which] makes the difference in its grandeur and power.[citation needed]</p><div class='pageBreak' ></div><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/d/da/Boisguilbert.gif/100px-Boisguilbert.gif" width="100" height="143"><p>


Pierre Le Pesant, sieur de Boisguilbert (1646–1714)


</p><p>
	In 1695 French economist Pierre Le Pesant, sieur de Boisguilbert (1646–1714) wrote a plea to Louis XIV to end Colbert's mercantilist program, containing the first notion of an economical market, becoming the first economist to question mercantile economic policy and value the wealth of a country by its production and exchange of goods instead its assets.</p><h3>Charles Davenant</h3><p> Main article: Charles Davenant</p><p>In 1696 British mercantilist Tory Member of parliament Charles Davenant (1656–1714) published Essay on the East India Trade, displaying the first understanding of consumer demand and perfect competition.</p><h3>Sir James Steuart</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/0/07/Sir_James_Denham_Steuart._1713-1780.gif/100px-Sir_James_Denham_Steuart._1713-1780.gif" width="100" height="135"><p>


Sir James Steuart (1713–1780)



</p><p>
	 Main article: Sir James Steuart</p><p>In 1767 Scottish mercantilist economist Sir James Steuart (1713–1780) published An Inquiry into the Principles of Political Economy, the first book in English with the term political economy in the title, and the first complete economics treatise.</p><h2>Pre-Classical (17th and 18th century)</h2><h3>The British Enlightenment</h3><p>In the 17th century Britain went through troubling times, enduring not only political and religious division in the English Civil War, King Charles I's execution, and the Cromwellian dictatorship, but also the Great Plague of London and Great Fire of London. The restoration of the monarchy under Charles II, who had Roman Catholic sympathies, led to turmoil and strife, and his Catholic-leaning successor King James II was swiftly ousted. Invited in his place were Protestant William of Orange and Mary, who assented to the Bill of Rights 1689, ensuring that the Parliament was dominant in what became known as the Glorious Revolution.</p><p>The upheaval was accompanied by a number of major scientific advances, including Robert Boyle's discovery of the gas pressure constant (1660) and Sir Isaac Newton's publication of Philosophiae Naturalis Principia Mathematica (1687), which described Newton's laws of motion and his universal law of gravitation.</p><p>All these factors spurred the advancement of economic thought. For instance, Richard Cantillon (1680–1734) consciously imitated Newton's forces of inertia and gravity in the natural world with human reason and market competition in the economic world.[19] In his Essay on the Nature of Commerce in General, he argued rational self-interest in a system of freely-adjusting markets would lead to order and mutually-compatible prices. Unlike the mercantilist thinkers however, wealth was found not in trade but in human labor. The first person to tie these ideas into a political framework was John Locke.</p><p> Main article: John Locke</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/d/d1/JohnLocke.png/100px-JohnLocke.png" width="100" height="129"><p>


John Locke (1632–1704) combined philosophy, politics and economics into one coherent framework.


</p><p>
	John Locke (1632–1704) was born near Bristol, and educated in London and Oxford. He is considered one of the most significant philosophers of his era mainly for his critique of Thomas Hobbes' defense of absolutism in Leviathan (1651) and of his social contract theory. Locke believed that people contracted into society, which was bound to protect their property rights.[20] He defined property broadly to include people's lives and liberties, as well as their wealth. When people combined their labor with their surroundings, that created property rights. In his words from his Second Treatise on Civil Government (1689):</p><p>God hath given the world to men in common... Yet every man has a property in his own person. The labour of his body and the work of his hands we may say are properly his. Whatsoever, then, he removes out of the state that nature hath provided and left it in, he hath mixed his labour with, and joined to it something that is his own, and thereby makes it his property.[21]</p><p>Locke argued that not only should the government cease interference with people's property (or their lives, liberties and estates), but also that it should positively work to ensure their protection. His views on price and money were laid out in a letter to a Member of Parliament in 1691 entitled Some Considerations on the Consequences of the Lowering of Interest and the Raising of the Value of Money (1691), arguing that the price of any commodity rises or falls, by the proportion of the number of buyers and sellers, a rule which holds universally in all things that are to be bought and sold.[22]</p><p> Main article: Dudley North (economist)</p><br><div class='pageBreak' ></div><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/1/13/Dudley_North.jpg/100px-Dudley_North.jpg" width="100" height="117"><p>


Dudley North (1641–1691) argued that the results of mercantile policy are undesirable.


</p><p>
	Dudley North (1641–1691) was a wealthy merchant and landowner who worked for Her Majesty's Treasury and opposed most mercantile policy. His Discourses upon trade (1691), published anonymously, argued against assuming a need for a favorable balance of trade. Trade, he argued, benefits both sides, promotes specialization, division of labor and wealth for everyone. Regulation of trade interferes with these benefits, he said.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/2/21/David_Hume.jpg/100px-David_Hume.jpg" width="100" height="121"><p>


David Hume (1711–76)



</p><p>
	 Main article: David Hume</p><p>David Hume (1711–1776) agreed with North's philosophy and denounced mercantilist assumptions. His contributions were set down in Political Discourses (1752), and later consolidated in his Essays, Moral, Political, Literary (1777). Adding to the argument that it was undesirable to strive for a favourable balance of trade, Hume argued that it is, in any case, impossible.</p><p>Hume held that any surplus of exports would be paid for by imports of gold and silver. This would increase the money supply, causing prices to rise. That in turn would cause a decline in exports until the balance with imports is restored.</p><p> Main article: Bernard Mandeville</p><p>Bernard Mandeville, (15 November 1670 – 21 January 1733), was an Anglo-Dutch philosopher, political economist and satirist. His main thesis is that the actions of men cannot be divided into lower and higher. The higher life of man is a mere fiction introduced by philosophers and rulers to simplify government and the relations of society. In fact, virtue (which he defined as every performance by which man, contrary to the impulse of nature, should endeavour the benefit of others, or the conquest of his own passions, out of a rational ambition of being good) is actually detrimental to the state in its commercial and intellectual progress. This is because it is the vices (i.e., the self-regarding actions of men) which alone, by means of inventions and the circulation of capital (economics) in connection with luxurious living, stimulate society into action and progress.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/1/16/Francis_Hutcheson_b1694.jpg/100px-Francis_Hutcheson_b1694.jpg" width="100" height="132"><p>


Francis Hutcheson (1694–1746)



</p><p>
	 Main article: Francis Hutcheson (philosopher)</p><p>Francis Hutcheson (1694–1746), the teacher of Adam Smith from 1737 to 1740[23] is considered the end of a long tradition of thought on economics as household or family (?????) management,[24] [25] [26] stemming from Xenophon's work Oeconomicus.[27] [28]</p><h3>The Physiocrats and the circular flow</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/5/59/Pierre_Samuel_du_Pont_de_Nemours.jpg/100px-Pierre_Samuel_du_Pont_de_Nemours.jpg" width="100" height="155"><p>


Pierre Samuel du Pont de Nemours, a prominent Physiocrat, emigrated to the United States, and his son founded DuPont, the world's second biggest chemicals company.



<br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/6/60/Fran%C3%A7ois_Quesnay.jpg/100px-Fran%C3%A7ois_Quesnay.jpg" width="100" height="127"><br>


Francois Quesnay (1694–1774)



</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/6/60/Fran%C3%A7ois_Quesnay.jpg/100px-Fran%C3%A7ois_Quesnay.jpg" width="100" height="127"><br><p>
	 Main article: Physiocracy</p><p>Similarly disenchanted with regulation on trade inspired by mercantilism, a Frenchman named Vincent de Gournay (1712–1759) is reputed to have asked why it was so hard to laissez faire (let it be), laissez passer (let it pass), advocating free enterprise and free trade. He was one of the early Physiocrats, a Greek word meaning Government of nature, who held that agriculture was the source of wealth. As historian David B. Danbom wrote, the Physiocrats damned cities for their artificiality and praised more natural styles of living. They celebrated farmers.[29] Over the end of the seventeenth and beginning of the eighteenth century big advances in natural science and anatomy included discovery of blood circulation through the human body. This concept was mirrored in the physiocrats' economic theory, with the notion of a circular flow of income throughout the economy.</p><p>François Quesnay (1694–1774) was the court physician to King Louis XV of France. He believed that trade and industry were not sources of wealth, and instead in his book Tableau économique (1758, Economic Table) argued that agricultural surpluses, by flowing through the economy in the form of rent, wages, and purchases were the real economic movers. Firstly, said Quesnay, regulation impedes the flow of income throughout all social classes and therefore economic development. Secondly, taxes on the productive classes, such as farmers, should be reduced in favour of rises for unproductive classes, such as landowners, since their luxurious way of life distorts the income flow. David Ricardo later showed that taxes on land are non-transferable to tenants in his Law of Rent.</p><div class='pageBreak' ></div><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/c/c8/Anne_Robert_Jacques_Turgot.jpg/100px-Anne_Robert_Jacques_Turgot.jpg" width="100" height="117"><p>


Anne Robert Jacques Turgot (1727–1781)


</p><p>
	Jacques Turgot (1727–1781) was born in Paris to an old Norman family. His best known work, Réflexions sur la formation et la distribution des richesses (Reflections on the Formation and Distribution of Wealth) (1766) developed Quesnay's theory that land is the only source of wealth. Turgot viewed society in terms of three classes: the productive agricultural class, the salaried artisan class (classe stipendice) and the landowning class (classe disponible). He argued that only the net product of land should be taxed and advocated the complete freedom of commerce and industry.</p><p>In August 1774 Turgot was appointed to be minister of finance, and in the space of two years he introduced many anti-mercantile and anti-feudal measures supported by the king. A statement of his guiding principles, given to the king were no bankruptcy, no tax increases, no borrowing. Turgot's ultimate wish was to have a single tax on land and abolish all other indirect taxes, but measures he introduced before that were met with overwhelming opposition from landed interests. Two edicts in particular, one suppressing corvées (charges from farmers to aristocrats) and another renouncing privileges given to guilds, inflamed influential opinion. He was forced from office in 1776.</p><h2>Classical (18th and 19th century)</h2><h3>Ferdinando Galiani and On Money</h3><p>In 1751, Neapolitan philosopher Ferdinando Galiani published a nearly exhaustive treatise on money called Della Moneta, 25 years before Adam Smith's The Wealth of Nations, and therefore is seen as possibly the first truly modern economic analysis. In its five sections, Della Moneta covered all modern aspects of monetary theory, including the value and origin of money, its regulation, and inflation. This text remained cited by various economists for centuries, as wide-ranging a list as Karl Marx and Austrian economist Joseph Schumpeter.</p><h3>Adam Smith and The Wealth of Nations</h3><p> Main articles: The Wealth of Nations, Adam Smith, Pitt the Younger, and Edmund Burke</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/7/7d/Adamsmithout.jpg/100px-Adamsmithout.jpg" width="100" height="117"><p>


Adam Smith (1723–1790), father of modern political economy.


</p><p>
	Adam Smith (1723–1790) is popularly seen as the father of modern political economy. His 1776 publication An Inquiry Into the Nature and Causes of the Wealth of Nations happened to coincide not only with the American Revolution, shortly before the Europe-wide upheavals of the French Revolution, but also the dawn of a new industrial revolution that allowed more wealth to be created on a larger scale than ever before.</p><p>Smith was a Scottish moral philosopher, whose first book was The Theory of Moral Sentiments (1759). He argued in it that people's ethical systems develop through personal relations with other individuals, that right and wrong are sensed through others' reactions to one's behaviour. This gained Smith more popularity than his next work, The Wealth of Nations, which the general public initially ignored.[30] Yet Smith's political economic magnum opus was successful in circles that mattered.</p><h3>Adam Smith's Invisible Hand</h3><p> Main article: Invisible hand</p><p>Smith argued for a system of natural liberty[32] where individual effort was the producer of social good. Smith believed even the selfish within society were kept under restraint and worked for the good of all when acting in a competitive market. Prices are often unrepresentative of the true value of goods and services. Following John Locke, Smith thought true value of things derived from the amount of labour invested in them.</p><p>Every man is rich or poor according to the degree in which he can afford to enjoy the necessaries, conveniencies, and amusements of human life. But after the division of labour has once thoroughly taken place, it is but a very small part of these with which a man's own labour can supply him. The far greater part of them he must derive from the labour of other people, and he must be rich or poor according to the quantity of that labour which he can command, or which he can afford to purchase. The value of any commodity, therefore, to the person who possesses it, and who means not to use or consume it himself, but to exchange it for other commodities, is equal to the quantity of labour which it enables him to purchase or command. Labour, therefore, is the real measure of the exchangeable value of all commodities. The real price of every thing, what every thing really costs to the man who wants to acquire it, is the toil and trouble of acquiring it.</p><p>When the butchers, the brewers and the bakers acted under the restraint of an open market economy, their pursuit of self-interest, thought Smith, paradoxically drives the process to correct real life prices to their just values. His classic statement on competition goes as follows.</p><p>When the quantity of any commodity which is brought to market falls short of the effectual demand, all those who are willing to pay... cannot be supplied with the quantity which they want... Some of them will be willing to give more. A competition will begin among them, and the market price will rise... When the quantity brought to market exceeds the effectual demand, it cannot be all sold to those who are willing to pay the whole value of the rent, wages and profit, which must be paid to bring it thither... The market price will sink...[34]</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/d/de/Wealth_of_Nations_title.jpg/100px-Wealth_of_Nations_title.jpg" width="100" height="143"><p>


Adam Smith's title page of The Wealth of Nations.


</p><div class='pageBreak' ></div><p>
	Smith's vision of a free market economy, based on secure property, capital accumulation, widening markets and a division of labour contrasted with the mercantilist tendency to attempt to regulate all evil human actions.[32] Smith believed there were precisely three legitimate functions of government. The third function was...</p><p>...erecting and maintaining certain public works and certain public institutions, which it can never be for the interest of any individual or small number of individuals, to erect and maintain... Every system which endeavours... to draw towards a particular species of industry a greater share of the capital of the society than what would naturally go to it... retards, instead of accelerating, the progress of the society toward real wealth and greatness.</p><p>In addition to the necessity of public leadership in certain sectors Smith argued, secondly, that cartels were undesirable because of their potential to limit production and quality of goods and services.[35] Thirdly, Smith criticised government support of any kind of monopoly which always charges the highest price which can be squeezed out of the buyers.[36] The existence of monopoly and the potential for cartels, which would later form the core of competition law policy, could distort the benefits of free markets to the advantage of businesses at the expense of consumer sovereignty.</p><h3>William Pitt the Younger</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/e/e8/OlderPittThe_Younger.jpg/100px-OlderPittThe_Younger.jpg" width="100" height="128"><p>


William Pitt the Younger (1759–1806)


</p><p>
	William Pitt the Younger (1759–1806), Tory Prime Minister in 1783–1801 based his tax proposals on Smith's ideas, and advocated free trade as a devout disciple of The Wealth of Nations.[37] Smith was appointed a commissioner of customs and within twenty years Smith had a following of new generation writers who were intent on building the science of political economy.[30]</p><h3>Edmund Burke</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/1/14/Edmund_Burke2_c.jpg/100px-Edmund_Burke2_c.jpg" width="100" height="129"><p>


Edmund Burke (1729–1797)


</p><p>
	Adam Smith expressed an affinity to the opinions of Irish MP Edmund Burke (1729–1797), known widely as a political philosopher:</p><p>Burke is the only man I ever knew who thinks on economic subjects exactly as I do without any previous communication having passed between us.[38]</p><p>Burke was an established political economist himself, known for his book Thoughts and Details on Scarcity. He was widely critical of liberal politics, and condemned the French Revolution which began in 1789. In Reflections on the Revolution in France (1790) he wrote that the age of chivalry is dead, that of sophisters, economists and calculators has succeeded, and the glory of Europe is extinguished forever. Smith's contemporary influences included François Quesnay and Jacques Turgot whom he met on a visit to Paris, and David Hume, his Scottish compatriot. The times produced a common need among thinkers to explain social upheavals of the Industrial revolution taking place, and in the seeming chaos without the feudal and monarchical structures of Europe, show there was order still.</p><h3>Jeremy Bentham</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/c/c8/Jeremy_Bentham_by_Henry_William_Pickersgill_detail.jpg/100px-Jeremy_Bentham_by_Henry_William_Pickersgill_detail.jpg" width="100" height="136"><p>


Jeremy Bentham (1748–1832) believed in "the greatest good for the greatest number".



</p><p>
	 Main article: Jeremy Bentham</p><p>Jeremy Bentham (1748–1832) was perhaps the most radical thinker of his time, and developed the concept of utilitarianism. Bentham was an atheist, a prison reformer, animal rights activist, believer in universal suffrage, freedom of speech, free trade and health insurance at a time when few dared to argue for any of these ideas. He was schooled rigorously from an early age, finishing university and being called to the bar at 18. His first book, A Fragment on Government (1776), published anonymously, was a trenchant critique of William Blackstone's Commentaries on the Laws of England. This gained wide success until it was found that the young Bentham, and not a revered Professor had penned it. In An Introduction to the Principles of Morals and Legislation (1789) Bentham set out his theory of utility.[39][40]</p><h3>Jean-Baptiste Say</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/1/1f/Jean-Baptiste_Say.gif/100px-Jean-Baptiste_Say.gif" width="100" height="138"><p>


Say's Law, by Jean-Baptiste Say (1767–1832), which states that supply always equals demand, was rarely challenged until the 20th century.



</p><p>
	 Main article: Jean-Baptiste Say</p><p>Jean-Baptiste Say (1767–1832) was a Frenchman born in Lyon who helped popularize Adam Smith's work in France.[41] His book A Treatise on Political Economy (1803) contained a brief passage, which later became orthodoxy in political economics until the Great Depression, now known as Say's Law of markets. Say argued that there could never be a general deficiency of demand or a general glut of commodities in the whole economy. People produce things, to fulfill their own wants rather than those of others, therefore production is not a question of supply but an indication of producers demanding goods.</p><div class='pageBreak' ></div><p>Say agreed that a part of income is saved by households, but in the long term, savings are invested. Investment and consumption are the two elements of demand, so that production is demand, therefore it is impossible for production to outrun demand, or for there to be a general glut of supply. Say also argued that money was neutral, because its sole role is to facilitate exchanges, therefore, people demand money only to buy commodities; money is a veil.[42]</p><h3>David Ricardo</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/d/dc/Portrait_of_David_Ricardo_by_Thomas_Phillips.jpg/100px-Portrait_of_David_Ricardo_by_Thomas_Phillips.jpg" width="100" height="129"><p>


David Ricardo (1772–1823) is renowned for his law of comparative advantage.



</p><p>
	 Main article: David Ricardo</p><p>David Ricardo (1772–1823) was born in London. By the age of 26, he had become a wealthy stock market trader, and bought himself a constituency seat in Ireland to gain a platform in the British parliament's House of Commons.[43] Ricardo's best known work is On the Principles of Political Economy and Taxation (1817), which contains his critique of barriers to international trade and a description of the manner in which income is distributed in the population. Ricardo made a distinction between workers, who received a wage fixed to a level at which they could survive, the landowners, who earn a rent, and capitalists, who own capital and receive a profit, a residual part of the income.[44]</p><p>If population grows, it becomes necessary to cultivate additional land, whose fertility is lower than that of already cultivated fields, because of the law of decreasing productivity. Therefore, the cost of the production of the wheat increases, as well as the price of the wheat: The rents increase also, the wages, indexed to inflation (because they must allow workers to survive) as well. Profits decrease, until the capitalists can no longer invest. The economy, Ricardo concluded, is bound to tend towards a steady state.[42]</p><h3>Jean Charles Léonard de Sismondi</h3><p> Main article: Jean_Charles_Léonard_de_Sismondi</p><p>Jean_Charles_Léonard_de_Sismondi(a.k.a. Jean Charles Leonard Simonde de Sismondi) (French: [sism?~di]; May 19, 1773 in Geneva – June 25, 1842 The earliest author of systemic Crisis theory.</p><h3>John Stuart Mill</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/en/thumb/9/9b/John-stuart-mill-sized.jpg/100px-John-stuart-mill-sized.jpg" width="100" height="116"><p>


John Stuart Mill (1806–1873), weaned on the philosophy of Jeremy Bentham, wrote the most authoritative economics text of his time.



</p><p>
	 Main articles: Principles of Political Economy and John Stuart Mill</p><p>John Stuart Mill (1806–1873) was the dominant figure of political economic thought of his time, as well as a Member of parliament for the seat of Westminster, and a leading political philosopher. Mill was a child prodigy, reading Ancient Greek from the age of 3, and being vigorously schooled by his father James Mill.[45] Jeremy Bentham was a close mentor and family friend, and Mill was heavily influenced by David Ricardo. Mill's textbook, first published in 1848 and titled Principles of Political Economy was essentially a summary of the economic thought of the mid-nineteenth century.[46]</p><p>Principles of Political Economy (1848) was used as the standard text by most universities well into the beginning of the twentieth century[citation needed]. On the question of economic growth Mill tried to find a middle ground between Adam Smith's view of ever-expanding opportunities for trade and technological innovation and Thomas Malthus' view of the inherent limits of population. In his fourth book Mill set out a number of possible future outcomes, rather than predicting one in particular.[42]</p><h3>Classical political economy</h3><p> Main article: Classical economics</p><p>The classical economists were referred to as a group for the first time by Karl Marx.[47] One unifying part of their theories was the labour theory of value, contrasting to value deriving from a general equilibrium theory of supply and demand. These economists had seen the first economic and social transformation brought by the Industrial Revolution: rural depopulation, precariousness, poverty, apparition of a working class.</p><p>They wondered about population growth, because demographic transition had begun in Great Britain at that time. They also asked many fundamental questions, about the source of value, the causes of economic growth and the role of money in the economy. They supported a free-market economy, arguing it was a natural system based upon freedom and property. However, these economists were divided and did not make up a unified current of thought.</p><p>A notable current within classical economics was underconsumption theory, as advanced by the Birmingham School and Thomas Robert Malthus in the early 19th century. These argued for government action to mitigate unemployment and economic downturns, and were an intellectual predecessor of what later became Keynesian economics in the 1930s. Another notable school was Manchester capitalism, which advocated free trade, against the previous policy of mercantilism.</p><h3>Capitalism, Communism, and Karl Marx</h3><p> Main article: Marxian economics</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/a/a2/Marx_old.jpg/100px-Marx_old.jpg" width="100" height="134"><p>


Karl Marx (1818–1883) published a fundamental critique of classical economics based on the labor theory of value.



<br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/7/7b/Engels_1856.jpg/100px-Engels_1856.jpg" width="100" height="123"><br>


With Marx, Friedrich Engels (1820–1895) co-authored The Communist Manifesto and the second volume of Das Kapital.


Key people: Karl Marx and Friedrich Engels

<br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/b/b6/G.W.F._Hegel_%28by_Sichling%2C_after_Sebbers%29.jpg/100px-G.W.F._Hegel_%28by_Sichling%2C_after_Sebbers%29.jpg" width="100" height="115"><br>


George Wilhelm Friedrich Hegel (1770–1831)


</p><div class='pageBreak' ></div><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/7/7b/Engels_1856.jpg/100px-Engels_1856.jpg" width="100" height="123"><br><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/b/b6/G.W.F._Hegel_%28by_Sichling%2C_after_Sebbers%29.jpg/100px-G.W.F._Hegel_%28by_Sichling%2C_after_Sebbers%29.jpg" width="100" height="115"><br><p>
	Just as the term mercantilism had been coined and popularized by critics like Adam Smith, so the term capitalism coined by Karl Marx (1818–1883) was used by its critics. Socialism emerged in response to the miserable living and working conditions of the working class in the new industrial era, and the classical economics from which it sprang. The economic and political theory published in The Communist Manifesto (1848) and Das Kapital (1867) combined with the dialectic theory of history inspired by Friedrich Hegel (1770–1831) to provide a revolutionary critique of nineteenth-century capitalism.[citation needed]</p><p>In 1845 German radical Friedrich Engels (1820–1895) published The Condition of the Working Class in England in 1844,[48] describing workers in Manchester as the most unconcealed pinnacle of social misery in our day. After Marx died, Engels completed the second volume of Das Kapital from his notes.</p><p> Main articles: Das Kapital; Capital, Volume I; and Karl Marx</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/8/8d/Zentralbibliothek_Z%C3%BCrich_Das_Kapital_Marx_1867.jpg/120px-Zentralbibliothek_Z%C3%BCrich_Das_Kapital_Marx_1867.jpg" width="120" height="202"><p>


The title page of the first edition of Das Kapital (1867) in German.


</p><p>
	Marx wrote his magnum opus Das Kapital (1867) at the British Museum's library in London. Karl Marx begins with the concept of commodities. Before capitalism, says Marx, production was based on slavery—in ancient Rome for example—then serfdom in the feudal societies of medieval Europe. The current mode of labor exchange[clarification needed] has produced an erratic and unstable situation allowing the conditions for revolution. People buy and sell their labor as people buy and sell goods and services. People themselves have become disposable commodities. As Marx wrote in The Communist Manifesto,</p><p>The history of all hitherto existing society is the history of class struggles. Freeman and slave, patrician and plebeian, lord and serf, guildmaster and journeyman, in a word, oppressor and oppressed, stood in constant opposition to one another... The modern bourgeois society that has sprouted from the ruins of feudal society has not done away with class antagonisms. It has but established new classes, new conditions of oppression, new forms of struggle in place of the old ones.</p><p>From the first page of Das Kapital:</p><p>The wealth of those societies in which the capitalist mode of production prevails, presents itself as an immense accumulation of commodities, its unit being a single commodity. Our investigation must therefore begin with the analysis of a commodity.[49]</p><p>Marx uses the word commodity in an extensive metaphysical discussion of the nature of material wealth, how the objects of wealth are perceived and how they can be used. A commodity contrasts to objects of the natural world. When people mix their labor with an object it becomes a commodity. In the natural world there are trees, diamonds, iron ore and people. In the economic world they become chairs, rings, factories and workers. However, says Marx, commodities have a dual nature, a dual value. He distinguishes the use value of a thing from its exchange value, which can be entirely different.[50] The use value of a commodity exists only as that commodity is used or consumed. If commodities are considered absolutely isolated from their useful qualities the common property is human labor in the abstract. In this sense, value is human labor and is the most abstract and common property embodied in commodities. This follows the classical economists in the labor theory of value. He believed value can derive too from natural goods and refined his definition of value to socially necessary labor time, by which he meant the time people need to produce things when they are not lazy or inefficient.[51] Furthermore, people subjectively inflate the value of things, for instance because there's a commodity fetish for glimmering diamonds,[52] and oppressive power relations involved in commodity production. These two factors mean exchange values differ greatly. An oppressive power relation, says Marx applying the use/exchange distinction to labor itself, in work-wage bargains derives from the fact that employers pay their workers less in exchange value than the workers produce in use value. The difference makes up the capitalist's profit, or in Marx's terminology, surplus value.[53] Therefore, says Marx, capitalism is a system of exploitation.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/e/e8/Panic_of_1873_bank_run.jpg/100px-Panic_of_1873_bank_run.jpg" width="100" height="130"><p>


Marx explained the booms and busts, like the Panic of 1873, as part of an inherent instability in capitalist economies.


</p><p>
	Marx's work turned the labor theory of value, as the classicists called it, on its head. His dark irony goes deeper by asking what is the socially necessary labor time for the production of labor (i.e. working people) itself. Marx answers that this is the bare minimum for people to subsist and to reproduce with skills necessary in the economy.[54]</p><p>People are therefore alienated from both the fruits of production and the means to realize their potential, psychologically, by their oppressed position in the labor market. But the tale told alongside exploitation and alienation is one of capital accumulation and economic growth. Employers are constantly under pressure from <br>
			

							 
						

			</p><br><h1 lang="en">Industrial organization</h1><p> From Wikipedia, the free encyclopedia</p><div class='pageBreak' ></div><p> This article is about the field of economics. For the field of psychology, see Industrial and organizational psychology.</p><p>In economics, industrial organization or Industrial economy is a field that builds on the theory of the firm by examining the structure of (and, therefore, the boundaries between) firms and markets. Industrial organization adds real-world complications to the perfectly competitive model, complications such as transaction costs,[1] limited information, and barriers to entry of new firms that may be associated with imperfect competition. It analyzes determinants of firm and market organization and behavior as between competition[2] and monopoly,[3] including from government actions.</p><p>There are different approaches to the subject. One approach is descriptive in providing an overview of industrial organization, such as measures of competition and the size-concentration of firms in an industry. A second approach uses microeconomic models to explain internal firm organization and market strategy, which includes internal research and development along with issues of internal reorganization and renewal.[4] A third aspect is oriented to public policy as to economic regulation,[5] antitrust law,[6] and, more generally, the economic governance of law in defining property rights, enforcing contracts, and providing organizational infrastructure.[7][8]</p><p>The subject has a theoretical side and a practical side. According to one textbook: On one plane the field is abstract, a set of analytical concepts about competition and monopoly. On a second plane the topic is about real markets, teeming with the excitement and drama of struggles among real firms (Shepherd, W.; 1985; 1).</p><p>The extensive use of game theory in industrial economics has led to the export of this tool to other branches of microeconomics, such as behavioral economics and corporate finance. Industrial organization has also had significant practical impacts on antitrust law and competition policy.[9]</p><p>The development of industrial organization as a separate field owes much to Edward Chamberlin,[10] Edward S. Mason,[11] J. M. Clark,[12] and particularly Joe S. Bain[13] among others.[14][15]</p><p>Assessments of the subject have differed over time. The preface to a related research volume in 1972 remarked on Whither industrial organization?: That all is not well with this in this once flourishing field is readily apparent.[16] A response came 15 years later: [T]oday's verdict is that industrial organization is alive and well and the queen of applied microeconomics.[17]</p><h2>Contents</h2><h2>Subareas</h2><p>The Journal of Economic Literature (JEL) classification codes are one way of representing the range of economics subjects and subareas. There, Industrial Organization, one of 20 primary categories, has 9 secondary categories, each with multiple tertiary categories.[18] The secondary categories are listed below with corresponding available article-preview links of The New Palgrave Dictionary of Economics Online and footnotes to their respective JEL-tertiary categories and associated New-Palgrave links.</p><h2>Market structures</h2><p>The common market structures studied in this field are the following:</p><h2>Areas of study</h2><p>Industrial organization investigates the outcomes of these market structures in environments with</p><h2>History of the field</h2><p>A 2009 book Pioneers of Industrial Organization traces the development of the field from Adam Smith to recent times and includes dozens of short biographies of major figures in Europe and North America who contributed to the growth and development of the discipline.[28]</p><p>Other reviews by publication year and earliest available cited works those in 1970/1937,[14] 1972/1933,[29] 1974,[30] 1987/1937-1956 (3 cites), 1968-9 (7 cites).[31] 2009/c. 1900,[32] and 2010/1951.[33]</p><p> Main article: Outline of industrial organization</p><h2>Notes</h2><h2>Journals</h2><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Industrial_organization&amp;oldid=777775018"					
				Categories:  Hidden categories:</p><br><h1 lang="en">International economics</h1><p> From Wikipedia, the free encyclopedia</p><p>International economics is concerned with the effects upon economic activity from international differences in productive resources and consumer preferences and the international institutions that affect them. It seeks to explain the patterns and consequences of transactions and interactions between the inhabitants of different countries, including trade, investment and migration.</p><h2>Contents</h2><h2>International trade</h2><h3>Scope and methodology</h3><p>The economic theory of international trade differs from the remainder of economic theory mainly because of the comparatively limited international mobility of the capital and labour.[5] In that respect, it would appear to differ in degree rather than in principle from the trade between remote regions in one country. Thus the methodology of international trade economics differs little from that of the remainder of economics. However, the direction of academic research on the subject has been influenced by the fact that governments have often sought to impose restrictions upon international trade, and the motive for the development of trade theory has often been a wish to determine the consequences of such restrictions.</p><p>The branch of trade theory which is conventionally categorized as classical consists mainly of the application of deductive logic, originating with Ricardo’s Theory of Comparative Advantage and developing into a range of theorems that depend for their practical value upon the realism of their postulates. Modern trade analysis, on the other hand, depends mainly upon empirical analysis.</p><h3>Classical theory</h3><p>The theory of comparative advantage provides a logical explanation of international trade as the rational consequence of the comparative advantages that arise from inter-regional differences - regardless of how those differences arise. Since its exposition by David Ricardo[6] the techniques of neo-classical economics have been applied to it to model the patterns of trade that would result from various postulated sources of comparative advantage. However, extremely restrictive (and often unrealistic) assumptions have had to be adopted in order to make the problem amenable to theoretical analysis.</p><div class='pageBreak' ></div><p>The best-known of the resulting models, the Heckscher-Ohlin theorem (H-O)[7] depends upon the assumptions of no international differences of technology, productivity, or consumer preferences; no obstacles to pure competition or free trade and no scale economies. On those assumptions, it derives a model of the trade patterns that would arise solely from international differences in the relative abundance of labour and capital (referred to as factor endowments). The resulting theorem states that, on those assumptions, a country with a relative abundance of capital would export capital-intensive products and import labour-intensive products. The theorem proved to be of very limited predictive value, as was demonstrated by what came to be known as the Leontief Paradox (the discovery that, despite its capital-rich factor endowment, America was exporting labour-intensive products and importing capital-intensive products[8]) Nevertheless, the theoretical techniques (and many of the assumptions) used in deriving the H-O model were subsequently used to derive further theorems.</p><p>The Stolper-Samuelson theorem,[9] which is often described as a corollary of the H-O theorem, was an early example. In its most general form it states that if the price of a good rises (falls) then the price of the factor used intensively in that industry will also rise (fall) while the price of the other factor will fall (rise). In the international trade context for which it was devised it means that trade lowers the real wage of the scarce factor of production, and protection from trade raises it.</p><p>Another corollary of the H-O theorem is Samuelson's factor price equalisation theorem[10] which states that as trade between countries tends to equalise their product prices, it tends also to equalise the prices paid to their factors of production. Those theories have sometimes been taken to mean that trade between an industrialised country and a developing country would lower the wages of the unskilled in the industrialised country. (But, as noted below, that conclusion depends upon the unlikely assumption that productivity is the same in the two countries). Large numbers of learned papers have been produced in attempts to elaborate on the H-O and Stolper-Samuelson theorems, and while many of them are considered to provide valuable insights, they have seldom proved to be directly applicable to the task of explaining trade patterns.</p><p>( the Rybczynski theorem[11][12])</p><h3>Modern analysis</h3><p>Modern trade analysis moves away from the restrictive assumptions of the H-O theorem and explores the effects upon trade of a range of factors, including technology and scale economies. It makes extensive use of econometrics to identify from the available statistics, the contribution of particular factors among the many different factors that affect trade. The contributions of differences of technology have been evaluated in several such studies. The temporary advantage arising from a country’s development of a new technology is seen as contributory factor in one study.[13]</p><p>Other researchers have found research and development expenditure, patents issued, and the availability of skilled labor, to be indicators of the technological leadership that enables some countries to produce a flow of such technological innovations[14] and have found that technology leaders tend to export hi-tech products to others and receive imports of more standard products from them. Another econometric study also established a correlation between country size and the share of exports made up of goods in the production of which there are scale economies.[15] The study further suggested that internationally traded goods fall into three categories, each with a different type of comparative advantage:</p><p>There is a strong presumption that any exchange that is freely undertaken will benefit both parties, but that does not exclude the possibility that it may be harmful to others. However (on assumptions that included constant returns and competitive conditions) Paul Samuelson has proved that it will always be possible for the gainers from international trade to compensate the losers.[16] Moreover, in that proof, Samuelson did not take account of the gains to others resulting from wider consumer choice, from the international specialisation of productive activities - and consequent economies of scale, and from the transmission of the benefits of technological innovation. An OECD study has suggested that there are further dynamic gains resulting from better resource allocation, deepening specialisation, increasing returns to R&amp;D, and technology spillover. The authors found the evidence concerning growth rates to be mixed, but that there is strong evidence that a 1 per cent increase in openness to trade increases the level of GDP per capita by between 0.9 per cent and 2.0 per cent.[17] They suggested that much of the gain arises from the growth of the most productive firms at the expense of the less productive. Those findings and others[18] have contributed to a broad consensus among economists that trade confers very substantial net benefits, and that government restrictions upon trade are generally damaging.</p><p>Nevertheless, there have been widespread misgivings about the effects of international trade upon wage earners in developed countries. Samuelson‘s factor price equalisation theorem indicates that, if productivity were the same in both countries, the effect of trade would be to bring about equality in wage rates. As noted above, that theorem is sometimes taken to mean that trade between an industrialised country and a developing country would lower the wages of the unskilled in the industrialised country. However, it is unreasonable to assume that productivity would be the same in a low-wage developing country as in a high-wage developed country. A 1999 study has found international differences in wage rates to be approximately matched by corresponding differences in productivity.[19] (Such discrepancies that remained were probably the result of over-valuation or under-valuation of exchange rates, or of inflexibilities in labour markets.) It has been argued that, although there may sometimes be short-term pressures on wage rates in the developed countries, competition between employers in developing countries can be expected eventually to bring wages into line with their employees' marginal products. Any remaining international wage differences would then be the result of productivity differences, so that there would be no difference between unit labour costs in developing and developed countries, and no downward pressure on wages in the developed countries.[20]</p><p>There has also been concern that international trade could operate against the interests of developing countries. Influential studies published in 1950 by the Argentine economist Raul Prebisch[21] and the British economist Hans Singer[22] suggested that there is a tendency for the prices of agricultural products to fall relative to the prices of manufactured goods; turning the terms of trade against the developing countries and producing an unintended transfer of wealth from them to the developed countries.</p><p>Their findings have been confirmed by a number of subsequent studies, although it has been suggested[23] that the effect may be due to quality bias in the index numbers used or to the possession of market power by manufacturers. The Prebisch/Singer findings remain controversial, but they were used at the time - and have been used subsequently - to suggest that the developing countries should erect barriers against manufactured imports in order to nurture their own “infant industries” and so reduce their need to export agricultural products. The arguments for and against such a policy are similar to those concerning the protection of infant industries in general.</p><p>The term infant industry is used to denote a new industry which has prospects of gaining comparative advantage in the long-term, but which would be unable to survive in the face of competition from imported goods. This situation can occur when time is needed either to achieve potential economies of scale, or to acquire potential learning curve economies. Successful identification of such a situation, followed by the temporary imposition of a barrier against imports can, in principle, produce substantial benefits to the country that applies it – a policy known as “import substitution industrialization”. Whether such policies succeed depends upon the governments’ skills in picking winners, with reasonably expectations of both successes and failures. It has been claimed that South Korea’s automobile industry owes its existence to initial protection against imports,[24] but a study of infant industry protection in Turkey reveals the absence of any association between productivity gains and degree of protection, such as might be expected of a successful import substitution policy. .[25]</p><p>Another study provides descriptive evidence suggesting that attempts at import substitution industrialisation since the 1970s have usually failed,[26] but the empirical evidence on the question has been contradictory and inconclusive.[27] It has been argued that the case against import substitution industrialisation is not that it is bound to fail, but that subsidies and tax incentives do the job better.[28] It has also been pointed out that, in any case, trade restrictions could not be expected to correct the domestic market imperfections that often hamper the development of infant industries.[29]</p><div class='pageBreak' ></div><h3>Trade policies</h3><p>Economists’ findings about the benefits of trade have often been rejected by government policy-makers, who have frequently sought to protect domestic industries against foreign competition by erecting barriers, such as tariffs and quotas, against imports. Average tariff levels of around 15 per cent in the late 19th century rose to about 30 percent in the 1930s, following the passage in the United States of the Smoot-Hawley Act.[30] Mainly as the result of international agreements under the auspices of the General Agreement on Tariffs and Trade (GATT) and subsequently the World Trade Organisation (WTO), average tariff levels were progressively reduced to about 7 per cent during the second half of the 20th century, and some other trade restrictions were also removed. The restrictions that remain are nevertheless of major economic importance: among other estimates[31] the World Bank estimated in 2004 that the removal of all trade restrictions would yield benefits of over $500 billion a year by 2015.[32]</p><p>The largest of the remaining trade-distorting policies are those concerning agriculture. In the OECD countries government payments account for 30 per cent of farmers’ receipts and tariffs of over 100 per cent are common.[33] OECD economists estimate that cutting all agricultural tariffs and subsidies by 50% would set off a chain reaction in realignments of production and consumption patterns that would add an extra $26 billion to annual world income.[34]</p><p>Quotas prompt foreign suppliers to raise their prices toward the domestic level of the importing country. That relieves some of the competitive pressure on domestic suppliers, and both they and the foreign suppliers gain at the expense of a loss to consumers, and to the domestic economy, in addition to which there is a deadweight loss to the world economy. When quotas were banned under the rules of the General Agreement on Tariffs and Trade (GATT), the United States, Britain and the European Union made use of equivalent arrangements known as voluntary restraint agreements (VRAs) or voluntary export restraints (VERs) which were negotiated with the governments of exporting countries (mainly Japan) - until they too were banned. Tariffs have been considered to be less harmful than quotas, although it can be shown that their welfare effects differ only when there are significant upward or downward trends in imports.[35] Governments also impose a wide range of non-tariff barriers[36] that are similar in effect to quotas, some of which are subject to WTO agreements.[37] A recent example has been the application of the precautionary principle to exclude innovatory products .[38]</p><h2>International finance</h2><h3>Scope and methodology</h3><p>The economics of international finance does not differ in principle from the economics of international trade, but there are significant differences of emphasis. The practice of international finance tends to involve greater uncertainties and risks because the assets that are traded are claims to flows of returns that often extend many years into the future. Markets in financial assets tend to be more volatile than markets in goods and services because decisions are more often revised and more rapidly put into effect. There is the share presumption that a transaction that is freely undertaken will benefit both parties, but there is a much greater danger that it will be harmful to others.</p><p>For example, mismanagement of mortgage lending in the United States led in 2008 to banking failures and credit shortages in other developed countries, and sudden reversals of international flows of capital have often led to damaging financial crises in developing countries. And, because of the incidence of rapid change, the methodology of comparative statics has fewer applications than in the theory of international trade, and empirical analysis is more widely employed. Also, the consensus among economists concerning its principal issues is narrower and more open to controversy than is the consensus about international trade.</p><h3>Exchange rates and capital mobility</h3><p>A major change in the organisation of international finance occurred in the latter years of the twentieth century, and economists are still debating its implications. At the end of the second world war the national signatories to the Bretton Woods Agreement had agreed to maintain their currencies each at a fixed exchange rate with the United States dollar, and the United States government had undertaken to buy gold on demand at a fixed rate of $35 per ounce. In support of those commitments, most signatory nations had maintained strict control over their nationals’ use of foreign exchange and upon their dealings in international financial assets.</p><p>But in 1971 the United States government announced that it was suspending the convertibility of the dollar, and there followed a progressive transition to the current regime of floating exchange rates in which most governments no longer attempt to control their exchange rates or to impose controls upon access to foreign currencies or upon access to international financial markets. The behaviour of the international financial system was transformed. Exchange rates became very volatile and there was an extended series of damaging financial crises. One study estimated that by the end of the twentieth century there had been 112 banking crises in 93 countries ,[39] another that there had been 26 banking crises, 86 currency crises and 27 mixed banking and currency crises[40] - many times more than in the previous post-war years.</p><p>The outcome was not what had been expected. In making an influential case for flexible exchange rates in the 1950s, Milton Friedman had claimed that if there were any resulting instability, it would mainly be the consequence of macroeconomic instability,[41] but an empirical analysis in 1999 found no apparent connection.[42]</p><p>Neoclassical theory had led them to expect capital to flow from the capital-rich developed economies to the capital-poor developing countries - because the returns to capital there would be higher. Flows of financial capital would tend to increase the level of investment in the developing countries by reducing their costs of capital, and the direct investment of physical capital would tend to promote specialisation and the transfer of skills and technology. However, theoretical considerations alone cannot determine the balance between those benefits and the costs of volatility, and the question has had to be tackled by empirical analysis.</p><p>A 2006 International Monetary Fund working paper offers a summary of the empirical evidence.[43] The authors found little evidence either of the benefits of the liberalisation of capital movements, or of claims that it is responsible for the spate of financial crises. They suggest that net benefits can be achieved by countries that are able to meet threshold conditions of financial competence but that for others, the benefits are likely to be delayed, and vulnerability to interruptions of capital flows is likely to be increased.</p><h3>Policies and institutions</h3><p>Although the majority of developed countries now have floating exchange rates, some of them – together with many developing countries – maintain exchange rates that are nominally fixed, usually with the US dollar or the euro. The adoption of a fixed rate requires intervention in the foreign exchange market by the country’s central bank, and is usually accompanied by a degree of control over its citizens’ access to international markets.</p><p>Some governments have abandoned their national currencies in favour of the common currency of a currency area such as the eurozone and some, such as Denmark, have retained their national currencies but have pegged them at a fixed rate to an adjacent common currency. On an international scale, the economic policies promoted by the International Monetary Fund (IMF) have had a major influence, especially upon the developing countries.</p><p>The IMF was set up in 1944 to encourage international cooperation on monetary matters, to stabilise exchange rates and create an international payments system. Its principal activity is the payment of loans to help member countries to overcome balance of payments problems, mainly by restoring their depleted currency reserves. Their loans are, however, conditional upon the introduction of economic measures by recipient governments that are considered by the Fund's economists to provide conditions favourable to recovery.</p><p>Their recommended economic policies are broadly those that have been adopted in the United States and the other major developed countries (known as the Washington Consensus) and have often included the removal of all restrictions upon incoming investment. The Fund has been severely criticised by Joseph Stiglitz and others for what they consider to be the inappropriate enforcement of those policies and for failing to warn recipient countries of the dangers that can arise from the volatility of capital movements.</p><div class='pageBreak' ></div><h3>International financial stability</h3><p>From the time of the Great Depression onwards, regulators and their economic advisors have been aware that economic and financial crises can spread rapidly from country to country, and that financial crises can have serious economic consequences. For many decades, that awareness led governments to impose strict controls over the activities and conduct of banks and other credit agencies, but in the 1980s many governments pursued a policy of deregulation in the belief that the resulting efficiency gains would outweigh any systemic risks. The extensive financial innovations that followed are described in the article on financial economics.</p><p>One of their effects has been greatly to increase the international inter-connectedness of the financial markets and to create an international financial system with the characteristics known in control theory as complex-interactive. The stability of such a system is difficult to analyse because there are many possible failure sequences. The internationally systemic crises that followed included the equity crash of October 1987,[44] the Japanese asset price collapse of the 1990s[45] the Asian financial crisis of 1997[46] the Russian government default of 1998[47](which brought down the Long-Term Capital Management hedge fund) and the 2007-8 sub-prime mortgages crisis.[48] The symptoms have generally included collapses in asset prices, increases in risk premiums, and general reductions in liquidity.</p><p>Measures designed to reduce the vulnerability of the international financial system have been put forward by several international institutions. The Bank for International Settlements made two successive recommendations (Basel I and Basel II[49]) concerning the regulation of banks, and a coordinating group of regulating authorities, and the Financial Stability Forum, that was set up in 1999 to identify and address the weaknesses in the system, has put forward some proposals in an interim report.[50]</p><h2>Migration</h2><p>Elementary considerations lead to a presumption that international migration results in a net gain in economic welfare. Wage differences between developed and developing countries have been found to be mainly due to productivity differences[19] which may be assumed to arise mostly from differences in the availability of physical, social and human capital. And economic theory indicates that the move of a skilled worker from a place where the returns to skill are relatively low to a place where they are relatively high should produce a net gain (but that it would tend to depress the wages of skilled workers in the recipient country).</p><p>There have been many econometric studies intended to quantify those gains. A Copenhagen Consensus study suggests that if the share of foreign workers grew to 3% of the labour force in the rich countries there would be global benefits of $675 billion a year by 2025.[51] However, a survey of the evidence led a House of Lords committee to conclude that any benefits of immigration to the United Kingdom are relatively small.[52] Evidence from the United States also suggests that the economic benefits to the receiving country are relatively small ,[53] and that the presence of immigrants in its labour market results in only a small reduction in local wages.[54]</p><p>From the standpoint of a developing country, the emigration of skilled workers represents a loss of human capital (known as brain drain), leaving the remaining workforce without the benefit of their support. That effect upon the welfare of the parent country is to some extent offset by the remittances that are sent home by the emigrants, and by the enhanced technical know-how with which some of them return. One study introduces a further offsetting factor to suggest that the opportunity to migrate fosters enrolment in education thus promoting a brain gain that can counteract the lost human capital associated with emigration .[55]</p><p>Whereas some studies suggest that parent countries can benefit from the emigration of skilled workers,[56] generally it is emigration of unskilled and semi-skilled workers that is of economic benefit to countries of origin, by reducing pressure for employment creation. Where skilled emigration is concentrated in specific highly skilled sectors, such as medicine, the consequences are severe and even catastrophic in cases where 50% or so of trained doctors have emigrated. The crucial issues, as recently acknowledged by the OECD, is the matter of return and reinvestment in their countries of origin by the migrants themselves: thus, government policies in Europe are increasingly focused upon facilitating temporary skilled migration alongside migrant remittances.</p><p>Unlike movement of capital and goods, since 1973 government policies have tried to restrict migration flows, often without any economic rationale. Such restrictions have had diversionary effects, channeling the great majority of migration flows into illegal migration and false asylum-seeking. Since such migrants work for lower wages and often zero social insurance costs, the gain from labour migration flows is actually higher than the minimal gains calculated for legal flows; accompanying side-effects are significant, however, and include political damage to the idea of immigration, lower unskilled wages for the host population, and increased policing costs alongside lower tax receipts.</p><h2>Globalization</h2><p>The term globalization has acquired a variety of meanings, but in economic terms it refers to the move that is taking place in the direction of complete mobility of capital and labour and their products, so that the world's economies are on the way to becoming totally integrated. The driving forces of the process are reductions in politically imposed barriers and in the costs of transport and communication (although, even if those barriers and costs were eliminated, the process would be limited by inter-country differences in social capital).</p><p>It is a process which has ancient origins[citation needed], which has gathered pace in the last fifty years, but which is very far from complete. In its concluding stages, interest rates, wage rates and corporate and income tax rates would become the same everywhere, driven to equality by competition, as investors, wage earners and corporate and personal taxpayers threatened to migrate in search of better terms. In fact, there are few signs of international convergence of interest rates, wage rates or tax rates. Although the world is more integrated in some respects, it is possible to argue that on the whole it is now less integrated than it was before the first world war,[57] and that many middle-east countries are less globalised than they were 25 years ago.[58]</p><p>Of the moves toward integration that have occurred, the strongest has been in financial markets, in which globalisation is estimated to have tripled since the mid-1970s.[59] Recent research has shown that it has improved risk-sharing, but only in developed countries, and that in the developing countries it has increased macroeconomic volatility. It is estimated to have resulted in net welfare gains worldwide, but with losers as well as gainers. .[60]</p><p>Increased globalisation has also made it easier for recessions to spread from country to country. A reduction in economic activity in one country can lead to a reduction in activity in its trading partners as a result of its consequent reduction in demand for their exports, which is one of the mechanisms by which the business cycle is transmitted from country to country. Empirical research confirms that the greater the trade linkage between countries the more coordinated are their business cycles.[61]</p><p>Globalisation can also have a significant influence upon the conduct of macroeconomic policy. The Mundell–Fleming model and its extensions[62] are often used to analyse the role of capital mobility (and it was also used by Paul Krugman to give a simple account of the Asian financial crisis[63]). Part of the increase in income inequality that has taken place within countries is attributable - in some cases - to globalisation. A recent IMF report demonstrates that the increase in inequality in the developing countries in the period 1981 to 2004 was due entirely to technological change, with globalisation making a partially offsetting negative contribution, and that in the developed countries globalisation and technological change were equally responsible.[64]</p><h3>Opposition</h3><p>Globalisation is seen as contributing to economic welfare by most economists – but not all. Professor Joseph Stiglitz[65] of the School of International and Public Affairs, Columbia University has advanced the infant industry case for protection in developing countries and criticised the conditions imposed for help by the International Monetary Fund.[66] Professor Dani Rodrik of Harvard[67] has noted that the benefits of globalisation are unevenly spread, and that it has led to income inequalities, and to damaging losses of social capital in the parent countries and to social stresses resulting from immigration in the receiving countries.[68] An extensive critical analysis of these contentions has been made by Martin Wolf,[69] and a lecture by Professor Jagdish Bhagwati has surveyed the debate that has taken place among economists[70]</p><div class='pageBreak' ></div><h2>Notes</h2><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=International_economics&amp;oldid=775007268"					
				Categories:  Hidden categories:</p><br><h1 lang="en">Labour economics</h1><p> From Wikipedia, the free encyclopedia</p><p>Labour economics seeks to understand the functioning and dynamics of the markets for wage labour.</p><p>Labour markets or job markets function through the interaction of workers and employers. Labour economics looks at the suppliers of labour services (workers) and the demanders of labour services (employers), and attempts to understand the resulting pattern of wages, employment, and income.</p><p>In economics, labour is a measure of the work done by human beings. It is conventionally contrasted with such other factors of production as land and capital. There are theories which have developed a concept called human capital (referring to the skills that workers possess, not necessarily their actual work).</p><h2>Contents</h2><h2>Macro and micro analysis of labour markets</h2><p>There are two sides to labour economics. Labour economics can generally be seen as the application of microeconomic or macroeconomic techniques to the labour market. Microeconomic techniques study the role of individuals and individual firms in the labour market. Macroeconomic techniques look at the interrelations between the labour market, the goods market, the money market, and the foreign trade market. It looks at how these interactions influence macro variables such as employment levels, participation rates, aggregate income and gross domestic product.</p><h2>The macroeconomics of labour markets</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/7/76/Job_Advertisement_Board_in_Shenzhen_-01.jpg/200px-Job_Advertisement_Board_in_Shenzhen_-01.jpg" width="200" height="150"><p>


Job advertisement board in Shenzhen.


</p><p>
	The labour force is defined as the number of people of working age, who are either employed or actively looking for work. The participation rate is the number of people in the labour force divided by the size of the adult civilian noninstitutional population (or by the population of working age that is not institutionalized). The non-labour force includes those who are not looking for work, those who are institutionalised such as in prisons or psychiatric wards, stay-at home spouses, children, and those serving in the military. The unemployment level is defined as the labour force minus the number of people currently employed. The unemployment rate is defined as the level of unemployment divided by the labour force. The employment rate is defined as the number of people currently employed divided by the adult population (or by the population of working age). In these statistics, self-employed people are counted as employed.</p><p>Variables like employment level, unemployment level, labour force, and unfilled vacancies are called stock variables because they measure a quantity at a point in time. They can be contrasted with flow variables which measure a quantity over a duration of time. Changes in the labour force are due to flow variables such as natural population growth, net immigration, new entrants, and retirements from the labour force. Changes in unemployment depend on inflows made up of non-employed people starting to look for jobs and of employed people who lose their jobs and look for new ones, and outflows of people who find new employment and of people who stop looking for employment. When looking at the overall macroeconomy, several types of unemployment have been identified, including:</p><h2>Neoclassical microeconomics of labour markets</h2><p>Neoclassical economists view the labour market as similar to other markets in that the forces of supply and demand jointly determine price (in this case the wage rate) and quantity (in this case the number of people employed).</p><p>However, the labour market differs from other markets (like the markets for goods or the financial market) in several ways. In particular, the labour market may act as a non-clearing market. While according to neoclassical theory most markets quickly attain a point of equilibrium without excess supply or demand, this may not be true of the labour market: it may have a persistent level of unemployment. Contrasting the labour market to other markets also reveals persistent compensating differentials among similar workers.</p><p>Models that assume perfect competition in the labour market, as discussed below, conclude that workers earn their marginal product of labour.[1]</p><h3>Neoclassical microeconomic model – Supply</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/0/0e/Tompkins_Square_Park_Central_Knoll.jpg/220px-Tompkins_Square_Park_Central_Knoll.jpg" width="220" height="165"><p>


The neoclassical model analyzes the trade-off between leisure hours and working hours



<br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/2/2a/RAILROAD_WORK_CREW_IMPROVES_THE_TRACKS_AND_BED_OF_THE_ATCHISON%2C_TOPEKA_AND_SANTA_FE_RAILROAD_NEAR_BELLEFONT%2C_KANSAS..._-_NARA_-_556012.jpg/220px-RAILROAD_WORK_CREW_IMPROVES_THE_TRACKS_AND_BED_OF_THE_ATCHISON%2C_TOPEKA_AND_SANTA_FE_RAILROAD_NEAR_BELLEFONT%2C_KANSAS..._-_NARA_-_556012.jpg" width="220" height="149"><br>


Railroad work.


</p><div class='pageBreak' ></div><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/2/2a/RAILROAD_WORK_CREW_IMPROVES_THE_TRACKS_AND_BED_OF_THE_ATCHISON%2C_TOPEKA_AND_SANTA_FE_RAILROAD_NEAR_BELLEFONT%2C_KANSAS..._-_NARA_-_556012.jpg/220px-RAILROAD_WORK_CREW_IMPROVES_THE_TRACKS_AND_BED_OF_THE_ATCHISON%2C_TOPEKA_AND_SANTA_FE_RAILROAD_NEAR_BELLEFONT%2C_KANSAS..._-_NARA_-_556012.jpg" width="220" height="149"><br><p>
	Households are suppliers of labour. In microeconomic theory, people are assumed to be rational and seeking to maximize their utility function. In the labour market model, their utility function expresses trade-offs in preference between leisure time and income from time used for labour. However, they are constrained by the hours available to them.</p><p>Let w denote the hourly wage, k denote total hours available for labour and leisure, L denote the chosen number of working hours, p denote income from non-labour sources, and A denote leisure hours chosen. The individual's problem is to maximise utility U, which depends on total income available for spending on consumption and also depends on time spent in leisure, subject to a time constraint, with respect to the chooses of labour time and leisure time:</p><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Labour_economics&amp;oldid=783362165"					
				Categories:  Hidden categories:</p><br><h1 lang="en">Managerial economics</h1><p> From Wikipedia, the free encyclopedia</p><p>Managerial economics is the application of the economic concepts and economic analysis to the problems of formulating rational managerial decisions.[1] It is sometimes referred to as business economics and is a branch of economics that applies microeconomic analysis to decision methods of businesses or other management units. As such, it bridges economic theory and economics in practice.[2] It draws heavily from quantitative techniques such as regression analysis, correlation and calculus.[3] If there is a unifying theme that runs through most of managerial economics, it is the attempt to optimize business decisions given the firm's objectives and given constraints imposed by scarcity, for example through the use of operations research, mathematical programming, game theory for strategic decisions,[4] and other computational methods.[5]</p><p>Managerial decision areas include:</p><p>Almost any business decision can be analyzed with managerial economics techniques, but it is most commonly applied to:</p><p>At universities, the subject is taught primarily to advanced undergraduates and graduate business schools. It is approached as an integration subject. That is, it integrates many concepts from a wide variety of prerequisite courses. In many countries it is possible to read for a degree in Business Economics which often covers managerial economics, financial economics, game theory, business forecasting and industrial economics.</p><h2>Contents</h2><h2>Scope</h2><p>Managerial economics to a certain degree is prescriptive in nature as it suggests course of action to a managerial problem. Problems can be related to various departments in a firm like production, accounts, sales, etc.</p><li>Demand decision.</li><li>Production decision.</li><li>Theory of exchange or price theory.</li><li>All human economic activity.</li><h2>Demand decision</h2><p>Demand is the willingness of potential customers to buy a commodity. It defines the market size for a commodity, and at a disaggregated level the composition of the customer base. Analysis of demand is important for a firm as its revenue, profits, and income of its employees depend on it.[8]</p><h2>Notes</h2><h2>Journals</h2><p>1. http://www.edushareonline.in/Management/eco%20new.pdf 2.http://www.swlearning.com/economics/hirschey/managerial_econ/chap01.pdf</p><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Managerial_economics&amp;oldid=776262047"					
				Categories:  Hidden categories:</p><br><h1 lang="en">Financial economics</h1><p> From Wikipedia, the free encyclopedia</p><p>Financial economics is the branch of economics characterized by a concentration on monetary activities, in which money of one type or another is likely to appear on both sides of a trade.[1] Its concern is thus the interrelation of financial variables, such as prices, interest rates and shares, as opposed to those concerning the real economy. It has two main areas of focus:[2] asset pricing (or investment theory) and corporate finance; the first being the perspective of providers of capital and the second of users of capital.</p><p>The subject is concerned with the allocation and deployment of economic resources, both spatially and across time, in an uncertain environment.[3] It therefore centers on decision making under uncertainty in the context of the financial markets, and the resultant economic and financial models and principles, and is concerned with deriving testable or policy implications from acceptable assumptions. It is built on the foundations of microeconomics and decision theory.</p><p>Financial econometrics is the branch of financial economics that uses econometric techniques to parameterise these relationships. Mathematical finance is related in that it will derive and extend the mathematical or numerical models suggested by financial economics. Note though that the emphasis there is mathematical consistency, as opposed to compatibility with economic theory.</p><p>Financial economics is usually taught at the postgraduate level; see Master of Financial Economics. Recently, specialist undergraduate degrees are offered in the discipline.[4]</p><p>Note that this article provides an overview and survey of the field: for derivations and more technical discussion, see the specific articles linked.</p><h2>Contents</h2><h2>Underlying economics</h2><p>As above, the discipline essentially explores how rational investors would apply decision theory to the problem of investment. The subject is thus built on the foundations of microeconomics and decision theory, and derives several key results for the application of decision making under uncertainty to the financial markets.</p><h3>Present value, expectation and utility</h3><p>Underlying all of financial economics are the concepts of present value and expectation.[6]Calculating their present value allows the decision maker to aggregate the cashflows (or other returns) to be produced by the asset in the future, to a single value at the date in question, and to thus more readily compare two opportunities; this concept is therefore the starting point for financial decision making. Its history is correspondingly early: Richard Witt discusses compound interest already in 1613, in his book Arithmeticall Questions;[7] further developed by Johan de Witt and Edmond Halley.</p><div class='pageBreak' ></div><p>An immediate extension is to combine probabilities with present value, leading to the expected value criterion which sets asset value as a function of the sizes of the expected payouts and the probabilities of their occurrence. These ideas originate with Blaise Pascal and Pierre de Fermat.</p><p>This decision method, however, fails to consider risk aversion (as any student of finance knows[6]). In other words, since individuals receive greater utility from an extra dollar when they are poor and less utility when comparatively rich, the approach is to therefore adjust the weight assigned to the various outcomes (states) correspondingly. (Some investors may in fact be risk seeking as opposed to risk averse, but the same logic would apply).</p><p>Choice under uncertainty here, may then be characterized as the maximization of expected utility. More formally, the resulting expected utility hypothesis states that, if certain axioms are satisfied, the subjective value associated with a gamble by an individual is that individual's statistical expectation of the valuations of the outcomes of that gamble.</p><p>The impetus for these ideas arise from various inconsistencies observed under the expected value framework, such as the St. Petersburg paradox ( Ellsberg paradox). The development here originally due to Daniel Bernoulli, and later formalized by John von Neumann and Oskar Morgenstern.</p><h3>Arbitrage-free pricing and equilibrium</h3><p>The concepts of arbitrage-free, rational, pricing and equilibrium are then coupled with the above to derive classical[8] financial economics. Rational pricing is the assumption that asset prices (and hence asset pricing models) will reflect the arbitrage-free price of the asset, as any deviation from this price will be arbitraged away. This assumption is useful in pricing fixed income securities, particularly bonds, and is fundamental to the pricing of derivative instruments.</p><p>Economic equilibrium is, in general, a state in which economic forces such as supply and demand are balanced, and, in the absence of external influences these equilibrium values of economic variables will not change. General equilibrium deals with the behavior of supply, demand, and prices in a whole economy with several or many interacting markets, by seeking to prove that a set of prices exists that will result in an overall equilibrium. (This is in contrast to partial equilibrium, which only analyzes single markets.)</p><p>The two concepts are linked as follows: where market prices do not allow for profitable arbitrage, i.e. they comprise an arbitrage-free market, then these prices are also said to constitute an arbitrage equilibrium. Intuitively, this may be seen by considering that where an arbitrage opportunity does exist, then prices can be expected to change, and are therefore not in equilibrium.[9] An arbitrage equilibrium is thus a precondition for a general economic equilibrium.</p><p>The immediate, and formal, extension of this idea, the Fundamental theorem of asset pricing, shows that where markets are as above—and are additionally (implicitly and correspondingly) complete—one may then make financial decisions by constructing a risk neutral probability measure corresponding to the market.</p><p>Complete here means that there is a price for every asset in every possible state of the world, and that the complete set of possible bets on future states-of-the-world can therefore be constructed with existing assets (assuming no friction), essentially solving simultaneously for n probabilities, given n prices. The formal derivation will proceed by arbitrage arguments.[6][9] For a worked example see Rational pricing#Risk neutral valuation, where, in a simplified environment, the economy has only two possible states—up and down—and where p and (1-p) are the two corresponding (i.e. implied) probabilities, and in turn, the derived distribution, or measure.</p><p>With this measure in place, the expected, i.e. required, return of any security (or portfolio) will then equal the riskless return, plus an adjustment for risk,[6] i.e. a security-specific risk premium, compensating for the extent to which its cashflows are unpredictable. All pricing models are then essentially variants of this, given specific assumptions and/or conditions.[6][10] This approach is consistent with the above, but with the expectation based on the market (i.e. arbitrage-free, and, per the theorem, therefore in equilibrium) as opposed to individual preferences.</p><p>Thus, continuing the example, to value a specific security, its forecasted cashflows in the up- and down-states are multiplied through by p and (1-p) respectively, and are then discounted at the risk-free interest rate plus an appropriate premium. In general, this premium may be derived by the CAPM (or extensions) as will be seen under #Uncertainty.</p><h3>State prices</h3><p>With the above relationship established, the further specialized Arrow–Debreu model may be derived. This important result suggests that, under certain economic conditions, there must be a set of prices such that aggregate supplies will equal aggregate demands for every commodity in the economy. The analysis here is often undertaken assuming a Representative agent.</p><p>The Arrow–Debreu model applies to economies with maximally complete markets, in which there exists a market for every time period and forward prices for every commodity at all time periods. A direct extension, then, is the concept of a state price security (also called an Arrow–Debreu security), a contract that agrees to pay one unit of a numeraire (a currency or a commodity) if a particular state occurs (up and down in the simplified example above) at a particular time in the future and pays zero numeraire in all the other states. The price of this security is the state price of this particular state of the world.</p><p>In the above example, the state prices would equate to the present values of $p and $(1-p): i.e. what one would pay today, respectively, for the up- and down-state securities; the state price vector is the vector of state prices for all states. Applied to valuation, the price of the derivative today would simply be [up-state-price × up-state-payoff + down-state-price × down-state-payoff]; see below regarding the absence of any risk premium here. For a continuous random variable indicating a continuum of possible states, the value is found by integrating over the state price density; see Stochastic discount factor. These concepts are extended to Martingale pricing and the related Risk-neutral measure.</p><p>State prices find immediate application as a conceptual tool;[6] but can also be applied to valuation problems.[11] Given the pricing mechanism described, one can decompose the derivative value as a linear combination of its state-prices; i.e. back-solve for the state-prices corresponding to observed derivative prices[12][11]. These recovered state-prices can then be used for valuation of other instruments with exposure to the underlyer (true in fact for every security [2]), or for other decision making relating to the underlyer itself. (Breeden and Litzenberger's work in 1978 [13] established the use of state prices in financial economics.)</p><h2>Resultant models</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/7/74/MM2.png/220px-MM2.png" width="220" height="167"><p>


Modigliani–Miller Proposition II with risky debt. As leverage (D/E) increases, the WACC (k0) stays constant.



<br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/e/e1/Markowitz_frontier.jpg/220px-Markowitz_frontier.jpg" width="220" height="121"><br>


Efficient Frontier. The hyperbola is sometimes referred to as the 'Markowitz Bullet', and its upward sloped portion is the efficient frontier if no risk-free asset is available. With a risk-free asset, the straight line is the efficient frontier. The graphic displays the CAL, Capital allocation line, formed when the risky asset is a single-asset rather than the market, in which case the line is the CML.



<br><img alt="" src="http://upload.wikimedia.org/wikipedia/en/thumb/7/7d/CML-plot.PNG/220px-CML-plot.PNG" width="220" height="180"><br>


The Capital market line is the tangent line drawn from the point of the risk-free asset to the feasible region for risky assets. The tangency point M represents the market portfolio. The CML results from the combination of the market portfolio and the risk-free asset (the point L). Addition of leverage (the point R) creates levered portfolios that are also on the CML.


 

<br><img alt="" src="http://upload.wikimedia.org/wikipedia/en/thumb/f/f3/SML-chart.png/220px-SML-chart.png" width="220" height="180"><br>


Security market line: the representation of the CAPM displaying the expected rate of return of an individual security as a function of its systematic, non-diversifiable risk.



<br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/f/f2/Stockpricesimulation.jpg/220px-Stockpricesimulation.jpg" width="220" height="167"><br>


Simulated geometric Brownian motions with parameters from market data.


 
 
</p><div class='pageBreak' ></div><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/e/e1/Markowitz_frontier.jpg/220px-Markowitz_frontier.jpg" width="220" height="121"><br><br><img alt="" src="http://upload.wikimedia.org/wikipedia/en/thumb/7/7d/CML-plot.PNG/220px-CML-plot.PNG" width="220" height="180"><br><br><img alt="" src="http://upload.wikimedia.org/wikipedia/en/thumb/f/f3/SML-chart.png/220px-SML-chart.png" width="220" height="180"><br><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/f/f2/Stockpricesimulation.jpg/220px-Stockpricesimulation.jpg" width="220" height="167"><br><p>
	Applying the preceding economic concepts, we may then derive various economic- and financial models and principles. As above, the two usual areas of focus are Asset Pricing and Corporate Finance, the first being the perspective of providers of capital, the second of users of capital. Here, and for (almost) all other financial economics models, the questions addressed are typically framed in terms of time, uncertainty, options, and information,[1] as will be seen below.</p><p>Applying this framework, with the above concepts, leads to the required models. This derivation begins with the assumption of no uncertainty and is then expanded to incorporate the other considerations. (This division sometimes denoted deterministic and random,[14] or stochastic.)</p><h3>Certainty</h3><p>A starting point here is “Investment under certainty. The Fisher separation theorem, asserts that the objective of a corporation will be the maximization of its present value, regardless of the preferences of its shareholders. Related is the Modigliani–Miller theorem, which shows that, under certain conditions, the value of a firm is unaffected by how that firm is financed, and depends neither on its dividend policy nor its decision to raise capital by issuing stock or selling debt. The proof here proceeds using arbitrage arguments, and acts as a benchmark for evaluating the effects of factors outside the model that do affect value.</p><p>The mechanism for determining (corporate) value is provided by The Theory of Investment Value (John Burr Williams), which proposes that the value of an asset should be calculated using evaluation by the rule of present worth. Thus, for a common stock, the intrinsic, long-term worth is the present value of its future net cashflows, in the form of dividends. What remains to be determined is the appropriate discount rate. Later developments show that, rationally, i.e. in the formal sense, the appropriate discount rate here will (should) depend on the asset's riskiness relative to the overall market, as opposed to its owners' preferences; see below. Net present value (NPV), a direct extension of these ideas, was first formally applied to Corporate Finance decisioning by Joel Dean in 1951.</p><p>Bond valuation, in that cashflows (coupons and return of principal) are deterministic, may proceed in the same fashion.[14] An immediate extension, Arbitrage-free bond pricing, discounts each cashflow at the market derived rate — i.e. at each coupon's corresponding zero-rate — as opposed to an overall rate.</p><p>Note that in many treatments bond valuation precedes equity valuation, where cashflows (dividends) are not known per se. Williams and onward allow for forecasting assumptions—based on historic ratios or published policy—as to these, and cashflows are then treated as essentially deterministic; see below under #Corporate finance theory.</p><p>These certainty results are all commonly employed under corporate finance; uncertainty is the focus of asset pricing models, as follows.</p><h3>Uncertainty</h3><p>For choice under uncertainty, the twin assumptions of rationality and market efficiency lead to modern portfolio theory (MPT) with its Capital asset pricing model (CAPM)—an equilibrium-based result—and to the Black–Scholes–Merton theory (BSM; often, simply Black–Scholes) for option pricing—an arbitrage-free result.</p><p>Briefly, and intuitively—and consistent with #Arbitrage-free pricing and equilibrium above—the linkage is as follows.[15] Given the ability to profit from private information, self-interested traders are motivated to acquire and act on their private information. In doing so, traders contribute to more and more correct, i.e. efficient, prices: the efficient market hypothesis, or EMH. The EMH (implicitly) assumes that average expectations constitute an optimal forecast, i.e. prices using all available information, are identical to the best guess of the future: the assumption of rational expectations. The EMH does allow that when faced with new information, some investors may overreact and some may underreact, but what is required, however, is that investors' reactions follow a normal distribution—so that the net effect on market prices cannot be reliably exploited to make an abnormal profit. In the competitive limit, then, market prices will reflect all available information and prices can only move in response to news, which, of course, may be good or bad, major or minor:[16] the random walk hypothesis. Thus, if prices of financial assets are (broadly) efficient, then deviations from these (equilibrium) values could not last for long.</p><p>Under these conditions investors can then be assumed to act rationally: their investment decision must be calculated or a loss is sure to follow; correspondingly, where an arbitrage opportunity presents itself, then arbitrageurs will exploit it, reinforcing this equilibrium. Here, as under the certainty-case above, the specific assumption as to pricing is that prices are calculated as the present value of expected future dividends,[10][16] as based on currently available information. What is required though is a theory for determining the appropriate discount rate given this uncertainty: this is provided by the MPT and its CAPM. Relatedly, rationality—in the sense of arbitrage-exploitation—gives rise to Black–Scholes; option values here ultimately consistent with the CAPM.</p><div class='pageBreak' ></div><p>In general, then, while portfolio theory studies how investors should balance risk and return when investing in many assets or securities, the CAPM is more focused, describing how, in equilibrium, markets set the prices of assets in relation to how risky they are. Importantly, this result will be independent of the investor's level of risk aversion, and / or assumed utility function, thus providing a readily determined discount rate for corporate finance decision makers as above,[17] and for other investors. The argument proceeds as follows: If one can construct an efficient frontier—i.e. each combination of assets offering the best possible expected level of return for its level of risk, see diagram—then mean-variance efficient portfolios can be formed simply as a combination of holdings of the risk-free asset and the market portfolio (the Mutual fund separation theorem), with the combinations here plotting as the capital market line, or CML. Then, given this CML, the required return on risky securities will be independent of the investor's utility function, and solely determined by their covariance with aggregate, i.e. market, risk (beta). As seen in the formula aside, this result is consistent with the preceding, equaling the riskless return plus an adjustment for risk.[10] (The efficient frontier was introduced by Harry Markowitz. The CAPM was derived by Jack Treynor (1961, 1962), William F. Sharpe (1964), John Lintner (1965) and Jan Mossin (1966) independently.)</p><p>Black–Scholes provides a mathematical model of a financial market containing derivative instruments, and the resultant formula for the price of European-styled options. The model is expressed as the Black–Scholes equation, a partial differential equation describing the changing price of the option over time; it is derived assuming log-normal, geometric Brownian motion. The key financial insight behind the model is that one can perfectly hedge the option by buying and selling the underlying asset in just the right way and consequently eliminate risk, absenting the risk adjustment from the pricing (
  
    
      
        V
      
    
    {\displaystyle V}
  
, the value, or price, of the option, grows at 
  
    
      
        r
      
    
    {\displaystyle r}
  
, the risk-free rate; see Black–Scholes equation §&nbsp;Financial interpretation).[6][10] This hedge, in turn, implies that there is only one right price—in an arbitrage-free sense—for the option. And this price is returned by the Black–Scholes option pricing formula. (The formula, and hence the price, is consistent with the equation, as the formula is the solution to the equation.) Since the formula is without reference to the share's expected return, Black–Scholes entails (assumes) risk neutrality, consistent with the elimination of risk here. Relatedly, therefore, the pricing formula may also be derived directly via risk neutral expectation; see Brownian model of financial markets. (BSM is consistent with previous versions of the formula of Louis Bachelier and Edward O. Thorp.[18]  Paul Samuelson (1965).[19])</p><p>As mentioned, it can be shown that the two models are consistent; then, as is to be expected, classical[8] financial economics is thus unified. Here, the Black Scholes equation may alternatively be derived from the CAPM, and the price obtained from the Black–Scholes model is thus consistent with the expected return from the CAPM.[20] The Black–Scholes theory, although built on Arbitrage-free pricing, is therefore consistent with the equilibrium based capital asset pricing. Both models, in turn, are ultimately consistent with the Arrow–Debreu theory, and may be derived via state-pricing,[6] further explaining, and if required demonstrating, this unity.</p><h2>Extensions</h2><p>More recent work further generalizes and / or extends these models.</p><h3>Portfolio theory</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/0/08/Pareto_Efficient_Frontier_for_the_Markowitz_Portfolio_selection_problem..png/200px-Pareto_Efficient_Frontier_for_the_Markowitz_Portfolio_selection_problem..png" width="200" height="134"><p>


Plot of two criteria when maximizing return and minimizing risk in financial portfolios (Pareto-optimal points in red)



: Post-modern portfolio theory; Mathematical finance#Risk and portfolio management: the P world.

</p><p>
	The majority of developments here relate to required return, extending the basic CAPM. Multi-factor models such as the Fama–French three-factor model and the Carhart four-factor model, propose factors other than market return as relevant in pricing. The Intertemporal CAPM and Consumption-based CAPM similarly extend the model. With intertemporal portfolio choice, the investor now repeatedly optimizes her portfolio; while the inclusion of consumption (in the economic sense) then incorporates all sources of wealth, and not just market-based investments, into the investor's calculation of required return.</p><p>Whereas the above extend the CAPM, the single-index model is a more simple model. It assumes, only, a correlation between security and market returns, without (numerous) other economic assumptions. It is useful in that it simplifies the estimation of correlation between securities, significantly reducing the inputs for building the correlation matrix required for portfolio optimization. The arbitrage pricing theory (APT) similarly differs as regards its assumptions. Instead of assuming equilibrium, it returns the required (expected) return of a financial asset as a linear function of various macro-economic factors, and assumes that arbitrage should bring incorrectly priced assets back into line.</p><p>As regards Portfolio optimization, the Black–Litterman model departs from the original Markowitz approach of constructing portfolios via an efficient frontier. Black–Litterman instead starts with an equilibrium assumption, and is then modified to take into account the 'views' (i.e., the specific opinions about asset returns) of the investor in question to arrive at a bespoke asset allocation. Where factors additional to volatility are considered (kurtosis, skew...) then multiple-criteria decision analysis can be applied; here deriving a Pareto efficient portfolio. The universal portfolio algorithm (Thomas M. Cover) applies machine learning to asset selection, learning adaptively from historical data. See Portfolio optimization#Improving portfolio optimization for other techniques and / or objectives.</p><h3>Derivative pricing</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/2/2e/Arbre_Binomial_Options_Reelles.png/220px-Arbre_Binomial_Options_Reelles.png" width="220" height="129"><p>


Binomial Lattice with CRR formulae


: Mathematical finance §&nbsp;Derivatives pricing: the Q world
</p><p>
	As regards derivative pricing, the binomial options pricing model provides a discretized version of Black–Scholes, useful for the valuation of American styled options. Discretized models of this type are built—at least implicitly—using state-prices (as above); relatedly, a large number of researchers have used options to extract state-prices for a variety of other applications in financial economics.[6][20][12] For path dependent derivatives, Monte Carlo methods for option pricing are employed; here the modelling is in continuous time, but similarly uses risk neutral expected value. Various other numeric techniques have also been developed. The theoretical framework too has been extended such that martingale pricing is now the standard approach. Developments relating to complexities in return and / or volatility are discussed below.</p><p>Drawing on these techniques, derivative models for various other underlyings and applications have also been developed, all based on the same logic. Real options valuation allows that option holders can influence the option's underlying; models for employee stock option valuation explicitly assume non-rationality on the part of option holders; Credit derivatives allow that payment obligations and / or delivery requirements might not be honored. Exotic derivatives are now routinely valued.</p><div class='pageBreak' ></div><p>Similarly, beginning with Oldrich Vasicek, various short rate models, as well as the HJM and BGM forward rate-based techniques, allow for an extension of these to fixed income- and interest rate derivatives. (The Vasicek and CIR models are equilibrium-based, while Ho–Lee and subsequent models are based on arbitrage-free pricing.) Bond valuation is relatedly extended: the Stochastic calculus approach, employing these methods, allows for rates that are random (while returning a price that is arbitrage free, as above); lattice models for hybrid securities allow for non-deterministic cashflows (and stochastic rates).</p><p>As above, (OTC) derivative pricing has relied on the BSM risk neutral pricing framework, under the assumptions of funding at the risk free rate and the ability to perfectly replicate cashflows so as to fully hedge. This, in turn, is built on the assumption of a credit-risk-free environment. Post the financial crisis of 2008, therefore, issues such as counterparty credit risk, funding costs and costs of capital are additionally considered,[21] and a Credit Valuation Adjustment, or CVA—and potentially other valuation adjustments, collectively xVA—is generally added to the risk-neutral derivative value. Swap pricing is relatedly and further modified. Previously, swaps were valued off a single self discounting interest rate curve; while post crisis, to accommodate credit risk, valuation is now under a multi-curve framework; see Interest rate swap §&nbsp;Valuation and pricing.</p><h3>Corporate finance theory</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/c/c6/Manual_decision_tree.jpg/220px-Manual_decision_tree.jpg" width="220" height="260"><p>


Project valuation via decision tree.


</p><p>
	Corporate finance theory has also been extended: mirroring the above developments, asset-valuation and decisioning no longer need assume certainty. As discussed, Monte Carlo methods in finance, introduced by David B. Hertz in 1964, allow financial analysts to construct stochastic or probabilistic corporate finance models, as opposed to the traditional static and deterministic models;[22] see Corporate finance#Quantifying uncertainty. Relatedly, Real Options theory allows for owner—i.e. managerial—actions that impact underlying value: by incorporating option pricing logic, these actions are then applied to a distribution of future outcomes, changing with time, which then determine the project's valuation today.[23]</p><p>More traditionally, decision trees—which are complementary—have been used to evaluate projects, by incorporating in the valuation (all) possible events (or states) and consequent management decisions.[22] (This technique predates the use of real options in corporate finance; it is borrowed from operations research, and is not a financial economics development per se.) Related to this, is the treatment of forecasted cashflows in equity valuation. In many cases, following Williams above, the most likely cash-flows were discounted, as opposed to a more correct state-by-state treatment under uncertainty; see comments under Financial modeling#Accounting. In more modern treatments, then, it is the expected cashflows (in the mathematical sense) combined into an overall value per forecast period which are discounted.[24][25][22] (And using the CAPM—or extensions—the discounting here is at the risk-free rate plus a premium linked to the uncertainty of the entity's cash flows.)</p><p>Other extensions here include[26] agency theory, which analyses the difficulties in motivating corporate management (the agent) to act in the best interests of shareholders (the principal), rather than in their own interests. Clean surplus accounting and the related residual income valuation provide a model that returns price as a function of earnings, expected returns, and change in book value, as opposed to dividends. This approach, to some extent, arises due to the implicit contradiction of seeing value as a function of dividends, while also holding that dividend policy cannot influence value per Modigliani and Miller's Irrelevance principle; see Dividend policy#Irrelevance of dividend policy.</p><p>The typical application of real options is to capital budgeting type problems as described. However, they are also applied to questions of capital structure and dividend policy, and to the related design of corporate securities; and since stockholder and bondholders have different objective functions, in the analysis of the related agency problems.[23] In all of these cases, state-prices can provide the market-implied information relating to the corporate, as above, which is then applied to the analysis. For example, convertible bonds can (must) be priced consistent with the state-prices of the corporate's equity.[11]</p><h2>Challenges and criticism</h2><p>As above, there is a very close link between the random walk hypothesis, with the associated expectation that price changes should follow a normal distribution, on the one hand, and market efficiency and rational expectations, on the other. Note, however, that (wide) departures from these are commonly observed, and there are thus, respectively, two main sets of challenges.</p><h3>Departures from normality</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/b/b1/Ivsrf.gif/220px-Ivsrf.gif" width="220" height="201"><p>


Implied volatility surface. The Z-axis represents implied volatility in percent, and X and Y axes represent the option delta, and the days to maturity.


: Capital asset pricing model §&nbsp;Problems of CAPM, Modern portfolio theory §&nbsp;Criticisms, and Black–Scholes model §&nbsp;Criticism and comments
</p><p>
	The first set of challenges: As discussed, the assumptions that market prices follow a random walk and / or that asset returns are normally distributed are fundamental. Empirical evidence, however, suggests that these assumptions may not hold (see Kurtosis risk, Skewness risk, Long tail) and that in practice, traders, analysts and risk managers frequently modify the standard models (see Model risk). In fact, Benoît Mandelbrot had discovered already in the 1960s that changes in financial prices do not follow a Gaussian distribution, the basis for much option pricing theory, although this observation was slow to find its way into mainstream financial economics.</p><p>Financial models with long-tailed distributions and volatility clustering have been introduced to overcome problems with the realism of the above classical financial models; while jump diffusion models allow for (option) pricing incorporating jumps in the spot price. Risk managers, similarly, complement (or substitute) the standard value at risk models with historical simulations, mixture models, principal component analysis, extreme value theory, as well as models for volatility clustering.[27] For further discussion see Fat-tailed distribution §&nbsp;Applications in economics, and Value at risk §&nbsp;Criticism.</p><div class='pageBreak' ></div><p>Closely related is the volatility smile, where implied volatility—the volatility corresponding to the BSM price—is observed to differ as a function of strike price (i.e. moneyness), true only if the price-change distribution is non-normal, unlike that assumed by BSM. The term structure of volatility describes how (implied) volatility differs for related options with different maturities. An implied volatility surface is then a three-dimensional surface plot of volatility smile and term structure. These empirical phenomena negate the assumption of constant volatility—and log-normality—upon which Black–Scholes is built;[18] see Black–Scholes model §&nbsp;The volatility smile.</p><p>Approaches developed here in response include local volatility and stochastic volatility (the Heston, SABR and CEV models, amongst others). Alternatively, implied-binomial and -trinomial trees instead of directly modelling volatility, return a lattice consistent with observed prices in an arbitrage-free sense (essentially recovering state-prices, as described above) facilitating the pricing of other, i.e. non-quoted, strike/maturity combinations. Edgeworth binomial trees allow for a specified (i.e. non-Gaussian) skew and kurtosis in the spot price. Priced here, options with differing strikes will return differing implied volatilities, and the tree can thus be calibrated to the smile if required.[28] Similarly purposed closed-form models include: Jarrow and Rudd (1982); Corrado and Su (1996); Backus, Foresi, and Wu (2004).[29]</p><p>As above, additional to log-normality in returns, BSM - and, typically, other derivative models - assume the ability to perfectly replicate cashflows so as to fully hedge, and hence to discount at the risk-free rate. This, in turn, is built on the assumption of a credit-risk-free environment. The post crisis reality, however, differs, necessitating the various x-value adjustments to the derivative valuation, as described. Note that these adjustments are additional to any smile or surface effect. This is valid as the surface is built on price data relating to fully collateralized positions, and there is therefore no double counting of credit risk (etc.) when including xVA. (Also, were this not the case, then each counterparty would have its own surface...)</p><h3>Departures from rationality</h3><p>The second set of challenges: As seen, a common assumption is that financial decision makers act rationally; see Homo economicus. Recently, however, researchers in experimental economics and experimental finance have challenged this assumption empirically. These assumptions are also challenged theoretically, by behavioral finance, a discipline primarily concerned with the limits to rationality of economic agents.</p><p>Consistent with, and complementary to these findings, various persistent market anomalies have been documented, these being price and/or return distortions—e.g. size premiums—which appear to contradict the efficient-market hypothesis; calendar effects are the best known group here. Related to these are various of the economic puzzles, concerning phenomena similarly contradicting the theory. The equity premium puzzle, as one example, arises in that the difference between the observed returns on stocks as compared to government bonds is consistently higher than the risk premium rational equity investors should demand, an abnormal return. For further context see Random walk hypothesis § A non-random walk hypothesis, and sidebar for specific instances.</p><p>More generally, and particularly following the financial crisis of 2007–2010, financial economics and mathematical finance have been subjected to deeper criticism; notable here is Nassim Nicholas Taleb, who claims that the prices of financial assets cannot be characterized by the simple models currently in use, rendering much of current practice at best irrelevant, and, at worst, dangerously misleading; see Black swan theory, Taleb distribution. A topic of general interest studied in recent years has thus been financial crises,[30] and the failure of financial economics to model these. (A related problem is systemic risk: where companies hold securities in each other then this interconnectedness may entail a valuation chain - and the performance of one company, or security, here will impact all, a phenomenon not easily modeled, regardless of whether the individual models are correct; see Systemic risk § Inadequacy of classic valuation models.)</p><p>Areas of research attempting to explain (or at least model) these phenomena, and crises, include noise trading, market microstructure, and Heterogeneous agent models. The latter is extended to agent-based computational economics, where price is treated as an emergent phenomenon, resulting from the interaction of the various market participants (agents). The noisy market hypothesis argues that prices can be influenced by speculators and momentum traders, as well as by insiders and institutions that often buy and sell stocks for reasons unrelated to fundamental value; see Noise (economic). The adaptive market hypothesis is an attempt to reconcile the efficient market hypothesis with behavioral economics, by applying the principles of evolution to financial interactions. An information cascade, alternatively, shows market participants engaging in the same acts as others (herd behavior), despite contradictions with their private information.  Hyman Minsky's financial instability hypothesis, as well as George Soros' approach, #Reflexivity, financial markets, and economic theory.</p><p>Note however, that on the obverse, various studies have shown that despite these departures from efficiency, asset prices do typically exhibit a random walk and that one cannot therefore consistently outperform market averages (alpha). [31] The practical implication, therefore, is that passive investing (e.g. via low-cost index funds) should, on average, serve better than any other active strategy.[32] Burton Malkiel's A Random Walk Down Wall Street—first published in 1973, and in its 11th edition as of 2015—is a widely read popularization of these arguments. ( John C. Bogle's Common Sense on Mutual Funds; but compare Warren Buffett's The Superinvestors of Graham-and-Doddsville.) Note also that institutionally inherent limits to arbitrage—as opposed to factors directly contradictory to the theory—are sometimes proposed as an explanation for these departures from efficiency.</p><p>Financial economics</p><p>Asset pricing</p><p>Corporate finance</p><p>Theory</p><p>Links and portals</p><p>Actuarial resources</p><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Financial_economics&amp;oldid=783724594"					
				Categories:  Hidden categories:</p><br><h1 lang="en">Public economics</h1><p> From Wikipedia, the free encyclopedia</p><p>Public economics (or economics of the public sector) is the study of government policy through the lens of economic efficiency and equity. At its most basic level, public economics provides a framework for thinking about whether or not the government should participate in economic markets and to what extent it should do so. In order to do this, microeconomic theory is utilized to assess whether the private market is likely to provide efficient outcomes in the absence of governmental interference. Inherently, this study involves the analysis of government taxation and expenditures. This subject encompasses a host of topics including market failures, externalities, and the creation and implementation of government policy. Public economics builds on the theory of welfare economics and is ultimately used as a tool to improve social welfare.[1]</p><p>Broad methods and topics include:</p><p>Emphasis is on analytical and scientific methods and normative-ethical analysis, as distinguished from ideology. Examples of topics covered are tax incidence,[7] optimal taxation,[8] and the theory of public goods.[9]</p><div class='pageBreak' ></div><h2>Contents</h2><h2>Subject range</h2><p>The Journal of Economic Literature (JEL) classification codes are one way categorizing the range of economics subjects. There, Public Economics, one of 19 primary classifications, has 8 categories. They are listed below with JEL-code links to corresponding available article-preview links of The New Palgrave Dictionary of Economics Online (2008) and with similar footnote links for each respective subcategory if available:[10]</p><h2>Taxation</h2><h3>Diamond–Mirrlees efficiency theorem</h3><p>In 1971, Peter A. Diamond and James A. Mirrlees published a seminal paper which showed that even when lump-sum taxation is not available, production efficiency is still desirable. This finding is known as the Diamond–Mirrlees efficiency theorem, and it is widely credited with having modernized Ramsey's analysis by considering the problem of income distribution with the problem of raising revenue. Joseph E. Stiglitz and Partha Dasgupta (1971) have criticized this theorem as not being robust on the grounds that production efficiency will not necessarily be desirable if certain tax instruments cannot be used.</p><h3>Pigouvian taxes</h3><p> Main article: Pigouvian tax</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/0/01/A.C._Pigou.jpg/100px-A.C._Pigou.jpg" width="100" height="152"><p>


A.C. Pigou (1877-1959).


</p><p>
	One of the achievements for which the great English economist A.C. Pigou is known, was his work on the divergences between marginal private costs and marginal social costs (externalities). In his book, The Economics of Welfare (1932), Pigou describes how these divergences come about:</p><p>...one person A, in the course of rendering some service, for which payment is made, to a second person B, incidentally also renders services or disservices to other persons (not producers of like services), of such a sort that payment cannot be extracted from the benefited parties or compensation enforced on behalf of the injured parties (Pigou p. 183).</p><p>In particular, Pigou is known for his advocacy of what are known as corrective taxes, or Pigouvian taxes:</p><p>It is plain that divergences between private and social net product of the kinds we have so far been considering cannot, like divergences due to tenancy laws, be mitigated by a modification of the contractual relation between any two contracting parties, because the divergence arises out of a service or disservice to persons other than the contracting parties. It is, however, possible for the State, if it so chooses, to remove the divergence in any field by extraordinary encouragements or extraordinary restraints upon investments in that field. The most obvious forms which these encouragements and restraints may assume are, of course, those of bounties and taxes (Pigou p. 192).</p><p>Pigou describes as positive externalities, examples such as resources invested in private parks that improve the surrounding air, and scientific research from which discoveries of high practical utility often grow. Alternatively, he describes negative externalities, such as the factory that destroys a great part of the amenities of neighboring sites.</p><p>In 1960, the economist Ronald H. Coase proposed an alternative scheme whereby negative externalities are dealt with through the appropriate assignment of property rights. This result is known as the Coase theorem.</p><h2>Public goods</h2><p> Main article: Public goods</p><p>Public goods, or collective consumption goods, exhibit two properties; non-rivalry and non-excludability. Something is non-rivaled if one person's consumption of it does not deprive another person, (to a point) a firework display is non-rivaled - since one person watching a firework display does not prevent another person from doing so. Something is non-excludable if its use cannot be limited to a certain group of people. Again, since one cannot prevent people from viewing a firework display it is non-excludable.[9] Conceptually, another example of public good is the service that is provided by law enforcement organizations, such as sheriffs and police.[19] Typically, cities and towns are served by only one police department, and the police department serves all of the people within its jurisdiction.</p><h2>Cost–benefit analysis</h2><p> Main article: Cost benefit analysis</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/5/5a/Julesdupuit.jpg/100px-Julesdupuit.jpg" width="100" height="141"><p>


Jules Dupuit (1804-1866).


</p><p>
	While the origins of cost–benefit analysis can be traced back to Jules Dupuit's classic article On the Measurement of the Utility of Public Works (1844), much of the subsequent scholarly development occurred in the United States and arose from the challenges of water-resource development. In 1950, the U.S. Federal Interagency River Basin Committee’s Subcommittee on Benefits and Costs published a report entitled, Proposed Practices for Economic Analysis of River Basin Projects (also known as the Green Book), which became noteworthy for bringing in the language of welfare economics.[20] In 1958, Otto Eckstein published Water-Resource Development: The Economics of Project Evaluation, and Roland McKean published his Efficiency in Government Through Systems Analysis: With Emphasis on Water Resources Development. The latter book is also considered a classic in the field of operations research. In subsequent years, several other important works appeared: Jack Hirshleifer, James DeHaven, and Jerome W. Milliman published a volume entitled Water Supply: Economics, Technology, and Policy (1960); and a group of Harvard scholars including Robert Dorfman, Stephen Marglin, and others published Design of Water-Resource Systems: New Techniques for Relating Economic Objectives, Engineering Analysis, and Governmental Planning (1962).[21]</p><div class='pageBreak' ></div><h2>Notes</h2><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Public_economics&amp;oldid=772499146"					
				Categories:  Hidden categories:</p><br><h1 lang="en">Organizational economics</h1><p> From Wikipedia, the free encyclopedia</p><p>Organizational economics (also referred to as economics of organization) involves the use of economic logic and methods to understand the existence, nature, design, and performance of organizations, especially managed ones.</p><p>Organizational economics is primarily concerned with the obstacles to coordination of activities inside and between organizations (firms, alliances, institutions, and market as a whole).</p><p>Organizational economics is known for its contribution to and its use of:</p><p>Notable theorists and contributors in the field of organizational economics:[1][2][3]</p><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Organizational_economics&amp;oldid=766902827"					
				Categories:  Hidden categories:</p><br><h1 lang="en">Service economy</h1><p> From Wikipedia, the free encyclopedia</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/3/3d/Gdp-and-labour-force-by-sector.png/300px-Gdp-and-labour-force-by-sector.png" width="300" height="278"><p>


GDP Composition By Sector and Labour Force By Occupation


</p><p>
	Service economy can refer to one or both of two recent economic developments:</p><p>The old dichotomy between product and service has been replaced by a service-product continuum. Many products are being transformed into services.</p><p>For example, IBM treats its business as a service business. Although it still manufactures computers, it sees the physical goods as a small part of the business solutions industry. They have found that the price elasticity of demand for business solutions is much less than for hardware. There has been a corresponding shift to a subscription pricing model. Rather than receiving a single payment for a piece of manufactured equipment, many manufacturers are now receiving a steady stream of revenue for ongoing contracts.</p><p>Full cost accounting and most accounting reform and monetary reform measures are usually thought to be impossible to achieve without a good model of the service economy.</p><h2>Contents</h2><h2>Environmental effects of the service economy</h2><p>This is seen, especially in green economics and more specific theories within it such as Natural Capitalism, as having these benefits:</p><p>Product stewardship or product take-back are words for a specific requirement or measure in which the service of waste disposal is included in the distribution chain of an industrial product and is paid for at time of purchase. That is, paying for the safe and proper disposal when you pay for the product, and relying on those who sold it to you to dispose of it.</p><p>Those who advocate it are concerned with the later phases of product lifecycle and the comprehensive outcome of the whole production process. It is considered a pre-requisite to a strict service economy interpretation of (fictional, national, legal) commodity and product relationships.</p><p>It is often applied to paint, tires, and other goods that become toxic waste if not disposed of properly. It is most familiar as the container deposit charged for a deposit bottle. One pays a fee to buy the bottle, separately from the fee to buy what it contains. If one returns the bottle, the fee is returned, and the supplier must return the bottle for re-use or recycling. If not, one has paid the fee, and presumably this can pay for landfill or litter control measures that dispose of diapers or a broken bottle. Also, since the same fee can be collected by anyone finding and returning the bottle, it is common for people to collect these and return them as a means of gaining a small income. This is quite common for instance among homeless people in U.S. cities. Legal requirements vary: the bottle itself may be considered the property of the purchaser of the contents, or, the purchaser may have some obligation to return the bottle to some depot so it can be recycled or re-used.</p><p>In some countries, such as Germany, law requires attention to the comprehensive outcome of the whole extraction, production, distribution, use and waste of a product, and holds those profiting from these legally responsible for any outcome along the way. This is also the trend in the UK and EU generally. In the United States, there have been many class action suits that are effectively product stewardship liability - holding companies responsible for things the product does which it was never advertised to do.</p><p>Rather than let liability for these problems be taken up by the public sector or be haphazardly assigned one issue at a time to companies via lawsuits, many accounting reform efforts focus on achieving full cost accounting. This is the financial reflection of the comprehensive outcome - noting the gains and losses to all parties involved, not just those investing or purchasing. Such moves have made moral purchasing more attractive, as it avoids liability and future lawsuits.</p><p>The United States Environmental Protection Agency advocates product stewardship to reduce the life-cycle environmental effects of products. The ideal of product stewardship, as administered by the EPA in 2004, taps the shared ingenuity and responsibility of businesses, consumers, governments, and others, the EPA states at a Web site.</p><h2>Role of the service economy in development</h2><p>Services constitute over 50% of GDP in low income countries and as their economies continue to develop, the importance of services in the economy continues to grow.[1] The service economy is also key to growth, for instance it accounted for 47% of economic growth in sub-Saharan Africa over the period 2000–2005 (industry contributed 37% and agriculture 16% in the same period).[1] This means that recent economic growth in Africa relies as much on services as on natural resources or textiles, despite many of those countries benefiting from trade preferences in primary and secondary goods. As a result, employment is also adjusting to the changes and people are leaving the agricultural sector to find work in the service economy. This job creation is particularly useful as often it provides employment for low skilled labour in the tourism and retail sectors, thus benefiting the poor in particular and representing an overall net increase in employment.[1] The service economy in developing countries is most often made up of the following:</p><div class='pageBreak' ></div><p>The export potential of many of these products is already well understood, e.g. in tourism, financial services and transport, however, new opportunities are arising in other sectors, such as the health sector. For example:</p><p>[1]</p><li>^ Shelp, Ronald (January 1982). Beyond Industrialization: Ascendancy of the Global Service Economy. Praeger Publishers. ISBN&nbsp;978-0030593048.&nbsp;</li><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Service_economy&amp;oldid=761815411"					
				Categories:  				
							
		<br>
			

							 
						

			</p><br><h1 lang="en">Welfare</h1><p> From Wikipedia, the free encyclopedia</p><p>Welfare is the provision of a minimal level of well-being and social support for citizens without current means to support basic needs. In most developed countries, welfare is largely provided by the government from tax income, and to a lesser extent by charities, informal social groups, religious groups, and inter-governmental organizations.</p><p>The welfare state expands on this concept to include services such as universal healthcare and unemployment insurance.</p><h2>Contents</h2><h2>History</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/c/c7/Abbey_of_Port-Royal%2C_Distributing_Alms_to_the_Poor_by_Louise-Magdeleine_Hortemels_c._1710.jpg/240px-Abbey_of_Port-Royal%2C_Distributing_Alms_to_the_Poor_by_Louise-Magdeleine_Hortemels_c._1710.jpg" width="240" height="188"><p>


Distributing alms to the poor, abbey of Port-Royal des Champs c. 1710.


</p><p>
	In the Roman Empire, the first emperor Augustus provided the Cura Annonae or grain dole for citizens who could not afford to buy food every month. Social welfare was enlarged by the Emperor Trajan.[1] Trajan's program brought acclaim from many, including Pliny the Younger.[2] The Song dynasty government (c.1000AD in China) supported multiple programs which could be classified as social welfare, including the establishment of retirement homes, public clinics, and paupers' graveyards. According to economist Robert Henry Nelson, The medieval Roman Catholic Church operated a far-reaching and comprehensive welfare system for the poor...[3][4]</p><p>Early welfare programs in Europe included the English Poor Law of 1601, which gave parishes the responsibility for providing welfare payments to the poor.[5] This system was substantially modified by the 19th-century Poor Law Amendment Act, which introduced the system of workhouses.</p><p>Public assistance programs were not called welfare until the early 20th century when the term was quickly adopted to avoid the negative connotations that had become associated with older terms such as charity.[6]</p><p>It was predominantly in the late 19th and early 20th centuries that an organized system of state welfare provision was introduced in many countries. Otto von Bismarck, Chancellor of Germany, introduced one of the first welfare systems for the working classes. In Great Britain the Liberal government of Henry Campbell-Bannerman and David Lloyd George introduced the National Insurance system in 1911,[7] a system later expanded by Clement Attlee. The United States inherited England's poor house laws and has had a form of welfare since before it won its independence[citation needed]. During the Great Depression, when emergency relief measures were introduced under President Franklin D. Roosevelt, Roosevelt's New Deal focused predominantly on a program of providing work and stimulating the economy through public spending on projects, rather than on cash payment.</p><p>Modern welfare states include Germany, France, the Netherlands,[8] as well as the Nordic countries, such as Iceland, Sweden, Norway, Denmark, and Finland[9] which employ a system known as the Nordic model. Esping-Andersen classified the most developed welfare state systems into three categories; Social Democratic, Conservative, and Liberal.[10]</p><p>In the Islamic world, Zakat (charity), one of the Five Pillars of Islam, has been collected by the government since the time of the Rashidun caliph Umar in the 7th century. The taxes were used to provide income for the needy, including the poor, elderly, orphans, widows, and the disabled. According to the Islamic jurist Al-Ghazali (Algazel, 1058–111), the government was also expected to store up food supplies in every region in case a disaster or famine occurred.[11][12] (See Bayt al-mal for further information.)</p><h2>Forms</h2><p>Welfare can take a variety of forms, such as monetary payments, subsidies and vouchers, or housing assistance. Welfare systems differ from country to country, but welfare is commonly provided to individuals who are unemployed, those with illness or disability, the elderly, those with dependent children, and veterans. A person's eligibility for welfare may also be constrained by means testing or other conditions.</p><h2>Provision and funding</h2><p>Welfare is provided by governments or their agencies, by private organizations, or a combination of both. Funding for welfare usually comes from general government revenue, but when dealing with charities or NGOs, donations may be used. Some countries run conditional cash transfer welfare programs where payment is conditional on behaviour of the recipients.[13][14][15][16]</p><h2>Welfare systems</h2><p> Further information: Welfare state</p><h3>Australia</h3><p> Main article: Social security in Australia</p><p>Prior to 1900 in Australia, charitable assistance from benevolent societies, sometimes with financial contributions from the authorities, was the primary means of relief for people not able to support themselves.[17] The 1890s economic depression and the rise of the trade unions and the Labor parties during this period led to a movement for welfare reform.[18]</p><div class='pageBreak' ></div><p>In 1900, the states of New South Wales and Victoria enacted legislation introducing non-contributory pensions for those aged 65 and over. Queensland legislated a similar system in 1907 before the Australian labor Commonwealth government led by Andrew Fisher introduced a national aged pension under the Invalid and Old-Aged Pensions Act 1908. A national invalid disability pension was started in 1910, and a national maternity allowance was introduced in 1912.[17][19]</p><p>During the Second World War, Australia under a labor government created a welfare state by enacting national schemes for: child endowment in 1941 (superseding the 1927 New South Wales scheme); a widows’ pension in 1942 (superseding the New South Wales 1926 scheme); a wife’s allowance in 1943; additional allowances for the children of pensioners in 1943; and unemployment, sickness, and special benefits in 1945 (superseding the Queensland 1923 scheme).[17][19]</p><h3>Canada</h3><p> Main article: Social programs in Canada</p><p>Canada has a welfare state in the European tradition; however, it is not referred to as welfare, but rather as social programs. In Canada, welfare usually refers specifically to direct payments to poor individuals (as in the American usage) and not to healthcare and education spending (as in the European usage).[20]</p><p>The Canadian social safety net covers a broad spectrum of programs, and because Canada is a federation, many are run by the provinces. Canada has a wide range of government transfer payments to individuals, which totaled $145 billion in 2006.[21] Only social programs that direct funds to individuals are included in that cost; programs such as medicare and public education are additional costs.</p><p>Generally speaking, before the Great Depression, most social services were provided by religious charities and other private groups. Changing government policy between the 1930s and 1960s saw the emergence of a welfare state, similar to many Western European countries. Most programs from that era are still in use, although many were scaled back during the 1990s as government priorities shifted towards reducing debt and deficits.</p><h3>Denmark</h3><p>Characteristics of the Danish welfare is that it is handled by the state through a series of policies (and the like) that seeks to provide welfare services to citizens, hence the term welfare state. This refers not only to social benefits, but also tax-funded education, public child care, medical care, etc. A number of these services are not provided by the state directly, but administered by municipalities, regions or private providers through outsourcing. This sometimes gives a source of tension between the state and municipalities, as there is not always consistency between the promises of welfare provided by the state (i.e. parliament) and local perception of what it would cost to fulfill these promises.</p><h3>France</h3><p> Main articles: Poverty in France, Social protection in France, French Fifth Risk Plan, Revenu de solidarité active, and Revenu minimum d'insertion</p><p>Solidarity is a strong value of the French Social Protection system. The first article of the French Code of Social Security describes the principle of solidarity. Solidarity is commonly comprehended in relations of similar work, shared responsibility and common risks. Existing solidarities in France caused the expansion of health and social security.[22]</p><h3>Germany</h3><p> Main articles: Welfare in Germany and Hartz_concept §&nbsp;Hartz_IV</p><p>The welfare state has a long tradition in Germany dating back to the industrial revolution. Due to the pressure of the workers' movement in the late 19th century, Reichskanzler Otto von Bismarck introduced the first rudimentary state social insurance scheme. Under Adolf Hitler, the National Socialist Program stated We demand an expansion on a large scale of old age welfare.[23] Today, the social protection of all its citizens is considered a central pillar of German national policy. 27.6 percent of Germany's GDP is channeled into an all-embracing system of health, pension, accident, longterm care and unemployment insurance, compared to 16.2 percent in the US. In addition, there are tax-financed services such as child benefits (Kindergeld, beginning at €184 per month for the first and second child, €190 for the third and €215 for each child thereafter, until they attain 25 years or receive their first professional qualification),[24] and basic provisions for those unable to work or anyone with an income below the poverty line.[25]</p><p>Since 2005, reception of full unemployment pay (60–67% of the previous net salary) has been restricted to 12 months in general and 18 months for those over 55. This is now followed by (usually much lower) Arbeitslosengeld II (ALG II) or Sozialhilfe, which is independent of previous employment (Hartz IV concept).</p><p>Under ALG II, a single person receives €391 per month plus the cost of 'adequate' housing and health insurance. ALG II can also be paid partially to supplement a low work income.</p><h3>Italy</h3><p> Main article: Italian welfare state</p><p>The Italian welfare state's foundations were laid along the lines of the corporatist-conservative model, or of its Mediterranean variant.[citation needed] Later, in the 1960s and 1970s, increases in public spending and a major focus on universality brought it on the same path as social-democratic systems. In 1978, a universalistic welfare model was introduced in Italy, offering a number of universal and free services such as a National Health Fund.[26]</p><h3>Japan</h3><p> Main article: Welfare in Japan</p><p>Social welfare, assistance for the ill or otherwise disabled and for the old, has long been provided in Japan by both the government and private companies. Beginning in the 1920s, the government enacted a series of welfare programs, based mainly on European models, to provide medical care and financial support. During the postwar period, a comprehensive system of social security was gradually established.[27][28]</p><h3>Latin America</h3><p>The 1980s marked a change in the structure of Latin American social protection programs. Social protection embraces three major areas: social insurance, financed by workers and employers; social assistance to the population’s poorest, financed by the state; and labor market regulations to protect worker rights.[29] Although diverse, recent Latin American social policy has tended to concentrate on social assistance.</p><p>The 1980s had a significant effect on social protection policies. Prior to the 1980s, most Latin American countries focused on social insurance policies involving formal sector workers, assuming that the informal sector would disappear with economic development. The economic crisis of the 1980s and the liberalization of the labor market led to a growing informal sector and a rapid increase in poverty and inequality. Latin American countries did not have the institutions and funds to properly handle such a crisis, both due to the structure of the social security system, and to the previously implemented structural adjustment policies (SAPs) that had decreased the size of the state.</p><div class='pageBreak' ></div><p>New Welfare programs have integrated the multidimensional, social risk management, and capabilities approaches into poverty alleviation. They focus on income transfers and service provisions while aiming to alleviate both long- and short-term poverty through, among other things, education, health, security, and housing. Unlike previous programs that targeted the working class, new programs have successfully focused on locating and targeting the very poorest.</p><p>The impacts of social assistance programs vary between countries, and many programs have yet to be fully evaluated. According to Barrientos and Santibanez, the programs have been more successful in increasing investment in human capital than in bringing households above the poverty line. Challenges still exist, including the extreme inequality levels and the mass scale of poverty; locating a financial basis for programs; and deciding on exit strategies or on the long-term establishment of programs.[29]</p><p>The economic crisis of the 1980s led to a shift in social policies, as understandings of poverty and social programs evolved (24). New, mostly short-term programs emerged. These include:[30]</p><h3>New Zealand</h3><p> Main article: Welfare in New Zealand</p><p>New Zealand is often regarded as having one of the first comprehensive welfare systems in the world. During the 1890s a Liberal government adopted many social programmes to help the poor who had suffered from a long economic depression in the 1880s. One of the most far reaching was the passing of tax legislation that made it difficult for wealthy sheep farmers to hold onto their large land holdings. This and the invention of refrigeration led to a farming revolution where many sheep farms were broken up and sold to become smaller dairy farms. This enabled thousands of new farmers to buy land and develop a new and vigorous industry that has become the backbone of New Zealand's economy to this day. This liberal tradition flourished with increased enfranchisement for indigenous Maori in the 1880s and women. Pensions for the elderly, the poor and war casualties followed, with State-run schools, hospitals and subsidized medical and dental care. By 1960 New Zealand was able to afford one of the best-developed and most comprehensive welfare systems in the world, supported by a well-developed and stable economy.</p><h3>Sweden</h3><p> Main articles: Welfare in Sweden and Social security in Sweden</p><p>Social welfare in Sweden is made up of several organizations and systems dealing with welfare. It is mostly funded by taxes, and executed by the public sector on all levels of government as well as private organisations. It can be separated into three parts falling under three different ministries; social welfare, falling under the responsibility of Ministry of Health and Social Affairs; education, under the responsibility of the Ministry of Education and Research and labour market, under the responsibility of Ministry of Employment.[31]</p><p>Government pension payments are financed through an 18.5% pension tax on all taxed incomes in the country, which comes partly from a tax category called a public pension fee (7% on gross income), and 30% of a tax category called employer fees on salaries (which is 33% on a netted income). Since January 2001 the 18.5% is divided in two parts: 16% goes to current payments, and 2.5% goes into individual retirement accounts, which were introduced in 2001. Money saved and invested in government funds, and IRAs for future pension costs, are roughly 5 times annual government pension expenses (725/150).</p><h3>United Kingdom</h3><p> Main article: Welfare state in the United Kingdom</p><p>The United Kingdom has a long history of welfare, notably including the English Poor laws which date back to 1536. After various reforms to the program, which involved workhouses, it was eventually abolished and replaced with a modern system by laws such as National Assistance Act 1948.</p><p>In more recent times, comparing the first Cameron ministry's austerity measures with the Opposition's, the respected Financial Times commentator Martin Wolf commented that the big shift from Labour ... is the cuts in welfare benefits.[33] The government's austerity programme, which involves reduction in government policy, has been linked to a rise in food banks. A study published in the British Medical Journal in 2015 found that each 1 percentage point increase in the rate of Jobseeker's Allowance claimants sanctioned was associated with a 0.09 percentage point rise in food bank use.[34] The austerity programme has faced opposition from disability rights groups for disproportionately affecting disabled people. The bedroom tax is an austerity measure that has attracted particular criticism, with activists arguing that two thirds of council houses affected by the policy are occupied with a person with a disability.[35]</p><h3>United States</h3><p> Main article: Social programs in the United States</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/2/28/Signing_Of_The_Social_Security_Act.jpg/250px-Signing_Of_The_Social_Security_Act.jpg" width="250" height="196"><p>


President Roosevelt signs the Social Security Act, August 14, 1935.


</p><p>
	In the United States, depending on the context, the term “welfare” can be used to refer to means-tested cash benefits, especially the Aid to Families with Dependent Children (AFDC) program and its successor, the Temporary Assistance for Needy Families Block Grant, or it can be used to refer to all means-tested programs that help individuals or families meet basic needs, including, for example, health care through Medicaid, Supplemental Security Income (SSI) benefits and food and nutrition programs (SNAP). It can also include Social Insurance programs such as Unemployment Insurance, Social Security, and Medicare.</p><p>AFDC (originally called Aid to Dependent Children) was created during the Great Depression to alleviate the burden of poverty for families with children and allow widowed mothers to maintain their households. The New Deal employment program such as the Works Progress Administration primarily served men. Prior to the New Deal, anti-poverty programs were primarily operated by private charities or state or local governments; however, these programs were overwhelmed by the depth of need during the Depression.[36] The United States has no national program of cash assistance for non-disabled poor individuals who are not raising children.</p><p>Race is brought up constantly in policies as to categorize whether it is a Black or White issue and in welfare's history there's a switch in the way the public is educated through news media. Until early in the year of 1965, the news media was conveying only Whites as living in poverty however that perception had changed to Blacks.[37] Some of the influences in this shift could have been the civil rights movement and urban riots from the mid 60s. Welfare had then shifted from being a White issue to a Black issue and during this time frame the war on poverty had already begun.[37] Subsequently, news media portrayed stereotypes of Blacks as lazy, undeserving and welfare queens. These shifts in media don't necessarily establish the population living in poverty decreasing.[37]</p><div class='pageBreak' ></div><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/6/66/Welfare_Benefits_Payments_Graph.gif/250px-Welfare_Benefits_Payments_Graph.gif" width="250" height="129"><p>


A chart showing the overall decline of average monthly welfare benefits (AFDC then TANF) per recipient 1962–2006 (in 2006 dollars).[38]


</p><p>
	In 1996, the Personal Responsibility and Work Opportunity Reconciliation Act changed the structure of Welfare payments and added new criteria to states that received Welfare funding. After reforms, which President Clinton said would end Welfare as we know it,[39] amounts from the federal government were given out in a flat rate per state based on population.[40] Each state must meet certain criteria to ensure recipients are being encouraged to work themselves out of Welfare. The new program is called Temporary Assistance for Needy Families (TANF).[41][42] It encourages states to require some sort of employment search in exchange for providing funds to individuals, and imposes a five-year lifetime limit on cash assistance.[39][41][43] In FY 2010, 31.8% of TANF families were white, 31.9% were African-American, and 30.0% were Hispanic.[42]</p><p>According to the U.S. Census Bureau data released September 13, 2011, the nation's poverty rate rose to 15.1% (46.2 million) in 2010,[44] up from 14.3% (approximately 43.6 million) in 2009 and to its highest level since 1993. In 2008, 13.2% (39.8 million) Americans lived in relative poverty.[45]</p><p>In a 2011 op-ed in Forbes, Peter Ferrara stated that, The best estimate of the cost of the 185 federal means tested Welfare programs for 2010 for the federal government alone is nearly $700 billion, up a third since 2008, according to the Heritage Foundation. Counting state spending, total Welfare spending for 2010 reached nearly $900 billion, up nearly one-fourth since 2008 (24.3%).[46] California, with 12% of the U.S. population, has one-third of the nation's welfare recipients.[47]</p><p>In FY 2011, federal spending on means-tested welfare, plus state contributions to federal programs, reached $927 billion per year. Roughly half of this welfare assistance, or $462 billion went to families with children, most of which are headed by single parents.[48]</p><p>The United States has also typically relied on charitable giving through non-profit agencies and fundraising instead of direct monetary assistance from the government itself. According to Giving USA, Americans gave $358.38 billion to charity in 2014. This is rewarded by the United States government through tax incentives for individuals and companies that are not typically seen in other countries.</p><h2>Criticism</h2><p> Main article: Criticisms of welfare</p><p>Income transfers can be either conditional or unconditional. Conditionalities are sometimes criticised as being paternalistic and unnecessary.</p><p>Current programs have been built as short-term rather than as permanent institutions, and many of them have rather short time spans (around five years). Some programs have time frames that reflect available funding. One example of this is Bolivia’s Bonosol, which is financed by proceeds from the privatization of utilities—an unsustainable funding source. Some see Latin America’s social assistance programs as a way to patch up high levels of poverty and inequalities, partly brought on by the current economic system.</p><p>Some opponents of welfare argue that it affects work incentives. They also argue that the taxes levied can also affect work incentives. A good example of this would be the reform of the Aid to Families with Dependent Children (AFDC) program. Per AFDC, some amount per recipient is guaranteed. However, for every dollar the recipient earns the monthly stipend is decreased by an equivalent amount. For most persons, this reduces their incentive to work. This program was replaced by Temporary Aid to Needy Families (TANF). Under TANF, people were required to actively seek employment while receiving aid and they could only receive aid for a limited amount of time. However, states can choose the amount of resources they will devote to the program.</p><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Welfare&amp;oldid=783361522"					
				Categories:  Hidden categories:</p><br><h1 lang="en">Regional science</h1><p> From Wikipedia, the free encyclopedia</p><p>Regional science is a field of the social sciences concerned with analytical approaches to problems that are specifically urban, rural, or regional. Topics in regional science include, but are not limited to location theory or spatial economics, location modeling, transportation, migration analysis, land use and urban development, interindustry analysis, environmental and ecological analysis, resource management, urban and regional policy analysis, geographical information systems, and spatial data analysis. In the broadest sense, any social science analysis that has a spatial dimension is embraced by regional scientists.</p><h2>Contents</h2><h2>Origins</h2><p>Regional science was founded in the late 1940s when some economists began to become dissatisfied with the low level of regional economic analysis and felt an urge to upgrade it. But even in this early era, the founders of regional science expected to catch the interest of people from a wide variety of disciplines. Regional science's formal roots date to the aggressive campaigns by Walter Isard and his supporters to promote the objective and scientific analysis of settlement, industrial location, and urban development. Isard targeted key universities and campaigned tirelessly. Accordingly, the Regional Science Association was founded in 1954, when the core group of scholars and practitioners held its first meetings independent from those initially held as sessions of the annual meetings of the American Economics Association.[1] A reason for meeting independently undoubtedly was the group's desire to extend the new science beyond the rather restrictive world of economists and have natural scientists, psychologists, anthropologists, lawyers, sociologists, political scientists, planners, and geographers join the club.[2] Now called the Regional Science Association International (RSAI), it maintains subnational and international associations, journals, and a conference circuit (notably in North America, continental Europe, Japan, and South Korea). Membership in the RSAI continues to grow.</p><h2>Seminal publications</h2><p>Topically speaking, regional science took off in the wake of Walter Christaller's book Die Zentralen Orte in Suddeutschland (Verlag von Gustav Fischer, Jena, 1933; transl. Central Places in Southern Germany, 1966), soon followed by Tord Palander's (1935) Beiträge zur Standortstheorie; August Lösch's Die räumliche Ordnung der Wirtschaft (Verlag von Gustav Fischer, Jena, 1940; 2nd rev. edit., 1944; transl. The Economics of Location, 1954)&nbsp;; and Edgar M. Hoover's two books--Location Theory and the Shoe and Leather Industry (1938) and The Location of Economic Activity (1948). Other important early publications include: Edward H. Chamberlin's (1950) The Theory of Monopolistic Competition&nbsp;; François Perroux's (1950) Economic Spaces: Theory and Application; Torsten Hägerstrand's (1953) Innovationsförloppet ur Korologisk Synpunkt; Edgar S. Dunn's (1954)The Location of Agricultural Production&nbsp;; Martin J. Beckmann, C.B McGuire, and Clifford B. Winston's (1956) Studies in the Economics of Transportation; Melvin L. Greenhut's (1956) Plant Location in Theory and Practice; Gunnar Myrdal's (1957) Economic Theory and Underdeveloped Regions; Albert O. Hirschman's (1958) The Strategy of Economic Development; and Claude Ponsard's (1958) Histoire des Théories Économiques Spatiales. Nonetheless, Walter Isard's first book in 1956, Location and Space Economy, apparently captured the imagination of many, and his third, Methods of Regional Analysis, published in 1960, only sealed his position as the father of the field.</p><div class='pageBreak' ></div><p>As is typically the case, the above works were built on the shoulders of giants. Much of this predecessor work is documented well in Walter Isard's Location and Space Economy[3] as well as Claude Ponsard's Histoire des Théorie Économique Spatiales.[4] Particularly important was the contribution by 19th century German economists to location theory. The early German hegemony more or less starts with Johann Heinrich von Thünen and runs through both Wilhelm Launhardt and Alfred Weber to Walter Christaller and August Lösch.</p><h2>Core journals</h2><p>If an academic discipline is identified by its journals, then technically regional science began in 1955 with the publication of the first volume of the Papers and Proceedings, Regional Science Association (now Papers in Regional Science published by Springer). In 1958, the Journal of Regional Science followed. Since the 1970s, the number of journals serving the field has exploded. The RSAI website displays most of them.</p><p>Most recently the journal Spatial Economic Analysis has been published by the RSAI British and Irish Section with the Regional Studies Association. The latter is a separate and growing organisation involving economists, planners, geographers, political scientists, management academics, policymakers, and practitioners.[5]</p><h2>Academic programs</h2><p>Walter Isard's efforts culminated in the creation of a few academic departments and several university-wide programs in regional science. At Walter Isard's suggestion, the University of Pennsylvania started the Regional Science Department in 1956. It featured as its first graduate William Alonso and was looked upon by many to be the international academic leader for the field. Another important graduate and faculty member of the department is Masahisa Fujita. The core curriculum of this department was microeconomics, input-output analysis, location theory, and statistics. Faculty also taught courses in mathematical programming, transportation economics, labor economics, energy and ecological policy modeling, spatial statistics, spatial interaction theory and models, benefit/cost analysis, urban and regional analysis, and economic development theory, among others. But the department's unusual multidisciplinary orientation undoubtedly encouraged its demise, and it lost its department status in 1993.[6]</p><p>With a few exceptions, such as Cornell University, which awards graduate degrees in Regional Science,[7] most practitioners hold positions in departments such as economics, geography, civil engineering, agricultural economics, rural sociology, urban planning, public policy, or demography. The diversity of disciplines participating in regional science have helped make it one of the most interesting and fruitful fields of academic specialization, but it has also made it difficult to fit the many perspectives into a curriculum for an academic major. It is even difficult for authors to write regional science textbooks, since what is elementary knowledge for one discipline might be entirely novel for another.[8]</p><h2>Public policy impact</h2><p>Part of the movement was, and continues to be, associated with the political and economic realities of the role of the local community. On any occasion where public policy is directed at the sub-national level, such as a city or group of counties, the methods of regional science can prove useful. Traditionally, regional science has provided policymakers with guidance on the following issues:[9]</p><p>By targeting federal resources to specific geographic areas the Kennedy administration realized that political favors could be bought. This is also evident in Europe and other places where local economic areas do not coincide with political boundaries. In the more current era of devolution knowledge about local solutions to local problems has driven much of the interest in regional science. Thus, there has been much political impetus to the growth of the discipline.</p><h2>Developments after 1980</h2><p>Regional science has enjoyed mixed fortunes since the 1980s. While it has gained a larger following among economists and public policy practitioners, the discipline has fallen out of favor among more radical and post-modernist geographers. In an apparent effort to secure a larger share of research funds, geographers had the National Science Foundation's Geography and Regional Science Program renamed Geography and Spatial Sciences.</p><h3>New economic geography</h3><p>In 1991, Paul Krugman, as a highly regarded international trade theorist, put out a call for economists to pay more attention to economic geography in a book entitled Geography and Trade, focusing largely on the core regional science concept of agglomeration economies. Krugman's call renewed interest by economists in regional science and, perhaps more importantly, founded what some term the new economic geography, which enjoys much common ground with regional science. Broadly trained new economic geographers combine quantitative work with other research techniques, for example at the London School of Economics. The unification of Europe and the increased internationalization of the world's economic, social, and political realms has further induced interest in the study of regional, as opposed to national, phenomena. The new economic geography appears to have garnered more interest in Europe than in America where amenities, notably climate, have been found to better predict human location and re-location patterns, as emphasized in recent work by Mark Partridge.[10] In 2008 Krugman won the Nobel Memorial Prize in Economic Sciences and his Prize Lecture has references both to work in regional science's location theory as well as economic's trade theory.[11]</p><h3>Criticisms</h3><p>Today there are dwindling numbers of regional scientists from academic planning programs and mainstream geography departments. Attacks on regional science's practitioners by radical critics began as early as the 1970s, notably David Harvey who believed it lacked social and political commitment. Regional science's founder, Walter Isard, never envisioned regional scientists would be political or planning activists. In fact, he suggested that they will seek to be sitting in front of a computer and surrounded by research assistants. Trevor J. Barnes suggests the decline of regional science practice among planners and geographers in North America could have been avoided. He says It is unreflective, and consequently inured to change, because of a commitment to a God’s eye view. It is so convinced of its own rightness, of its Archimedean position, that it remained aloof and invariant, rather than being sensitive to its changing local context. [12]</p><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Regional_science&amp;oldid=777035392"					
				Categories:  Hidden categories:</p><br><br><img alt="Permanently protected page" src="http://upload.wikimedia.org/wikipedia/commons/thumb/f/fc/Padlock-silver.svg/20px-Padlock-silver.svg.png" width="20" height="20"><h1 lang="en">Help:IPA for English</h1><div class='pageBreak' ></div><p> From Wikipedia, the free encyclopedia</p><p>Throughout Wikipedia, the pronunciation of words is indicated by means of the International Phonetic Alphabet (IPA). The following tables list the IPA symbols used for English words and pronunciations. Please note that several of these symbols are used in ways that are specific to Wikipedia and differ from those used by dictionaries.</p><p>If the IPA symbols are not displayed properly by your browser, see the links below.</p><p>If you are adding a pronunciation using this key, such pronunciations should generally be formatted using the template {{IPAc-en}}. The template provides tooltips for each symbol in the pronunciation. See the template page for instructions.</p><h2>Key</h2><p>If the words given as examples for two different symbols sound the same to you (for example, if you pronounce cot and caught the same, or do and dew, or marry and merry), you can pronounce those symbols the same in explanations of all words. The footnotes explain some of these mergers. ( Dialect variation below.)</p><p>If there is an IPA symbol you are looking for that you do not see here, see Help:IPA, which is a more complete list. For a table listing all spellings of the sounds on this page, see English orthography §&nbsp;Sound-to-spelling correspondences. For help converting spelling to pronunciation, see English orthography §&nbsp;Spelling-to-sound correspondences.</p><p>Notes</p><h2>Dialect variation</h2><p> Main article: International Phonetic Alphabet chart for English dialects</p><p>This key represents diaphonemes, abstractions of speech sounds that accommodate General American (GenAm), Received Pronunciation (RP), Canadian English, South African, Australian, and New Zealand pronunciations. Therefore, not all of the distinctions shown here are relevant to a particular dialect:</p><p>On the other hand, there are some distinctions which you might make but which this key does not encode, as they are seldom reflected in the dictionaries used as sources for Wikipedia articles:</p><p>Other words may have different vowels depending on the speaker.</p><p>The pronunciation of the /æ/ vowel in most dialects of Scotland, Northern Ireland, northern England and Wales has always been closer to [a]. BBC English has moved away from the traditional near-open front realization [æ] towards almost fully open front realization [a], and both the Oxford English Dictionary and the 2014 edition of Gimson's Pronunciation of English transcribe the vowel in lad, bad, cat, trap with /a/.[33]</p><p>For more extensive information on dialect variations, you may wish to see the IPA chart for English dialects.</p><p>Note that place names are not generally exempted from being transcribed in this abstracted system, so rules such as the above must be applied in order to recover the local pronunciation. Examples include place names in much of England ending -ford, which although locally pronounced [-f?d] are transcribed /-f?rd/. This is best practice for editors. However, readers should be aware that not all editors may have followed this consistently, so for example if /-f?d/ is encountered for such a place name, it should not be interpreted as a claim that the /r/ would be absent even in a rhotic dialect.</p><h2>Other transcriptions</h2><p>If you feel it is necessary to add a pronunciation respelling using another convention, then please use the conventions of Wikipedia's pronunciation respelling key.</p><h2>Notes</h2><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Help:IPA_for_English&amp;oldid=784078373"					
				Categories:  Hidden categories:</p><br><br><img alt="Permanently protected page" src="http://upload.wikimedia.org/wikipedia/commons/thumb/f/fc/Padlock-silver.svg/20px-Padlock-silver.svg.png" width="20" height="20"><h1 lang="en">Help:IPA for English</h1><p> From Wikipedia, the free encyclopedia</p><p>Throughout Wikipedia, the pronunciation of words is indicated by means of the International Phonetic Alphabet (IPA). The following tables list the IPA symbols used for English words and pronunciations. Please note that several of these symbols are used in ways that are specific to Wikipedia and differ from those used by dictionaries.</p><p>If the IPA symbols are not displayed properly by your browser, see the links below.</p><p>If you are adding a pronunciation using this key, such pronunciations should generally be formatted using the template {{IPAc-en}}. The template provides tooltips for each symbol in the pronunciation. See the template page for instructions.</p><h2>Key</h2><p>If the words given as examples for two different symbols sound the same to you (for example, if you pronounce cot and caught the same, or do and dew, or marry and merry), you can pronounce those symbols the same in explanations of all words. The footnotes explain some of these mergers. ( Dialect variation below.)</p><p>If there is an IPA symbol you are looking for that you do not see here, see Help:IPA, which is a more complete list. For a table listing all spellings of the sounds on this page, see English orthography §&nbsp;Sound-to-spelling correspondences. For help converting spelling to pronunciation, see English orthography §&nbsp;Spelling-to-sound correspondences.</p><p>Notes</p><h2>Dialect variation</h2><p> Main article: International Phonetic Alphabet chart for English dialects</p><p>This key represents diaphonemes, abstractions of speech sounds that accommodate General American (GenAm), Received Pronunciation (RP), Canadian English, South African, Australian, and New Zealand pronunciations. Therefore, not all of the distinctions shown here are relevant to a particular dialect:</p><div class='pageBreak' ></div><p>On the other hand, there are some distinctions which you might make but which this key does not encode, as they are seldom reflected in the dictionaries used as sources for Wikipedia articles:</p><p>Other words may have different vowels depending on the speaker.</p><p>The pronunciation of the /æ/ vowel in most dialects of Scotland, Northern Ireland, northern England and Wales has always been closer to [a]. BBC English has moved away from the traditional near-open front realization [æ] towards almost fully open front realization [a], and both the Oxford English Dictionary and the 2014 edition of Gimson's Pronunciation of English transcribe the vowel in lad, bad, cat, trap with /a/.[33]</p><p>For more extensive information on dialect variations, you may wish to see the IPA chart for English dialects.</p><p>Note that place names are not generally exempted from being transcribed in this abstracted system, so rules such as the above must be applied in order to recover the local pronunciation. Examples include place names in much of England ending -ford, which although locally pronounced [-f?d] are transcribed /-f?rd/. This is best practice for editors. However, readers should be aware that not all editors may have followed this consistently, so for example if /-f?d/ is encountered for such a place name, it should not be interpreted as a claim that the /r/ would be absent even in a rhotic dialect.</p><h2>Other transcriptions</h2><p>If you feel it is necessary to add a pronunciation respelling using another convention, then please use the conventions of Wikipedia's pronunciation respelling key.</p><h2>Notes</h2><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Help:IPA_for_English&amp;oldid=784078373"					
				Categories:  Hidden categories:</p><br><br><img alt="Permanently protected page" src="http://upload.wikimedia.org/wikipedia/commons/thumb/f/fc/Padlock-silver.svg/20px-Padlock-silver.svg.png" width="20" height="20"><h1 lang="en">Help:IPA for English</h1><p> From Wikipedia, the free encyclopedia</p><p>Throughout Wikipedia, the pronunciation of words is indicated by means of the International Phonetic Alphabet (IPA). The following tables list the IPA symbols used for English words and pronunciations. Please note that several of these symbols are used in ways that are specific to Wikipedia and differ from those used by dictionaries.</p><p>If the IPA symbols are not displayed properly by your browser, see the links below.</p><p>If you are adding a pronunciation using this key, such pronunciations should generally be formatted using the template {{IPAc-en}}. The template provides tooltips for each symbol in the pronunciation. See the template page for instructions.</p><h2>Key</h2><p>If the words given as examples for two different symbols sound the same to you (for example, if you pronounce cot and caught the same, or do and dew, or marry and merry), you can pronounce those symbols the same in explanations of all words. The footnotes explain some of these mergers. ( Dialect variation below.)</p><p>If there is an IPA symbol you are looking for that you do not see here, see Help:IPA, which is a more complete list. For a table listing all spellings of the sounds on this page, see English orthography §&nbsp;Sound-to-spelling correspondences. For help converting spelling to pronunciation, see English orthography §&nbsp;Spelling-to-sound correspondences.</p><p>Notes</p><h2>Dialect variation</h2><p> Main article: International Phonetic Alphabet chart for English dialects</p><p>This key represents diaphonemes, abstractions of speech sounds that accommodate General American (GenAm), Received Pronunciation (RP), Canadian English, South African, Australian, and New Zealand pronunciations. Therefore, not all of the distinctions shown here are relevant to a particular dialect:</p><p>On the other hand, there are some distinctions which you might make but which this key does not encode, as they are seldom reflected in the dictionaries used as sources for Wikipedia articles:</p><p>Other words may have different vowels depending on the speaker.</p><p>The pronunciation of the /æ/ vowel in most dialects of Scotland, Northern Ireland, northern England and Wales has always been closer to [a]. BBC English has moved away from the traditional near-open front realization [æ] towards almost fully open front realization [a], and both the Oxford English Dictionary and the 2014 edition of Gimson's Pronunciation of English transcribe the vowel in lad, bad, cat, trap with /a/.[33]</p><p>For more extensive information on dialect variations, you may wish to see the IPA chart for English dialects.</p><p>Note that place names are not generally exempted from being transcribed in this abstracted system, so rules such as the above must be applied in order to recover the local pronunciation. Examples include place names in much of England ending -ford, which although locally pronounced [-f?d] are transcribed /-f?rd/. This is best practice for editors. However, readers should be aware that not all editors may have followed this consistently, so for example if /-f?d/ is encountered for such a place name, it should not be interpreted as a claim that the /r/ would be absent even in a rhotic dialect.</p><h2>Other transcriptions</h2><p>If you feel it is necessary to add a pronunciation respelling using another convention, then please use the conventions of Wikipedia's pronunciation respelling key.</p><h2>Notes</h2><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Help:IPA_for_English&amp;oldid=784078373"					
				Categories:  Hidden categories:</p><br><h1 lang="en">Production (economics)</h1><p> From Wikipedia, the free encyclopedia</p><p>Production is a process of workers combining various material inputs and immaterial inputs (plans, know-how) in order to make something for consumption (the output). It is the act of creating output, a good or service which has value and contributes to the utility of individuals.[1]</p><div class='pageBreak' ></div><p>Economic well-being is created in a production process, meaning all economic activities that aim directly or indirectly to satisfy human wants and needs. The degree to which the needs are satisfied is often accepted as a measure of economic well-being. In production there are two features which explain increasing economic well-being. They are improving quality-price-ratio of goods and services and increasing incomes from growing and more efficient market production.</p><p>The most important forms of production are</p><p>In order to understand the origin of the economic well-being we must understand these three production processes. All of them produce commodities which have value and contribute to well-being of individuals.</p><p>The satisfaction of needs originates from the use of the commodities which are produced. The need satisfaction increases when the quality-price-ratio of the commodities improves and more satisfaction is achieved at less cost. Improving the quality-price-ratio of commodities is to a producer an essential way to improve the competitiveness of products but this kind of gains distributed to customers cannot be measured with production data. Improving the competitiveness of products means often to the producer lower product prices and therefore losses in incomes which are to compensated with the growth of sales volume.</p><p>Economic well-being also increases due to the growth of incomes that are gained from the growing and more efficient market production. Market production is the only production form which creates and distributes incomes to stakeholders. Public production and household production are financed by the incomes generated in market production. Thus market production has a double role in creating well-being, i.e. the role of producing goods and services and the role of creating income. Because of this double role market production is the “primus motor” of economic well-being and therefore here under review.[citation needed]</p><h2>Contents</h2><h2>As a source of economic well-being</h2><p>In principle there are two main activities in an economy, production and consumption. Similarly there are two kinds of actors, producers and consumers. Well-being is made possible by efficient production and by the interaction between producers and consumers. In the interaction, consumers can be identified in two roles both of which generate well-being. Consumers can be both customers of the producers and suppliers to the producers. The customers’ well-being arises from the commodities they are buying and the suppliers’ well-being is related to the income they receive as compensation for the production inputs they have delivered to the producers.</p><h3>Stakeholders of production</h3><p>Stakeholders of production are persons, groups or organizations with an interest in a producing company. Economic well-being originates in efficient production and it is distributed through the interaction between the company’s stakeholders. The stakeholders of companies are economic actors which have an economic interest in a company. Based on the similarities of their interests, stakeholders can be classified into three groups in order to differentiate their interests and mutual relations. The three groups are as follows:</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/0/02/Interactive_contributions_of_a_company%E2%80%99s_stakeholders.png/400px-Interactive_contributions_of_a_company%E2%80%99s_stakeholders.png" width="400" height="199"><p>


Interactive contributions of a company’s stakeholders (Saari, 2011,4)


 
</p><p>
	The interests of these stakeholders and their relations to companies are described briefly below. Our purpose is to establish a framework for further analysis.</p><p>Customers</p><p>The customers of a company are typically consumers, other market producers or producers in the public sector. Each of them has their individual production functions. Due to competition, the price-quality-ratios of commodities tend to improve and this brings the benefits of better productivity to customers. Customers get more for less. In households and the public sector this means that more need satisfaction is achieved at less cost. For this reason the productivity of customers can increase over time even though their incomes remain unchanged.</p><p>Suppliers</p><p>The suppliers of companies are typically producers of materials, energy, capital, and services. They all have their individual production functions. The changes in prices or qualities of supplied commodities have an effect on both actors’ (company and suppliers) production functions. We come to the conclusion that the production functions of the company and its suppliers are in a state of continuous change.</p><p>Producer community</p><p>The incomes are generated for those participating in production, i.e., the labour force, society and owners. These stakeholders are referred to here as producer communities or, in shorter form, as producers. The producer communities have a common interest in maximizing their incomes. These parties that contribute to production receive increased incomes from the growing and developing production.</p><p>The well-being gained through commodities stems from the price-quality relations of the commodities. Due to competition and development in the market, the price-quality relations of commodities tend to improve over time. Typically the quality of a commodity goes up and the price goes down over time. This development favourably affects the production functions of customers. Customers get more for less. Consumer customers get more satisfaction at less cost. This type of well-being generation can only partially be calculated from the production data. The situation is presented in this study. The producer community (labour force, society, and owners) earns income as compensation for the inputs they have delivered to the production. When the production grows and becomes more efficient, the income tends to increase. In production this brings about an increased ability to pay salaries, taxes and profits. The growth of production and improved productivity generate additional income for the producing community. Similarly the high income level achieved in the community is a result of the high volume of production and its good performance. This type of well-being generation – as mentioned earlier - can be reliably calculated from the production data.</p><h3>Main processes of a producing company</h3><p>A producing company can be divided into sub-processes in different ways; yet, the following five are identified as main processes, each with a logic, objectives, theory and key figures of its own. It is important to examine each of them individually, yet, as a part of the whole, in order to be able to measure and understand them. The main processes of a company are as follows:</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/3/37/Main_processes_of_a_company.png/400px-Main_processes_of_a_company.png" width="400" height="223"><div class='pageBreak' ></div><p>


Main processes of a producing company (Saari 2006,3)


 
</p><p>
	Production output is created in the real process, gains of production are distributed in the income distribution process and these two processes constitute the production process. The production process and its sub-processes, the real process and income distribution process occur simultaneously, and only the production process is identifiable and measurable by the traditional accounting practices. The real process and income distribution process can be identified and measured by extra calculation, and this is why they need to be analyzed separately in order to understand the logic of production and its performance.</p><p>Real process generates the production output from input, and it can be described by means of the production function. It refers to a series of events in production in which production inputs of different quality and quantity are combined into products of different quality and quantity. Products can be physical goods, immaterial services and most often combinations of both. The characteristics created into the product by the producer imply surplus value to the consumer, and on the basis of the market price this value is shared by the consumer and the producer in the marketplace. This is the mechanism through which surplus value originates to the consumer and the producer likewise. It is worth noting that surplus values to customers cannot be measured from any production data. Instead the surplus value to a producer can be measured. It can be expressed both in terms of nominal and real values. The real surplus value to the producer is an outcome of the real process, real income, and measured proportionally it means productivity.</p><p>The concept “real process” in the meaning quantitative structure of production process was introduced in Finnish management accounting in 1960´s. Since then it has been a cornerstone in the Finnish management accounting theory. (Riistama et al. 1971)</p><p>Income distribution process of the production refers to a series of events in which the unit prices of constant-quality products and inputs alter causing a change in income distribution among those participating in the exchange. The magnitude of the change in income distribution is directly proportionate to the change in prices of the output and inputs and to their quantities. Productivity gains are distributed, for example, to customers as lower product sales prices or to staff as higher income pay.</p><p>The production process consists of the real process and the income distribution process. A result and a criterion of success of the owner is profitability. The profitability of production is the share of the real process result the owner has been able to keep to himself in the income distribution process. Factors describing the production process are the components of profitability, i.e., returns and costs. They differ from the factors of the real process in that the components of profitability are given at nominal prices whereas in the real process the factors are at periodically fixed prices.</p><p>Monetary process refers to events related to financing the business. Market value process refers to a series of events in which investors determine the market value of the company in the investment markets.</p><h3>Production growth and performance</h3><p> Main article: Economic growth</p><p>Economic growth is often defined as a production increase of an output of a production process. It is usually expressed as a growth percentage depicting growth of the real production output. The real output is the real value of products produced in a production process and when we subtract the real input from the real output we get the real income. The real output and the real income are generated by the real process of production from the real inputs.</p><p>The real process can be described by means of the production function. The production function is a graphical or mathematical expression showing the relationship between the inputs used in production and the output achieved. Both graphical and mathematical expressions are presented and demonstrated. The production function is a simple description of the mechanism of income generation in production process. It consists of two components. These components are a change in production input and a change in productivity.[2]</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/0/00/Components_of_economic_growth.png/300px-Components_of_economic_growth.png" width="300" height="224"><p>


Components of economic growth (Saari 2006,2)


</p><p>
	The figure illustrates an income generation process(exaggerated for clarity). The Value T2 (value at time 2) represents the growth in output from Value T1 (value at time 1). Each time of measurement has its own graph of the production function for that time (the straight lines). The output measured at time 2 is greater than the output measured at time one for both of the components of growth: an increase of inputs and an increase of productivity. The portion of growth caused by the increase in inputs is shown on line 1 and does not change the relation between inputs and outputs. The portion of growth caused by an increase in productivity is shown on line 2 with a steeper slope. So increased productivity represents greater output per unit of input.</p><p>The growth of production output does not reveal anything about the performance of the production process. The performance of production measures production’s ability to generate income. Because the income from production is generated in the real process, we call it the real income. Similarly, as the production function is an expression of the real process, we could also call it “income generated by the production function”.</p><p>The real income generation follows the logic of the production function. Two components can also be distinguished in the income change: the income growth caused by an increase in production input (production volume) and the income growth caused by an increase in productivity. The income growth caused by increased production volume is determined by moving along the production function graph. The income growth corresponding to a shift of the production function is generated by the increase in productivity. The change of real income so signifies a move from the point 1 to the point 2 on the production function (above). When we want to maximize the production performance we have to maximize the income generated by the production function.</p><p>The sources of productivity growth and production volume growth are explained as follows. Productivity growth is seen as the key economic indicator of innovation. The successful introduction of new products and new or altered processes, organization structures, systems, and business models generates growth of output that exceeds the growth of inputs. This results in growth in productivity or output per unit of input. Income growth can also take place without innovation through replication of established technologies. With only replication and without innovation, output will increase in proportion to inputs. (Jorgenson et al. 2014,2) This is the case of income growth through production volume growth.</p><div class='pageBreak' ></div><p>Jorgenson et al. (2014,2) give an empiric example. They show that the great preponderance of economic growth in the US since 1947 involves the replication of existing technologies through investment in equipment, structures, and software and expansion of the labor force. Further they show that innovation accounts for only about twenty percent of US economic growth.</p><p>In the case of a single production process (described above) the output is defined as an economic value of products and services produced in the process. When we want to examine an entity of many production processes we have to sum up the value-added created in the single processes. This is done in order to avoid the double accounting of intermediate inputs. Value-added is obtained by subtracting the intermediate inputs from the outputs. The most well-known and used measure of value-added is the GDP (Gross Domestic Product). It is widely used as a measure of the economic growth of nations and industries.</p><h3>Absolute (total) and average income</h3><p>The production performance can be measured as an average or an absolute income. Expressing performance both in average (avg.) and absolute (abs.) quantities is helpful for understanding the welfare effects of production. For measurement of the average production performance, we use the known productivity ratio</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/f/f7/Average_and_marginal_productivity.png/400px-Average_and_marginal_productivity.png" width="400" height="267"><p>


Average and marginal productivity (Saari 2011,8)


 
</p><p>
	The absolute income of performance is obtained by subtracting the real input from the real output as follows:</p><p>The growth of the real income is the increase of the economic value which can be distributed between the production stakeholders. With the aid of the production model we can perform the average and absolute accounting in one calculation. Maximizing production performance requires using the absolute measure, i.e. the real income and its derivatives as a criterion of production performance.</p><p>The differences between the absolute and average performance measures can be illustrated by the following graph showing marginal and average productivity. The figure is a traditional expression of average productivity and marginal productivity. The maximum for production performance is achieved at the volume where marginal productivity is zero. The maximum for production performance is the maximum of the real incomes. In this illustrative example the maximum real income is achieved, when the production volume is 7.5 units. The maximum average productivity is reached when the production volume is 3.0 units. It is worth noting that the maximum average productivity is not the same as the maximum of real income.</p><p>Figure above is a somewhat exaggerated depiction because the whole production function is shown. In practice, decisions are made in a limited range of the production functions, but the principle is still the same; the maximum real income is aimed for. An important conclusion can be drawn. When we try to maximize the welfare effects of production we have to maximize real income formation. Maximizing productivity leads to a suboptimum, i.e. to losses of incomes.</p><p>Maximizing productivity also leads to the phenomenon called jobless growth This refers to economic growth as a result of productivity growth but without creation of new jobs and new incomes from them. A practical example illustrates the case. When a jobless person obtains a job in market production we may assume it is a low productivity job. As a result, average productivity decreases but the real income per capita increases. Furthermore, the well-being of the society also grows. This example reveals the difficulty to interpret the total productivity change correctly. The combination of volume increase and total productivity decrease leads in this case to the improved performance because we are on the “diminishing returns” area of the production function. If we are on the part of “increasing returns” on the production function, the combination of production volume increase and total productivity increase leads to improved production performance. Unfortunately we do not know in practice on which part of the production function we are. Therefore, a correct interpretation of a performance change is obtained only by measuring the real income change.</p><h2>Production models</h2><p>A production model is a numerical description of the production process and is based on the prices and the quantities of inputs and outputs. There are two main approaches to operationalize the concept of production function. We can use mathematical formulae, which are typically used in macroeconomics (in growth accounting) or arithmetical models, which are typically used in microeconomics and management accounting. We do not present the former approach here but refer to the survey “Growth accounting” by Hulten 2009.</p><p>We use here arithmetical models because they are like the models of management accounting, illustrative and easily understood and applied in practice. Furthermore, they are integrated to management accounting, which is a practical advantage. A major advantage of the arithmetical model is its capability to depict production function as a part of production process. Consequently, production function can be understood, measured, and examined as a part of production process.</p><p>There are different production models according to different interests. Here we use a production income model and a production analysis model in order to demonstrate production function as a phenomenon and a measureable quantity.</p><h3>Production income model</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/0/0f/Profitability_of_production_measured_by_surplus_value.png/400px-Profitability_of_production_measured_by_surplus_value.png" width="400" height="245"><p>


Profitability of production measured by surplus value (Saari 2006,3)


</p><p>
	The scale of success run by a going concern is manifold, and there are no criteria that might be universally applicable to success. Nevertheless, there is one criterion by which we can generalise the rate of success in production. This criterion is the ability to produce surplus value. As a criterion of profitability, surplus value refers to the difference between returns and costs, taking into consideration the costs of equity in addition to the costs included in the profit and loss statement as usual. Surplus value indicates that the output has more value than the sacrifice made for it, in other words, the output value is higher than the value (production costs) of the used inputs. If the surplus value is positive, the owner’s profit expectation has been surpassed.</p><div class='pageBreak' ></div><p>The table presents a surplus value calculation. We call this set of production data a basic example and we use the data through the article in illustrative production models. The basic example is a simplified profitability calculation used for illustration and modelling. Even as reduced, it comprises all phenomena of a real measuring situation and most importantly the change in the output-input mix between two periods. Hence, the basic example works as an illustrative “scale model” of production without any features of a real measuring situation being lost. In practice, there may be hundreds of products and inputs but the logic of measuring does not differ from that presented in the basic example.</p><p>In this context we define the quality requirements for the production data used in productivity accounting. The most important criterion of good measurement is the homogenous quality of the measurement object. If the object is not homogenous, then the measurement result may include changes in both quantity and quality but their respective shares will remain unclear. In productivity accounting this criterion requires that every item of output and input must appear in accounting as being homogenous. In other words, the inputs and the outputs are not allowed to be aggregated in measuring and accounting. If they are aggregated, they are no longer homogenous and hence the measurement results may be biased.</p><p>Both the absolute and relative surplus value have been calculated in the example. Absolute value is the difference of the output and input values and the relative value is their relation, respectively. The surplus value calculation in the example is at a nominal price, calculated at the market price of each period.</p><h3>Production analysis model</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/e/e2/Productivity_model.png/350px-Productivity_model.png" width="350" height="459"><p>


Production Model Saari 2004 (Saari 2006,4)


</p><p>
	A model [3] used here is a typical production analysis model by help of which it is possible to calculate the outcome of the real process, income distribution process and production process. The starting point is a profitability calculation using surplus value as a criterion of profitability. The surplus value calculation is the only valid measure for understanding the connection between profitability and productivity or understanding the connection between real process and production process. A valid measurement of total productivity necessitates considering all production inputs, and the surplus value calculation is the only calculation to conform to the requirement. If we omit an input in productivity or income accounting, this means that the omitted input can be used unlimitedly in production without any cost impact on accounting results.</p><h3>Accounting and interpreting</h3><p>The process of calculating is best understood by applying the term ceteris paribus, i.e. all other things being the same, stating that at a time only the impact of one changing factor be introduced to the phenomenon being examined. Therefore, the calculation can be presented as a process advancing step by step. First, the impacts of the income distribution process are calculated, and then, the impacts of the real process on the profitability of the production.</p><p>The first step of the calculation is to separate the impacts of the real process and the income distribution process, respectively, from the change in profitability (285.12&nbsp;– 266.00 = 19.12). This takes place by simply creating one auxiliary column (4) in which a surplus value calculation is compiled using the quantities of Period 1 and the prices of Period 2. In the resulting profitability calculation, Columns 3 and 4 depict the impact of a change in income distribution process on the profitability and in Columns 4 and 7 the impact of a change in real process on the profitability.</p><p>The accounting results are easily interpreted and understood. We see that the real income has increased by 58.12 units from which 41.12 units come from the increase of productivity growth and the rest 17.00 units come from the production volume growth. The total increase of real income (58.12) is distributed to the stakeholders of production, in this case 39.00 units to the customers and to the suppliers of inputs and the rest 19.12 units to the owners.</p><p>Here we can make an important conclusion. Income formation of production is always a balance between income generation and income distribution. The income change created in a real process (i.e. by production function) is always distributed to the stakeholders as economic values within the review period. Accordingly, the changes in real income and income distribution are always equal in terms of economic value.</p><p>Based on the accounted changes of productivity and production volume values we can explicitly conclude on which part of the production function the production is. The rules of interpretations are the following:</p><p>The production is on the part of “increasing returns” on the production function, when</p><p>The production is on the part of “diminishing returns” on the production function, when</p><p>In the basic example the combination of volume growth (+17.00) and productivity growth (+41.12) reports explicitly that the production is on the part of “increasing returns” on the production function (Saari 2006 a, 138–144).</p><p>Another production model (Production Model Saari 1989) also gives details of the income distribution (Saari 2011,14). Because the accounting techniques of the two models are different, they give differing, although complementary, analytical information. The accounting results are, however, identical. We do not present the model here in detail but we only use its detailed data on income distribution, when the objective functions are formulated in the next section.</p><h2>Objective functions</h2><p>An efficient way to improve the understanding of production performance is to formulate different objective functions according to the objectives of the different interest groups. Formulating the objective function necessitates defining the variable to be maximized (or minimized). After that other variables are considered as constraints or free variables. The most familiar objective function is profit maximization which is also included in this case. Profit maximization is an objective function that stems from the owner’s interest and all other variables are constraints in relation to maximizing of profits.</p><div class='pageBreak' ></div><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/d/da/Income_formation.png/300px-Income_formation.png" width="300" height="152"><p>


Summary of objective function formulations (Saari 2011,17)


</p><h3>The procedure for formulating objective functions</h3><p>
	The procedure for formulating different objective functions, in terms of the production model, is introduced next. In the income formation from production the following objective functions can be identified:</p><p>These cases are illustrated using the numbers from the basic example. The following symbols are used in the presentation: The equal sign (=) signifies the starting point of the computation or the result of computing and the plus or minus sign (+ / -) signifies a variable that is to be added or subtracted from the function. A producer means here the producer community, i.e. labour force, society and owners.</p><p>Objective function formulations can be expressed in a single calculation which concisely illustrates the logic of the income generation, the income distribution and the variables to be maximized.</p><p>The calculation resembles an income statement starting with the income generation and ending with the income distribution. The income generation and the distribution are always in balance so that their amounts are equal. In this case it is 58.12 units. The income which has been generated in the real process is distributed to the stakeholders during the same period. There are three variables which can be maximized. They are the real income, the producer income and the owner income. Producer income and owner income are practical quantities because they are addable quantities and they can be computed quite easily. Real income is normally not an addable quantity and in many cases it is difficult to calculate.</p><h3>The dual approach for the formulation</h3><p>Here we have to add that the change of real income can also be computed from the changes in income distribution. We have to identify the unit price changes of outputs and inputs and calculate their profit impacts (i.e. unit price change x quantity). The change of real income is the sum of these profit impacts and the change of owner income. This approach is called the dual approach because the framework is seen in terms of prices instead of quantities (ONS 3, 23).</p><p>The dual approach has been recognized in growth accounting for long but its interpretation has remained unclear. The following question has remained unanswered: “Quantity based estimates of the residual are interpreted as a shift in the production function, but what is the interpretation of the price-based growth estimates?” (Hulten 2009, 18). We have demonstrated above that the real income change is achieved by quantitative changes in production and the income distribution change to the stakeholders is its dual. In this case the duality means that the same accounting result is obtained by accounting the change of the total income generation (real income) and by accounting the change of the total income distribution.</p><h2>Footnotes</h2><h2>Further references and external links</h2><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Production_(economics)&amp;oldid=776641833"					
				Categories:  Hidden categories:</p><br><h1 lang="en">Consumption (economics)</h1><p> From Wikipedia, the free encyclopedia</p><p>Consumption is major concept in economics and is also studied by many other social sciences. Economists are particularly interested in the relationship between consumption and income, as modeled with the consumption function.</p><p>Different schools of economists define production and consumption differently. According to mainstream economists, only the final purchase of goods and services by individuals constitutes consumption, while other types of expenditure — in particular, fixed investment, intermediate consumption, and government spending — are placed in separate categories (See consumer choice). Other economists define consumption much more broadly, as the aggregate of all economic activity that does not entail the design, production and marketing of goods and services (e.g. the selection, adoption, use, disposal and recycling of goods and services).[citation needed]</p><h2>Contents</h2><h2>Consumption function</h2><p> Main article: Consumption function</p><p>The consumption function is a mathematical function that expresses consumer spending in terms of its determinants, such as income and accumulated wealth.</p><h2>Behavioural economics and consumption</h2><p>The Keynesian consumption function is also known as the absolute income hypothesis, as it only bases consumption on current income and ignores potential future income (or lack of). Criticism of this assumption led to the development of Milton Friedman's permanent income hypothesis and Franco Modigliani's life cycle hypothesis. More recent theoretical approaches are based on behavioral economics and suggest that a number of behavioural principles can be taken as microeconomic foundations for a behaviourally-based aggregate consumption function.[1]</p><h2>Consumption and household production</h2><p>Consumption is defined in part by comparison to production. In the tradition of the Columbia School of Household Economics, also known as the New Home Economics, commercial consumption has to be analyzed in the context of household production. The opportunity cost of time affects the cost of home-produced substitutes and therefore demand for commercial goods and services.[2][3] The elasticity of demand for consumption goods is also a function of who performs chores in households and how their spouses compensate them for opportunity costs of home production.[4]</p><p>Different schools of economists define production and consumption differently. According to mainstream economists, only the final purchase of goods and services by individuals constitutes consumption, while other types of expenditure — in particular, fixed investment, intermediate consumption, and government spending — are placed in separate categories (See consumer choice). Other economists define consumption much more broadly, as the aggregate of all economic activity that does not entail the design, production and marketing of goods and services (e.g. the selection, adoption, use, disposal and recycling of goods and services).[citation needed]</p><div class='pageBreak' ></div><p>Consumption can also be measured by a variety of different ways such as energy in energy economics metrics.</p><h2>Effects of consumption</h2><p>Aggregate consumption is a component of aggregate demand.[5] According to the UN, today’s consumption is undermining the environmental resource base. It is exacerbating inequalities. And the dynamics of the consumption-poverty-inequality-environment nexus are accelerating. If the trends continue without change — not redistributing from high-income to low-income consumers, not shifting from polluting to cleaner goods and production technologies, not shifting priority from consumption for conspicuous display to meeting basic needs — today’s problems of consumption and human development will worsen. Developing countries like India, as they move down the path of copying the consumption patterns of developed economies, will basically create demands that earth will not be able to fulfill. Some economists[who?] talk about putting a price on using earth's resources which is in addition to the cost of just extracting them.</p><h2>Old-age spending</h2><p>Spending the Kids' Inheritance (originally the title of a book on the subject by Annie Hulley) and the acronyms SKI and SKI'ing refer to the growing number of older people in Western society spending their money on travel, cars and property, in contrast to previous generations who tended to leave that money to their children.</p><p>Die Broke (from the book Die Broke: A Radical Four-Part Financial Plan by Stephen Pollan and Mark Levine) is a similar idea.</p><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Consumption_(economics)&amp;oldid=781344074"					
				Categories:  Hidden categories:</p><br><h1 lang="en">Production (economics)</h1><p> From Wikipedia, the free encyclopedia</p><p>Production is a process of workers combining various material inputs and immaterial inputs (plans, know-how) in order to make something for consumption (the output). It is the act of creating output, a good or service which has value and contributes to the utility of individuals.[1]</p><p>Economic well-being is created in a production process, meaning all economic activities that aim directly or indirectly to satisfy human wants and needs. The degree to which the needs are satisfied is often accepted as a measure of economic well-being. In production there are two features which explain increasing economic well-being. They are improving quality-price-ratio of goods and services and increasing incomes from growing and more efficient market production.</p><p>The most important forms of production are</p><p>In order to understand the origin of the economic well-being we must understand these three production processes. All of them produce commodities which have value and contribute to well-being of individuals.</p><p>The satisfaction of needs originates from the use of the commodities which are produced. The need satisfaction increases when the quality-price-ratio of the commodities improves and more satisfaction is achieved at less cost. Improving the quality-price-ratio of commodities is to a producer an essential way to improve the competitiveness of products but this kind of gains distributed to customers cannot be measured with production data. Improving the competitiveness of products means often to the producer lower product prices and therefore losses in incomes which are to compensated with the growth of sales volume.</p><p>Economic well-being also increases due to the growth of incomes that are gained from the growing and more efficient market production. Market production is the only production form which creates and distributes incomes to stakeholders. Public production and household production are financed by the incomes generated in market production. Thus market production has a double role in creating well-being, i.e. the role of producing goods and services and the role of creating income. Because of this double role market production is the “primus motor” of economic well-being and therefore here under review.[citation needed]</p><h2>Contents</h2><h2>As a source of economic well-being</h2><p>In principle there are two main activities in an economy, production and consumption. Similarly there are two kinds of actors, producers and consumers. Well-being is made possible by efficient production and by the interaction between producers and consumers. In the interaction, consumers can be identified in two roles both of which generate well-being. Consumers can be both customers of the producers and suppliers to the producers. The customers’ well-being arises from the commodities they are buying and the suppliers’ well-being is related to the income they receive as compensation for the production inputs they have delivered to the producers.</p><h3>Stakeholders of production</h3><p>Stakeholders of production are persons, groups or organizations with an interest in a producing company. Economic well-being originates in efficient production and it is distributed through the interaction between the company’s stakeholders. The stakeholders of companies are economic actors which have an economic interest in a company. Based on the similarities of their interests, stakeholders can be classified into three groups in order to differentiate their interests and mutual relations. The three groups are as follows:</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/0/02/Interactive_contributions_of_a_company%E2%80%99s_stakeholders.png/400px-Interactive_contributions_of_a_company%E2%80%99s_stakeholders.png" width="400" height="199"><p>


Interactive contributions of a company’s stakeholders (Saari, 2011,4)


 
</p><p>
	The interests of these stakeholders and their relations to companies are described briefly below. Our purpose is to establish a framework for further analysis.</p><p>Customers</p><p>The customers of a company are typically consumers, other market producers or producers in the public sector. Each of them has their individual production functions. Due to competition, the price-quality-ratios of commodities tend to improve and this brings the benefits of better productivity to customers. Customers get more for less. In households and the public sector this means that more need satisfaction is achieved at less cost. For this reason the productivity of customers can increase over time even though their incomes remain unchanged.</p><p>Suppliers</p><p>The suppliers of companies are typically producers of materials, energy, capital, and services. They all have their individual production functions. The changes in prices or qualities of supplied commodities have an effect on both actors’ (company and suppliers) production functions. We come to the conclusion that the production functions of the company and its suppliers are in a state of continuous change.</p><div class='pageBreak' ></div><p>Producer community</p><p>The incomes are generated for those participating in production, i.e., the labour force, society and owners. These stakeholders are referred to here as producer communities or, in shorter form, as producers. The producer communities have a common interest in maximizing their incomes. These parties that contribute to production receive increased incomes from the growing and developing production.</p><p>The well-being gained through commodities stems from the price-quality relations of the commodities. Due to competition and development in the market, the price-quality relations of commodities tend to improve over time. Typically the quality of a commodity goes up and the price goes down over time. This development favourably affects the production functions of customers. Customers get more for less. Consumer customers get more satisfaction at less cost. This type of well-being generation can only partially be calculated from the production data. The situation is presented in this study. The producer community (labour force, society, and owners) earns income as compensation for the inputs they have delivered to the production. When the production grows and becomes more efficient, the income tends to increase. In production this brings about an increased ability to pay salaries, taxes and profits. The growth of production and improved productivity generate additional income for the producing community. Similarly the high income level achieved in the community is a result of the high volume of production and its good performance. This type of well-being generation – as mentioned earlier - can be reliably calculated from the production data.</p><h3>Main processes of a producing company</h3><p>A producing company can be divided into sub-processes in different ways; yet, the following five are identified as main processes, each with a logic, objectives, theory and key figures of its own. It is important to examine each of them individually, yet, as a part of the whole, in order to be able to measure and understand them. The main processes of a company are as follows:</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/3/37/Main_processes_of_a_company.png/400px-Main_processes_of_a_company.png" width="400" height="223"><p>


Main processes of a producing company (Saari 2006,3)


 
</p><p>
	Production output is created in the real process, gains of production are distributed in the income distribution process and these two processes constitute the production process. The production process and its sub-processes, the real process and income distribution process occur simultaneously, and only the production process is identifiable and measurable by the traditional accounting practices. The real process and income distribution process can be identified and measured by extra calculation, and this is why they need to be analyzed separately in order to understand the logic of production and its performance.</p><p>Real process generates the production output from input, and it can be described by means of the production function. It refers to a series of events in production in which production inputs of different quality and quantity are combined into products of different quality and quantity. Products can be physical goods, immaterial services and most often combinations of both. The characteristics created into the product by the producer imply surplus value to the consumer, and on the basis of the market price this value is shared by the consumer and the producer in the marketplace. This is the mechanism through which surplus value originates to the consumer and the producer likewise. It is worth noting that surplus values to customers cannot be measured from any production data. Instead the surplus value to a producer can be measured. It can be expressed both in terms of nominal and real values. The real surplus value to the producer is an outcome of the real process, real income, and measured proportionally it means productivity.</p><p>The concept “real process” in the meaning quantitative structure of production process was introduced in Finnish management accounting in 1960´s. Since then it has been a cornerstone in the Finnish management accounting theory. (Riistama et al. 1971)</p><p>Income distribution process of the production refers to a series of events in which the unit prices of constant-quality products and inputs alter causing a change in income distribution among those participating in the exchange. The magnitude of the change in income distribution is directly proportionate to the change in prices of the output and inputs and to their quantities. Productivity gains are distributed, for example, to customers as lower product sales prices or to staff as higher income pay.</p><p>The production process consists of the real process and the income distribution process. A result and a criterion of success of the owner is profitability. The profitability of production is the share of the real process result the owner has been able to keep to himself in the income distribution process. Factors describing the production process are the components of profitability, i.e., returns and costs. They differ from the factors of the real process in that the components of profitability are given at nominal prices whereas in the real process the factors are at periodically fixed prices.</p><p>Monetary process refers to events related to financing the business. Market value process refers to a series of events in which investors determine the market value of the company in the investment markets.</p><h3>Production growth and performance</h3><p> Main article: Economic growth</p><p>Economic growth is often defined as a production increase of an output of a production process. It is usually expressed as a growth percentage depicting growth of the real production output. The real output is the real value of products produced in a production process and when we subtract the real input from the real output we get the real income. The real output and the real income are generated by the real process of production from the real inputs.</p><p>The real process can be described by means of the production function. The production function is a graphical or mathematical expression showing the relationship between the inputs used in production and the output achieved. Both graphical and mathematical expressions are presented and demonstrated. The production function is a simple description of the mechanism of income generation in production process. It consists of two components. These components are a change in production input and a change in productivity.[2]</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/0/00/Components_of_economic_growth.png/300px-Components_of_economic_growth.png" width="300" height="224"><div class='pageBreak' ></div><p>


Components of economic growth (Saari 2006,2)


</p><p>
	The figure illustrates an income generation process(exaggerated for clarity). The Value T2 (value at time 2) represents the growth in output from Value T1 (value at time 1). Each time of measurement has its own graph of the production function for that time (the straight lines). The output measured at time 2 is greater than the output measured at time one for both of the components of growth: an increase of inputs and an increase of productivity. The portion of growth caused by the increase in inputs is shown on line 1 and does not change the relation between inputs and outputs. The portion of growth caused by an increase in productivity is shown on line 2 with a steeper slope. So increased productivity represents greater output per unit of input.</p><p>The growth of production output does not reveal anything about the performance of the production process. The performance of production measures production’s ability to generate income. Because the income from production is generated in the real process, we call it the real income. Similarly, as the production function is an expression of the real process, we could also call it “income generated by the production function”.</p><p>The real income generation follows the logic of the production function. Two components can also be distinguished in the income change: the income growth caused by an increase in production input (production volume) and the income growth caused by an increase in productivity. The income growth caused by increased production volume is determined by moving along the production function graph. The income growth corresponding to a shift of the production function is generated by the increase in productivity. The change of real income so signifies a move from the point 1 to the point 2 on the production function (above). When we want to maximize the production performance we have to maximize the income generated by the production function.</p><p>The sources of productivity growth and production volume growth are explained as follows. Productivity growth is seen as the key economic indicator of innovation. The successful introduction of new products and new or altered processes, organization structures, systems, and business models generates growth of output that exceeds the growth of inputs. This results in growth in productivity or output per unit of input. Income growth can also take place without innovation through replication of established technologies. With only replication and without innovation, output will increase in proportion to inputs. (Jorgenson et al. 2014,2) This is the case of income growth through production volume growth.</p><p>Jorgenson et al. (2014,2) give an empiric example. They show that the great preponderance of economic growth in the US since 1947 involves the replication of existing technologies through investment in equipment, structures, and software and expansion of the labor force. Further they show that innovation accounts for only about twenty percent of US economic growth.</p><p>In the case of a single production process (described above) the output is defined as an economic value of products and services produced in the process. When we want to examine an entity of many production processes we have to sum up the value-added created in the single processes. This is done in order to avoid the double accounting of intermediate inputs. Value-added is obtained by subtracting the intermediate inputs from the outputs. The most well-known and used measure of value-added is the GDP (Gross Domestic Product). It is widely used as a measure of the economic growth of nations and industries.</p><h3>Absolute (total) and average income</h3><p>The production performance can be measured as an average or an absolute income. Expressing performance both in average (avg.) and absolute (abs.) quantities is helpful for understanding the welfare effects of production. For measurement of the average production performance, we use the known productivity ratio</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/f/f7/Average_and_marginal_productivity.png/400px-Average_and_marginal_productivity.png" width="400" height="267"><p>


Average and marginal productivity (Saari 2011,8)


 
</p><p>
	The absolute income of performance is obtained by subtracting the real input from the real output as follows:</p><p>The growth of the real income is the increase of the economic value which can be distributed between the production stakeholders. With the aid of the production model we can perform the average and absolute accounting in one calculation. Maximizing production performance requires using the absolute measure, i.e. the real income and its derivatives as a criterion of production performance.</p><p>The differences between the absolute and average performance measures can be illustrated by the following graph showing marginal and average productivity. The figure is a traditional expression of average productivity and marginal productivity. The maximum for production performance is achieved at the volume where marginal productivity is zero. The maximum for production performance is the maximum of the real incomes. In this illustrative example the maximum real income is achieved, when the production volume is 7.5 units. The maximum average productivity is reached when the production volume is 3.0 units. It is worth noting that the maximum average productivity is not the same as the maximum of real income.</p><p>Figure above is a somewhat exaggerated depiction because the whole production function is shown. In practice, decisions are made in a limited range of the production functions, but the principle is still the same; the maximum real income is aimed for. An important conclusion can be drawn. When we try to maximize the welfare effects of production we have to maximize real income formation. Maximizing productivity leads to a suboptimum, i.e. to losses of incomes.</p><p>Maximizing productivity also leads to the phenomenon called jobless growth This refers to economic growth as a result of productivity growth but without creation of new jobs and new incomes from them. A practical example illustrates the case. When a jobless person obtains a job in market production we may assume it is a low productivity job. As a result, average productivity decreases but the real income per capita increases. Furthermore, the well-being of the society also grows. This example reveals the difficulty to interpret the total productivity change correctly. The combination of volume increase and total productivity decrease leads in this case to the improved performance because we are on the “diminishing returns” area of the production function. If we are on the part of “increasing returns” on the production function, the combination of production volume increase and total productivity increase leads to improved production performance. Unfortunately we do not know in practice on which part of the production function we are. Therefore, a correct interpretation of a performance change is obtained only by measuring the real income change.</p><h2>Production models</h2><div class='pageBreak' ></div><p>A production model is a numerical description of the production process and is based on the prices and the quantities of inputs and outputs. There are two main approaches to operationalize the concept of production function. We can use mathematical formulae, which are typically used in macroeconomics (in growth accounting) or arithmetical models, which are typically used in microeconomics and management accounting. We do not present the former approach here but refer to the survey “Growth accounting” by Hulten 2009.</p><p>We use here arithmetical models because they are like the models of management accounting, illustrative and easily understood and applied in practice. Furthermore, they are integrated to management accounting, which is a practical advantage. A major advantage of the arithmetical model is its capability to depict production function as a part of production process. Consequently, production function can be understood, measured, and examined as a part of production process.</p><p>There are different production models according to different interests. Here we use a production income model and a production analysis model in order to demonstrate production function as a phenomenon and a measureable quantity.</p><h3>Production income model</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/0/0f/Profitability_of_production_measured_by_surplus_value.png/400px-Profitability_of_production_measured_by_surplus_value.png" width="400" height="245"><p>


Profitability of production measured by surplus value (Saari 2006,3)


</p><p>
	The scale of success run by a going concern is manifold, and there are no criteria that might be universally applicable to success. Nevertheless, there is one criterion by which we can generalise the rate of success in production. This criterion is the ability to produce surplus value. As a criterion of profitability, surplus value refers to the difference between returns and costs, taking into consideration the costs of equity in addition to the costs included in the profit and loss statement as usual. Surplus value indicates that the output has more value than the sacrifice made for it, in other words, the output value is higher than the value (production costs) of the used inputs. If the surplus value is positive, the owner’s profit expectation has been surpassed.</p><p>The table presents a surplus value calculation. We call this set of production data a basic example and we use the data through the article in illustrative production models. The basic example is a simplified profitability calculation used for illustration and modelling. Even as reduced, it comprises all phenomena of a real measuring situation and most importantly the change in the output-input mix between two periods. Hence, the basic example works as an illustrative “scale model” of production without any features of a real measuring situation being lost. In practice, there may be hundreds of products and inputs but the logic of measuring does not differ from that presented in the basic example.</p><p>In this context we define the quality requirements for the production data used in productivity accounting. The most important criterion of good measurement is the homogenous quality of the measurement object. If the object is not homogenous, then the measurement result may include changes in both quantity and quality but their respective shares will remain unclear. In productivity accounting this criterion requires that every item of output and input must appear in accounting as being homogenous. In other words, the inputs and the outputs are not allowed to be aggregated in measuring and accounting. If they are aggregated, they are no longer homogenous and hence the measurement results may be biased.</p><p>Both the absolute and relative surplus value have been calculated in the example. Absolute value is the difference of the output and input values and the relative value is their relation, respectively. The surplus value calculation in the example is at a nominal price, calculated at the market price of each period.</p><h3>Production analysis model</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/e/e2/Productivity_model.png/350px-Productivity_model.png" width="350" height="459"><p>


Production Model Saari 2004 (Saari 2006,4)


</p><p>
	A model [3] used here is a typical production analysis model by help of which it is possible to calculate the outcome of the real process, income distribution process and production process. The starting point is a profitability calculation using surplus value as a criterion of profitability. The surplus value calculation is the only valid measure for understanding the connection between profitability and productivity or understanding the connection between real process and production process. A valid measurement of total productivity necessitates considering all production inputs, and the surplus value calculation is the only calculation to conform to the requirement. If we omit an input in productivity or income accounting, this means that the omitted input can be used unlimitedly in production without any cost impact on accounting results.</p><h3>Accounting and interpreting</h3><p>The process of calculating is best understood by applying the term ceteris paribus, i.e. all other things being the same, stating that at a time only the impact of one changing factor be introduced to the phenomenon being examined. Therefore, the calculation can be presented as a process advancing step by step. First, the impacts of the income distribution process are calculated, and then, the impacts of the real process on the profitability of the production.</p><p>The first step of the calculation is to separate the impacts of the real process and the income distribution process, respectively, from the change in profitability (285.12&nbsp;– 266.00 = 19.12). This takes place by simply creating one auxiliary column (4) in which a surplus value calculation is compiled using the quantities of Period 1 and the prices of Period 2. In the resulting profitability calculation, Columns 3 and 4 depict the impact of a change in income distribution process on the profitability and in Columns 4 and 7 the impact of a change in real process on the profitability.</p><div class='pageBreak' ></div><p>The accounting results are easily interpreted and understood. We see that the real income has increased by 58.12 units from which 41.12 units come from the increase of productivity growth and the rest 17.00 units come from the production volume growth. The total increase of real income (58.12) is distributed to the stakeholders of production, in this case 39.00 units to the customers and to the suppliers of inputs and the rest 19.12 units to the owners.</p><p>Here we can make an important conclusion. Income formation of production is always a balance between income generation and income distribution. The income change created in a real process (i.e. by production function) is always distributed to the stakeholders as economic values within the review period. Accordingly, the changes in real income and income distribution are always equal in terms of economic value.</p><p>Based on the accounted changes of productivity and production volume values we can explicitly conclude on which part of the production function the production is. The rules of interpretations are the following:</p><p>The production is on the part of “increasing returns” on the production function, when</p><p>The production is on the part of “diminishing returns” on the production function, when</p><p>In the basic example the combination of volume growth (+17.00) and productivity growth (+41.12) reports explicitly that the production is on the part of “increasing returns” on the production function (Saari 2006 a, 138–144).</p><p>Another production model (Production Model Saari 1989) also gives details of the income distribution (Saari 2011,14). Because the accounting techniques of the two models are different, they give differing, although complementary, analytical information. The accounting results are, however, identical. We do not present the model here in detail but we only use its detailed data on income distribution, when the objective functions are formulated in the next section.</p><h2>Objective functions</h2><p>An efficient way to improve the understanding of production performance is to formulate different objective functions according to the objectives of the different interest groups. Formulating the objective function necessitates defining the variable to be maximized (or minimized). After that other variables are considered as constraints or free variables. The most familiar objective function is profit maximization which is also included in this case. Profit maximization is an objective function that stems from the owner’s interest and all other variables are constraints in relation to maximizing of profits.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/d/da/Income_formation.png/300px-Income_formation.png" width="300" height="152"><p>


Summary of objective function formulations (Saari 2011,17)


</p><h3>The procedure for formulating objective functions</h3><p>
	The procedure for formulating different objective functions, in terms of the production model, is introduced next. In the income formation from production the following objective functions can be identified:</p><p>These cases are illustrated using the numbers from the basic example. The following symbols are used in the presentation: The equal sign (=) signifies the starting point of the computation or the result of computing and the plus or minus sign (+ / -) signifies a variable that is to be added or subtracted from the function. A producer means here the producer community, i.e. labour force, society and owners.</p><p>Objective function formulations can be expressed in a single calculation which concisely illustrates the logic of the income generation, the income distribution and the variables to be maximized.</p><p>The calculation resembles an income statement starting with the income generation and ending with the income distribution. The income generation and the distribution are always in balance so that their amounts are equal. In this case it is 58.12 units. The income which has been generated in the real process is distributed to the stakeholders during the same period. There are three variables which can be maximized. They are the real income, the producer income and the owner income. Producer income and owner income are practical quantities because they are addable quantities and they can be computed quite easily. Real income is normally not an addable quantity and in many cases it is difficult to calculate.</p><h3>The dual approach for the formulation</h3><p>Here we have to add that the change of real income can also be computed from the changes in income distribution. We have to identify the unit price changes of outputs and inputs and calculate their profit impacts (i.e. unit price change x quantity). The change of real income is the sum of these profit impacts and the change of owner income. This approach is called the dual approach because the framework is seen in terms of prices instead of quantities (ONS 3, 23).</p><p>The dual approach has been recognized in growth accounting for long but its interpretation has remained unclear. The following question has remained unanswered: “Quantity based estimates of the residual are interpreted as a shift in the production function, but what is the interpretation of the price-based growth estimates?” (Hulten 2009, 18). We have demonstrated above that the real income change is achieved by quantitative changes in production and the income distribution change to the stakeholders is its dual. In this case the duality means that the same accounting result is obtained by accounting the change of the total income generation (real income) and by accounting the change of the total income distribution.</p><h2>Footnotes</h2><h2>Further references and external links</h2><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Production_(economics)&amp;oldid=776641833"					
				Categories:  Hidden categories:</p><br><h1 lang="en">Agent (economics)</h1><p> From Wikipedia, the free encyclopedia</p><p>In economics, an agent is an actor and more specifically a decision maker in a model of some aspect of the economy. Typically, every agent makes decisions by solving a well or ill-defined optimization or choice problem.</p><p>For example, buyers and sellers are two common types of agents in partial equilibrium models of a single market. Macroeconomic models, especially dynamic stochastic general equilibrium models that are explicitly based on microfoundations, often distinguish households, firms, and governments or central banks as the main types of agents in the economy. Each of these agents may play multiple roles in the economy; households, for example, might act as consumers, as workers, and as voters in the model. Some macroeconomic models distinguish even more types of agents, such as workers and shoppers[1] or commercial banks.[2]</p><div class='pageBreak' ></div><p>The term agent is also used in relation to principal–agent models; in this case it refers specifically to someone delegated to act on behalf of a principal.[3]</p><p>In agent-based computational economics, corresponding agents are computational objects modeled as interacting according to rules over space and time, not real people. The rules are formulated to model behavior and social interactions based on stipulated incentives and information.[4] The concept of an agent may be broadly interpreted to be any persistent individual, social, biological, or physical entity interacting with other such entities in the context of a dynamic multi-agent economic system.</p><h2>Contents</h2><h2>Representative vs. heterogenous agents</h2><p>An economic model in which all agents of a given type (such as all consumers, or all firms) are assumed to be exactly identical is called a representative agent model. A model which recognizes differences among agents is called a heterogeneous agent model. Economists often use representative agent models when they want to describe the economy in the simplest terms possible. In contrast, they may be obliged to use heterogeneous agent models when differences among agents are directly relevant for the question at hand.[5] For example, considering heterogeneity in age is likely to be necessary in a model used to study the economic effects of pensions;[6] considering heterogeneity in wealth is likely to be necessary in a model used to study precautionary saving[7] or redistributive taxation.[8]</p><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Agent_(economics)&amp;oldid=780715784"					
				Categories:  				
							
		<br>
			

							 
						

			</p><br><h1 lang="en">Microeconomics</h1><p> From Wikipedia, the free encyclopedia</p><p> Further information: Evolution of microeconomics</p><p>Microeconomics (from Greek prefix mikro- meaning small) is a branch of economics that studies the behavior of individuals and firms in making decisions regarding the allocation of scarce resources and the interactions among these individuals and firms.[1][2][3]</p><p>One goal of microeconomics is to analyze the market mechanisms that establish relative prices among goods and services and allocate limited resources among alternative uses. Microeconomics shows conditions under which free markets lead to desirable allocations. It also analyzes market failure, where markets fail to produce efficient results.</p><p>Microeconomics stands in contrast to macroeconomics, which involves the sum total of economic activity, dealing with the issues of growth, inflation, and unemployment and with national policies relating to these issues.[2] Microeconomics also deals with the effects of economic policies (such as changing taxation levels) on the aforementioned aspects of the economy.[4] Particularly in the wake of the Lucas critique, much of modern macroeconomic theory has been built upon 'microfoundations'—i.e. based upon basic assumptions about micro-level behavior.</p><h2>Contents</h2><h2>Assumptions and definitions</h2><p>Microeconomic theory typically begins with the study of a single rational and utility maximizing individual. To economists, rationality means an individual possesses stable preferences that are both complete and transitive. The technical assumption that preference relations are continuous is needed to ensure the existence of a utility function. Although microeconomic theory can continue without this assumption, it would make comparative statics impossible since there is no guarantee that the resulting utility function would be differentiable.</p><p>Microeconomic theory progresses by defining a competitive budget set which is a subset of the consumption set. It is at this point that economists make the technical assumption that preferences are locally non-satiated. Without the assumption of LNS (local non-satiation) there is no guarantee that a rational individual would maximize utility. With the necessary tools and assumptions in place the utility maximization problem (UMP) is developed.</p><p>The utility maximization problem is the heart of consumer theory. The utility maximization problem attempts to explain the action axiom by imposing rationality axioms on consumer preferences and then mathematically modeling and analyzing the consequences. The utility maximization problem serves not only as the mathematical foundation of consumer theory but as a metaphysical explanation of it as well. That is, the utility maximization problem is used by economists to not only explain what or how individuals make choices but why individuals make choices as well.</p><p>The utility maximization problem is a constrained optimization problem in which an individual seeks to maximize utility subject to a budget constraint. Economists use the extreme value theorem to guarantee that a solution to the utility maximization problem exists. That is, since the budget constraint is both bounded and closed, a solution to the utility maximization problem exists. Economists call the solution to the utility maximization problem a Walrasian demand function or correspondence.</p><p>The utility maximization problem has so far been developed by taking consumer tastes (i.e. consumer utility) as the primitive. However, an alternative way to develop microeconomic theory is by taking consumer choice as the primitive. This model of microeconomic theory is referred to as Revealed preference theory.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/e/eb/Supply-demand-right-shift-demand.svg/220px-Supply-demand-right-shift-demand.svg.png" width="220" height="220"><p>


The supply and demand model describes how prices vary as a result of a balance between product availability at each price (supply) and the desires of those with purchasing power at each price (demand). The graph depicts a right-shift in demand from D1 to D2 along with the consequent increase in price and quantity required to reach a new market-clearing equilibrium point on the supply curve (S).


</p><p>
	The theory of supply and demand usually assumes that markets are perfectly competitive. This implies that there are many buyers and sellers in the market and none of them have the capacity to significantly influence prices of goods and services. In many real-life transactions, the assumption fails because some individual buyers or sellers have the ability to influence prices. Quite often, a sophisticated analysis is required to understand the demand-supply equation of a good model. However, the theory works well in situations meeting these assumptions.</p><p>Mainstream economics does not assume a priori that markets are preferable to other forms of social organization. In fact, much analysis is devoted to cases where market failures lead to resource allocation that is suboptimal and creates deadweight loss. A classic example of suboptimal resource allocation is that of a public good. In such cases, economists may attempt to find policies that avoid waste, either directly by government control, indirectly by regulation that induces market participants to act in a manner consistent with optimal welfare, or by creating missing markets to enable efficient trading where none had previously existed.</p><p>This is studied in the field of collective action and public choice theory. Optimal welfare usually takes on a Paretian norm, which is a mathematical application of the Kaldor–Hicks method. This can diverge from the Utilitarian goal of maximizing utility because it does not consider the distribution of goods between people. Market failure in positive economics (microeconomics) is limited in implications without mixing the belief of the economist and their theory.</p><div class='pageBreak' ></div><p>The demand for various commodities by individuals is generally thought of as the outcome of a utility-maximizing process, with each individual trying to maximize their own utility under a budget constraint and a given consumption set.</p><p>
Microeconomic theories are involved with the choices that households and firms make. Some of these microeconomic concepts include elasticity of demand and supply, market structures and utility. Microeconomic looks into the way individuals and businesses behave in coming up with decisions to do with the distribution of rare resources and collaborations between these individuals and the firm. A production possibility frontier illustrates the maximum probable output combinations of two services or goods an economy may realise while all other resources are efficiently and wholly engaged. A production possibility frontier is used to explain the models of opportunity cost, illustrate the effects of economic development and demonstrate the theory of trade-offs.</p><p>Supply and demand is possibly amongst the most crucial conceptions of economics and it is the pillar of the economy of a market. Demand can be explained as the extent to which a service or a good is desired by users. The amount demanded is the sum of a commodity individuals are ready to purchase at a certain given price. Supply on the other hand refers to how much of a product a market can provide. The supplied quantity is the volume of a particular commodity manufacturers are willing to supply at a certain price. The relationship between demand and supply trigger the forces as a result of the sharing of resources. The law of demand states that when all other influences stay constant the higher the price of a good, the lesser the demand of the given produce. In other word the greater the price the lower the amount needed. The amount of a good bought by customers at a greater price is lower as the price rises the opportunity cost of buying a commodity. People will therefore naturally evade buying a commodity that will need them to sacrifice the use of something else that is more significant to them. Similar to the law of demand, the law of supply reveals the amounts that will be traded at a certain given price. Contrasting the law of demand, the supply relationship gives a rising slope. This means that the bigger the price the greater the quantity in supply. Manufacturers supply more at a high price because selling a quantity at a higher price rises income. Where demand and supply are the same, the economy is held to be at equilibrium. At the point of equilibrium the distribution of goods is at its most effectual because the amount of goods at supply is precisely the same as the volume of goods in demand. Therefore every individual is contented with prevailing state of the economy.</p><p>Elasticity is defined as the degree of receptiveness in demand and supply in relation to fluctuations in price. If a curve is more elastic then lesser alterations in price will result to a higher change in quantity used up. If a curve is less elastic it will then cause higher deviations in price to affect a change in amount consumed. Price elasticity of demand is the extent of responsiveness in quantity demanded in relation to price. Utility on the other hand is the amount of contentment resulting from the consumption of a commodity or services at a particular period. Utility is a psychological satisfaction not inherent. It is dependent on the persons own subjective approximate of satisfaction to be acquired from the consumption of a commodity. Utility is further divided into marginal utility, total utility and maximizing utility. Marginal utility refers to the extra utility resulting from the consumption of one extra unit of a commodity, the consumption of the rest of the goods remaining unaffected. Total utility is refers to as the number of units of utility that a consumer gains from consuming a given quantity of a good, service, or activity during a particular time period. The greater a consumers total utility, the larger the customer’s level of consumption. The cost to any firm of producing any output evidently depends upon the physical amounts of real resources. For instance material, labour and machine hours used in production. As the larger output needs a larger amount of resources, the total cost for larger output becomes high. Whereas the smaller output requires the smaller resources. The total cost for smaller output becomes smaller. A company can produce at lower cost when it produces better new techniques to products. Production with traditional and old method implicates high cost. The maximisation of returns includes the use of a definite technique to produce that can facilitate the optimal combination of factors. Production cost is defined as the expenditures by a business in producing a commodity. There are several kinds of cost concepts, these are marginal cost, total cost and average cost. Total is the cost of producing a certain output of the product in question. Total cost can be classified into variable cost and fixed cost. Fixed costs is also known as overhead cost. These are costs which do not differ with output. The costs will be the same whether the output is ten or twenty or a thousand of a product. Fixed costs entails interest on bank loans, depreciation of machinery, insurance charges and rent of factory. Variable costs are also called prime cost. Variable costs differ with alterations in output. The greater the output, the bigger the variable costs. Average cost is the cost of each unit of output and is achieved by dividing the total cost by the level of output. It is further divided into two parts, average fixed cost and average variable cost. Marginal cost is defined as the extra cost incurred by increasing output by one unit. It is the added cost of producing an additional unit of output. Perfect competition is a market structure in which the following characteristics are met. All businesses trade the same commodity, all firms will have a comparatively small market share, all firms are price takers meaning they cannot control the market price of their goods, the industry is characterized by freedom of entry and exit, and buyers have complete information about the product being sold and the prices charged by each firm. Perfect competition is a hypothetical market structure. Under perfect competition there are numerous buyers and sellers and prices reveal supply and demand. Customers will have several substitutes when the commodity they wish to buy quality begins to reduce or if it becomes more expensive. News firms can as well simply enter the market, leading to an extra competition. Monopoly on the other hand is where there is only one supplier in the market. For the reasons of regulation, monopoly power occurs where a single business owns 25% or more of a particular market. Monopolies can form for a number of reasons. For example, government can grant a business monopoly powers, if a firm has exclusive ownership of a limited resource, producers may have patents over designs for instance, giving them rights to trade a good or a service and a merger of two or more firms would create a monopoly. Monopolies have basic characteristics such as, they can maintain super normal returns in the long run, a monopolist with no substitute would be able to develop the greatest monopoly power and with no close substitutes, the monopolist can therefore derive supernormal profits.</p><p>In conclusion, microeconomics tries in any way not to explain what ought to happen in a market. Instead it will explains what to anticipate if some conditions are altered. For instance if producers increase the price of a commodity, customers will opt to purchase fewer of a product than before.</p><h2>Topics</h2><p>The study of microeconomics involves several key areas:</p><h3>Demand, supply, and equilibrium</h3><p> Main article: Supply and demand</p><p>Supply and demand is an economic model of price determination in a perfectly competitive market. It concludes that in a perfectly competitive market with no externalities, per unit taxes, or price controls, the unit price for a particular good is the price at which the quantity demanded by consumers equals the quantity supplied by producers. This price results in a stable economic equilibrium.</p><h3>Measurement of elasticities</h3><p> Main article: Elasticity (economics)</p><p>Elasticity is the measurement of how responsive an economic variable is to a change in another variable. Elasticity can be quantified as the ratio of the percentage change in one variable to the percentage change in another variable, when the later variable has a causal influence on the former. It is a tool for measuring the responsiveness of a variable, or of the function that determines it, to changes in causative variables in unitless ways. Frequently used elasticities include price elasticity of demand, price elasticity of supply, income elasticity of demand, elasticity of substitution between factors of production and elasticity of intertemporal substitution.</p><h3>Consumer demand theory</h3><p> Main article: Consumer choice</p><div class='pageBreak' ></div><p>Consumer demand theory relates preferences for the consumption of both goods and services to the consumption expenditures; ultimately, this relationship between preferences and consumption expenditures is used to relate preferences to consumer demand curves. The link between personal preferences, consumption and the demand curve is one of the most closely studied relations in economics. It is a way of analyzing how consumers may achieve equilibrium between preferences and expenditures by maximizing utility subject to consumer budget constraints.</p><h3>Theory of production</h3><p> Main article: Production theory</p><p>Production theory is the study of production, or the economic process of converting inputs into outputs. Production uses resources to create a good or service that is suitable for use, gift-giving in a gift economy, or exchange in a market economy. This can include manufacturing, storing, shipping, and packaging. Some economists define production broadly as all economic activity other than consumption. They see every commercial activity other than the final purchase as some form of production.</p><h3>Costs of production</h3><p> Main article: Cost-of-production theory of value</p><p>The cost-of-production theory of value states that the price of an object or condition is determined by the sum of the cost of the resources that went into making it. The cost can comprise any of the factors of production: labour, capital, land. Technology can be viewed either as a form of fixed capital (ex:plant) or circulating capital (ex:intermediate goods).</p><h3>Perfect competition</h3><p> Main article: Perfect competition</p><p>Perfect competition describes markets such that no participants are large enough to have the market power to set the price of a homogeneous product. A good example would be that of digital marketplaces, such as eBay, on which many different sellers sell similar products to many different buyers.</p><p>Benefits of Perfect Competition- All the knowledge such as price and information pertaining goods is equally dispersed among all buyers and sellers. As there are no barriers to enter into the market, monopoly does not usually occur. As all goods and products are same, advertisement is not required and it helps save the advertisement cost.in perfect competition products are identical</p><h3>Monopoly</h3><p> Main article: monopoly</p><p>A monopoly (from Greek monos µ???? (alone or single) + polein p??e?? (to sell)) exists when a single company is the only supplier of a particular commodity.</p><p>Benefits of Monopoly Market- Prices in monopoly market are stable as there is only one firm and so there is no competition. Due to the absence of competition there are high profits and leads to high number of sales monopoly firms tend to receive super profits from their operations.</p><h3>Oligopoly</h3><p> Main article: Oligopoly</p><p>An oligopoly is a market form in which a market or industry is dominated by a small number of sellers (oligopolists). Oligopolies can create the incentive for firms to engage in collusion and form cartels that reduce competition leading to higher prices for consumers and less overall market output.[5]</p><p>Benefits of oligopoly market-As there is less competition in the firm, it tends to have massive profit.It is also able to easily compare prices forces these companies to keep their prices in competition with the other companies involved in the market.Each company scrambles to come out with latest and greatest thing in order to sway consumers to go with their company over a different one.</p><h3>Market structure</h3><p>The market structure can have several types of interacting market systems. Different forms of markets are a feature of capitalism and advocates of socialism often criticize markets and aim to substitute markets with economic planning to varying degrees. Competition is the regulatory mechanism of the market system.</p><p>Examples of markets include but are not limited to: commodity markets, insurance markets, bond markets, energy markets, flea markets, debt markets, stock markets, online auctions, media exchange markets, real estate market.</p><h3>Game theory</h3><p> Main article: Game theory</p><p>Game theory is a major method used in mathematical economics and business for modeling competing behaviors of interacting agents. The term game here implies the study of any strategic interaction between people. Applications include a wide array of economic phenomena and approaches, such as auctions, bargaining, mergers &amp; acquisitions pricing, fair division, duopolies, oligopolies, social network formation, agent-based computational economics, general equilibrium, mechanism design,and voting systems, and across such broad areas as experimental economics, behavioral economics, information economics, industrial organization, and political economy.</p><h3>Labour economics</h3><p> Main article: Labour economics</p><p>Labour economics seeks to understand the functioning and dynamics of the markets for wage labour. Labour markets function through the interaction of workers and employers. Labour economics looks at the suppliers of labour services (workers), the demands of labour services (employers), and attempts to understand the resulting pattern of wages, employment, and income. In economics, labour is a measure of the work done by human beings. It is conventionally contrasted with such other factors of production as land and capital. There are theories which have developed a concept called human capital (referring to the skills that workers possess, not necessarily their actual work), although there are also counter posing macro-economic system theories that think human capital is a contradiction in terms.</p><h3>Welfare economics</h3><p> Main article: Welfare economics</p><p>Welfare economics is a branch of economics that uses microeconomics techniques to evaluate well-being from allocation of productive factors as to desirability and economic efficiency within an economy, often relative to competitive general equilibrium.[7] It analyzes social welfare, however measured, in terms of economic activities of the individuals that compose the theoretical society considered. Accordingly, individuals, with associated economic activities, are the basic units for aggregating to social welfare, whether of a group, a community, or a society, and there is no social welfare apart from the welfare associated with its individual units.</p><h3>Economics of information</h3><p> Main article: Information economics</p><div class='pageBreak' ></div><p>Information economics or the economics of information is a branch of microeconomic theory that studies how information and information systems affect an economy and economic decisions. Information has special characteristics. It is easy to create but hard to trust. It is easy to spread but hard to control. It influences many decisions. These special characteristics (as compared with other types of goods) complicate many standard economic theories.[8]</p><h2>Opportunity cost</h2><p> Main article: Opportunity cost</p><p>Opportunity cost of an activity (or goods) is equal to the best next alternative uses/forgone. Although opportunity cost can be hard to quantify, the effect of opportunity cost is universal and very real on the individual level. In fact, this principle applies to all decisions, not just economic ones.</p><p>Opportunity cost is one way to measure the cost of something. Rather than merely identifying and adding the costs of a project, one may also identify the next best alternative way to spend the same amount of money. The forgone profit of this next best alternative is the opportunity cost of the original choice. A common example is a farmer that chooses to farm their land rather than rent it to neighbors, wherein the opportunity cost is the forgone profit from renting. In this case, the farmer may expect to generate more profit alone. This kind of reasoning is a very important part of the calculation of discount rates in discounted cash flow investment valuation methodologies. Similarly, the opportunity cost of attending university is the lost wages a student could have earned in the workforce, rather than the cost of tuition, books, and other requisite items (whose sum makes up the total cost of attendance).</p><p>Note that opportunity cost is not the sum of the available alternatives, but rather the benefit of the single, best alternative. Possible opportunity costs of a city's decision to build a hospital on its vacant land are the loss of the land for a sporting center, or the inability to use the land for a parking lot, or the money that could have been made from selling the land, or the loss of any of the various other possible uses — but not all of these in aggregate. The true opportunity cost would be the forgone profit of the most lucrative of those listed.</p><p>One question that arises here is how to determine a money value for each alternative to facilitate comparison and assess opportunity cost, which may be more or less difficult depending on the things we are trying to compare. For example, many decisions involve environmental impacts whose monetary value is difficult to assess because of scientific uncertainty. Valuing a human life or the economic impact of an Arctic oil spill involves making subjective choices with ethical implications.</p><p>It is imperative to understand that no decision on allocating time is free. No matter what one chooses to do, they are always giving something up in return. An example of opportunity cost is deciding between going to a concert and doing homework. If one decides to go the concert, then they are giving up valuable time to study, but if they choose to do homework then the cost is giving up the concert. Any decision in allocating capital is likewise: there is an opportunity cost of capital, or a hurdle rate, defined as the expected rate one could get by investing in similar projects on the open market. Opportunity cost is vital in understanding microeconomics and decisions that are made.</p><h2>Applied</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/e/e8/United_States_Capitol_Building.jpg/220px-United_States_Capitol_Building.jpg" width="220" height="146"><p>


United States Capitol Building: meeting place of the United States Congress, where many tax laws are passed, which directly impact economic welfare. This is studied in the subject of public economics.


</p><p>
	Applied microeconomics includes a range of specialized areas of study, many of which draw on methods from other fields. Industrial organization examines topics such as the entry and exit of firms, innovation, and the role of trademarks. Labor economics examines wages, employment, and labor market dynamics. Financial economics examines topics such as the structure of optimal portfolios, the rate of return to capital, econometric analysis of security returns, and corporate financial behavior. Public economics examines the design of government tax and expenditure policies and economic effects of these policies (e.g., social insurance programs). Political economy examines the role of political institutions in determining policy outcomes. Health economics examines the organization of health care systems, including the role of the health care workforce and health insurance programs. Education economics examines the organization of education provision and its implication for efficiency and equity, including the effects of education on productivity. Urban economics, which examines the challenges faced by cities, such as sprawl, air and water pollution, traffic congestion, and poverty, draws on the fields of urban geography and sociology. Law and economics applies microeconomic principles to the selection and enforcement of competing legal regimes and their relative efficiencies. Economic history examines the evolution of the economy and economic institutions, using methods and techniques from the fields of economics, history, geography, sociology, psychology, and political science.</p><p>&lt;ref&gt;==References==</p><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Microeconomics&amp;oldid=783350389"					
				Categories:  Hidden categories:</p><br><h1 lang="en">Rational choice theory</h1><p> From Wikipedia, the free encyclopedia</p><p> This article is about a theory of economics. For rational choice theory as applied to criminology, see Rational choice theory (criminology).</p><p>Rational choice theory, also known as choice theory or rational action theory, is a framework for understanding and often formally modeling social and economic behavior.[1] The basic premise of rational choice theory is that aggregate social behavior results from the behavior of individual actors, each of whom is making their individual decisions. The theory also focuses on the determinants of the individual choices (methodological individualism).</p><p>Rational choice theory then assumes that an individual has preferences among the available choice alternatives that allow them to state which option they prefer. These preferences are assumed to be complete (the person can always say which of two alternatives they consider preferable or that neither is preferred to the other) and transitive (if option A is preferred over option B and option B is preferred over option C, then A is preferred over C). The rational agent is assumed to take account of available information, probabilities of events, and potential costs and benefits in determining preferences, and to act consistently in choosing the self-determined best choice of action.</p><p>Rationality is widely used as an assumption of the behavior of individuals in microeconomic models and analyses and appears in almost all economics textbook treatments of human decision-making. It is also used in political science,[2] sociology,[3] and philosophy. A particular version of rationality is instrumental rationality, which involves seeking the most cost-effective means to achieve a specific goal without reflecting on the worthiness of that goal. Gary Becker was an early proponent of applying rational actor models more widely.[4] Becker won the 1992 Nobel Memorial Prize in Economic Sciences for his studies of discrimination, crime, and human capital.[5]</p><h2>Contents</h2><h2>Definition and scope</h2><div class='pageBreak' ></div><p>The concept of rationality used in rational choice theory is different from the colloquial and most philosophical use of the word. Colloquially, rational behaviour typically means sensible, predictable, or in a thoughtful, clear-headed manner. Rational choice theory uses a narrower definition of rationality. At its most basic level, behavior is rational if it is goal-oriented, reflective (evaluative), and consistent (across time and different choice situations). This contrasts with behavior that is random, impulsive, conditioned, or adopted by (unevaluative) imitation.[citation needed]</p><p>Early neoclassical economists writing about rational choice, including William Stanley Jevons, assumed that agents make consumption choices so as to maximize their happiness, or utility. Contemporary theory bases rational choice on a set of choice axioms that need to be satisfied, and typically does not specify where the goal (preferences, desires) comes from. It mandates just a consistent ranking of the alternatives.[6]:501 Individuals choose the best action according to their personal preferences and the constraints facing them. E.g., there is nothing irrational in preferring fish to meat the first time, but there is something irrational in preferring fish to meat in one instant and preferring meat to fish in another, without anything else having changed.</p><p>Rational choice theorists do not claim that the theory describes the choice process, but rather that it predicts the outcome and pattern of choices. An assumption often added to the rational choice paradigm is that individual preferences are self-interested, in which case the individual can be referred to as a homo economicus. Such an individual acts as if balancing costs against benefits to arrive at action that maximizes personal advantage.[7] Proponents of such models, particularly those associated with the Chicago school of economics, do not claim that a model's assumptions are an accurate description of reality, only that they help formulate clear and falsifiable hypotheses.[citation needed] In this view, the only way to judge the success of a hypothesis is empirical tests.[7] To use an example from Milton Friedman, if a theory that says that the behavior of the leaves of a tree is explained by their rationality passes the empirical test, it is seen as successful.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/c/c8/Daniel_KAHNEMAN.jpg" width="150" height="179"><p>Without specifying the individual's goal or preferences it may not be possible to empirically test, or falsify, the rationality assumption. However, the predictions made by a specific version of the theory are testable. In recent years, the most prevalent version of rational choice theory, expected utility theory, has been challenged by the experimental results of behavioral economics. Economists are learning from other fields, such as psychology, and are enriching their theories of choice in order to get a more accurate view of human decision-making. For example, the behavioral economist and experimental psychologist Daniel Kahneman won the Nobel Memorial Prize in Economic Sciences in 2002 for his work in this field.</p><p>Rational choice theory has become increasingly employed in social sciences other than economics, such as sociology, evolutionary theory and political science in recent decades.[8][9] It has had far-reaching impacts on the study of political science, especially in fields like the study of interest groups, elections, behaviour in legislatures, coalitions, and bureaucracy.[10] In these fields, the use of the rational choice paradigm to explain broad social phenomena is the subject of active controversy.[11][12]</p><h2>Actions, assumptions, and individual preferences</h2><p>The premise of rational choice theory as a social science methodology is that the aggregate behavior in society reflects the sum of the choices made by individuals. Each individual, in turn, makes their choice based on their own preferences and the constraints (or choice set) they face.</p><p>At the individual level, rational choice theory stipulates that the agent chooses the action (or outcome) they most prefer. In the case where actions (or outcomes) can be evaluated in terms of costs and benefits, a rational individual chooses the action (or outcome) that provides the maximum net benefit, i.e., the maximum benefit minus cost.</p><p>The theory applies to more general settings than those identified by costs and benefit. In general, rational decision making entails choosing among all available alternatives the alternative that the individual most prefers. The alternatives can be a set of actions (what to do?) or a set of objects (what to choose/buy). In the case of actions, what the individual really cares about are the outcomes that results from each possible action. Actions, in this case, are only an instrument for obtaining a particular outcome.</p><h3>Formal statement</h3><p>The available alternatives are often expressed as a set of objects, for example a set of j exhaustive and exclusive actions:</p><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Rational_choice_theory&amp;oldid=770556981"					
				Categories:  Hidden categories:</p><br><h1 lang="en">Normative economics</h1><p> From Wikipedia, the free encyclopedia</p><p>Normative economics (as opposed to positive economics) is a part of economics that expresses value or normative judgments about economic fairness or what the outcome of the economy or goals of public policy ought to be.[1]</p><p>Economists commonly prefer to distinguish normative economics (what ought to be in economic matters) from positive economics (what is). Many normative (value) judgments, however, are held conditionally, to be given up if facts or knowledge of facts changes, so that a change of values may be purely scientific.[2] On the other hand, welfare economist Amartya Sen distinguishes basic (normative) judgments, which do not depend on such knowledge, from nonbasic judgments, which do. He finds it interesting to note that no judgments are demonstrably basic while some value judgments may be shown to be nonbasic. This leaves open the possibility of fruitful scientific discussion of value judgments.[3]</p><p>Positive and normative economics are often synthesized in the style of practical idealism. In this discipline, sometimes called the art of economics, positive economics is utilized as a practical tool for achieving normative objectives.</p><p>An example of a normative economic statement is as follows:</p><p>This is a normative statement, because it reflects value judgments. This specific statement makes the judgment that farmers need a higher living standard and that family farms need to be saved.[1]</p><p>Subfields of normative economics include social choice theory, cooperative game theory, and mechanism design.</p><p>Some earlier technical problems posed in welfare economics and the theory of justice have been sufficiently addressed as to leave room for consideration of proposals in applied fields such as resource allocation, public policy, social indicators, and inequality and poverty measurement.[4]</p><div class='pageBreak' ></div><h2>Notes</h2><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Normative_economics&amp;oldid=782036831"					
				Categories:  				
							
		<br>
			

							 
						

			</p><br><h1 lang="en">Business economics</h1><p> From Wikipedia, the free encyclopedia</p><p>Business economics is a field in applied economics which uses economic theory and quantitative methods to analyze business enterprises and the factors contributing to the diversity of organizational structures and the relationships of firms with labour, capital and product markets.[1] A professional focus of the journal Business Economics has been expressed as providing practical information for people who apply economics in their jobs.[2]</p><h2>Contents</h2><h2>Subject matter</h2><p>Business economics is concerned with economic issues and problems related to business organization, management, and strategy. Issues and problems include: an explanation of why corporate firms emerge and exist; why they expand: horizontally, vertically and spacially; the role of entrepreneurs and entrepreneurship; the significance of organizational structure; the relationship of firms with the employees, the providers of capital, the customers, the government; the interactions between firms and the business environment.[1]</p><h2>Ambiguity in the use of term</h2><p>The term 'business economics' is used in a variety of ways. Sometimes it is used as synonymously with industrial economics/industrial organisation, managerial economics, and economics for business. Still, there may be substantial differences in the usage of 'economics for business' and 'managerial economics' with the latter used more narrowly. One view of the distinctions between these would be that business economics is wider in its scope than industrial economics in that it would be concerned not only with industry but also businesses in the service sector. Economics for business looks at the major principles of economics but focuses on applying these economic principles to the real world of business.[3] Managerial economics is the application of economic methods in the managerial decision-making process.[4]</p><h2>Interpretations from various universities</h2><p>Many universities offer courses in business economics and offer a range of interpretations as to the meaning of the word.[5] The Bachelor of Business Economics (BBE) Program at University of Delhi is designed to meet the growing need for an analytical and quantitative approach to problem solving in the changing corporate world by the application of the latest techniques evolved in the fields of economics and business.[6]</p><p>The program at Harvard University uses economic methods to analyze practical aspects of business, including business administration, management, and related fields of business economics.[7]</p><p>The University of Miami defines business economics as involving the study of how we use our resources for the production, distribution, and consumption of goods and services. This requires business economists to analyze social institutions, banks, the stock market, the government and their relationships with labor negotiations, taxes, international trade, and urban and environmental issues.[8]</p><p>Courses at the University of Manchester interpret business economics to be concerned with the economic analysis of how businesses contribute to welfare of society rather than on the welfare of an individual or a business. This is done via an examination of the relationship between ownership, control and firm objectives; theories of the growth of the firm; the behavioural theory of the firm; theories of entrepreneurship; the factors that influence the structure, conduct and performance of business at the industry level.[9]</p><p>Italian Universities borrow their concept of business economics from the tradition of Gino Zappa, for example a standard course[10] at the Politecnico di Milano involves studying corporate governance, accounting, investment analysis, budgeting and business strategy.</p><p>La Trobe University of Melbourne, Australia associates business economics with the process of demand, supply and equilibrium coordinating the behaviour of individuals and businesses in the market. Also, business economics extends to government policy, economic variables and international factors which influence business and competition.</p><h2>Notes</h2><h2>Journals</h2><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Business_economics&amp;oldid=771210217"					
				Categories:  Hidden categories:</p><br><h1 lang="en">Mainstream economics</h1><p> From Wikipedia, the free encyclopedia</p><p>Mainstream economics is the body of knowledge, theories, and models of economics, as taught across prominent universities, that are widely accepted by scholars in the field. It can be contrasted to heterodox economics, which are various schools or approaches that are only accepted by their expositors, with little influence on the majority of academic economists. Mainstream economics has been associated with neoclassical economics[1] and with the neoclassical synthesis, which combines neoclassical methods and a Keynesian approach to macroeconomics.[2]</p><h2>Contents</h2><h2>United States</h2><p>In the United States, mainstream economists are not generally separated into schools, but two major contemporary economic schools of thought have been the saltwater and freshwater schools. In the early 1970s, so-called fresh-water economists challenged the prevailing consensus in macroeconomics research. Key elements of their approach were that macroeconomics had to be dynamic, quantitative, and based on how individuals and institutions make decisions under uncertainty. Many of the proponents of this radically new approach to macroeconomics were associated with Carnegie Mellon University, the University of Chicago, the University of Rochester and the University of Minnesota. They were referred to as the freshwater school since Pittsburgh, Chicago, Rochester, and Minneapolis are located nearer to the Great Lakes. The established consensus was primarily defended by economists at the universities and other institutions located near the east and west coast of the United States, such as Berkeley, Harvard, MIT, University of Pennsylvania, Princeton, Columbia, Stanford, and Yale. They were therefore often referred to as the saltwater schools. Today, mainstream economists do not, in general, identify themselves as members of a particular school.</p><h2>History</h2><p>Economics has always featured multiple schools of economic thought, with different schools having different prominence across countries and over time. The current use of the term mainstream economics is specific to the post–World War II era, particularly in the English-speaking world, and to a lesser extent globally.</p><p>Prior to the development of modern academic economics, the dominant school in Europe was mercantilism, which was rather a loose set of related ideas than an institutionalized school. With the development of modern economics, conventionally given as the late 18th-century The Wealth of Nations by Adam Smith, British economics developed and became dominated by what is now called the classical school. From The Wealth of Nations until the Great Depression, the dominant school within the English-speaking world was classical economics, and its successor, neoclassical economics.[3] In continental Europe, the earlier work of the physiocrats in France formed a distinct tradition, as did the later work of the historical school of economics in Germany, and throughout the 19th century there were debates in British economics, notably the opposition underconsumptionist school.</p><div class='pageBreak' ></div><p>During the Great Depression and the following Second World War, the school of Keynesian economics gained prominence, which built on the work of the underconsumptionist school, and present-day mainstream economics stems from the neoclassical synthesis, which was the post–World War II merger of Keynesian macroeconomics and neoclassical microeconomics.</p><p>In continental Europe, by contrast, Keynesian economics was rejected, with German thought dominated by the Freiburg school, whose political philosophy of ordoliberalism formed the intellectual basis of Germany's post-war social market economy. Within developing economies, which formed the majority of the world's population, various schools of development economics have been influential.</p><p>Since 2007, the financial crisis of 2007–2010 and the ensuing global economic crisis has publicly exposed divisions within mainstream economics and significantly intensified controversy about its status, with some arguing for radical overhaul or rejection of mainstream economics, others arguing for evolutionary change, and others still arguing that mainstream economics explains the crisis.[4]</p><h3>Term</h3><p>The term mainstream economics came into common use in the late 20th century. It appears in 2001 edition of the seminal textbook Economics by Samuelson and Nordhaus[5] on the inside back cover in the Family Tree of Economics, which depicts arrows into Modern Mainstream Economics from J.M. Keynes (1936) and neoclassical economics (1860–1910). The term neoclassical synthesis itself also first appears in the 1955 edition of Samuelson's textbook.[6]</p><h2>Scope</h2><p>Mainstream economics can be defined, as distinct from other schools of economics, by various criteria, notably by its assumptions, its methods, and its topics.</p><h3>Assumptions</h3><p>A number of assumptions may underpin many mainstream economic models, while being rejected by some heterodox schools. These include the neoclassical assumptions of rational choice theory, a representative agent, and, often, rational expectations. Much of modern economic modelling consists of exploring the effects that complicating factors have on models, such as imperfect and asymmetric information, incomplete markets, imperfect competition and transaction costs.</p><p>The starting point of orthodox economic analysis is the individual. People are generally defined as units with a common goal: maximisation through rational behaviour. The only differences consist of:</p><p>From this theoretical framework, orthodox economists derive that political action should not be used to solve the problems of the economic system. Instead, the solution ought to derive from an intervention on the above-mentioned maximisation objectives and constraints. It is in this context that economic capitalism finds its justification. Capitalism and its arguments seem logical because orthodox economics theories think of the aggregate economy as the sum of the agents trying to maximise their utility or profit through exchange.[7]</p><h3>Methods</h3><p>Mainstream economics has also been defined methodologically as work which mainstream economists are willing to engage, which requires conforming to the mainstream language of mathematical models,[8] featuring calculus, optimization, and comparative statics. Under this definition, areas of thought which are typically thought of as heterodox because they do not work under the typical neoclassical assumptions, such as econophysics, behavioral economics, and evolutionary economics, can be considered mainstream when they are engaged in the mainstream, using mainstream methods.[8] Geoffrey Hodgson has considered the possibility that evolutionary economics and institutional economics may eventually become a new mainstream.[9]</p><p>Additionally, some economic fields include elements of both mainstream economics and heterodox economics: for example, the Austrian economics[how?],[10] institutional economics, neuroeconomics and non-linear complexity theory.[11] They may use neoclassical economics as a point of departure. At least one institutionalist has argued that neoclassical economics no longer dominates a mainstream economics.[12]</p><p>A countervailing trend is the expansion of mainstream methods to such seemingly distant fields as crime, the family, law, politics, and religion. The latter phenomenon is sometimes referred to as economic imperialism.[13]</p><h3>Topics</h3><p>Mainstream economics includes theories of market and government failure and private and public goods. These developments suggest a range of views on the desirability or otherwise of government intervention.</p><h2>Criticisms</h2><p>Since the financial crisis of 2007–2010, considerable conflict has arisen, among both economic theorists and a wider cross-section of the public, regarding the status and future of mainstream economics.[4][14] Some critics have argued that potentially promising approaches have been excluded in major mainstream publications by a focus on problems amenable to formal modeling.[15][16]</p><p>Chartalists, who are generally considered part of the Post-Keynesian school of thought, criticise mainstream theory as failing to describe the actual mechanics of modern fiat monetary economies. Chartalism focuses on a detailed understanding of the way money actually flows through the different sectors of an economy. Specifically, Chartalism focuses on the interaction between central banks, treasury and the private banking system. Chartalism rejects critical mainstream theories such as the loanable funds market, the money multiplier, and the utility of fiscal austerity.</p><p>Some economists, in the vein of ecological economics, believe that the neoclassical holy trinity of rationality, greed, and equilibrium, is being replaced by the holy trinity of purposeful behavior, enlightened self-interest, and sustainability, considerably broadening the scope of what is mainstream.[8] Ecological economics addresses sustainability issues, such as public goods, natural capital and negative externalities (such as pollution).[17]</p><p>Energy related theories of economic concepts also exist within energy economics relating to thermodynamic concepts of economic thinking, such as energy accounting.[18] Biophysical economics relates to this area.[19]</p><h3>Survey articles</h3><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Mainstream_economics&amp;oldid=783714535"					
				Categories:  Hidden categories:</p><br><h1 lang="en">Green economy</h1><p> From Wikipedia, the free encyclopedia</p><p>The green economy is defined as an economy that aims at reducing environmental risks and ecological scarcities, and that aims for sustainable development without degrading the environment. It is closely related with ecological economics, but has a more politically applied focus.[1][2] The 2011 UNEP Green Economy Report argues that to be green, an economy must not only be efficient, but also fair. Fairness implies recognising global and country level equity dimensions, particularly in assuring a just transition to an economy that is low-carbon, resource efficient, and socially inclusive. [3]</p><div class='pageBreak' ></div><p>A feature distinguishing it from prior economic regimes is the direct valuation of natural capital and ecological services as having economic value (see The Economics of Ecosystems and Biodiversity and Bank of Natural Capital) and a full cost accounting regime in which costs externalized onto society via ecosystems are reliably traced back to, and accounted for as liabilities of, the entity that does the harm or neglects an asset.[4]</p><p>Green Sticker and ecolabel practices have emerged as consumer facing measurements of friendliness to the environment and sustainable development. Many industries are starting to adopt these standards as a viable way to promote their greening practices in a globalizing economy.</p><h2>Contents</h2><h2>Green economists and economics</h2><p>Green economics is loosely defined as any theory of economics by which an economy is considered to be component of the ecosystem in which it resides (after Lynn Margulis). A holistic approach to the subject is typical, such that economic ideas are commingled with any number of other subjects, depending on the particular theorist. Proponents of feminism, postmodernism, the ecology movement, peace movement, Green politics, green anarchism and anti-globalization movement have used the term to describe very different ideas, all external to some equally ill-defined mainstream economics.[citation needed]</p><p>The use of the term is further ambiguated by the political distinction of Green parties which are formally organized and claim the capital-G Green term as a unique and distinguishing mark. It is thus preferable to refer to a loose school of 'green economists' who generally advocate shifts towards a green economy, biomimicry and a fuller accounting for biodiversity. (see The Economics of Ecosystems and Biodiversity especially for current authoritative international work towards these goals and Bank of Natural Capital for a layperson's presentation of these.)[citation needed]</p><p>Some economists view green economics as a branch or subfield of more established schools. For instance, it is regarded as classical economics where the traditional land is generalized to natural capital and has some attributes in common with labor and physical capital (since natural capital assets like rivers directly substitute for man-made ones such as canals). Or, it is viewed as Marxist economics with nature represented as a form of Lumpenproletariat, an exploited base of non-human workers providing surplus value to the human economy, or as a branch of neoclassical economics in which the price of life for developing vs. developed nations is held steady at a ratio reflecting a balance of power and that of non-human life is very low.[citation needed]</p><p>An increasing commitment by the UNEP (and national governments such as the UK) to the ideas of natural capital and full cost accounting under the banner 'green economy' could blur distinctions between the schools and redefine them all as variations of green economics. As of 2010 the Bretton Woods institutions (notably the World Bank[5] and International Monetary Fund (via its Green Fund initiative) responsible for global monetary policy have stated a clear intention to move towards biodiversity valuation and a more official and universal biodiversity finance.[citation needed] Taking these into account targeting not less but radically zero emission and waste is what is promoted by the Zero Emissions Research and Initiatives.[citation needed] The UNEP 2011 Green Economy Report informs that [b]ased on existing studies, the annual financing demand to green the global economy was estimated to be in the range US$ 1.05 to US$ 2.59 trillion. To place this demand in perspective, it is about one-tenth of total global investment per year, as measured by global Gross Capital Formation. [3]</p><h2>Definition</h2><p>Karl Burkart defines a green economy as based on six main sectors:[6]</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/7/70/Sustainable_development.svg/300px-Sustainable_development.svg.png" width="300" height="191" usemap="#ImageMap_1_1484116788"><p>The International Chamber of Commerce (ICC) representing global business defines green economy as “an economy in which economic growth and environmental responsibility work together in a mutually reinforcing fashion while supporting progress on social development”.[7][8]</p><p>In 2012, the ICC published the Green Economy Roadmap, containing contributions from experts from around the globe brought together in a two-year consultation process. The Roadmap represents a comprehensive and multidisciplinary effort to clarify and frame the concept of “green economy”. It highlights the essential role of business in bringing solutions to common global challenges. It sets out the following 10 conditions which relate to business/intra-industry and collaborative action for a transition towards a green economy:</p><h2>Ecological measurements</h2><p>Measuring economic output and progress is done through the use of economic index indicators. Green indices emerged from the need to measure human ecological impact, efficiency sectors like transport, energy, buildings and tourism, as well as the investment flows targeted to areas like renewable energy and cleantech innovation.</p><li>2010 - 2016 Global Green Economy Index™ (GGEI),[9] published by consultancy Dual Citizen LLC is in its 5th edition. It measures the green economic performance and perceptions of it in 80 countries and 50 cities along four main dimensions of leadership &amp; climate change, efficiency sectors, markets &amp; investment and the environment.</li><li>2009 - 2012 Green City Index [10] A global study commissioned by Siemens</li><li>2009 - 2013 Circles of Sustainability project scored 5 cities in 5 separate countries.</li><p>Ecological footprint measurements are a way to gauge anthropogenic impact and are another standard used by municipal governments.[11]</p><h2>Green energy issues</h2><p>Green economies require green energy generation based on renewable energy to replace fossil fuels as well as energy conservation and efficient energy use.[citation needed]</p><p>There is justification for market failure to respond to environmental protection and climate protection needs with the excuse that high external costs and high initial costs for research, development, and marketing of green energy sources and green products prevents firms from voluntarily reducing their ecological footprints.[12] The green economy may need government subsidies as market incentives to motivate firms to invest and produce green products and services. The German Renewable Energy Act, legislations of many other member states of the European Union and the American Recovery and Reinvestment Act of 2009, all provide such market incentives.[citation needed] However, other experts[13] argue that green strategies can be highly profitable for corporations that understand the business case for sustainability and can market green products and services beyond the traditional green consumer.</p><div class='pageBreak' ></div><h2>Criticisms</h2><p>A number of organisations and individuals have criticised aspects of the 'Green Economy', particularly the mainstream conceptions of it based on using price mechanisms to protect nature, arguing that this will extend corporate control into new areas from forestry to water. The research organisation ETC Group argues that the corporate emphasis on bio-economy will spur even greater convergence of corporate power and unleash the most massive resource grab in more than 500 years.[14] Venezuelan professor Edgardo Lander says that the UNEP's report, Towards a Green Economy,[15] while well-intentioned ignores the fact that the capacity of existing political systems to establish regulations and restrictions to the free operation of the markets – even when a large majority of the population call for them – is seriously limited by the political and financial power of the corporations.[16] Ulrich Hoffmann, in a paper for UNCTAD also says that the focus on Green Economy and green growth in particular, based on an evolutionary (and often reductionist) approach will not be sufficient to cope with the complexities of climate change and may rather give much false hope and excuses to do nothing really fundamental that can bring about a U-turn of global greenhouse gas emissions.[17] Clive Spash, an ecological economist, has criticised the use of economic growth to address environmental losses,[18] and argued that the Green Economy, as advocated by the UN, is not a new approach at all and is actually a diversion from the real drivers of environmental crisis.[19] He has also criticised the UN's project on the economics of ecosystems and biodiversity (TEEB),[20] and the basis for valuing ecosystems services in monetary terms.[21]</p><h2>Notes and references</h2><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Green_economy&amp;oldid=781971723"					
				Categories:  Hidden categories:</p><br><p>Michael Grossman's 1972 model of health production[8] has been extremely influential in this field of study and has several unique elements that make it notable. Grossman's model views each individual as both a producer and a consumer of health. Health is treated as a stock which degrades over time in the absence of investments in health, so that health is viewed as a sort of capital. The model acknowledges that health is both a consumption good that yields direct satisfaction and utility, and an investment good, which yields satisfaction to consumers indirectly through fewer sick days. Investment in health is costly as consumers must trade off time and resources devoted to health, such as exercising at a local gym, against other goals. These factors are used to determine the optimal level of health that an individual will demand. The model makes predictions over the effects of changes in prices of healthcare and other goods, labour market outcomes such as employment and wages, and technological changes. These predictions and other predictions from models extending Grossman's 1972 paper form the basis of much of the econometric research conducted by health economists.</p><p>In Grossman's model, the optimal level of investment in health occurs where the marginal cost of health capital is equal to the marginal benefit. With the passing of time, health depreciates at some rate d. The interest rate faced by the consumer is denoted by r. The marginal cost of health capital can be found by adding these variables: 
  
    
      
        M
        
          C
          
            H
            K
          
        
        =
        r
        +
        d
        
      
    
    {\displaystyle MC_{HK}=r+\delta \,}
  
. The marginal benefit of health capital is the rate of return from this capital in both market and non-market sectors. In this model, the optimal health stock can be impacted by factors like age, wages and education. As an example, 
  
    
      
        d
        
      
    
    {\displaystyle \delta \,}
  
 increases with age, so it becomes more and more costly to attain the same level of health capital or health stock as one ages. Age also decreases the marginal benefit of health stock. The optimal health stock will therefore decrease as one ages.</p><p>Beyond issues of the fundamental, real demand for medical care derived from the desire to have good health (and thus influenced by the production function for health) is the important distinction between the marginal benefit of medical care (which is always associated with this real demand curve based on derived demand), and a separate effective demand curve, which summarizes the amount of medical care demanded at particular market prices. Because most medical care is not purchased from providers directly, but is rather obtained at subsidized prices due to insurance, the out-of-pocket prices faced by consumers are typically much lower than the market price. The consumer sets MB=MC out of pocket, and so the effective demand will have a separate relationship between price and quantity than will the marginal benefit curve or real demand relationship. This distinction is often described under the rubric of ex-post moral hazard (which is again distinct from ex-ante moral hazard, which is found in any type of market with insurance).</p><h2>Health technology assessment</h2><p>Economic evaluation, and in particular cost-effectiveness analysis, has become a fundamental part of technology appraisal processes for agencies in a number of countries. The Institute for Quality and Economy in Health Services (Institut für Qualität und Wirtschaftlichkeit im Gesundheitswesen – IQWiG) in Germany and the National Institute for Health and Care Excellence (NICE) in the United Kingdom, for example, both consider the cost-effectiveness of new pharmaceuticals entering the market.</p><p>Some agencies, including NICE, recommend the use of cost–utility analysis (CUA). This approach measures outcomes in a composite metric of both length and quality of life, the Quality-adjusted life year (QALY).</p><h2>Healthcare markets</h2><p>The five health markets typically analyzed are:</p><p>Although assumptions of textbook models of economic markets apply reasonably well to healthcare markets, there are important deviations. Many states have created risk pools in which relatively healthy enrollees subsidise the care of the rest. Insurers must cope with adverse selection which occurs when they are unable to fully predict the medical expenses of enrollees; adverse selection can destroy the risk pool. Features of insurance market risk pools, such as group purchases, preferential selection (cherry-picking), and preexisting condition exclusions are meant to cope with adverse selection.</p><p>Insured patients are naturally less concerned about healthcare costs than they would if they paid the full price of care. The resulting moral hazard drives up costs, as shown by the famous RAND Health Insurance Experiment. Insurers use several techniques to limit the costs of moral hazard, including imposing copayments on patients and limiting physician incentives to provide costly care. Insurers often compete by their choice of service offerings, cost sharing requirements, and limitations on physicians.</p><p>Consumers in healthcare markets often suffer from a lack of adequate information about what services they need to buy and which providers offer the best value proposition. Health economists have documented a problem with supplier induced demand, whereby providers base treatment recommendations on economic, rather than medical criteria. Researchers have also documented substantial practice variations, whereby the treatment also on service availability to rein in inducement and practice variations.</p><p>Some economists argue that requiring doctors to have a medical license constrains inputs, inhibits innovation, and increases cost to consumers while largely only benefiting the doctors themselves.[9]</p><h2>Other issues</h2><h3>Medical economics</h3><p>Often used synonymously with health economics, medical economics, according to Culyer,[10] is the branch of economics concerned with the application of economic theory to phenomena and problems associated typically with the second and third health market outlined above. Typically, however, it pertains to cost–benefit analysis of pharmaceutical products and cost-effectiveness of various medical treatments. Medical economics often uses mathematical models to synthesise data from biostatistics and epidemiology for support of medical decision-making, both for individuals and for wider health policy.</p><h3>Behavioral economics</h3><div class='pageBreak' ></div><p>Peter Orszag has suggested that behavioral economics is an important factor for improving the healthcare system, but that relatively little progress has been made when compared to retirement policy.[11]</p><h3>Mental health economics</h3><p>Mental health economics incorporates a vast array of subject matters, ranging from pharmacoeconomics to labor economics and welfare economics. Mental health can be directly related to economics by the potential of affected individuals to contribute as human capital. In 2009 Currie and Stabile published Mental Health in Childhood and Human Capital in which they assessed how common childhood mental health problems may alter the human capital accumulation of affected children.[12] Externalities may include the influence that affected individuals have on surrounding human capital, such as at the workplace or in the home.[13] In turn, the economy also affects the individual, particularly in light of globalization. For example, studies in India, where there is an increasingly high occurrence of western outsourcing, have demonstrated a growing hybrid identity in young professionals who face very different sociocultural expectations at the workplace and in at home.[14]</p><p>Mental health economics presents a unique set of challenges to researchers. Individuals with cognitive disabilities may not be able to communicate preferences. These factors represent challenges in terms of placing value on the mental health status of an individual, especially in relation to the individual's potential as human capital. Further, employment statistics are often used in mental health economic studies as a means of evaluating individual productivity; however, these statistics do not capture presenteeism, when an individual is at work with a lowered productivity level, quantify the loss of non-paid working time, or capture externalities such as having an affected family member. Also, considering the variation in global wage rates or in societal values, statistics used may be contextually, geographically confined, and study results may not be internationally applicable.[13]</p><p>Though studies have demonstrated mental healthcare to reduce overall healthcare costs, demonstrate efficacy, and reduce employee absenteeism while improving employee functioning, the availability of comprehensive mental health services is in decline. Petrasek and Rapin (2002) cite the three main reasons for this decline as (1) stigma and privacy concerns, (2) the difficulty of quantifying medical savings and (3) physician incentive to medicate without specialist referral.[15] Evers et al. (2009) have suggested that improvements could be made by promoting more active dissemination of mental health economic analysis, building partnerships through policy-makers and researchers, and employing greater use of knowledge brokers.[13]</p><h2>Journals</h2><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Health_economics&amp;oldid=783361465"					
				Categories:  Hidden categories:</p><br><h1 lang="en">Public choice</h1><p> From Wikipedia, the free encyclopedia</p><p>Public choice or public choice theory refers to the use of economic tools to deal with traditional problems of political science.[1] Its content includes the study of political behavior. In political science, it is the subset of positive political theory that studies self-interested agents (voters, politicians, bureaucrats) and their interactions, which can be represented in a number of ways – using (for example) standard constrained utility maximization, game theory, or decision theory.[1] Public-choice analysis has roots in positive analysis (what is) but is often used for normative purposes (what ought to be) in order to identify a problem or to suggest improvements to constitutional rules (i.e., constitutional economics).[1][2][3]</p><p>The Journal of Economic Literature's classification code regards public choice as a subarea of microeconomics, under JEL: D7: Analysis of Collective Decision-Making (specifically, JEL: D72: Economic Models of Political Processes: Rent-Seeking, Elections, Legislatures, and Voting Behavior).[4] Public choice theory is also closely related to social-choice theory, a mathematical approach to aggregation of individual interests, welfares, or votes.[5] Much early work had aspects of both, and both fields use the tools of economics and game theory. Since voter behavior influences the behavior of public officials, public-choice theory often uses results from social-choice theory. General treatments of public choice may also be classified under public economics.[6]</p><h2>Contents</h2><h2>Background and development</h2><p>A precursor of modern public choice theory was the work of Knut Wicksell (1896),[7] which treated government as political exchange, a quid pro quo, in formulating a benefit principle linking taxes and expenditures.[8]</p><p>Some subsequent economic analysis has been described as treating government as though it attempted to maximize some kind sort of welfare function for society and as distinct from characterizations of economic agents, such as those in business.[1] In contrast, public choice theory modeled government as made up of officials who, besides pursuing the public interest, might act to benefit themselves, for example in the budget-maximizing model of bureaucracy, possibly at the cost of efficiency.[1][9]</p><p>Modern public-choice theory has been dated from the work of Duncan Black, sometimes called the founding father of public choice.[10] In a series of papers from 1948, which culminated in The Theory of Committees and Elections (1958),[11] and later, Black outlined a program of unification toward a more general Theory of Economic and Political Choices based on common formal methods,[12] developed underlying concepts of what would become median voter theory, and rediscovered earlier works on voting theory.[13][1][14]</p><p>Kenneth J. Arrow's Social Choice and Individual Values (1951) influenced formulation of the theory. Among other important works are Anthony Downs (1957) An Economic Theory of Democracy and Mancur Olson (1965) The Logic of Collective Action.[15]</p><p>James M. Buchanan and Gordon Tullock coauthored The Calculus of Consent: Logical Foundations of Constitutional Democracy (1962), considered one of the landmarks in public choice. In particular, the preface describes the book as about the political organization of a free society. But its methodology, conceptual apparatus, and analytics are derived, essentially, from the discipline that has as its subject the economic organization of such a society (1962, p. v). The book focuses on positive-economic analysis as to the development of constitutional democracy but in an ethical context of consent. The consent takes the form of a compensation principle like Pareto efficiency for making a policy change and unanimity or at least no opposition as a point of departure for social choice.</p><p>Somewhat later, the probabilistic voting theory started to displace the median voter theory in showing how to find Nash equilibria in multidimensional space. The theory was later formalized further by Peter Coughlin.[16]</p><h2>Decision-making processes and the state</h2><p>One way to organize the subject matter studied by public choice theorists is to begin with the foundations of the state itself. According to this procedure, the most fundamental subject is the origin of government. Although some work has been done on anarchy, autocracy, revolution, and even war, the bulk of the study in this area has concerned the fundamental problem of collectively choosing constitutional rules. This work assumes a group of individuals who aim to form a government, then it focuses on the problem of hiring the agents required to carry out government functions agreed upon by the members.[citation needed]</p><h2>Expressive interests and democratic irrationality</h2><p>Geoffrey Brennan and Loren Lomasky claim that democratic policy is biased to favor expressive interests and neglect practical and utilitarian considerations. Brennan and Lomasky differentiate between instrumental interests (any kind of practical benefit, both monetary and non-monetary) and expressive interests (forms of expression like applause). According to Brennan and Lomasky, the voting paradox can be resolved by differentiating between expressive and instrumental interests.</p><div class='pageBreak' ></div><p>This argument has led some public choice scholars to claim that politics is plagued by irrationality. In articles published in the Econ Journal Watch, economist Bryan Caplan contended that voter choices and government economic decisions are inherently irrational.[17][18] Caplan's ideas are more fully developed in his book The Myth of the Rational Voter (Princeton University Press 2007). Countering Donald Wittman's arguments in The Myth of Democratic Failure, Caplan claims that politics is biased in favor of irrational beliefs.</p><p>According to Caplan, democracy effectively subsidizes irrational beliefs. Anyone who derives utility from potentially irrational policies like protectionism can receive private benefits while imposing the costs of such beliefs on the general public. Were people to bear the full costs of their irrational beliefs, they would lobby for them optimally, taking into account both their instrumental consequences and their expressive appeal. Instead, democracy oversupplies policies based on irrational beliefs. Caplan defines rationality mainly in terms of mainstream price theory, pointing out that mainstream economists tend to oppose protectionism and government regulation more than the general population, and that more educated people are closer to economists on this score, even after controlling for confounding factors such as income, wealth or political affiliation. One criticism is that many economists do not share Caplan's views on the nature of public choice. However, Caplan does have data to support his position. Economists have, in fact, often been frustrated by public opposition to economic reasoning. As Sam Peltzman puts it:</p><p>Economists know what steps would improve the efficiency of HSE [health, safety, and environmental] regulation, and they have not been bashful advocates of them. These steps include substituting markets in property rights, such as emission rights, for command and control...The real problem lies deeper than any lack of reform proposals or failure to press them. It is our inability to understand their lack of political appeal.[19]</p><p>Public choice's application to government regulation was developed by George Stigler (1971) and Sam Peltzman (1976).</p><h2>Special interests</h2><p>Public choice theory is often used to explain how political decision-making results in outcomes that conflict with the preferences of the general public. For example, many advocacy group and pork barrel projects are not the desire of the overall democracy. However, it makes sense for politicians to support these projects. It may make them feel powerful and important. It can also benefit them financially by opening the door to future wealth as lobbyists. The project may be of interest to the politician's local constituency, increasing district votes or campaign contributions. The politician pays little or no cost to gain these benefits, as he is spending public money. Special-interest lobbyists are also behaving rationally. They can gain government favors worth millions or billions for relatively small investments. They face a risk of losing out to their competitors if they don't seek these favors. The taxpayer is also behaving rationally. The cost of defeating any one government give-away is very high, while the benefits to the individual taxpayer are very small. Each citizen pays only a few pennies or a few dollars for any given government favor, while the costs of ending that favor would be many times higher. Everyone involved has rational incentives to do exactly what they are doing, even though the desire of the general constituency is opposite. Costs are diffused, while benefits are concentrated. The voices of vocal minorities with much to gain are heard over those of indifferent majorities with little to individually lose.[20][21] However the notion that groups with concentrated interests will dominate politics is incomplete because it is only one half of political equilibrium. Something must incite those preyed upon to resist even the best organized concentrated interests. In his article on interest groups Gary Becker identified this countervailing force as being the deadweight loss from predation. His views capped what has come to be known as the Chicago school of political economy and it has come in sharp conflict with the so-called Virginia faction of public choice due to its assertion that politics will tend towards efficiency due to nonlinear deadweight losses and due to its claim that political efficiency renders policy advice irrelevant.[22]</p><p>While good government tends to be a pure public good for the mass of voters, there may be many advocacy groups that have strong incentives for lobbying the government to implement specific policies that would benefit them, potentially at the expense of the general public. For example, lobbying by the sugar manufacturers might result in an inefficient subsidy for the production of sugar, either direct or by protectionist measures. The costs of such inefficient policies are dispersed over all citizens, and therefore unnoticeable to each individual. On the other hand, the benefits are shared by a small special-interest group with a strong incentive to perpetuate the policy by further lobbying. Due to rational ignorance, the vast majority of voters will be unaware of the effort; in fact, although voters may be aware of special-interest lobbying efforts, this may merely select for policies which are even harder to evaluate by the general public, rather than improving their overall efficiency. Even if the public were able to evaluate policy proposals effectively, they would find it infeasible to engage in collective action in order to defend their diffuse interest. Therefore, theorists expect that numerous special interests will be able to successfully lobby for various inefficient policies. In public choice theory, such scenarios of inefficient government policies are referred to as government failure – a term akin to market failure from earlier theoretical welfare economics.[20]</p><h2>Rent-seeking</h2><p>A field that is closely related to public choice is rent-seeking. This field combines the study of a market economy with that of government. Thus, one might regard it as a new political economy. Its basic thesis is that when both a market economy and government are present, government agents provide numerous special market privileges. Both the government agents and self-interested market participants seek these privileges in order to partake in the resulting monopoly rent. Rentiers gain benefits above what the market would have offered, but in the process allocate resources in sub-optimal fashion from a societal point of view.</p><p>Rent-seeking is broader than public choice in that it applies to autocracies as well as democracies and, therefore, is not directly concerned with collective decision making. However, the obvious pressures it exerts on legislators, executives, bureaucrats, and even judges are factors that public choice theory must account for in its analysis of collective decision-making rules and institutions. Moreover, the members of a collective who are planning a government would be wise to take prospective rent-seeking into account.[21]</p><p>Another major claim is that much of political activity is a form of rent-seeking which wastes resources. Gordon Tullock, Jagdish Bhagwati, and Anne Osborn Krueger have argued that rent-seeking has caused considerable waste.[21] In a parallel line of research Fred McChesney claims that rent extraction causes considerable waste, especially in the developing world. As the term implies, rent extraction happens when officials use threats to extort payments from private parties.</p><h2>Bureaucracy</h2><p>Another major sub-field is the study of bureaucracy. The usual model depicts the top bureaucrats as being chosen by the chief executive and legislature, depending on whether the democratic system is presidential or parliamentary. The typical image of a bureau chief is a person on a fixed salary who is concerned with pleasing those who appointed him. The latter have the power to hire and fire him more or less at will. The bulk of the bureaucrats, however, are civil servants whose jobs and pay are protected by a civil service system against major changes by their appointed bureau chiefs. This image is often compared with that of a business owner whose profit varies with the success of production and sales, who aims to maximize profit, and who can in an ideal system hire and fire employees at will.[9] William Niskanen is generally considered the founder of public choice literature on the bureaucracy.[9]</p><h2>Political stance</h2><p>From such results it is sometimes asserted that public choice theory has an anti-state tilt. But there is ideological diversity among public choice theorists. Mancur Olson for example was an advocate of a strong state and instead opposed political interest group lobbying.[15] More generally, James Buchanan has suggested that public choice theory be interpreted as politics without romance, a critical approach to a pervasive earlier notion of idealized politics set against market failure.[23]</p><p>The British journalist, Alistair Cooke, commenting on the Nobel Prize awarded to James M. Buchanan in 1986, reportedly summarized the public choice view of politicians by saying, Public choice embodies the homely but important truth that politicians are, after all, no less selfish than the rest of us.[24]</p><div class='pageBreak' ></div><h2>Recognition</h2><p>Several notable public choice scholars have been awarded the Nobel Prize in Economics, including James M. Buchanan (1986), George Stigler (1982), Gary Becker (1992), Vernon Smith (2002) and Elinor Ostrom (2009). In addition, Vernon Smith and Elinor Ostrom were former presidents of the Public Choice Society.[25]</p><h2>Criticisms</h2><p>In their 1994 book Pathologies of Rational Choice Theory, political scientists Donald P. Green and Ian Shapiro argue that rational choice theory (of which public choice theory is a branch) has contributed less to the field than its popularity suggests.[26] They write:</p><p>Linda McQuaig writes in All You Can Eat:[citation needed]</p><p>Amartya Sen has acknowledged the contribution of Buchanan and Tullock's analysis of unanimity as a criterion for collective choice,[28] but argued for the logical inconsistency of the Pareto-principle version of unanimity with even minimal liberty in a social-choice framework.[29] More broadly he qualified its use when other information besides personal utility is given a weight in public judgments.[30]</p><p>Buchanan and Tullock themselves outline methodological qualifications of the approach developed in their work The Calculus of Consent (1962), p. 30:</p><p>The reach of public choice theory might be even wider than Buchanan and Tullock indicate. Some theory shows that relaxing the assumption of self-interest leaves many public choice problems in place (although sometimes in altered from). As long as political actors are rational maximizers who disagree about the objectives government should pursue, public choice problems persist even if the disagreement stems from adherence to competing ethical principles rather than from competing self-interested wants.[31]</p><h3>New Ideas and Policy Innovation rather than Self Interest</h3><p>Another criticism suggests that some of the great developments in politics and policy have not been a product of individual actor's vested self interests, but rather because of new ideas. New ideas, by virtue of being innovative, expand the policy choices on the menu outside of simple vested interests and allow for equilibriums which were previously not possible. Dani Rodrik of the Harvard Kennedy School provides several examples of this phenomenon, where both Elites and Non-Elites were made better off through policy innovation, or in the case of the democratization of South Africa, making commitments to avoid Hold-up problems.[32]</p><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Public_choice&amp;oldid=780790157"					
				Categories:  Hidden categories:</p><br><h1 lang="en">Institutional economics</h1><p> From Wikipedia, the free encyclopedia</p><p>Institutional economics focuses on understanding the role of the evolutionary process and the role of institutions in shaping economic behaviour. Its original focus lay in Thorstein Veblen's instinct-oriented dichotomy between technology on the one side and the ceremonial sphere of society on the other. Its name and core elements trace back to a 1919 American Economic Review article by Walton H. Hamilton.[1][2]</p><p>Institutional economics emphasizes a broader study of institutions and views markets as a result of the complex interaction of these various institutions (e.g. individuals, firms, states, social norms). The earlier tradition continues today as a leading heterodox approach to economics.[3]</p><p>A significant variant is the new institutional economics from the later 20th century, which integrates later developments of neoclassical economics into the analysis. Law and economics has been a major theme since the publication of the Legal Foundations of Capitalism by John R. Commons in 1924. Since then, there is heated debate on the role of law (formal institution) on economic growth.[4] Behavioral economics is another hallmark of institutional economics based on what is known about psychology and cognitive science, rather than simple assumptions of economic behavior.</p><p>Institutional economics focuses on learning, bounded rationality, and evolution (rather than assume stable preferences, rationality and equilibrium). It was a central part of American economics in the first part of the 20th century, including such famous but diverse economists as Thorstein Veblen, Wesley Mitchell, and John R. Commons.[5] Some institutionalists see Karl Marx as belonging to the institutionalist tradition, because he described capitalism as a historically-bounded social system; other institutionalist economists[who?] disagree with Marx's definition of capitalism, instead seeing defining features such as markets, money and the private ownership of production as indeed evolving over time, but as a result of the purposive actions of individuals.</p><p>Traditional institutionalism rejects the reduction of institutions to simply tastes, technology, and nature (see naturalistic fallacy).[6] Tastes, along with expectations of the future, habits, and motivations, not only determine the nature of institutions but are limited and shaped by them. If people live and work in institutions on a regular basis, it shapes their world-views. Fundamentally, this traditional institutionalism (and its modern counterpart institutionalist political economy) emphasizes the legal foundations of an economy (see John R. Commons) and the evolutionary, habituated, and volitional processes by which institutions are erected and then changed (see John Dewey, Thorstein Veblen, and Daniel Bromley.)</p><p>The vacillations of institutions are necessarily a result of the very incentives created by such institutions, and are thus endogenous. Emphatically, traditional institutionalism is in many ways a response to the current economic orthodoxy; its reintroduction in the form of institutionalist political economy is thus an explicit challenge to neoclassical economics, since it is based on the fundamental premise that neoclassicists oppose: that economics cannot be separated from the political and social system within which it is embedded.</p><p>Some of the authors associated with this school include Robert H. Frank, Warren Samuels, Mark Tool, Geoffrey Hodgson, Daniel Bromley, Jonathan Nitzan, Shimshon Bichler, Elinor Ostrom, Anne Mayhew, John Kenneth Galbraith and Gunnar Myrdal, but even the sociologist C. Wright Mills was highly influenced by the institutionalist approach in his major studies.</p><h2>Contents</h2><div class='pageBreak' ></div><h2>Thorstein Veblen</h2><p> Main articles: Thorstein Veblen and The Theory of the Leisure Class</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/e/e9/Veblen3a.jpg/220px-Veblen3a.jpg" width="220" height="288"><p>


Thorstein Veblen came from a Norwegian immigrant family in rural Mid-western America.


</p><p>
	Thorstein Veblen (1857–1929) wrote his first and most influential book while he was at the University of Chicago, on The Theory of the Leisure Class (1899).[7] In it he analyzed the motivation in capitalism to conspicuously consume their riches as a way of demonstrating success. Conspicuous leisure was another focus of Veblen's critique. The concept of conspicuous consumption was in direct contradiction to the neoclassical view that capitalism was efficient.</p><p>In The Theory of Business Enterprise (1904) Veblen distinguished the motivations of industrial production for people to use things from business motivations that used, or misused, industrial infrastructure for profit, arguing that the former is often hindered because businesses pursue the latter. Output and technological advance are restricted by business practices and the creation of monopolies. Businesses protect their existing capital investments and employ excessive credit, leading to depressions and increasing military expenditure and war through business control of political power. These two books, focusing on criticism first of consumerism, and second of profiteering, did not advocate change.</p><p>Through the 1920s and after the Wall Street Crash of 1929 Thorstein Veblen's warnings of the tendency for wasteful consumption and the necessity of creating sound financial institutions seemed to ring true. Veblen remains a leading critic, which cautions against the excesses of the American way.</p><p>Thorstein Veblen wrote in 1898 an article entitled Why is Economics Not an Evolutionary Science[8] and he became the precursor of current evolutionary economics.</p><h2>John R. Commons</h2><p> Main article: John R. Commons</p><p>John R. Commons (1862–1945) also came from mid-Western America. Underlying his ideas, consolidated in Institutional Economics (1934) was the concept that the economy is a web of relationships between people with diverging interests. There are monopolies, large corporations, labour disputes and fluctuating business cycles. They do however have an interest in resolving these disputes.</p><p>Commons thought that government should be the mediator between the conflicting groups. Commons himself devoted much of his time to advisory and mediation work on government boards and industrial commissions.</p><h2>Wesley Mitchell</h2><p> Main article: Wesley Mitchell</p><p>Wesley Clair Mitchell (August 5, 1874 – October 29, 1948) was an American economist known for his empirical work on business cycles and for guiding the National Bureau of Economic Research in its first decades. Mitchell’s teachers included economists Thorstein Veblen and J. L. Laughlin and philosopher John Dewey.</p><h2>Clarence Ayres</h2><p> Main article: Clarence Edwin Ayres</p><p>Clarence Ayres (May 6, 1891 – July 24, 1972) was the principal thinker of what some has called the Texas school of institutional economics. Ayres developed on the ideas of Thorstein Veblen with a dichotomy of technology and institutions to separate the inventive from the inherited aspects of economic structures. He claimed that technology was always one step ahead of the socio-cultural institutions.</p><p>It can be argued that Ayres was not an institutionalist in any normal sense of the term; since he identified institutions with sentiments and superstition and in consequence institutions only played a kind of residual role in this theory of development which core center was that of technology. Ayres was under strong influence of Hegel and institutions for Ayres had the same function as Schein (with the connotation of deception, and illusion) for Hegel. A more appropriate name for Ayres' position would be that of a techno-behaviorist rather than an institutionalist.</p><h2>Adolf Berle</h2><p> Main article: Adolf Berle</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/5/5f/Adolf_Augustus_Berle_NYWTS.jpg/220px-Adolf_Augustus_Berle_NYWTS.jpg" width="220" height="272"><p>


Adolf Augustus Berle, Jr.


</p><p>
	Adolf A. Berle (1895–1971) was one of the first authors to combine legal and economic analysis, and his work stands as a foundig pillar of thought in modern corporate governance. Like Keynes, Berle was at the Paris Peace Conference, 1919, but subsequently resigned from his diplomatic job dissatisfied with the Versailles Treaty terms. In his book with Gardiner C. Means, The Modern Corporation and Private Property (1932), he detailed the evolution in the contemporary economy of big business, and argued that those who controlled big firms should be better held to account.</p><p>Directors of companies are held to account to the shareholders of companies, or not, by the rules found in company law statutes. This might include rights to elect and fire the management, require for regular general meetings, accounting standards, and so on. In 1930s America, the typical company laws (e.g. in Delaware) did not clearly mandate such rights. Berle argued that the unaccountable directors of companies were therefore apt to funnel the fruits of enterprise profits into their own pockets, as well as manage in their own interests. The ability to do this was supported by the fact that the majority of shareholders in big public companies were single individuals, with scant means of communication, in short, divided and conquered.</p>
	
	<div class='pageBreak' ></div>
	<p>


An airline ticket showing the price in the ISO 4217 code "EUR" (bottom left) and not the currency sign €


</p><p>
	ISO 4217 is a standard first published by International Organization for Standardization in 1978, which delineates currency designators, country codes (alpha and numeric), and references to minor units in three tables:</p><p>The tables, history and ongoing discussion are maintained by SIX Interbank Clearing on behalf of ISO and the Swiss Association for Standardization.[4]</p><p>The ISO 4217 code list is used in banking and business globally. In many countries the ISO codes for the more common currencies are so well known publicly that exchange rates published in newspapers or posted in banks use only these to delineate the different currencies, instead of translated currency names or ambiguous currency symbols. ISO 4217 codes are used on airline tickets and international train tickets to remove any ambiguity about the price.</p><h2>Contents</h2><h2>Code formation</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/d/db/South_East_Asia_Exchange_Rates_%286031878489%29.jpg/220px-South_East_Asia_Exchange_Rates_%286031878489%29.jpg" width="220" height="219"><p>


A list of exchange rates for various base currencies given by a money changer in Thailand, with the Thailand Baht as the counter (or quote) currency.


</p><p>
	The first two letters of the code are the two letters of the ISO 3166-1 alpha-2 country codes (which are also used as the basis for national top-level domains on the Internet) and the third is usually the initial of the currency itself. So Japan's currency code is JPY—JP for Japan and Y for yen. This eliminates the problem caused by the names dollar, franc, peso and pound being used in dozens of different countries, each having significantly differing values. Also, if a currency is revalued, the currency code's last letter is changed to distinguish it from the old currency. In some cases, the third letter is the initial for new in that country's language, to distinguish it from an older currency that was revalued; the code sometimes outlasts the usage of the term new itself (for example, the code for the Mexican peso is MXN). Other changes can be seen, however; the Russian ruble, for example, changed from RUR to RUB, where the B comes from the third letter in the word ruble.</p><h3>X currencies</h3><p>In addition to codes for most active national currencies ISO 4217 provides codes for supranational currencies, procedural purposes, and several things which are similar to currencies:</p><p>The use of an initial letter X for these purposes is facilitated by the ISO 3166 rule that no official country code beginning with X will ever be assigned. Because of this rule ISO 4217 can use X codes without risk of clashing with a future country code. ISO 3166 country codes beginning with X are used for private custom use (reserved), never for official codes. For instance, the ISO 3166-based NATO country codes (STANAG 1059, 9th edition) use X codes for imaginary exercise countries ranging from XXB for Brownland to XXR for Redland, as well as for major commands such as XXE for SHAPE or XXS for SACLANT. Consequently, ISO 4217 can use X codes for non-country-specific currencies without risk of clashing with future country codes.</p><p>The inclusion of EU (denoting the European Union) in the ISO 3166-1 reserved codes list, allows the euro to be coded as EUR rather than assigned a code beginning with X even though it is a supranational currency.</p><h3>Treatment of minor currency units (the exponent)</h3><p>The ISO 4217 standard includes a crude mechanism for expressing the relationship between a major currency unit and its corresponding minor currency unit. This mechanism is called the currency exponent and assumes a base of 10. For example, USD (the United States dollar) is equal to 100 of its minor currency unit the cent. So the USD has exponent 2 (10 to the power 2 is 100, which is the number of cents in a dollar). The code JPY (Japanese yen) is given the exponent 0, because its minor unit, the sen, although nominally valued at 1/100 of a yen, is of such negligible value that it is no longer used. Usually, as with the USD, the minor currency unit has a value that is 1/100 of the major unit, but in some cases (including most varieties of the dinar) 1/1000 is used, and sometimes ratios apply which are not integer powers of 10. Mauritania does not use a decimal division of units, setting 1 ouguiya (UM) equal to 5 khoums, and Madagascar has 1 ariary = 5 iraimbilanja. Some currencies do not have any minor currency unit at all and these are given an exponent of 0, as with currencies whose minor units are unused due to negligible value.</p><h3>Currency numbers</h3><p>There is also a three-digit code number assigned to each currency, in the same manner as there is also a three-digit code number assigned to each country as part of ISO 3166. This numeric code is usually the same as the ISO 3166-1 numeric code. For example, USD (United States dollar) has code 840 which is also the numeric code for the US (United States).</p><h2>Position of ISO 4217 code in amounts  </h2><p>The ISO standard does not regulate either the spacing, prefixing or suffixing in usage of currency codes. According however to the European Union's Publication Office,[5] in English, Irish, Latvian and Maltese texts, the ISO 4217 code is to be followed by a fixed space and the amount:</p><p>In Bulgarian, Croatian, Czech, Danish, Dutch, Estonian, Finnish, French, German, Greek, Hungarian, Italian, Lithuanian, Polish, Portuguese, Romanian, Slovak, Slovene, Spanish and Swedish the order is reversed; the amount is followed by a fixed space and the ISO 4217 code:</p><p>Note that, as illustrated, the order is determined not by the currency, but by the native language of the document context.</p><h2>History</h2><p>In 1973, the ISO Technical Committee 68 decided to develop codes for the representation of currencies and funds for use in any application of trade, commerce or banking. At the 17th session (February 1978), the related UN/ECE Group of Experts agreed that the three-letter alphabetic codes for International Standard ISO 4217, Codes for the representation of currencies and funds, would be suitable for use in international trade.</p><div class='pageBreak' ></div><p>Over time, new currencies are created and old currencies are discontinued. Frequently, these changes are due to the formation of new governments, treaties between countries standardizing on a shared currency, or revaluation of an existing currency due to excessive inflation. As a result, the list of codes must be updated from time to time. The ISO 4217 maintenance agency (MA), SIX Interbank Clearing, is responsible for maintaining the list of codes.</p><h2>Active codes</h2><p>The following is a list of active codes of official ISO 4217 currency names.</p><h3>USD/USS/USN, three currency codes belonging to the US</h3><p>The US dollar has two codes assigned: USD and USN (next day). The USS (same day) code is not in use any longer, and was removed from the list of active ISO 4217 codes in March 2014.</p><p>According to UN/CEFACT recommendation 9, paragraphs 8–9 ECE/TRADE/203, 1996, available online:</p><h2>Non ISO 4217 currencies</h2><h3>Currencies without ISO 4217 currency codes</h3><p>A number of currencies are not included in ISO 4217, because these currencies are: (a) minor currencies pegged 1:1 to a larger currency, even if independently regulated (b) a legal tender only issued as commemorative banknotes or coinage, or (c) a currency of an unrecognized or partially recognized state. These currencies include:</p><p>See Category:Fixed exchange rate for a list of all currently pegged currencies.</p><h3>Unofficial currency codes</h3><p>Despite having no official recognition in ISO 4217, the following non-ISO codes are sometimes used locally or commercially.</p><p>In addition, GBX is sometimes used (for example on the London Stock Exchange) to denote Penny sterling, a subdivision of pound sterling, the currency for the United Kingdom.</p><h3>Cryptocurrencies</h3><p>Recently, cryptocurrencies have unofficially used ISO codes used on various cryptocurrency exchanges, for instance LTC for Litecoin, NMC for Namecoin and XRP for Ripples. SIX Interbank Clearing (a Maintenance Agency of ISO) is currently studying the impact and role of cryptocurrencies and other independent currencies on ISO 4217.[16]</p><h2>Historical currency codes</h2><p>A number of currencies were official ISO 4217 currency codes and currency names until their replacement by the euro or other currencies. The table below shows the ISO currency codes of former currencies and their common names (which do not always match the ISO 4217 names). These codes were first introduced in 1989 after a request from the reinsurance sector in 1988 was accepted.</p><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=ISO_4217&amp;oldid=783976077"					
				Categories:  Hidden categories:</p><br><h1 lang="en">Human Development Index</h1><p> From Wikipedia, the free encyclopedia</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/0/0a/2016_UN_Human_Development_Report.svg/450px-2016_UN_Human_Development_Report.svg.png" width="450" height="197"><p>


World map indicating the Human Development Index (based on 2015 and 2016 data, published on March 21, 2017).
 




<br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/9/93/2016_UN_Human_Development_Report_%28Quartiles%29.svg/450px-2016_UN_Human_Development_Report_%28Quartiles%29.svg.png" width="450" height="195"><br>


World map indicating the categories of Human Development Index by country (based on 2015 and 2016 data, published on March 21, 2017).
 



</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/9/93/2016_UN_Human_Development_Report_%28Quartiles%29.svg/450px-2016_UN_Human_Development_Report_%28Quartiles%29.svg.png" width="450" height="195"><br><p>
	The Human Development Index (HDI) is a composite statistic of life expectancy, education, and per capita income indicators, which are used to rank countries into four tiers of human development. A country scores higher HDI when the lifespan is higher, the education level is higher, and the GDP per capita is higher. The HDI was developed by the Pakistani economist Mahbub ul Haq,[1] often framed in terms of whether people are able to be and do desirable things in their life, and was published by the United Nations Development Programme.</p><p>The 2010 Human Development Report introduced an Inequality-adjusted Human Development Index (IHDI). While the simple HDI remains useful, it stated that the IHDI is the actual level of human development (accounting for inequality), and the HDI can be viewed as an index of 'potential' human development (or the maximum IHDI that could be achieved if there were no inequality).</p><h2>Contents</h2><div class='pageBreak' ></div><h2>Origins</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/f/fc/Mahbub-ul-Haq.jpg/175px-Mahbub-ul-Haq.jpg" width="175" height="178"><p>


Mahbub ul Haq



<br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/e/e0/Amartya_Sen_NIH.jpg/175px-Amartya_Sen_NIH.jpg" width="175" height="280"><br>


Amartya Sen


</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/e/e0/Amartya_Sen_NIH.jpg/175px-Amartya_Sen_NIH.jpg" width="175" height="280"><br><p>
	The origins of the HDI are found in the annual Human Development Reports produced by the Human Development Reports Office of the United Nations Development Programme (UNDP). These were devised and launched by Pakistani economist Mahbub ul Haq in 1990, and had the explicit purpose to shift the focus of development economics from national income accounting to people-centered policies. To produce the Human Development Reports, Mahbub ul Haq formed a group of development economists including Paul Streeten, Frances Stewart, Gustav Ranis, Keith Griffin, Sudhir Anand, and Meghnad Desai. Nobel laureate Amartya Sen, utilized Haq's work in his own work on human capabilities.[2] Haq believed that a simple composite measure of human development was needed to convince the public, academics, and politicians that they can and should evaluate development not only by economic advances but also improvements in human well-being.</p><h2>Dimensions and calculation</h2><h3>New method (2010 Index onwards)</h3><p>Published on 4 November 2010 (and updated on 10 June 2011), the 2010 Human Development Index (HDI) combines three dimensions:[3][4]</p><p>In its 2010 Human Development Report, the UNDP began using a new method of calculating the HDI. The following three indices are used:</p><p>1. Life Expectancy Index (LEI) 
  
    
      
        =
        
          
            
              
                
                  LE
                
              
              -
              20
            
            
              85
              -
              20
            
          
        
      
    
    {\displaystyle ={\frac {{\textrm {LE}}-20}{85-20}}}
  
</p><p>2. Education Index (EI) 
  
    
      
        =
        
          
            
              
                
                  MYSI
                
              
              +
              
                
                  EYSI
                
              
            
            2
          
        
      
    
    {\displaystyle ={\frac {{\textrm {MYSI}}+{\textrm {EYSI}}}{2}}}
  
</p><br><img src="http:https://wikimedia.org/api/rest_v1/media/math/render/svg/55aabf77d89eb9e57d504c519802826d7a7da917" aria-hidden="true" style="vertical-align: -2.005ex; width:8.498ex; height:5.509ex;" alt="={\frac {\textrm {MYS}}{15}}"><br><img src="http:https://wikimedia.org/api/rest_v1/media/math/render/svg/d144416b4a2047923a6c231941cd3099f90fd5dd" aria-hidden="true" style="vertical-align: -2.005ex; width:7.95ex; height:5.509ex;" alt="={\frac {\textrm {EYS}}{18}}"><p>3. Income Index (II) 
  
    
      
        =
        
          
            
              ln
              ?
              (
              
                
                  GNIpc
                
              
              )
              -
              ln
              ?
              (
              100
              )
            
            
              ln
              ?
              (
              75
              ,
              000
              )
              -
              ln
              ?
              (
              100
              )
            
          
        
      
    
    {\displaystyle ={\frac {\ln({\textrm {GNIpc}})-\ln(100)}{\ln(75,000)-\ln(100)}}}
  
</p><p>Finally, the HDI is the geometric mean of the previous three normalized indices:

  
    
      
        
          
            HDI
          
        
        =
        
          
            
              
                
                  LEI
                
              
              ·
              
                
                  EI
                
              
              ·
              
                
                  II
                
              
            
            
              3
            
          
        
        .
      
    
    {\displaystyle {\textrm {HDI}}={\sqrt[{3}]{{\textrm {LEI}}\cdot {\textrm {EI}}\cdot {\textrm {II}}}}.}
  
</p><p>LE: Life expectancy at birth
MYS: Mean years of schooling (i.e. years that a person aged 25 or older has spent in formal education)
EYS: Expected years of schooling (i.e. total expected years of schooling for children under 18 years of age)
GNIpc: Gross national income at purchasing power parity per capita</p><h3>Old method (before 2010 Index)</h3><p>The HDI combined three dimensions last used in its 2009 Report:</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/d/d7/Human_Development_Index_trends.svg/280px-Human_Development_Index_trends.svg.png" width="280" height="274"><p>


HDI trends between 1975 and 2004
 



</p><p>
	This methodology was used by the UNDP until their 2011 report.</p><p>The formula defining the HDI is promulgated by the United Nations Development Programme (UNDP).[7] In general, to transform a raw variable, say 
  
    
      
        x
      
    
    {\displaystyle x}
  
, into a unit-free index between 0 and 1 (which allows different indices to be added together), the following formula is used:</p><p>where 
  
    
      
        a
      
    
    {\displaystyle a}
  
 and 
  
    
      
        b
      
    
    {\displaystyle b}
  
 are the lowest and highest values the variable 
  
    
      
        x
      
    
    {\displaystyle x}
  
 can attain, respectively.</p><div class='pageBreak' ></div><p>The Human Development Index (HDI) then represents the uniformly weighted sum with ? contributed by each of the following factor indices:</p><p>Other organizations/companies may include other factors, such as infant mortality, which produces a different HDI.</p><h2>2016 Human Development Index</h2><p> Main article: List of countries by Human Development Index</p><p>The 2016 Human Development Report by the United Nations Development Programme was released on March 21, 2017, and calculates HDI values based on estimates for 2015. Below is the list of the very high human development countries:[8]</p><h3>Inequality-adjusted HDI</h3><p> Main article: List of countries by inequality-adjusted HDI</p><p>The Inequality-adjusted Human Development Index (IHDI)[8] is a measure of the average level of human development of people in a society once inequality is taken into account.</p><p>The rankings are not relative to the HDI list above due to the exclusion of countries which are missing IHDI data (p.&nbsp;206).</p><li>&nbsp;Norway 0.898</li><li>&nbsp;Iceland 0.868</li><li>&nbsp;Netherlands 0.861</li><li>&nbsp;Australia 0.861</li><li>&nbsp;Germany 0.859</li><li>&nbsp;&nbsp;Switzerland 0.859</li><li>&nbsp;Denmark 0.858</li><li>&nbsp;Sweden 0.851</li><li>&nbsp;Ireland 0.850</li><li>&nbsp;Finland 0.843</li><li>&nbsp;Canada 0.839</li><li>&nbsp;Slovenia 0.838</li><li>&nbsp;United Kingdom 0.836</li><li>&nbsp;Czech Republic 0.830</li><li>&nbsp;Luxembourg 0.827</li><li>&nbsp;Belgium 0.821</li><li>&nbsp;Austria 0.815</li><li>&nbsp;France 0.813</li><li>&nbsp;United States 0.796</li><li>&nbsp;Slovakia 0.793</li><li>&nbsp;Japan 0.791</li><li>&nbsp;Spain 0.791</li><li>&nbsp;Estonia 0.788</li><li>&nbsp;Malta 0.786</li><li>&nbsp;Italy 0.784</li><li>&nbsp;Israel 0.778</li><li>&nbsp;Poland 0.774</li><li>&nbsp;Hungary 0.771</li><li>&nbsp;Cyprus 0.762</li><li>&nbsp;Lithuania 0.759</li><li>&nbsp;Greece 0.758</li><li>&nbsp;Portugal 0.755</li><li>&nbsp;South Korea 0.753</li><li>&nbsp;Croatia 0.752</li><li>&nbsp;Latvia 0.742</li><li>&nbsp;Montenegro 0.736</li><li>&nbsp;Russia 0.725</li><li>&nbsp;Romania 0.714</li><li>&nbsp;Argentina 0.698</li><li>&nbsp;Chile 0.692</li><p>Countries in the top quartile of HDI (very high human development group) with a missing IHDI: New Zealand, Singapore, Hong Kong, Liechtenstein, Brunei, Qatar, Saudi Arabia, Andorra, United Arab Emirates, Bahrain, and Kuwait.</p><h2>2015 Human Development Index</h2><p> Main article: List of countries by Human Development Index</p><p>The 2015 Human Development Report by the United Nations Development Programme was released on December 14, 2015, and calculates HDI values based on estimates for 2014. Below is the list of the very high human development countries:[10][11][12]</p><h3>Inequality-adjusted HDI</h3><p> Main article: List of countries by inequality-adjusted HDI</p><p>The Inequality-adjusted Human Development Index (IHDI)[10] is a measure of the average level of human development of people in a society once inequality is taken into account.</p><p>Note: The green arrows (), red arrows (), and blue dashes () represent changes in rank. The rankings are not relative to the HDI list above due to the exclusion of countries which are missing IHDI data (p.&nbsp;216).</p><li>&nbsp;Norway 0.893 ()</li><li>&nbsp;Netherlands 0.861 ( 1)</li><li>&nbsp;&nbsp;Switzerland 0.861 ( 1)</li><li>&nbsp;Australia 0.858 ( 2)</li><li>&nbsp;Denmark 0.856 ( 3)</li><li>&nbsp;Germany 0.853 ( 1)</li><li>&nbsp;Iceland 0.846 ( 1)</li><li>&nbsp;Sweden 0.846 ( 1)</li><li>&nbsp;Ireland 0.836 ( 1)</li><li>&nbsp;Finland 0.834 ( 1)</li><li>&nbsp;Canada 0.832 ( 2)</li><li>&nbsp;Slovenia 0.829 ()</li><li>&nbsp;United Kingdom 0.829 ( 3)</li><li>&nbsp;Czech Republic 0.823 ( 1)</li><li>&nbsp;Luxembourg 0.822 ( 1)</li><li>&nbsp;Belgium 0.820 ( 1)</li><li>&nbsp;Austria 0.816 ( 4)</li><li>&nbsp;France 0.811 ()</li><li>&nbsp;Slovakia 0.791 ( 2)</li><li>&nbsp;Estonia 0.782 ( 4)</li><li>&nbsp;Japan 0.780 ( 1)</li><div class='pageBreak' ></div><li>&nbsp;Israel 0.775 ( 3)</li><li>&nbsp;Spain 0.775 ( 1)</li><li>&nbsp;Italy 0.773 ( 1)</li><li>&nbsp;Hungary 0.769 ( 2)</li><li>&nbsp;Malta 0.767 ()</li><li>&nbsp;Poland 0.760 ( 2)</li><li>&nbsp;United States 0.760 ()</li><li>&nbsp;Cyprus 0.758 ( 1)</li><li>&nbsp;Greece 0.758 ( 5)</li><li>&nbsp;Lithuania 0.754 ()</li><li>&nbsp;South Korea 0.751 ( 1)</li><li>&nbsp;Portugal 0.744 ( 1)</li><li>&nbsp;Croatia 0.743 ( 1)</li><li>&nbsp;Belarus 0.741</li><li>&nbsp;Latvia 0.730</li><p>Countries in the top quartile of HDI (very high human development group) with a missing IHDI: New Zealand, Singapore, Hong Kong, Liechtenstein, Brunei, Qatar, Saudi Arabia, Andorra, United Arab Emirates, Bahrain, Cuba, and Kuwait.</p><h2>2014 Human Development Index</h2><p>The 2014 Human Development Report by the United Nations Development Programme was released on July 24, 2014, and calculates HDI values based on estimates for 2013. Below is the list of the very high human development countries:[16][11][12]</p><h3>Countries not included</h3><p>Some countries were not included for various reasons, primarily due to the lack of necessary data. The following United Nations Member States were not included in the 2014 report:[16] North Korea, Marshall Islands, Monaco, Nauru, San Marino, Somalia, South Sudan, Sudan, and Tuvalu.</p><h3>Inequality-adjusted HDI</h3><p> Main article: List of countries by inequality-adjusted HDI</p><p>The Inequality-adjusted Human Development Index (IHDI)[16] is a measure of the average level of human development of people in a society once inequality is taken into account.</p><p>Note: The green arrows (), red arrows (), and blue dashes () represent changes in rank. The rankings are not relative to the HDI list above due to the exclusion of countries which are missing IHDI data (p.&nbsp;168).</p><li>&nbsp;Norway 0.891 ()</li><li>&nbsp;Australia 0.860 ()</li><li>&nbsp;Netherlands 0.854 ( 1)</li><li>&nbsp;&nbsp;Switzerland 0.847 ( 3)</li><li>&nbsp;Germany 0.846 ()</li><li>&nbsp;Iceland 0.843 ( 2)</li><li>&nbsp;Sweden 0.840 ( 4)</li><li>&nbsp;Denmark 0.838 ( 1)</li><li>&nbsp;Canada 0.833 ( 4)</li><li>&nbsp;Ireland 0.832 ( 4)</li><li>&nbsp;Finland 0.830 ()</li><li>&nbsp;Slovenia 0.824 ( 2)</li><li>&nbsp;Austria 0.818 ( 1)</li><li>&nbsp;Luxembourg 0.814 ( 3)</li><li>&nbsp;Czech Republic 0.813 ( 1)</li><li>&nbsp;United Kingdom 0.812 ( 3)</li><li>&nbsp;Belgium 0.806 ( 2)</li><li>&nbsp;France 0.804 ()</li><li>&nbsp;Israel 0.793 ( 1)</li><li>&nbsp;Japan 0.779 (New)</li><li>&nbsp;Slovakia 0.778 ( 1)</li><li>&nbsp;Spain 0.775 ( 2)</li><li>&nbsp;Italy 0.768 ( 1)</li><li>&nbsp;Estonia 0.767 ( 1)</li><li>&nbsp;Greece 0.762 ( 2)</li><li>&nbsp;Malta 0.760 ( 3)</li><li>&nbsp;Hungary 0.757 ( 1)</li><li>&nbsp;United States 0.755 ( 12)</li><li>&nbsp;Poland 0.751 ( 1)</li><li>&nbsp;Cyprus 0.752 ( 1)</li><li>&nbsp;Lithuania 0.746 ( 2)</li><li>&nbsp;Portugal 0.739 ()</li><li>&nbsp;South Korea 0.736 ( 5)</li><li>&nbsp;Latvia 0.725 ( 1)</li><li>&nbsp;Croatia 0.721 ( 4)</li><li>&nbsp;Argentina 0.680 ( 7)</li><li>&nbsp;Chile 0.661 ( 4)</li><p>Countries in the top quartile of HDI (very high human development group) with a missing IHDI: New Zealand, Singapore, Hong Kong, Liechtenstein, Brunei, Qatar, Saudi Arabia, Andorra, United Arab Emirates, Bahrain, Cuba, and Kuwait.</p><h2>Past top countries</h2><p>The list below displays the top-ranked country from each year of the Human Development Index. Norway has been ranked the highest twelve times, Canada eight times, followed by Japan which has been ranked highest three times. Iceland has been ranked highest twice.</p><h3>In each original HDI</h3><p>The year represents when the report was published. In parentheses is the year for which the index was calculated.</p><h2>Geographical coverage</h2><p>The HDI has extended its geographical coverage: David Hastings, of the United Nations Economic and Social Commission for Asia and the Pacific, published a report geographically extending the HDI to 230+ economies, whereas the UNDP HDI for 2009 enumerates 182 economies and coverage for the 2010 HDI dropped to 169 countries.[18][19]</p><h2>Country/region specific HDI lists</h2><h2>Criticism</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/0/0f/Human_welfare_and_ecological_footprint.jpg/220px-Human_welfare_and_ecological_footprint.jpg" width="220" height="135"><div class='pageBreak' ></div><p>


HDI vs. ecological footprint


</p><p>
	The Human Development Index has been criticized on a number of grounds including alleged lack of consideration of technological development or contributions to the human civilization, focusing exclusively on national performance and ranking, lack of attention to development from a global perspective, measurement error of the underlying statistics, and on the UNDP's changes in formula which can lead to severe misclassification in the categorisation of 'low', 'medium', 'high' or 'very high' human development countries.[20]</p><p>Economists Hendrik Wolff, Howard Chong and Maximilian Auffhammer discuss the HDI from the perspective of data error in the underlying health, education and income statistics used to construct the HDI. They identified three sources of data error which are due to (i) data updating, (ii) formula revisions and (iii) thresholds to classify a country's development status and conclude that 11%, 21% and 34% of all countries can be interpreted as currently misclassified in the development bins due to the three sources of data error, respectively. The authors suggest that the United Nations should discontinue the practice of classifying countries into development bins because - they claim - the cut-off values seem arbitrary, can provide incentives for strategic behavior in reporting official statistics, and have the potential to misguide politicians, investors, charity donors and the public who use the HDI at large.[20]</p><p>In 2010, the UNDP reacted to the criticism and updated the thresholds to classify nations as low, medium, and high human development countries. In a comment to The Economist in early January 2011, the Human Development Report Office responded[21] to a January 6, 2011 article in the magazine[22] which discusses the Wolff et al. paper. The Human Development Report Office states that they undertook a systematic revision of the methods used for the calculation of the HDI and that the new methodology directly addresses the critique by Wolff et al. in that it generates a system for continuous updating of the human development categories whenever formula or data revisions take place.</p><h2>Notes and references</h2><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Human_Development_Index&amp;oldid=782574749"					
				Categories:  Hidden categories:</p><br><br><img alt="This is a good article. Click here for more information." src="http://upload.wikimedia.org/wikipedia/en/thumb/9/94/Symbol_support_vote.svg/19px-Symbol_support_vote.svg.png" width="19" height="20"><h1 lang="en">Euro</h1><p> From Wikipedia, the free encyclopedia</p><p> This article is about the currency. For other uses, see Euro (disambiguation).</p><p>The euro (sign: €; code: EUR) is the official currency of the eurozone, which consists of 19 of the 28 member states of the European Union: Austria, Belgium, Cyprus, Estonia, Finland, France, Germany, Greece, Ireland, Italy, Latvia, Lithuania, Luxembourg, Malta, the Netherlands, Portugal, Slovakia, Slovenia, and Spain.[3][4] The currency is also officially used by the institutions of the European Union and four other European countries, as well as unilaterally by two others, and is consequently used daily by some 337&nbsp;million Europeans as of 2015[update].[5] Outside of Europe, a number of overseas territories of EU members also use the euro as their currency.</p><p>Additionally, 210&nbsp;million people worldwide as of 2013[update] use currencies pegged to the euro. The euro is the second largest reserve currency as well as the second most traded currency in the world after the United States dollar.[6][7][8] As of January 2017[update], with more than €1,109,000,000,000 in circulation, the euro has one of the highest combined values of banknotes and coins in circulation in the world, having surpassed the U.S. dollar at one point.[9][note 17]</p><p>The name euro was officially adopted on 16 December 1995 in Madrid.[10] The euro was introduced to world financial markets as an accounting currency on 1 January 1999, replacing the former European Currency Unit (ECU) at a ratio of 1:1 (US$1.1743). Physical euro coins and banknotes entered into circulation on 1 January 2002, making it the day-to-day operating currency of its original members, and by May 2002 had completely replaced the former currencies.[11] While the euro dropped subsequently to US$0.8252 within two years (26 October 2000), it has traded above the U.S. dollar since the end of 2002, peaking at US$1.6038 on 18 July 2008.[12] Since late 2009, the euro has been immersed in the European sovereign-debt crisis which has led to the creation of the European Financial Stability Facility as well as other reforms aimed at stabilising the currency. In July 2012, the euro fell below US$1.21 for the first time in two years, following concerns raised over Greek debt and Spain's troubled banking sector.[13] As of June 2017, the euro–dollar exchange rate stands at ~ US$1.13.[14]</p><h2>Contents</h2><h2>Administration</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/5/51/European_Central_Bank_-_building_under_construction_-_Frankfurt_-_Germany_-_13.jpg/150px-European_Central_Bank_-_building_under_construction_-_Frankfurt_-_Germany_-_13.jpg" width="150" height="248"><p>


The European Central Bank has its seat in Frankfurt (Germany) and is in charge of the monetary policy of the euro area.



</p><p>
	 Main articles: European Central Bank, Maastricht Treaty, and Eurogroup</p><p>The euro is managed and administered by the Frankfurt-based European Central Bank (ECB) and the Eurosystem (composed of the central banks of the eurozone countries). As an independent central bank, the ECB has sole authority to set monetary policy. The Eurosystem participates in the printing, minting and distribution of notes and coins in all member states, and the operation of the eurozone payment systems.</p><p>The 1992 Maastricht Treaty obliges most EU member states to adopt the euro upon meeting certain monetary and budgetary convergence criteria, although not all states have done so. The United Kingdom and Denmark negotiated exemptions,[15] while Sweden (which joined the EU in 1995, after the Maastricht Treaty was signed) turned down the euro in a 2003 referendum, and has circumvented the obligation to adopt the euro by not meeting the monetary and budgetary requirements. All nations that have joined the EU since 1993 have pledged to adopt the euro in due course.</p><div class='pageBreak' ></div><h2>Issuing modalities for banknotes</h2><p>Since 5 January 2002, the national central banks (NCBs) and the ECB have issued euro banknotes on a joint basis.[16] Euro banknotes do not show which central bank issued them. Eurosystem NCBs are required to accept euro banknotes put into circulation by other Eurosystem members and these banknotes are not repatriated. The ECB issues 8% of the total value of banknotes issued by the Eurosystem.[16] In practice, the ECB's banknotes are put into circulation by the NCBs, thereby incurring matching liabilities vis-à-vis the ECB. These liabilities carry interest at the main refinancing rate of the ECB. The other 92% of the euro banknotes are issued by the NCBs in proportion to their respective shares in the capital key of the ECB,[16] calculated using national share of European Union population and national share of European Union GDP, equally weighted.[17]</p><h2>Characteristics</h2><h3>Coins and banknotes</h3><p> Main articles: Euro coins and Euro banknotes</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/6/65/Euro_coins_and_banknotes.jpg/220px-Euro_coins_and_banknotes.jpg" width="220" height="165"><p>


Euro coins and banknotes of various denominations.


</p><p>
	The euro is divided into 100 cents (sometimes referred to as euro cents, especially when distinguishing them from other currencies, and referred to as such on the common side of all cent coins). In Community legislative acts the plural forms of euro and cent are spelled without the s, notwithstanding normal English usage.[18][19] Otherwise, normal English plurals are sometimes used,[20] with many local variations such as centime in France.</p><p>All circulating coins have a common side showing the denomination or value, and a map in the background. Due to the linguistic plurality in the European Union, the Latin alphabet version of euro is used (as opposed to the less common Greek or Cyrillic) and Arabic numerals (other text is used on national sides in national languages, but other text on the common side is avoided). For the denominations except the 1-, 2- and 5-cent coins, the map only showed the 15 member states which were members when the euro was introduced. Beginning in 2007 or 2008 (depending on the country) the old map is being replaced by a map of Europe also showing countries outside the Union like Norway. The 1-, 2- and 5-cent coins, however, keep their old design, showing a geographical map of Europe with the 15 member states of 2002 raised somewhat above the rest of the map. All common sides were designed by Luc Luycx. The coins also have a national side showing an image specifically chosen by the country that issued the coin. Euro coins from any member state may be freely used in any nation that has adopted the euro.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/8/86/New_finnish_2013_5_euro.png/220px-New_finnish_2013_5_euro.png" width="220" height="223"><p>


The new banknotes were introduced in the beginning of 2013. The top half of the image shows the front side of the banknote and the bottom half shows the back side.



<br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/a/a8/EUR_10_obverse_%282014_issue%29.png/220px-EUR_10_obverse_%282014_issue%29.png" width="220" height="114"><br>


10 euro note from the new Europa series written in Latin (EURO) and Greek (???O) alphabets, but also in the Cyrillic (????) alphabet, as a result of Bulgaria joining the European Union in 2007.


</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/a/a8/EUR_10_obverse_%282014_issue%29.png/220px-EUR_10_obverse_%282014_issue%29.png" width="220" height="114"><br><p>
	The coins are issued in €2, €1, 50c, 20c, 10c, 5c, 2c, and 1c denominations. To avoid the use of the two smallest coins, some cash transactions are rounded to the nearest five cents in the Netherlands and Ireland[21][22] (by voluntary agreement) and in Finland (by law).[23] This practice is discouraged by the Commission, as is the practice of certain shops to refuse to accept high value euro notes.[24]</p><p>Commemorative coins with €2 face value have been issued with changes to the design of the national side of the coin. These include both commonly issued coins, such as the €2 commemorative coin for the fiftieth anniversary of the signing of the Treaty of Rome, and nationally issued coins, such as the coin to commemorate the 2004 Summer Olympics issued by Greece. These coins are legal tender throughout the eurozone. Collector coins with various other denominations have been issued as well, but these are not intended for general circulation, and they are legal tender only in the member state that issued them.[25]</p><p>The design for the euro banknotes has common designs on both sides. The design was created by the Austrian designer Robert Kalina.[26] Notes are issued in €500, €200, €100, €50, €20, €10, €5. Each banknote has its own colour and is dedicated to an artistic period of European architecture. The front of the note features windows or gateways while the back has bridges, symbolising links between countries and with the future. While the designs are supposed to be devoid of any identifiable characteristics, the initial designs by Robert Kalina were of specific bridges, including the Rialto and the Pont de Neuilly, and were subsequently rendered more generic; the final designs still bear very close similarities to their specific prototypes; thus they are not truly generic. The monuments looked similar enough to different national monuments to please everyone.[27]</p><h3>Payments clearing, electronic funds transfer</h3><p> Main article: Single Euro Payments Area</p><p>Capital within the EU may be transferred in any amount from one country to another. All intra-EU transfers in euro are treated as domestic transactions and bear the corresponding domestic transfer costs.[28] This includes all member states of the EU, even those outside the eurozone providing the transactions are carried out in euro.[29] Credit/debit card charging and ATM withdrawals within the eurozone are also treated as domestic transactions; however paper-based payment orders, like cheques, have not been standardised so these are still domestic-based. The ECB has also set up a clearing system, TARGET, for large euro transactions.[30]</p><h3>Currency sign</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/3/3b/Euro_logo_plus_character.png/220px-Euro_logo_plus_character.png" width="220" height="110"><div class='pageBreak' ></div><p>


The euro sign; logotype and handwritten



</p><p>
	 Main article: Euro sign</p><p>A special euro currency sign (€) was designed after a public survey had narrowed the original ten proposals down to two. The European Commission then chose the design created by the Belgian Alain Billiet.</p><p>Inspiration for the € symbol itself came from the Greek epsilon (?)[note 18]&nbsp;– a reference to the cradle of European civilisation&nbsp;– and the first letter of the word Europe, crossed by two parallel lines to 'certify' the stability of the euro.</p><p>The European Commission also specified a euro logo with exact proportions and foreground and background colour tones.[31] While the Commission intended the logo to be a prescribed glyph shape, font designers made it clear that they intended to design their own variants instead.[32] Typewriters lacking the euro sign can create it by typing a capital 'C', backspacing and overstriking it with the equal ('=') sign. Placement of the currency sign relative to the numeric amount varies from nation to nation, but for texts in English the symbol (or the ISO-standard EUR) should precede the amount.[33]</p><p>There is no official symbol for the cent.[citation needed]</p><h2>History</h2><p> Main article: History of the euro</p><h3>Introduction</h3><p>The euro was established by the provisions in the 1992 Maastricht Treaty. To participate in the currency, member states are meant to meet strict criteria, such as a budget deficit of less than three percent of their GDP, a debt ratio of less than sixty percent of GDP (both of which were ultimately widely flouted after introduction), low inflation, and interest rates close to the EU average. In the Maastricht Treaty, the United Kingdom and Denmark were granted exemptions per their request from moving to the stage of monetary union which would result in the introduction of the euro.</p><p>Economists who helped create or contributed to the euro include Fred Arditti, Neil Dowling, Wim Duisenberg, Robert Mundell, Tommaso Padoa-Schioppa and Robert Tollison.[citation needed] (For macroeconomic theory, see below.)</p><p>The name euro was officially adopted in Madrid on 16 December 1995.[10] Belgian Esperantist Germain Pirlot, a former teacher of French and history is credited with naming the new currency by sending a letter to then President of the European Commission, Jacques Santer, suggesting the name euro on 4 August 1995.[35]</p><p>Due to differences in national conventions for rounding and significant digits, all conversion between the national currencies had to be carried out using the process of triangulation via the euro. The definitive values of one euro in terms of the exchange rates at which the currency entered the euro are shown on the right.</p><p>The rates were determined by the Council of the European Union,[note 19] based on a recommendation from the European Commission based on the market rates on 31 December 1998. They were set so that one European Currency Unit (ECU) would equal one euro. The European Currency Unit was an accounting unit used by the EU, based on the currencies of the member states; it was not a currency in its own right. They could not be set earlier, because the ECU depended on the closing exchange rate of the non-euro currencies (principally the pound sterling) that day.</p><p>The procedure used to fix the conversion rate between the Greek drachma and the euro was different, since the euro by then was already two years old. While the conversion rates for the initial eleven currencies were determined only hours before the euro was introduced, the conversion rate for the Greek drachma was fixed several months beforehand.[note 20]</p><p>The currency was introduced in non-physical form (traveller's cheques, electronic transfers, banking, etc.) at midnight on 1 January 1999, when the national currencies of participating countries (the eurozone) ceased to exist independently. Their exchange rates were locked at fixed rates against each other. The euro thus became the successor to the European Currency Unit (ECU). The notes and coins for the old currencies, however, continued to be used as legal tender until new euro notes and coins were introduced on 1 January 2002.</p><p>The changeover period during which the former currencies' notes and coins were exchanged for those of the euro lasted about two months, until 28 February 2002. The official date on which the national currencies ceased to be legal tender varied from member state to member state. The earliest date was in Germany, where the mark officially ceased to be legal tender on 31 December 2001, though the exchange period lasted for two months more. Even after the old currencies ceased to be legal tender, they continued to be accepted by national central banks for periods ranging from several years to forever (the latter in Austria, Germany, Ireland, Estonia and Latvia for banknotes and coins; also, Belgium, Luxembourg, Slovenia and Slovakia will accept banknotes forever, but not coins). The earliest coins to become non-convertible were the Portuguese escudos, which ceased to have monetary value after 31 December 2002, although banknotes remain exchangeable until 2022.</p><h3>Eurozone crisis</h3><p> Main articles: Eurozone crisis and Greek government-debt crisis</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/0/0e/Government_surplus_or_deficit_%28EU-USA-UK%29.png/220px-Government_surplus_or_deficit_%28EU-USA-UK%29.png" width="220" height="188"><p>


Budget deficit of the euro area compared to the United States and the UK.


</p><p>
	Following the U.S. financial crisis in 2008, fears of a sovereign debt crisis developed in 2009 among fiscally conservative investors concerning some European states, with the situation becoming particularly tense in early 2010.[36][37] This included eurozone members Greece,[38] Ireland and Portugal and also some EU countries outside the area.[39] Iceland, the country which experienced the largest crisis in 2008 when its entire international banking system collapsed, has emerged less affected by the sovereign-debt crisis as the government was unable to bail the banks out. In the EU, especially in countries where sovereign debts have increased sharply due to bank bailouts, a crisis of confidence has emerged with the widening of bond yield spreads and risk insurance on credit default swaps between these countries and other EU members, most importantly Germany.[40][41] To be included in the eurozone, the countries had to fulfil certain convergence criteria, but the meaningfulness of such criteria was diminished by the fact it was not enforced with the same degree of strictness from country to country.[42]</p><div class='pageBreak' ></div><p>According to the Economist Intelligence Unit in 2011, [I]f the [euro area] is treated as a single entity, its [economic and fiscal] position looks no worse and in some respects, rather better than that of the US or the UK and the budget deficit for the euro area as a whole is much lower and the euro area's government debt/GDP ratio of 86% in 2010 was about the same level as that of the United States. Moreover, they write, private-sector indebtedness across the euro area as a whole is markedly lower than in the highly leveraged Anglo-Saxon economies. The authors conclude that the crisis is as much political as economic and the result of the fact that the euro area lacks the support of institutional paraphernalia (and mutual bonds of solidarity) of a state.[43]</p><p>The crisis continued with S&amp;P downgrading nine euro-area countries, including France, then downgrading the entire European Financial Stability Facility (EFSF) fund.[44]</p><p>In May 2012, socialist François Hollande was elected as president of France and a month later the French socialist legislative position was strengthened, while German leader Angela Merkel has appeared to be floundering and been badly let down by her advisers in recent months, one commentator said. As such, serious discord between French and German monetary decision-makers was [comparable to that of] ... 1992–93, at the height of the crisis over the European Monetary System, the forerunner to EMU (European Monetary Union). [H]itherto relatively dormant signs of euro skepticism in German public opinion and throughout industry have been multiplying in recent months, making Hollande's proposals increasingly unpalatable to a broad swathe of German opinion. Although considerable controversy will continue to swirl over Greece and Spain, the real battle lines over the future of the euro will be drawn up between Germany and France, the commentary concluded.[45] Another historical parallel&nbsp;– to 1931 when Germany was burdened with debt, unemployment and austerity while France and the United States were relatively strong creditors&nbsp;– gained attention in summer 2012[46] even as Germany received a debt-rating warning of its own.[47][48]</p><h2>Direct and indirect usage</h2><p> Further information: Eurozone, International status and usage of the euro, and Enlargement of the eurozone</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/f/f1/Eurozone_map.svg/400px-Eurozone_map.svg.png" width="400" height="396"><p>
Andorra
Bulgaria
Croatia
Czech Rep.
Denmark
Eurozone
Hungary
Kosovo
Monaco
Monte
negro
Poland
Romania
San Marino
Sweden
United
Kingdom
Vatican

&nbsp;&nbsp;Eurozone


&nbsp;&nbsp;ERM II


&nbsp;&nbsp;Other EU members


&nbsp;&nbsp;Monetary agreement


&nbsp;&nbsp;Unilaterally adopted


<br><img alt="Desc-i.svg" src="http://upload.wikimedia.org/wikipedia/commons/thumb/4/46/Desc-i.svg/10px-Desc-i.svg.png" width="10" height="10">

</p><br><img alt="Desc-i.svg" src="http://upload.wikimedia.org/wikipedia/commons/thumb/4/46/Desc-i.svg/10px-Desc-i.svg.png" width="10" height="10"><h3>Direct usage</h3><p>
	The euro is the sole currency of 19 EU member states: Austria, Belgium, Cyprus, Estonia, Finland, France, Germany, Greece, Ireland, Italy, Latvia, Lithuania, Luxembourg, Malta, the Netherlands, Portugal, Slovakia, Slovenia, and Spain. These countries constitute the eurozone, some 332&nbsp;million people in total as of 2013[update].[49]</p><p>With all but two of the remaining EU members obliged to join, together with future members of the EU, the enlargement of the eurozone is set to continue. Outside the EU, the euro is also the sole currency of Montenegro and Kosovo and several European microstates (Andorra, Monaco, San Marino and the Vatican City) as well as in four overseas territories of EU members that are not themselves part of the EU (Saint Barthélemy, Saint Pierre and Miquelon, the French Southern and Antarctic Lands and Akrotiri and Dhekelia). Together this direct usage of the euro outside the EU affects nearly 3&nbsp;million people.</p><p>The euro has been used as a trading currency in Cuba since 1998,[50] and Syria since 2006.[51] There are also various currencies pegged to the euro (see below). In 2009, Zimbabwe abandoned its local currency and used major currencies instead, including the euro and the United States dollar.[52]</p><h3>Use as reserve currency</h3><p>Since its introduction, the euro has been the second most widely held international reserve currency after the U.S. dollar. The share of the euro as a reserve currency increased from 18% in 1999 to 27% in 2008. Over this period, the share held in U.S. dollar fell from 71% to 64% and that held in Yen fell from 6.4% to 3.3%. The euro inherited and built on the status of the Deutsche Mark as the second most important reserve currency. The euro remains underweight as a reserve currency in advanced economies while overweight in emerging and developing economies: according to the International Monetary Fund[53] the total of euro held as a reserve in the world at the end of 2008 was equal to $1.1&nbsp;trillion or €850 billion, with a share of 22% of all currency reserves in advanced economies, but a total of 31% of all currency reserves in emerging and developing economies.</p><p>The possibility of the euro becoming the first international reserve currency is now widely debated among economists.[54] Former US Federal Reserve Chairman Alan Greenspan gave his opinion in September 2007 that it was absolutely conceivable that the euro will replace the US dollar as reserve currency, or will be traded as an equally important reserve currency.[55] In contrast to Greenspan's 2007 assessment, the euro's increase in the share of the worldwide currency reserve basket has slowed considerably since 2007 and since the beginning of the worldwide credit crunch related recession and European sovereign-debt crisis.[53]</p><h3>Currencies pegged to the euro</h3><p> Main article: International status and usage of the euro</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/9/91/DOLLAR_AND_EURO_IN_THE_WORLD.svg/300px-DOLLAR_AND_EURO_IN_THE_WORLD.svg.png" width="300" height="154"><p>


Worldwide use of the euro and the US dollar:
&nbsp;&nbsp;Eurozone
&nbsp;&nbsp;External adopters of the euro
&nbsp;&nbsp;Currencies pegged to the euro
&nbsp;&nbsp;Currencies pegged to the euro within narrow band
&nbsp;&nbsp;United States
&nbsp;&nbsp;External adopters of the US dollar
&nbsp;&nbsp;Currencies pegged to the US dollar
&nbsp;&nbsp;Currencies pegged to the US dollar within narrow band

Note: The Belarusian ruble is pegged to the Euro, Russian ruble and US$ in a currency basket.


</p><div class='pageBreak' ></div><p>
	Outside the eurozone, a total of 22 countries and territories that do not belong to the EU have currencies that are directly pegged to the euro including 13 countries in mainland Africa (CFA franc), two African island countries (Comorian franc and Cape Verdean escudo), three French Pacific territories (CFP franc) and three Balkan countries, Bosnia and Herzegovina (Bosnia and Herzegovina convertible mark), Bulgaria (Bulgarian lev) and Macedonia (Macedonian denar).[56] On 28 July 2009, São Tomé and Príncipe signed an agreement with Portugal which will eventually tie its currency to the euro.[57] Additionally, the Moroccan dirham is tied to a basket of currencies, including the Euro and the US dollar, with the Euro given the highest weighting.</p><p>With the exception of Bosnia, Bulgaria, Macedonia (which had pegged their currencies against the Deutsche Mark) and Cape Verde (formerly pegged to the Portuguese escudo), all of these non-EU countries had a currency peg to the French Franc before pegging their currencies to the euro. Pegging a country's currency to a major currency is regarded as a safety measure, especially for currencies of areas with weak economies, as the euro is seen as a stable currency, prevents runaway inflation and encourages foreign investment due to its stability.</p><p>Within the EU several currencies have a peg to the euro, in most instances as a precondition to joining the eurozone. The Bulgarian lev was formerly pegged to the Deutsche Mark; one other EU member state has a direct peg due to ERM II: the Danish krone.</p><p>In total, as of 2013[update], 182&nbsp;million people in Africa use a currency pegged to the euro, 27&nbsp;million people outside the eurozone in Europe, and another 545,000 people on Pacific islands.[49]</p><p>Since 2005, stamps issued by the Sovereign Military Order of Malta have been denominated in euros, although the Order's official currency remains the Maltese scudo.[58] The Maltese scudo itself is pegged to the euro and is only recognised as legal tender within the Order.[59]</p><h2>Economics</h2><h3>Optimal currency area</h3><p> Further information: Optimum currency area</p><p>In economics, an optimum currency area, or region (OCA or OCR), is a geographical region in which it would maximise economic efficiency to have the entire region share a single currency. There are two models, both proposed by Robert Mundell: the stationary expectations model and the international risk sharing model. Mundell himself advocates the international risk sharing model and thus concludes in favour of the euro.[60] However, even before the creation of the single currency, there were concerns over diverging economies. Before the late-2000s recession the chances of a state leaving the euro, or the chances that the whole zone would collapse, were considered extremely slim.[61] However the Greek government-debt crisis led to former British Foreign Secretary Jack Straw claiming the eurozone could not last in its current form.[62] Part of the problem seems to be the rules that were created when the euro was set up. John Lanchester, writing for The New Yorker, explains it thus:</p><p>The guiding principle of the currency, which opened for business in 1999, were supposed to be a set of rules to limit a country's annual deficit to three per cent of gross domestic product, and the total accumulated debt to sixty per cent of G.D.P. It was a nice idea, but by 2004 the two biggest economies in the euro zone, Germany and France, had broken the rules for three years in a row.[63]</p><h3>Transaction costs and risks</h3><p>The most obvious benefit of adopting a single currency is to remove the cost of exchanging currency, theoretically allowing businesses and individuals to consummate previously unprofitable trades. For consumers, banks in the eurozone must charge the same for intra-member cross-border transactions as purely domestic transactions for electronic payments (e.g., credit cards, debit cards and cash machine withdrawals).</p><p>The absence of distinct currencies also theoretically removes exchange rate risks, although the imposition of transfer restrictions in 2012–13 Cypriot financial crisis means that the situation is not quite so simple. The risk of unanticipated exchange rate movement has always added an additional risk or uncertainty for companies or individuals that invest or trade outside their own currency zones. Companies that hedge against this risk will no longer need to shoulder this additional cost. This is particularly important for countries whose currencies had traditionally fluctuated a great deal, particularly the Mediterranean nations[citation needed].</p><p>Financial markets on the continent are expected to be far more liquid and flexible than they were in the past. The reduction in cross-border transaction costs will allow larger banking firms to provide a wider array of banking services that can compete across and beyond the eurozone. However, although transaction costs were reduced, some studies have shown that risk aversion has increased during the last 40 years in the Eurozone.[65]</p><h3>Price parity</h3><p>Another effect of the common European currency is that differences in prices—in particular in price levels—should decrease because of the law of one price. Differences in prices can trigger arbitrage, i.e., speculative trade in a commodity across borders purely to exploit the price differential. Therefore, prices on commonly traded goods are likely to converge, causing inflation in some regions and deflation in others during the transition. Some evidence of this has been observed in specific eurozone markets.[66]</p><h3>Macroeconomic stability</h3><p>Low levels of inflation are the hallmark of stable and modern economies. Because a high level of inflation acts as a tax (seigniorage) and theoretically discourages investment, it is generally viewed as undesirable. In spite of the downside, many countries have been unable or unwilling to deal with serious inflationary pressures.[citation needed] Before the introduction of the euro, some countries had successfully contained inflation, which was then seen as a major economic problem, by establishing largely independent central banks. One such bank was the Bundesbank in Germany; the European Central Bank was modelled on the Bundesbank.[67] It is independent of the pressures of national governments and has a mandate to keep inflation low. Member countries that join the euro hope to enjoy the macroeconomic stability associated with low levels of inflation. The ECB (unlike the Federal Reserve in the United States of America) does not have a second objective to sustain growth and employment.[citation needed]</p><p>The Euro has come under criticism due to its imperialistic style regulation, lack of flexibility and [68] rigidity towards sharing member States on issues such as nominal interest rates Many national and corporate bonds denominated in euro are significantly more liquid and have lower interest rates than was historically the case when denominated in national currencies. While increased liquidity may lower the nominal interest rate on the bond, denominating the bond in a currency with low levels of inflation arguably plays a much larger role. A credible commitment to low levels of inflation and a stable debt reduces the risk that the value of the debt will be eroded by higher levels of inflation or default in the future, allowing debt to be issued at a lower nominal interest rate.</p><p>Unfortunately, there is also a cost in structurally keeping inflation lower than in the United States, UK, and China. The result is that seen from those countries, the euro has become expensive, making European products increasingly expensive for its largest importers. Hence export from the euro zone becomes more difficult. This is one of the main reasons why economic growth inside the euro zone now lags behind growth in other large economies.[citation needed] This effect is strongest in European countries with a weak economy.</p><p>In general, those in Europe who own large amounts of euros are served by high stability and low inflation. Those who now need to earn euros, including those countries who need to pay interest on large debts, are likely better served with a slightly less strong euro leading to more export. Because with a lower euro, investors would see better chances for (companies in) southern European countries to grow themselves out of the crisis. As a result, investing there would become less risky, and that would push interest rates for southern countries more in line with the European average.[citation needed]</p><div class='pageBreak' ></div><p>The contradiction here is that high macroeconomic stability in the form of ongoing historically low inflation over time leads to economic problems, creating higher interest rates and political and economic instability for the weaker partners.[citation needed]</p><p>A 2009 consensus from the studies of the introduction of the euro concluded that it has increased trade within the eurozone by 5% to 10%,[69] although one study suggested an increase of only 3%[70] while another estimated 9 to 14%.[71] However, a meta-analysis of all available studies suggests that the prevalence of positive estimates is caused by publication bias and that the underlying effect may be negligible.[72] Furthermore, studies accounting for time trend reflecting general cohesion policies in Europe that started before, and continue after implementing the common currency find no effect on trade.[73][74] These results suggest that other policies aimed at European integration might be the source of observed increase in trade.</p><p>Physical investment seems to have increased by 5% in the eurozone due to the introduction.[75] Regarding foreign direct investment, a study found that the intra-eurozone FDI stocks have increased by about 20% during the first four years of the EMU.[76] Concerning the effect on corporate investment, there is evidence that the introduction of the euro has resulted in an increase in investment rates and that it has made it easier for firms to access financing in Europe. The euro has most specifically stimulated investment in companies that come from countries that previously had weak currencies. A study found that the introduction of the euro accounts for 22% of the investment rate after 1998 in countries that previously had a weak currency.[77]</p><p>The introduction of the euro has led to extensive discussion about its possible effect on inflation. In the short term, there was a widespread impression in the population of the eurozone that the introduction of the euro had led to an increase in prices, but this impression was not confirmed by general indices of inflation and other studies.[78][79] A study of this paradox found that this was due to an asymmetric effect of the introduction of the euro on prices: while it had no effect on most goods, it had an effect on cheap goods which have seen their price round up after the introduction of the euro. The study found that consumers based their beliefs on inflation of those cheap goods which are frequently purchased.[80] It has also been suggested that the jump in small prices may be because prior to the introduction, retailers made fewer upward adjustments and waited for the introduction of the euro to do so.[81]</p><p>One of the advantages of the adoption of a common currency is the reduction of the risk associated with changes in currency exchange rates. It has been found that the introduction of the euro created significant reductions in market risk exposures for nonfinancial firms both in and outside of Europe.[82] These reductions in market risk were concentrated in firms domiciled in the eurozone and in non-Euro firms with a high fraction of foreign sales or assets in Europe.</p><p>The introduction of the euro seems to have had a strong effect on European financial integration. According to a study on this question, it has significantly reshaped the European financial system, especially with respect to the securities markets [...] However, the real and policy barriers to integration in the retail and corporate banking sectors remain significant, even if the wholesale end of banking has been largely integrated.[83] Specifically, the euro has significantly decreased the cost of trade in bonds, equity, and banking assets within the eurozone.[84] On a global level, there is evidence that the introduction of the euro has led to an integration in terms of investment in bond portfolios, with eurozone countries lending and borrowing more between each other than with other countries.[85]</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/e/ea/Long-term_interest_rates_of_eurozone_countries_since_1993.png/300px-Long-term_interest_rates_of_eurozone_countries_since_1993.png" width="300" height="143"><p>


Long-term interest rates of Euro countries, 1993–2016


</p><p>
	As of January 2014, and since the introduction of the euro, interest rates of most members countries (particularly those with a weak currency), have decreased. The countries whose interest rates fell most as a result of the adoption of the euro are Greece, Ireland, Portugal, Spain, and Italy. These very countries have had the most serious sovereign financing problems.</p><p>The effect of declining interest rates, combined with excess liquidity continually provided by the ECB, made it easier for banks within the countries in which interest rates fell the most, and their linked sovereigns, to borrow significant amounts (above the 3% of GDP budget deficit imposed on the eurozone initially) and significantly inflate their public and private debt levels.[86] Following the financial crisis of 2007–2008, governments in these countries found it necessary to bail out or nationalise their privately held banks to prevent systemic failure of the banking system when underlying hard or financial asset values were found to be grossly inflated and sometimes so near worthless there was no liquid market for them.[87] This further increased the already high levels of public debt to a level the markets began to consider unsustainable, via increasing government bond interest rates, producing the ongoing European sovereign-debt crisis.</p><p>The evidence on the convergence of prices in the eurozone with the introduction of the euro is mixed. Several studies failed to find any evidence of convergence following the introduction of the euro after a phase of convergence in the early 1990s.[88][89] Other studies have found evidence of price convergence,[90][91] in particular for cars.[92] A possible reason for the divergence between the different studies is that the processes of convergence may not have been linear, slowing down substantially between 2000 and 2003, and resurfacing after 2003 as suggested by a recent study (2009).[93]</p><p>A study suggests that the introduction of the euro has had a positive effect on the amount of tourist travel within the EMU, with an increase of 6.5%.[94]</p><h2>Exchange rates</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/c/c5/EUR-USD.PNG/300px-EUR-USD.PNG" width="300" height="200"><p>


Euro-US Dollar exchange rate, starting from 2002. More recent information is available here.


</p><div class='pageBreak' ></div><h3>Flexible exchange rates</h3><p>
	The ECB targets interest rates rather than exchange rates and in general does not intervene on the foreign exchange rate markets. This is because of the implications of the Mundell–Fleming model, which implies a central bank cannot (without capital controls) maintain interest rate and exchange rate targets simultaneously, because increasing the money supply results in a depreciation of the currency. In the years following the Single European Act, the EU has liberalised its capital markets, and as the ECB has chosen monetary autonomy, the exchange-rate regime of the euro is flexible, or floating. The result of the ECB maintaining historically low interest rates and restricting money supply has been that over the last decade the euro has become expensive relative to the currency of Europe's main trading partners. However, in 2010, the euro started on a sharp decline. Starting at U.S$1.60 in 2008, and dropping to US$1.04 in 2015. The Canadian dollar, despite seeing a decline in value against the USD, has seen an increase in value relative to the euro.</p><h3>Against other major currencies</h3><p>The euro is the second-most widely held reserve currency after the U.S. dollar. After its introduction on 4 January 1999 its exchange rate against the other major currencies fell reaching its lowest exchange rates in 2000 (25 October vs the U.S. dollar, 26 October vs Japanese Yen, 3 May vs Pound Sterling). Afterwards it regained and its exchange rate reached its historical highest point in 2008 (15 July vs U.S. dollar, 23 July vs Japanese Yen, 29 December vs Pound Sterling). With the advent of the global financial crisis the euro initially fell, only to regain later. Despite pressure due to the European sovereign-debt crisis the euro remained stable.[95] In November 2011 the euro's exchange rate index&nbsp;– measured against currencies of the bloc's major trading partners&nbsp;– was trading almost two percent higher on the year, approximately at the same level as it was before the crisis kicked off in 2007.[96]</p><h2>Linguistic issues</h2><p> Main article: Linguistic issues concerning the euro</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/f/f5/EUR_5_obverse_%282013_issue%29.png/220px-EUR_5_obverse_%282013_issue%29.png" width="220" height="113"><p>


5 euro note from the new Europa series written in Latin (EURO) and Greek (???O) alphabets, but also in the Cyrillic (????) alphabet, as a result of Bulgaria joining the European Union in 2007.


</p><p>
	The formal titles of the currency are euro for the major unit and cent for the minor (one hundredth) unit and for official use in most eurozone languages; according to the ECB, all languages should use the same spelling for the nominative singular.[100] This may contradict normal rules for word formation in some languages, e.g., those where there is no eu diphthong. Bulgaria has negotiated an exception; euro in the Bulgarian Cyrillic alphabet is spelled as e??? (evro) and not e??? (euro) in all official documents.[101] In the Greek script the term e??? (evró) is used; the Greek cent coins are denominated in ?ept?/? (leptó/á). Official practice for English-language EU legislation is to use the words euro and cent as both singular and plural,[102] although the European Commission's Directorate-General for Translation states that the plural forms euros and cents should be used in English.[103]</p><h2>Criticism</h2><h3>Unemployment</h3><p>Nobel memorial prize-winning economist James Meade thought that a central bank should not make price stability the objective of aggregate demand management. When prices are likely to be pushed up by increase of indirect taxes or adverse terms-of-trade shocks, the surge in prices must be cancelled out by decline in domestic money wage costs, as long as such a price stability policy is adopted.[104] There would be unemployment in the all industrial sectors under a price stabilisation policy, suggesting that in the short run the elasticity of demand for labour is low.</p><p>Under the ECB's price stabilisation policy, many people in the eurozone have difficulty finding a job. The unemployment rate of Spain is around 25 percent in 2014, and an economic forecast says that the figure will not decrease below 20 percent until 2017.[105]</p><p>ELSTAT, the statistics agency of Greece, shows that Greece's unemployment rate was 27 percent in June 2014.[106] OECD forecasts that Greece's unemployment rate will remain around 27 percent until 2016. Due to long-term unemployment, skills of jobless persons have been depreciated and their motivation of finding jobs has been lost, which causes the country's level of unemployment to remain high.[107]</p><p>Spain's youth unemployment rate is 53.8 percent in July 2014, and this is the highest figure in the eurozone.[109] This figure is comparable to 53.1 percent of the Greek youth unemployment in May 2014.</p><p>In July 2014, the averaged unemployment rate of the eurozone is 11.7 percent, slight decrease from 11.9 percent in 2013.[108][109]</p><p>Likewise, Paul Krugman argued that the existence of a single shared currency across the entire eurozone, in combination with tight money policies of the ECB (motivated by insistence of Germany on low inflation), placed much of Southern Europe in a state of permanent high unemployment. According to Krugman, during the period between the creation of the euro and the 2008 financial crisis, countries of Southern Europe experienced abnormally high rates of wage growth due to high influx of investor money. Between 2000 and 2008, unit labor costs actually declined slightly in Germany, but rose by 30% in Spain and Greece.[110] This created an imbalance that put these countries at competitive disadvantage relative to Northern Europe. Returning to full employment at this point requires that the labor costs gap is somehow cancelled out. If Spain and Greece had their own currencies, this would have easily happened through exchange rate adjustment. Since they don't, it can either happen through a decrease in nominal wages in Spain and Greece, also known as internal devaluation, (an extremely difficult and slow process, since nominal wages, in general, exhibit downward rigidity), or through an equal increase in nominal wages (i.e. inflation) in Northern Europe, which does not happen because of active resistance from Germany.[111][112]</p><h2>Notes</h2><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Euro&amp;oldid=783608999"					
				Categories:  Hidden categories:</p><br><h1 lang="en">Outline of economics</h1><p> From Wikipedia, the free encyclopedia</p><p>The following hierarchical outline is provided as an overview of and topical guide to economics:</p><p>Economics – analyzes the production, distribution, and consumption of goods and services. It aims to explain how economies work and how economic agents interact.</p><h2>Contents</h2><div class='pageBreak' ></div><h2>Description of Economics</h2><p>Economics can be described as all of the following:</p><h2>Branches of economics</h2><h3>Subdisciplines of economics</h3><h3>Methodologies or approaches</h3><h3>Multidisciplinary fields involving economics</h3><h2>Types of economies</h2><p> Main articles: Economy and Economic system</p><p>Economy – system of human activities related to the production, distribution, exchange, and consumption of goods and services of a country or other area.</p><h3>Economies, by political &amp; social ideological structure</h3><h3>Economies, by scope</h3><h3>Economies, by regulation</h3><h2>Economic elements</h2><h3>Economic activities</h3><h3>Economic forces</h3><h3>Economic measures</h3><h3>Economic participants</h3><h3>Economic politics</h3><p>Economic policy</p><h3>Infrastructure</h3><p>Infrastructure</p><h3>Markets</h3><p>Market</p><p>Market form</p><h3>Money</h3><p>Money</p><h3>Resources</h3><p>Resource management</p><p>Factors of production</p><p>Land</p><p>Capital</p><h2>Economic theory</h2><h3>Economic ideologies</h3><h2>History of economics</h2><h3>History of economic thought</h3><p>History of economic thought</p><h3>Economic history</h3><p>Economic history</p><h2>General economic concepts</h2><h2>Economics organizations</h2><h2>Economics publications</h2><h2>Persons influential in the field of economics</h2><h3>Nobel Memorial Prize–winning economic historians</h3><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Outline_of_economics&amp;oldid=779322882"					
				Categories:  Hidden categories:</p><br><h1 lang="en">Economics (disambiguation)</h1><p> From Wikipedia, the free encyclopedia</p><div class='pageBreak' ></div><p>Economics is the social science that studies the production, distribution, and consumption of goods and services.</p><p>Economics may also refer to:</p><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Economics_(disambiguation)&amp;oldid=642984251"					
				Categories:  Hidden categories:</p><br><h1 lang="en">Schools of economic thought</h1><p> From Wikipedia, the free encyclopedia</p><p>In the history of economic thought, a school of economic thought is a group of economic thinkers who share or shared a common perspective on the way economies work. While economists do not always fit into particular schools, particularly in modern times, classifying economists into schools of thought is common. Economic thought may be roughly divided into three phases: premodern (Greco-Roman, Indian, Persian, Islamic, and Imperial Chinese), early modern (mercantilist, physiocrats) and modern (beginning with Adam Smith and classical economics in the late 18th century). Systematic economic theory has been developed mainly since the beginning of what is termed the modern era.</p><p>Currently, the great majority of economists follow an approach referred to as mainstream economics (sometimes called 'orthodox economics'). Within the mainstream in the United States, distinctions can be made between the Saltwater school (associated with Berkeley, Harvard, MIT, Pennsylvania, Princeton, and Yale), and the more laissez-faire ideas of the Freshwater school (represented by the Chicago school of economics, Carnegie Mellon University, the University of Rochester and the University of Minnesota). Both of these schools of thought are associated with the neoclassical synthesis.</p><p>Some influential approaches of the past, such as the historical school of economics and institutional economics, have become defunct or have declined in influence, and are now considered heterodox approaches. Other longstanding heterodox schools of economic thought include Austrian economics and Marxian economics. Some more recent developments in economic thought such as feminist economics and ecological economics adapt and critique mainstream approaches with an emphasis on particular issues rather than developing as independent schools.</p><h2>Contents</h2><h2>Ancient economic thought</h2><p> Main article: Ancient economic thought</p><h2>Islamic economics</h2><p> Main articles: Islamic economic jurisprudence and Islamic economics in the world</p><p>Islamic economics is the practice of economics in accordance with Islamic law. The origins can be traced back to the Caliphate,[1] where an early market economy and some of the earliest forms of merchant capitalism took root between the 8th–12th centuries, which some refer to as Islamic capitalism.[2]</p><p>Islamic economics seeks to enforce Islamic regulations not only on personal issues, but to implement broader economic goals and policies of an Islamic society, based on uplifting the deprived masses. It was founded on free and unhindered circulation of wealth so as to handsomely reach even the lowest echelons of society. One distinguishing feature is the tax on wealth (in the form of both Zakat and Jizya), and bans levying taxes on all kinds of trade and transactions (Income/Sales/Excise/Import/Export duties etc.). Another distinguishing feature is prohibition of interest in the form of excess charged while trading in money. Its pronouncement on use of paper currency also stands out. Though promissory notes are recognized, they must be fully backed by reserves. Fractional-reserve banking is disallowed as a form of breach of trust.</p><p>It saw innovations such as trading companies, big businesses, contracts, bills of exchange, long-distance international trade, the first forms of partnership (mufawada) such as limited partnerships (mudaraba), and the earliest forms of credit, debt, profit, loss, capital (al-mal), capital accumulation (nama al-mal),[3] circulating capital, capital expenditure, revenue, cheques, promissory notes,[4] trusts (see Waqf), startup companies,[5] savings accounts, transactional accounts, pawning, loaning, exchange rates, bankers, money changers, ledgers, deposits, assignments, the double-entry bookkeeping system,[6] lawsuits,[7] and agency institution.[8][9]</p><p>This school has seen a revived interest in development and understanding since the later part of the 20th century.</p><h2>Scholasticism</h2><p> Main article: Scholasticism</p><h2>Mercantilism</h2><p> Main article: Mercantilism</p><p>Economic policy in Europe during the late Middle Ages and early Renaissance treated economic activity as a good which was to be taxed to raise revenues for the nobility and the church. Economic exchanges were regulated by feudal rights, such as the right to collect a toll or hold a faire, as well as guild restrictions and religious restrictions on lending. Economic policy, such as it was, was designed to encourage trade through a particular area. Because of the importance of social class, sumptuary laws were enacted, regulating dress and housing, including allowable styles, materials and frequency of purchase for different classes. Niccolò Machiavelli in his book The Prince was one of the first authors to theorize economic policy in the form of advice. He did so by stating that princes and republics should limit their expenditures and prevent either the wealthy or the populace from despoiling the other. In this way a state would be seen as generous because it was not a heavy burden on its citizens.</p><h2>Physiocrats</h2><p> Main article: Physiocrats</p><p>The Physiocrats were 18th century French economists who emphasized the importance of productive work, and particularly agriculture, to an economy's wealth. Their early support of free trade and deregulation influenced Adam Smith and the classical economists.</p><h2>Classical political economy</h2><p> Main article: Classical economics</p><p>Classical economics, also called classical political economy, was the original form of mainstream economics of the 18th and 19th centuries. Classical economics focuses on the tendency of markets to move to equilibrium and on objective theories of value. Neo-classical economics differs from classical economics primarily in being utilitarian in its value theory and using marginal theory as the basis of its models and equations. Marxian economics also descends from classical theory. Anders Chydenius (1729–1803) was the leading classical liberal of Nordic history. Chydenius, who was a Finnish priest and member of parliament, published a book called The National Gain in 1765, in which he proposes ideas of freedom of trade and industry and explores the relationship between economy and society and lays out the principles of liberalism, all of this eleven years before Adam Smith published a similar and more comprehensive book, The Wealth of Nations. According to Chydenius, democracy, equality and a respect for human rights were the only way towards progress and happiness for the whole of society.</p><h2>American (National) School</h2><div class='pageBreak' ></div><p> Main article: American School (economics)</p><p>The American School owes its origin to the writings and economic policies of Alexander Hamilton, the first Treasury Secretary of the United States. It emphasized high tariffs on imports to help develop the fledgling American manufacturing base and to finance infrastructure projects, as well as National Banking, Public Credit, and government investment into advanced scientific and technological research and development. Friedrich List, one of the most famous proponents of the economic system, named it the National System, and was the main impetus behind the development of the German Zollverein and the economic policies of Germany under Chancellor Otto Von Bismarck beginning in 1879.</p><h2>French liberal school</h2><p> Main article: French Liberal School</p><p>The French Liberal School (also called the Optimist School or Orthodox School) is a 19th-century school of economic thought that was centered on the Collège de France and the Institut de France. The Journal des Économistes was instrumental in promulgating the ideas of the School. The School voraciously defended free trade and laissez-faire capitalism. They were primary opponents of collectivist, interventionist and protectionist ideas. This made the French School a forerunner of the modern Austrian School.</p><h2>German historical school</h2><p> Main article: Historical school of economics</p><p>The Historical school of economics was an approach to academic economics and to public administration that emerged in the 19th century in Germany, and held sway there until well into the 20th century. The Historical school held that history was the key source of knowledge about human actions and economic matters, since economics was culture-specific, and hence not generalizable over space and time. The School rejected the universal validity of economic theorems. They saw economics as resulting from careful empirical and historical analysis instead of from logic and mathematics. The School preferred historical, political, and social studies to self-referential mathematical modelling. Most members of the school were also Kathedersozialisten, i.e. concerned with social reform and improved conditions for the common man during a period of heavy industrialization. The Historical School can be divided into three tendencies: the Older, led by Wilhelm Roscher, Karl Knies, and Bruno Hildebrand; the Younger, led by Gustav von Schmoller, and also including Étienne Laspeyres, Karl Bücher, Adolph Wagner, and to some extent Lujo Brentano; the Youngest, led by Werner Sombart and including, to a very large extent, Max Weber.</p><p>Predecessors included Friedrich List. The Historical school largely controlled appointments to Chairs of Economics in German universities, as many of the advisors of Friedrich Althoff, head of the university department in the Prussian Ministry of Education 1882-1907, had studied under members of the School. Moreover, Prussia was the intellectual powerhouse of Germany and so dominated academia, not only in central Europe, but also in the United States until about 1900, because the American economics profession was led by holders of German Ph.Ds. The Historical school was involved in the Methodenstreit (strife over method) with the Austrian School, whose orientation was more theoretical and a prioristic. In English speaking countries, the Historical school is perhaps the least known and least understood approach to the study of economics, because it differs radically from the now-dominant Anglo-American analytical point of view. Yet the Historical school forms the basis—both in theory and in practice—of the social market economy, for many decades the dominant economic paradigm in most countries of continental Europe. The Historical school is also a source of Joseph Schumpeter's dynamic, change-oriented, and innovation-based economics. Although his writings could be critical of the School, Schumpeter's work on the role of innovation and entrepreneurship can be seen as a continuation of ideas originated by the Historical School, especially the work of von Schmoller and Sombart.</p><h2>English historical school</h2><p> Main article: English historical school of economics</p><p>Although not nearly as famous as its German counterpart, there was also an English Historical School, whose figures included William Whewell, Richard Jones, Thomas Edward Cliffe Leslie, Walter Bagehot, Thorold Rogers, Arnold Toynbee, William Cunningham, and William Ashley. It was this school that heavily critiqued the deductive approach of the classical economists, especially the writings of David Ricardo. This school revered the inductive process and called for the merging of historical fact with those of the present period.</p><h2>French historical school</h2><h2>Utopian economics</h2><h2>Georgist economics</h2><p> Main article: Georgism</p><p>Georgism or geoism is an economic philosophy proposing that both individual and national economic outcomes would be improved by the utilization of economic rent resulting from control over land and natural resources through levies such as a land value tax.</p><h2>Marxian economics</h2><p> Main article: Marxian economics</p><p>Marxian economics descended from the work of Karl Marx and Friedrich Engels. This school focuses on the labor theory of value and what Marx considered to be the exploitation of labour by capital. Thus, in Marxian economics, the labour theory of value is a method for measuring the exploitation of labour in a capitalist society rather than simply a theory of price.[10][11]</p><h2>Neo-Marxian economics</h2><p> Main article: Neo-Marxian economics</p><h2>State socialism</h2><p> Main article: Socialist economics</p><h2>Ricardian socialism</h2><p> Main article: Ricardian socialism</p><p>Ricardian socialism is a branch of early 19th century classical economic thought based on the theory that labor is the source of all wealth and exchange value, and rent, profit and interest represent distortions to a free market. The pre-Marxian theories of capitalist exploitation they developed are widely regarded as having been heavily influenced by the works of David Ricardo, and favoured collective ownership of the means of production.</p><h2>Anarchist economics</h2><p> Main article: Anarchist economics</p><p>Anarchist economics comprises a set of theories which seek to outline modes of production and exchange not governed by coercive social institutions:</p><p>Thinkers associated with anarchist economics include:</p><h2>Distributism</h2><div class='pageBreak' ></div><p> Main article: Distributism</p><p>Distributism is an economic philosophy that was originally formulated in the late 19th century and early 20th century by Catholic thinkers to reflect the teachings of Pope Leo XIII's encyclical Rerum Novarum, and Pope Pius's XI encyclical Quadragesimo Anno. It seeks to pursue a third way between capitalism and socialism, desiring to order society according to Christian principles of justice while still preserving private property.</p><h2>Institutional economics</h2><p> Main article: Institutional economics</p><p>Institutional economics focuses on understanding the role of the evolutionary process and the role of institutions in shaping economic behaviour. Its original focus lay in Thorstein Veblen's instinct-oriented dichotomy between technology on the one side and the ceremonial sphere of society on the other. Its name and core elements trace back to a 1919 American Economic Review article by Walton H. Hamilton.[12][13]</p><h2>New institutional economics</h2><p> Main article: New institutional economics</p><p>New institutional economics is a perspective that attempts to extend economics by focusing on the social and legal norms and rules (which are institutions) that underlie economic activity and with analysis beyond earlier institutional economics and neoclassical economics.[14] It can be seen as a broadening step to include aspects excluded in neoclassical economics. It rediscovers aspects of classical political economy.</p><h2>Neoclassical economics</h2><p> Main article: Neoclassical economics</p><p>Neoclassical economics is the dominant form of economics used today and has the highest amount of adherents among economists.[dubious – discuss] It is often referred to by its critics as Orthodox Economics. The more specific definition this approach implies was captured by Lionel Robbins in a 1932 essay: the science which studies human behavior as a relation between scarce means having alternative uses. The definition of scarcity is that available resources are insufficient to satisfy all wants and needs; if there is no scarcity and no alternative uses of available resources, then there is no economic problem.</p><h2>Lausanne school</h2><p> Main article: Lausanne School</p><h2>Austrian school</h2><p> Main article: Austrian School</p><p>Austrian economists advocate methodological individualism in interpreting economic developments, the subjective theory of value, that money is non-neutral, and emphasize the organizing power of the price mechanism (see economic calculation debate) and a laissez faire approach to the economy.[15]</p><h2>Stockholm school</h2><p> Main article: Stockholm School</p><h2>Keynesian economics</h2><p> Main articles: Keynesian economics, Post-Keynesian economics, Neo-Keynesian economics, and New Keynesian economics</p><p>Keynesian economics has developed from the work of John Maynard Keynes and focused on macroeconomics in the short-run, particularly the rigidities caused when prices are fixed. It has two successors. Post-Keynesian economics is an alternative school—one of the successors to the Keynesian tradition with a focus on macroeconomics. They concentrate on macroeconomic rigidities and adjustment processes, and research micro foundations for their models based on real-life practices rather than simple optimizing models. Generally associated with Cambridge, England and the work of Joan Robinson (see Post-Keynesian economics). New-Keynesian economics is the other school associated with developments in the Keynesian fashion. These researchers tend to share with other Neoclassical economists the emphasis on models based on micro foundations and optimizing behavior, but focus more narrowly on standard Keynesian themes such as price and wage rigidity. These are usually made to be endogenous features of these models, rather than simply assumed as in older style Keynesian ones (see New-Keynesian economics).</p><h2>Chicago school</h2><p> Main article: Chicago school of economics</p><p>The Chicago School is a neoclassical school of economic thought associated with the work of the faculty at the University of Chicago, notable particularly in macroeconomics for developing monetarism as an alternative to Keynesianism and its influence on the use of rational expectations in macroeconomic modelling.</p><h2>Carnegie school</h2><p> Main article: Carnegie School</p><h2>Neo-Ricardianism</h2><p> Main article: Neo-Ricardianism</p><h2>Modern schools (late 19th and 20th century)</h2><p>Mainstream economics is a term used to distinguish economics in general from heterodox approaches and schools within economics. It begins with the premise that resources are scarce and that it is necessary to choose between competing alternatives. That is, economics deals with tradeoffs. With scarcity, choosing one alternative implies forgoing another alternative—the opportunity cost. The opportunity cost expresses an implicit relationship between competing alternatives. Such costs, considered as prices in a market economy, are used for analysis of economic efficiency or for predicting responses to disturbances in a market. In a planned economy comparable shadow price relations must be satisfied for the efficient use of resources, as first demonstrated by the Italian economist Enrico Barone. Economists represent incentives and costs as playing a pervasive role in shaping decision making. An immediate example of this is the consumer theory of individual demand, which isolates how prices (as costs) and income affect quantity demanded. Modern mainstream economics builds primarily on neoclassical economics, which began to develop in the late 19th century. Mainstream economics also acknowledges the existence of market failure and insights from Keynesian economics. It uses models of economic growth for analyzing long-run variables affecting national income. It employs game theory for modeling market or non-market behavior. Some important insights on collective behavior (for example, emergence of organizations) have been incorporated through the new institutional economics. A definition that captures much of modern economics is that of Lionel Robbins in a 1932 essay: the science which studies human behaviour as a relationship between ends and scarce means which have alternative uses. Scarcity means that available resources are insufficient to satisfy all wants and needs. Absent scarcity and alternative uses of available resources, there is no economic problem. The subject thus defined involves the study of choice, as affected by incentives and resources. Economics generally is the study of how people allocate scarce resources among alternative uses.</p><p>Heterodox economics: Some schools of thought are at variance with the microeconomic formalism of neoclassical economics. Heterodox economists instead emphasize the influence of history, natural systems, uncertainty, and power. Among these, we have institutional economics, Marxian economics, feminist economics, socialist economics, binary economics, ecological economics, bioeconomics and thermoeconomics.</p><div class='pageBreak' ></div><h2>Heterodox schools (20th and 21st century)</h2><p>In the late 19th century, a number of heterodox schools contended with the neoclassical school that arose following the marginal revolution. Most survive to the present day as self-consciously dissident schools, but with greatly diminished size and influence relative to mainstream economics. The most significant are Institutional economics, Marxian economics and the Austrian School.</p><p>The development of Keynesian economics was a substantial challenge to the dominant neoclassical school of economics. Keynesian views eventually entered the mainstream as a result of the Keynesian-neoclassical synthesis developed by John Hicks. The rise of Keynesianism, and its incorporation into mainstream economics, reduced the appeal of heterodox schools. However, advocates of a more fundamental critique of orthodox economics formed a school of Post-Keynesian economics.</p><p>More recent heterodox developments include evolutionary economics (though this term is also used to describe institutional economics), feminist, Green economics, Post-autistic economics, and Thermoeconomics</p><p>Heterodox approaches often embody criticisms of the mainstream approaches. For instance:</p><p>Most heterodox views are critical of capitalism. The most notable exception is Austrian economics.</p><p>Georgescu-Roegen reintroduced into economics, the concept of entropy from thermodynamics (as distinguished from what, in his view, is the mechanistic foundation of neoclassical economics drawn from Newtonian physics) and did foundational work which later developed into evolutionary economics. His work contributed significantly to thermoeconomics and to ecological economics.[16][17][18][19][20]</p><h2>20th century schools</h2><p>Notable schools or trends of thought in economics in the 20th century were as follows. These were advocated by well-defined groups of academics that became widely known:</p><p>In the late 20th century, areas of study that produced change in economic thinking were: risk-based (rather than price-based models), imperfect economic actors, and treating economics as a biological science (based on evolutionary norms rather than abstract exchange).</p><p>The study of risk was influential, in viewing variations in price over time as more important than actual price. This applied particularly to financial economics, where risk/return tradeoffs were the crucial decisions to be made.</p><p>An important area of growth was the study of information and decision. Examples of this school included the work of Joseph Stiglitz. Problems of asymmetric information and moral hazard, both based around information economics, profoundly affected modern economic dilemmas like executive stock options, insurance markets, and Third-World debt relief.</p><p>Finally, there were a series of economic ideas rooted in the conception of economics as a branch of biology, including the idea that energy relationships, rather than price relationships, determine economic structure. The use of fractal geometry to create economic models (see Energy Economics). In its infancy the application of non-linear dynamics to economic theory, as well as the application of evolutionary psychology explored the processes of valuation and the persistence of non-equilibrium conditions. The most visible work was in the area of applying fractals to market analysis, particularly arbitrage (see Complexity economics). Another infant branch of economics was neuroeconomics. The latter combines neuroscience, economics, and psychology to study how we make choices.</p><h2>Economic viewpoints</h2><h3>Within mainstream</h3><p>Mainstream economics encompasses a wide (but not unbounded) range of views. Politically, most mainstream economists hold views ranging from laissez-faire to modern liberalism. There are also divergent views on particular issues within economics, such as the effectiveness and desirability of Keynesian macroeconomic policy. Although, historically, few mainstream economists have regarded themselves as members of a school, many would identify with one or more of neoclassical economics, monetarism, Keynesian economics, new classical economics, or behavioral economics.</p><p>Controversies within mainstream economics tend to be stated in terms of:</p><p>An example of a mainstream economic approach is the Triple Bottom Line accounting methods for cities developed by ICLEI and advocated by the C40 organization of the world's 40 largest cities. As this example suggests, a mainstream approach is defined by the degree to which it is adopted and advocated, not necessarily its technical rigor.</p><h3>Outside the mainstream</h3><p>Other viewpoints on economic issues from outside mainstrain economics include dependency theory and world systems theory in the study of international relations</p><p>Proposed radical reforms of the economic system originating outside mainstream economics include the participatory economics movement and binary economics.</p><h2>Notes</h2><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Schools_of_economic_thought&amp;oldid=783673823"					
				Categories:  Hidden categories:</p><br><h1 lang="en">Demand</h1><p> From Wikipedia, the free encyclopedia</p><p>In economics, demand is the quantity of a commodity or a service that people are willing or able to buy at a certain price.[1]</p><p>The relationship between price and quantity demanded is also known as demand curve. Preferences and choices, which underly demand, can be represented as functions of cost, benefit, odds and other variables.</p><h2>Contents</h2><h2>Determinants of (Factors affecting) demand</h2><p>Innumerable factors and circumstances could affect a buyer's willingness or ability to buy a good. Some of the more common factors are:</p><h2>Demand function and equation</h2><div class='pageBreak' ></div><p>The demand equation is the mathematical expression of the relationship between the quantity of a good demanded and those factors that affect the willingness and ability of a consumer to buy the good. For example, Qd = f(P; Prg, Y) is a demand equation where Qd is the quantity of a good demanded, P is the price of the good, Prg is the price of a related good, and Y is income; the function on the right side of the equation is called the demand function. The semi-colon in the list of arguments in the demand function means that the variables to the right are being held constant as one plots the demand curve in (quantity, price) space. A simple example of a demand equation is Qd = 325 - P - 30Prg + 1.4Y. Here 325 is the repository of all relevant non-specified factors that affect demand for the product. P is the price of the good. The coefficient is negative in accordance with the law of demand. The related good may be either a complement or a substitute. If a complement, the coefficient of its price would be negative as in this example. If a substitute, the coefficient of its price would be positive. Income, Y, has a positive coefficient indicating that the good is a normal good. If the coefficient was negative the good in question would be an inferior good meaning that the demand for the good would fall as the consumer's income increased. Specifying values for the non price determinants, Prg = 4.00 and Y = 50, results in the demand equation Q = 325 - P - 30(4) +1.4(50) or Q = 275 - P. If income were to increase to 55 the new demand equation would be Q = 282 - P. Graphically this change in a non price determinant of demand would be reflected in an outward shift of the demand function caused by a change in the x intercept.</p><h2>Demand curve</h2><p> Main article: Demand curve</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/3/36/Marshall_PED.png" width="175" height="180"><p>In economics, the demand curve is the graph depicting the relationship between the price of a certain commodity and the amount of it that consumers are willing and able to purchase at that given price.</p><h2>Price elasticity of demand (PED)</h2><p> Main article: Price elasticity of demand</p><p>PED is a measure of the sensitivity of the quantity variable, Q, to changes in the price variable, P. Elasticity answers the question of the percent by which the quantity demanded will change relative to (divided by) a given percentage change in the price. For infinitesimal changes the formula for calculating PED is the absolute value of (?Q/?P)×(P/Q).</p><h3>Determinants of PED</h3><p>The overriding factor in determining PED is the willingness and ability of consumers after a price changes to postpone immediate consumption decisions concerning the good and to search for substitutes (wait and look).</p><h3>Elasticity along linear demand curve</h3><p>The slope of a linear demand curve is constant. The elasticity of demand changes continuously as one moves down the demand curve because the ratio of price to quantity continuously falls. At the point the demand curve intersects the y-axis PED is infinitely elastic, because the variable Q appearing in the denominator of the elasticity formula is zero there. At the point the demand curve intersects the x-axis PED is zero, because the variable P appearing in the numerator of the elasticity formula is zero there.[2] At one point on the demand curve PED is unitary elastic: PED equals one. Above the point of unitary elasticity is the elastic range of the demand curve (meaning that the elasticity is greater than one). Below is the inelastic range, in which the elasticity is less than one. The decline in elasticity as one moves down the curve is due to the falling P/Q ratio.</p><h3>Constant price elasticity demand</h3><p>
  
    
      
        Q
        =
        a
        
          P
          
            c
          
        
      
    
    {\displaystyle Q=aP^{c}}
  
 where a and c are parameters, and the constant price elasticity is c and 
  
    
      
        c
        =
        0
      
    
    {\displaystyle c\leq 0}
  
.</p><h2>Market structure and the demand curve</h2><p>In perfectly competitive markets the demand curve, the average revenue curve, and the marginal revenue curve all coincide and are horizontal at the market-given price.[3] The demand curve is perfectly elastic and coincides with the average and marginal revenue curves. Economic actors are price-takers. Perfectly competitive firms have zero market power; that is, they have no ability to affect the terms and conditions of exchange. A perfectly competitive firm's decisions are limited to whether to produce and if so, how much. In less than perfectly competitive markets the demand curve is negatively sloped and there is a separate marginal revenue curve. A firm in a less than perfectly competitive market is a price-setter. The firm can decide how much to produce or what price to charge. In deciding one variable the firm is necessarily determining the other variable</p><h2>Inverse demand function</h2><p> Main article: Inverse demand function</p><p>In its standard form a linear demand equation is Q = a - bP. That is, quantity demanded is a function of price. The inverse demand equation, or price equation, treats price as a function g of quantity demanded: P = f(Q). To compute the inverse demand equation, simply solve for P from the demand equation.[4] For example, if the demand equation is Q = 240 - 2P then the inverse demand equation would be P = 120 - .5Q, the right side of which is the inverse demand function.[5]</p><p>The inverse demand function is useful in deriving the total and marginal revenue functions. Total revenue equals price, P, times quantity, Q, or TR = P×Q. Multiply the inverse demand function by Q to derive the total revenue function: TR = (120 - .5Q) × Q = 120Q - 0.5Q². The marginal revenue function is the first derivative of the total revenue function; here MR = 120 - Q. Note that the MR function has the same y-intercept as the inverse demand function in this linear example; the x-intercept of the MR function is one-half the value of that of the demand function, and the slope of the MR function is twice that of the inverse demand function. This relationship holds true for all linear demand equations. The importance of being able to quickly calculate MR is that the profit-maximizing condition for firms regardless of market structure is to produce where marginal revenue equals marginal cost (MC). To derive MC the first derivative of the total cost function is taken. For example, assume cost, C, equals 420 + 60Q + Q2. Then MC = 60 + 2Q. Equating MR to MC and solving for Q gives Q = 20. So 20 is the profit maximizing quantity: to find the profit-maximizing price simply plug the value of Q into the inverse demand equation and solve for P.</p><div class='pageBreak' ></div><h2>Residual demand curve</h2><p>The demand curve facing a particular firm is called the residual demand curve. The residual demand curve is the market demand that is not met by other firms in the industry at a given price. The residual demand curve is the market demand curve D(p), minus the supply of other organizations, So(p): Dr(p) = D(p) - So(p )[6]</p><h2>Is the demand curve for PC firm really flat?</h2><p>Practically every introductory microeconomics text describes the demand curve facing a perfectly competitive firm as being flat or horizontal. A horizontal demand curve is perfectly elastic. If there are n identical firms in the market then the elasticity of demand PED facing any one firm is</p><p>where PEDm is the market elasticity of demand, PES is the elasticity of supply of each of the other firms, and (n -1) is the number of other firms. This formula suggests two things. The demand curve is not perfectly elastic and if there are a large number of firms in the industry the elasticity of demand for any individual firm will be extremely high and the demand curve facing the firm will be nearly flat.[6]</p><p>For example assume that there are 80 firms in the industry and that the demand elasticity for industry is -1.0 and the price elasticity of supply is 3. Then</p><p>That is the firm PED is 317 times as elastic as the market PED. If a firm raised its price by one tenth of one percent demand would drop by nearly one third.[6] if the firm raised its price by three tenths of one percent the quantity demanded would drop by nearly 100%. Three tenths of one percent marks the effective range of pricing power the firm has because any attempt to raise prices by a higher percentage will effectively reduce quantity demanded to zero.</p><h2>Demand management in economics</h2><p>Demand management in economics is the art or science of controlling economic or aggregate demand to avoid a recession. Such management is inspired by Keynesian macroeconomics, and Keynesian economics is sometimes referred to as demand-side economics.</p><h2>Different types of goods demand</h2><p>Negative demand: If the market response to a product is negative, it shows that people are not aware of the features of the service and the benefits offered. Under such circumstances, the marketing unit of a service firm has to understand the psyche of the potential buyers and find out the prime reason for the rejection of the service. For example: if passengers refuse a bus conductor's call to board the bus. The service firm has to come up with an appropriate strategy to remove the misunderstandings of the potential buyers. A strategy needs to be designed to transform the negative demand into a positive demand.</p><p>No demand: If people are unaware, have insufficient information about a service or due to the consumer's indifference this type of a demand situation could occur. The marketing unit of the firm should focus on promotional campaigns and communicating reasons for potential customers to use the firm's services. Service differentiation is one of the popular strategies used to compete in a no demand situation in the market.</p><p>Latent demand: At any given time it is impossible to have a set of services that offer total satisfaction to all the needs and wants of society. In the market there exists a gap between desirables and the availables. There is always a search on for better and newer offers to fill the gap between desirability and availability. Latent demand is a phenomenon of any economy at any given time, it should be looked upon as a business opportunity by service firms and they should orient themselves to identify and exploit such opportunities at the right time. For example, a passenger traveling in an ordinary bus dreams of traveling in a luxury bus. Therefore, latent demand is nothing but the gap between desirability and availability.</p><p>Seasonal demand:Some services do not have an all year round demand, they might be required only at a certain period of time. Seasons all over the world are very diverse. Seasonal demands create many problems to service organizations, such as:- idling the capacity, fixed cost and excess expenditure on marketing and promotions. Strategies used by firms to overcome this hurdle are like - to nurture the service consumption habit of customers so as to make the demand unseasonal, or other than that firms recognize markets elsewhere in the world during the off-season period. Hence, this presents and opportunity to target different markets with the appropriate season in different parts of the world. For example, the need for Christmas cards comes around once a year. Or the, seasonal fruits in a country.</p><p>Demand patterns need to be studied in different segments of the market. Service organizations need to constantly study changing demands related to there service offerings over various time periods. They have to develop a system to chart these demand fluctuations, which helps them in predicting the demand cycles. Demands do fluctuate randomly, therefore, they should be followed on a daily, weekly or a monthly basis.</p><h2>Criticism</h2><p>E. F. Schumacher challenges the prevailing economic assumption that fulfilling demand is the purpose of economic activity, offering a framework of what he calls Buddhist economics in which wise demands, fulfilling genuine human needs, are distinguished from unwise demands, arising from the five intellectual impairments recognized by Buddhism:[7]</p><p>The cultivation and expansion of needs is the antithesis of wisdom. It is also the antithesis of freedom and peace. Every increase of needs tends to increase one’s dependence on outside forces over which one cannot have control, and therefore increases existential fear. Only by a reduction of needs can one promote a genuine reduction in those tensions which are the ultimate causes of strife and war.[8]</p><h2>Demand reduction</h2><h3>In psychopharmacology</h3><p> Main article: Demand reduction</p><p>Demand reduction refers to efforts aimed at reducing the public desire for illegal and illicit drugs. The drug policy is in contrast to the reduction of drug supply, but the two policies are often implemented together.</p><h3>In energy conservation</h3><p> Main article: Energy demand management</p><p>Energy demand management, also known as demand-side management (DSM) or demand-side response (DSR), is the modification of consumer demand for energy through various methods such as financial incentives and behavioral change through education.</p><h2>Notes</h2><div class='pageBreak' ></div><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Demand&amp;oldid=778789425"					
				Categories:  				
							
		<br>
			

							 
						

			</p><br><h1 lang="en">Macroeconomics</h1><p> From Wikipedia, the free encyclopedia</p><p>Macroeconomics (from the Greek prefix makro- meaning large and economics) is a branch of economics dealing with the performance, structure, behavior, and decision-making of an economy as a whole. This includes national, regional, and global economies.[1] Macroeconomics and microeconomics, a pair of terms coined by Ragnar Frisch, are the two most general fields in economics.[2] In contrast to macroeconomics, microeconomics is the branch of economics that studies the behavior of individuals and firms in making decisions and the interactions among these individuals and firms in narrowly-defined markets.</p><p>Macroeconomists study aggregated indicators such as GDP, unemployment rates, national income, price indices, and the interrelations among the different sectors of the economy to better understand how the whole economy functions. Macroeconomists develop models that explain the relationship between such factors as national income, output, consumption, unemployment, inflation, savings, investment, international trade and international finance.</p><p>While macroeconomics is a broad field of study, there are two areas of research that are emblematic of the discipline: the attempt to understand the causes and consequences of short-run fluctuations in national income (the business cycle), and the attempt to understand the determinants of long-run economic growth (increases in national income). Macroeconomic models and their forecasts are used by governments to assist in the development and evaluation of economic policy.</p><h2>Contents</h2><h2>Basic macroeconomic concepts</h2><p>Macroeconomics encompasses a variety of concepts and variables, but there are three central topics for macroeconomic research.[3] Macroeconomic theories usually relate the phenomena of output, unemployment, and inflation. Outside of macroeconomic theory, these topics are also important to all economic agents including workers, consumers, and producers.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/7/7e/Circulation_in_macroeconomics.svg/220px-Circulation_in_macroeconomics.svg.png" width="220" height="196"><p>


Circulation in macroeconomics.


</p><h3>Output and income</h3><p>
	National output is the total amount of everything a country produces in a given period of time. Everything that is produced and sold generates an equal amount of income. Therefore, output and income are usually considered equivalent and the two terms are often used interchangeably. Output can be measured as total income, or it can be viewed from the production side and measured as the total value of final goods and services or the sum of all value added in the economy.[4]</p><p>Macroeconomic output is usually measured by gross domestic product (GDP) or one of the other national accounts. Economists are interested in long-run increases in output study economic growth. Advances in technology, accumulation of machinery and other capital, and better education and human capital all these factors lead to increased economic output over time. However, output does not always increase consistently. Business cycles can cause short-term drops in output called recessions. Economists look for macroeconomic policies that prevent economies from slipping into recessions and that lead to faster long-term growth.</p><h3>Unemployment</h3><p> Main article: Unemployment</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/d/db/Okuns_law_differences_1948_to_mid_2011.png/220px-Okuns_law_differences_1948_to_mid_2011.png" width="220" height="160"><p>


A chart using US data showing the relationship between economic growth and unemployment expressed by Okun's law. The relationship demonstrates cyclical unemployment. Economic growth leads to a lower unemployment rate.


</p><p>
	The amount of unemployment in an economy is measured by the unemployment rate, i.e. the percentage of workers without jobs in the labor force. The unemployment rate in the labor force only includes workers actively looking for jobs. People who are retired, pursuing education, or discouraged from seeking work by a lack of job prospects are excluded.</p><p>Unemployment can be generally broken down into several types that are related to different causes.</p><h3>Inflation and deflation</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/8/80/M2andInflation.png/220px-M2andInflation.png" width="220" height="160"><p>


The ten-year moving averages of changes in price level and growth in money supply (using the measure of M2, the supply of hard currency and money held in most types of bank accounts) in the US from 1875 to 2011. Over the long run, the two series show a close relationship.


</p><p>
	A general price increase across the entire economy is called inflation. When prices decrease, there is deflation. Economists measure these changes in prices with price indexes. Inflation can occur when an economy becomes overheated and grows too quickly. Similarly, a declining economy can lead to deflation.</p><div class='pageBreak' ></div><p>Central bankers, who manage a country's money supply, try to avoid changes in price level by using monetary policy. Raising interest rates or reducing the supply of money in an economy will reduce inflation. Inflation can lead to increased uncertainty and other negative consequences. Deflation can lower economic output. Central bankers try to stabilize prices to protect economies from the negative consequences of price changes.</p><p>Changes in price level may be the result of several factors. The quantity theory of money holds that changes in price level are directly related to changes in the money supply. Most economists believe that this relationship explains long-run changes in the price level.[10] Short-run fluctuations may also be related to monetary factors, but changes in aggregate demand and aggregate supply can also influence price level. For example, a decrease in demand due to a recession can lead to lower price levels and deflation. A negative supply shock, such as an oil crisis, lowers aggregate supply and can cause inflation.</p><h2>Macroeconomic models</h2><h3>Aggregate demand–aggregate supply</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/2/25/AS_%2B_AD_graph.svg/220px-AS_%2B_AD_graph.svg.png" width="220" height="172"><p>


A traditional AS–AD diagram showing a shift in AD and the AS curve becoming inelastic beyond potential output.


</p><p>
	The AD-AS model has become the standard textbook model for explaining the macroeconomy.[11] This model shows the price level and level of real output given the equilibrium in aggregate demand and aggregate supply. The aggregate demand curve's downward slope means that more output is demanded at lower price levels.[12] The downward slope is the result of three effects: the Pigou or real balance effect, which states that as real prices fall, real wealth increases, resulting in higher consumer demand of goods; the Keynes or interest rate effect, which states that as prices fall, the demand for money decreases, causing interest rates to decline and borrowing for investment and consumption to increase; and the net export effect, which states that as prices rise, domestic goods become comparatively more expensive to foreign consumers, leading to a decline in exports.[12]</p><p>In the conventional Keynesian use of the AS-AD model, the aggregate supply curve is horizontal at low levels of output and becomes inelastic near the point of potential output, which corresponds with full employment.[11] Since the economy cannot produce beyond the potential output, any AD expansion will lead to higher price levels instead of higher output.</p><p>The AD–AS diagram can model a variety of macroeconomic phenomena, including inflation. Changes in the non-price level factors or determinants cause changes in aggregate demand and shifts of the entire aggregate demand (AD) curve. When demand for goods exceeds supply there is an inflationary gap where demand-pull inflation occurs and the AD curve shifts upward to a higher price level. When the economy faces higher costs, cost-push inflation occurs and the AS curve shifts upward to higher price levels.[13] The AS–AD diagram is also widely used as a pedagogical tool to model the effects of various macroeconomic policies.[14]</p><h3>IS–LM</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/b/b9/Islm.svg/220px-Islm.svg.png" width="220" height="220"><p>


In this example of an IS/LM chart, the IS curve moves to the right, causing higher interest rates (i) and expansion in the "real" economy (real GDP, or Y).


</p><p>
	The IS–LM model represents all the combinations of interest rates and output that ensure the equilibrium in the goods and money markets.[15] The goods market is represented by the equilibrium in investment and saving (IS), and the money market is represented by the equilibrium between the money supply and liquidity preference.[16] The IS curve consists of the points where investment, given the interest rate, is equal to savings, given output.[17]</p><p>The IS curve is downward sloping because output and interest rate have an inverse relationship in the goods market: as output increases, more money is saved, which means interest rates must be lower to spur enough investment to match savings.[17] The LM curve is upward sloping because interest rate and output have a positive relationship in the money market: as output increases, the demand for money increases, resulting in a rise in interest rate.[18]</p><p>The IS/LM model is often used to demonstrate the effects of monetary and fiscal policy.[15] Textbooks frequently use the IS/LM model, but it does not feature the complexities of most modern macroeconomic models.[15] Nevertheless, these models still feature similar relationships to those in IS/LM.[15]</p><h3>Growth models</h3><p>The neoclassical growth model of Robert Solow has become a common textbook model for explaining economic growth in the long-run.[citation needed] The model begins with a production function where national output is the product of two inputs: capital and labor. The Solow model assumes that labor and capital are used at constant rates without the fluctuations in unemployment and capital utilization commonly seen in business cycles.[19]</p><p>An increase in output, or economic growth, can only occur because of an increase in the capital stock, a larger population, or technological advancements that lead to higher productivity (total factor productivity). An increase in the savings rate leads to a temporary increase as the economy creates more capital, which adds to output. However, eventually the depreciation rate will limit the expansion of capital: savings will be used up replacing depreciated capital, and no savings will remain to pay for an additional expansion in capital. Solow's model suggests that economic growth in terms of output per capita depends solely on technological advances that enhance productivity.[20]</p><p>In the 1980s and 1990s endogenous growth theory arose to challenge neoclassical growth theory. This group of models explains economic growth through other factors, such as increasing returns to scale for capital and learning-by-doing, that are endogenously determined instead of the exogenous technological improvement used to explain growth in Solow's model.[21]</p><h2>Macroeconomic policy</h2><p>Macroeconomic policy is usually implemented through two sets of tools: fiscal and monetary policy. Both forms of policy are used to stabilize the economy, which can mean boosting the economy to the level of GDP consistent with full employment.[22] Macroeconomic policy focuses on limiting the effects of the business cycle to achieve the economic goals of price stability, full employment, and growth. [23]</p><div class='pageBreak' ></div><h3>Monetary policy</h3><p> Further information: Monetary policy</p><p>Central banks implement monetary policy by controlling the money supply through several mechanisms. Typically, central banks take action by issuing money to buy bonds (or other assets), which boosts the supply of money and lowers interest rates, or, in the case of contractionary monetary policy, banks sell bonds and take money out of circulation. Usually policy is not implemented by directly targeting the supply of money.</p><p>Central banks continuously shift the money supply to maintain a targeted fixed interest rate. Some of them allow the interest rate to fluctuate and focus on targeting inflation rates instead. Central banks generally try to achieve high output without letting loose monetary policy that create large amounts of inflation.</p><p>Conventional monetary policy can be ineffective in situations such as a liquidity trap. When interest rates and inflation are near zero, the central bank cannot loosen monetary policy through conventional means.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/a/a7/Economic_Policy_-_Intervention_Strategy_Matrix.png/350px-Economic_Policy_-_Intervention_Strategy_Matrix.png" width="350" height="263"><p>


An example of intervention strategy under different conditions


</p><p>
	Central banks can use unconventional monetary policy such as quantitative easing to help increase output. Instead of buying government bonds, central banks can implement quantitative easing by buying not only government bonds, but also other assets such as corporate bonds, stocks, and other securities. This allows lower interest rates for a broader class of assets beyond government bonds. In another example of unconventional monetary policy, the United States Federal Reserve recently made an attempt at such a policy with Operation Twist. Unable to lower current interest rates, the Federal Reserve lowered long-term interest rates by buying long-term bonds and selling short-term bonds to create a flat yield curve.</p><h3>Fiscal policy</h3><p> Further information: Fiscal policy</p><p>Fiscal policy is the use of government's revenue and expenditure as instruments to influence the economy. Examples of such tools are expenditure, taxes, debt.</p><p>For example, if the economy is producing less than potential output, government spending can be used to employ idle resources and boost output. Government spending does not have to make up for the entire output gap. There is a multiplier effect that boosts the impact of government spending. For instance, when the government pays for a bridge, the project not only adds the value of the bridge to output, but also allows the bridge workers to increase their consumption and investment, which helps to close the output gap.</p><p>The effects of fiscal policy can be limited by crowding out. When the government takes on spending projects, it limits the amount of resources available for the private sector to use. Crowding out occurs when government spending simply replaces private sector output instead of adding additional output to the economy. Crowding out also occurs when government spending raises interest rates, which limits investment. Defenders of fiscal stimulus argue that crowding out is not a concern when the economy is depressed, plenty of resources are left idle, and interest rates are low.[citation needed]</p><p>Fiscal policy can be implemented through automatic stabilizers. Automatic stabilizers do not suffer from the policy lags of discretionary fiscal policy. Automatic stabilizers use conventional fiscal mechanisms but take effect as soon as the economy takes a downturn: spending on unemployment benefits automatically increases when unemployment rises and, in a progressive income tax system, the effective tax rate automatically falls when incomes decline.</p><h3>Comparison</h3><p>Economists usually favor monetary over fiscal policy because it has two major advantages. First, monetary policy is generally implemented by independent central banks instead of the political institutions that control fiscal policy. Independent central banks are less likely to make decisions based on political motives.[22] Second, monetary policy suffers shorter inside lags and outside lags than fiscal policy. Central banks can quickly make and implement decisions while discretionary fiscal policy may take time to pass and even longer to carry out.[22]</p><h2>Development</h2><p> Main article: History of macroeconomic thought</p><h3>Origins</h3><p>Macroeconomics descended from the once divided fields of business cycle theory and monetary theory.[24] The quantity theory of money was particularly influential prior to World War II. It took many forms, including the version based on the work of Irving Fisher:</p><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Macroeconomics&amp;oldid=784150718"					
				Categories:  Hidden categories:</p><br><h1 lang="en">Heterodox economics</h1><p> From Wikipedia, the free encyclopedia</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/8/8a/Heterodox3.png/220px-Heterodox3.png" width="220" height="164"><p>


Heterodox economics family tree.


</p><p>
	Heterodox economics refers to schools of economic thought or methodologies that are outside mainstream economics, often represented by expositors as contrasting with or going beyond neoclassical economics.[1][2] Heterodox economics is an umbrella term used to cover various approaches, schools, or traditions. These include anarchist, socialist, Marxian, institutional, evolutionary, Georgist, Austrian, feminist,[3] social, post-Keynesian (not to be confused with New Keynesian),[2] and ecological economics among others.[4] In the JEL classification codes developed by the Journal of Economic Literature, heterodox economics is in the second of the 19 primary categories at:</p><div class='pageBreak' ></div><p>Mainstream economics may be called orthodox or conventional economics by its critics.[5] Alternatively, mainstream economics deals with the rationality–individualism–equilibrium nexus and heterodox economics is more radical in dealing with the institutions–history–social structure nexus.[6] Many mainstream economists dismiss heterodox economics as fringe and irrelevant,[7] with little or no influence on the vast majority of academic economists in the English-speaking world.</p><p>A recent review documents several prominent groups of heterodox economists since at least the 1990s as working together with a resulting increase in coherence across different constituents.[2] Along these lines, the International Confederation of Associations for Pluralism in Economics (ICAPE) does not define heterodox economics and has avoided defining its scope. ICAPE defines its mission as promoting pluralism in economics.</p><p>In defining a common ground in the critical commentary, one writer described fellow heterodox economists as trying to do three things: (1) identify shared ideas that generate a pattern of heterodox critique across topics and chapters of introductory macro texts; (2) give special attention to ideas that link methodological differences to policy differences; and (3) characterize the common ground in ways that permit distinct paradigms to develop common differences with textbook economics in different ways.[8]</p><p>One study suggests four key factors as important to the study of economics by self-identified heterodox economists: history, natural systems, uncertainty, and power.[9]</p><h2>Contents</h2><h2>History</h2><p>A number of heterodox schools of economic thought challenged the dominance of neoclassical economics after the neoclassical revolution of the 1870s. In addition to socialist critics of capitalism, heterodox schools in this period included advocates of various forms of mercantilism, such as the American School dissenters from neoclassical methodology such as the historical school, and advocates of unorthodox monetary theories such as Social credit. Other heterodox schools active before and during the Great Depression included Technocracy and Georgism.</p><p>Physical scientists and biologists were the first individuals to use energy flows to explain social and economic development. Joseph Henry, an American physicist and first secretary of the Smithsonian Institution, remarked that the fundamental principle of political economy is that the physical labor of man can only be ameliorated by… the transformation of matter from a crude state to a artificial condition...by expending what is called power or energy.[10][11]</p><p>The rise, and absorption into the mainstream of Keynesian economics, which appeared to provide a more coherent policy response to unemployment than unorthodox monetary or trade policies contributed to the decline of interest in these schools.</p><p>After 1945, the neoclassical synthesis of Keynesian and neoclassical economics resulted in a clearly defined mainstream position based on a division of the field into microeconomics (generally neoclassical but with a newly developed theory of market failure) and macroeconomics (divided between Keynesian and monetarist views on such issues as the role of monetary policy). Austrians and post-Keynesians who dissented from this synthesis emerged as clearly defined heterodox schools. In addition, the Marxist and institutionalist schools remained active.</p><p>Up to 1980 the most notable themes of heterodox economics in its various forms included:</p><li>rejection of the atomistic individual conception in favor of a socially embedded individual conception;</li><li>emphasis on time as an irreversible historical process;</li><li>reasoning in terms of mutual influences between individuals and social structures.</li><p>From approximately 1980 mainstream economics has been significantly influenced by a number of new research programs, including behavioral economics, complexity economics, evolutionary economics, experimental economics, and neuroeconomics. As a consequence, some heterodox economists, such as John B. Davis, proposed that the definition of heterodox economics has to be adapted to this new, more complex reality:[12]</p><h2>Rejection of neoclassical economics</h2><p>There is no single heterodox economic theory; there are many different heterodox theories in existence. What they all share, however, is a rejection of the neoclassical orthodoxy as representing the appropriate tool for understanding the workings of economic and social life.[13] The reasons for this rejection may vary. Some of the elements commonly found in heterodox critiques are listed below.</p><h3>Criticism of the neoclassical model of individual behavior</h3><p>One of the most broadly accepted principles of neoclassical economics is the assumption of the rationality of economic agents. Indeed, for a number of economists, the notion of rational maximizing behavior is taken to be synonymous with economic behavior (Becker 1976, Hirshleifer 1984). When some economists' studies do not embrace the rationality assumption, they are seen as placing the analyses outside the boundaries of the Neoclassical economics discipline (Landsberg 1989, 596). Neoclassical economics begins with the a priori assumptions that agents are rational and that they seek to maximize their individual utility (or profits) subject to environmental constraints. These assumptions provide the backbone for rational choice theory.</p><p>Many heterodox schools are critical of the homo economicus model of human behavior used in standard neoclassical model. A typical version of the critique is that of Satya Gabriel:[14]</p><p>Neoclassical economic theory is grounded in a particular conception of human psychology, agency or decision-making. It is assumed that all human beings make economic decisions so as to maximize pleasure or utility. Some heterodox theories reject this basic assumption of neoclassical theory, arguing for alternative understandings of how economic decisions are made and/or how human psychology works. It is possible to accept the notion that humans are pleasure seeking machines, yet reject the idea that economic decisions are governed by such pleasure seeking. Human beings may, for example, be unable to make choices consistent with pleasure maximization due to social constraints and/or coercion. Humans may also be unable to correctly assess the choice points that are most likely to lead to maximum pleasure, even if they are unconstrained (except in budgetary terms) in making such choices. And it is also possible that the notion of pleasure seeking is itself a meaningless assumption because it is either impossible to test or too general to refute. Economic theories that reject the basic assumption of economic decisions as the outcome of pleasure maximization are heterodox.</p><p>Shiozawa emphasizes that economic agents act in a complex world and therefore impossible for them to attain maximal utility point. They instead behave as if there are a repertories of many ready made rules, one of which they chose according to relevant situation.[15]</p><h3>Criticism of the neoclassical model of market equilibrium</h3><div class='pageBreak' ></div><p>In microeconomic theory, cost-minimization by consumers and by firms implies the existence of supply and demand correspondences for which market clearing equilibrium prices exist, if there are large numbers of consumers and producers. Under convexity assumptions or under some marginal-cost pricing rules, each equilibrium will be Pareto efficient: In large economies, non-convexity also leads to quasi-equilibria that are nearly efficient.</p><p>However, the concept of market equilibrium has been criticized by Austrians, post-Keynesians and others, who object to applications of microeconomic theory to real-world markets, when such markets are not usefully approximated by microeconomic models. Heterodox economists assert that micro-economic models rarely capture reality.</p><p>Mainstream microeconomics may be defined in terms of optimization and equilibrium, following the approaches of Paul Samuelson and Hal Varian. On the other hand, heterodox economics may be labeled as falling into the nexus of institutions, history, and social structure.[4][16]</p><h2>Most recent developments</h2><p>Over the past two decades, the intellectual agendas of heterodox economists have taken a decidedly pluralist turn. Leading heterodox thinkers have moved beyond the established paradigms of Austrian, Feminist, Institutional-Evolutionary, Marxian, Post Keynesian, Radical, Social, and Sraffian economics—opening up new lines of analysis, criticism, and dialogue among dissenting schools of thought. This cross-fertilization of ideas is creating a new generation of scholarship in which novel combinations of heterodox ideas are being brought to bear on important contemporary and historical problems, such as socially grounded reconstructions of the individual in economic theory; the goals and tools of economic measurement and professional ethics; the complexities of policymaking in today's global political economy; and innovative connections among formerly separate theoretical traditions (Marxian, Austrian, feminist, ecological, Sraffian, institutionalist, and post-Keynesian) (for a review of post-Keynesian economics, see Lavoie (1992); Rochon (1999)).</p><p>David Colander, an advocate of complexity economics, argues that the ideas of heterodox economists are now being discussed in the mainstream without mention of the heterodox economists, because the tools to analyze institutions, uncertainty, and other factors have now been developed by the mainstream. He suggests that heterodox economists should embrace rigorous mathematics and attempt to work from within the mainstream, rather than treating it as an enemy.[17]</p><p>Some schools of heterodox economic thought have also taken a transdisciplinary approach. Thermoeconomics is based on the claim that human economic processes are governed by the second law of thermodynamics. The posited relationship between economic theory, energy and entropy, has been extended further by systems scientists to explain the role of energy in biological evolution in terms of such economic criteria as productivity, efficiency, and especially the costs and benefits of the various mechanisms for capturing and utilizing available energy to build biomass and do work.[18][19]</p><h2>Fields of heterodox economic thought</h2><p># Listed in Journal of Economic Literature codes scrolled to at JEL: B5 - Current Heterodox Approaches.</p><p>§ Listed in The New Palgrave Dictionary of Economics, 2nd Edition, v. 8, Appendix IV, p.&nbsp;856, searchable by clicking (the JEL classification codes JEL:) radio button B5, B52, or B59, then the Search button (or Update Search Results button) at http://www.dictionaryofeconomics.com/search_results?edition=all&amp;field=content&amp;q=&amp;topicid=B5.</p><p>Some schools in the social sciences aim to promote certain perspectives: classical and modern political economy; economic sociology and anthropology; gender and racial issues in economics; and so on.</p><h3>Notable heterodox economists</h3><h3>Articles</h3><h3>Books</h3><h3>Articles, conferences, papers</h3><h3>Journals</h3><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Heterodox_economics&amp;oldid=784013342"					
				Categories:  Hidden categories:</p><br><h1 lang="en">Econometrics</h1><p> From Wikipedia, the free encyclopedia</p><p>Econometrics is the application of statistical methods to economic data and is described as the branch of economics that aims to give empirical content to economic relations.[1] More precisely, it is the quantitative analysis of actual economic phenomena based on the concurrent development of theory and observation, related by appropriate methods of inference.[2] An introductory economics textbook describes econometrics as allowing economists to sift through mountains of data to extract simple relationships.[3] The first known use of the term econometrics (in cognate form) was by Polish economist Pawel Ciompa in 1910.[4] Ragnar Frisch is credited with coining the term in the sense in which it is used today.[5]</p><p>The basic tool for econometrics is the multiple linear regression model.[6] Econometric theory uses statistical theory and mathematical statistics to evaluate and develop econometric methods.[7][8] Econometricians try to find estimators that have desirable statistical properties including unbiasedness, efficiency, and consistency. Applied econometrics uses theoretical econometrics and real-world data for assessing economic theories, developing econometric models, analyzing economic history, and forecasting.</p><h2>Contents</h2><h2>Basic models: linear regression</h2><p>The basic tool for econometrics is the multiple linear regression model.[6] In modern econometrics, other statistical tools are frequently used, but linear regression is still the most frequently used starting point for an analysis.[6] Estimating a linear regression on two variables can be visualized as fitting a line through data points representing paired values of the independent and dependent variables.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/d/db/Okuns_law_differences_1948_to_mid_2011.png/220px-Okuns_law_differences_1948_to_mid_2011.png" width="220" height="160"><p>


Okun's law representing the relationship between GDP growth and the unemployment rate. The fitted line is found using regression analysis.


</p><p>
	For example, consider Okun's law, which relates GDP growth to the unemployment rate. This relationship is represented in a linear regression where the change in unemployment rate (
  
    
      
        ?
        &nbsp;
        
          Unemployment
        
      
    
    {\displaystyle \Delta \ {\text{Unemployment}}}
  
) is a function of an intercept (
  
    
      
        
          ß
          
            0
          
        
      
    
    {\displaystyle \beta _{0}}
  
), a given value of GDP growth multiplied by a slope coefficient 
  
    
      
        
          ß
          
            1
          
        
      
    
    {\displaystyle \beta _{1}}
  
 and an error term, 
  
    
      
        e
      
    
    {\displaystyle \varepsilon }
  
:</p><div class='pageBreak' ></div><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Econometrics&amp;oldid=783675655"					
				Categories:  Hidden categories:</p><br><h1 lang="en">Economic system</h1><p> From Wikipedia, the free encyclopedia</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/6/6a/DiagFuncMacroSyst.pdf/page1-360px-DiagFuncMacroSyst.pdf.jpg" width="360" height="509"><p>


Circulation model of economic flows for a closed market economy


</p><p>
	An economic system is a system of production, resource allocation, and distribution of goods and services within a society or a given geographic area. It includes the combination of the various institutions, agencies, entities, decision-making processes, and patterns of consumption that comprise the economic structure of a given community. As such, an economic system is a type of social system. The mode of production is a related concept.[1] All economic systems have three basic questions to ask: what to produce, how to produce and in what quantities, and who receives the output of production.</p><p>The study of economic systems includes how these various agencies and institutions are linked to one another, how information flows between them, and the social relations within the system (including property rights and the structure of management).</p><p>The analysis of economic systems traditionally focused on the dichotomies and comparisons between market economies and planned economies, and on the distinctions between capitalism and socialism.[2] Subsequently, the categorization of economic systems expanded to include other topics and models that do not conform to the traditional dichotomy. Today the dominant form of economic organization at the world level is based on market-oriented mixed economies.[3]</p><p>Economic systems is the category in the Journal of Economic Literature classification codes that includes the study of such systems. One field that cuts across them is comparative economic systems, which include the following subcategories of different systems:</p><h2>Contents</h2><h2>Components</h2><p>There are multiple components to economic systems. Decision-making structures of an economy determine the use of economic inputs (the factors of production), distribution of output, the level of centralization in decision-making, and who makes these decisions. Decisions might be carried out by industrial councils, by a government agency, or by private owners.</p><p>In one view, every economic system represents an attempt to solve three fundamental and interdependent problems:</p><p>Thus every economy is a system that allocates resources for exchange, production, distribution and consumption. The system is stabilized through a combination of threat and trust, which are the outcome of institutional arrangements.[6] An economic system possesses the following institutions:</p><h2>Typology</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/8/80/Common_Economic_Systems_Typology_%28v2%29.png/350px-Common_Economic_Systems_Typology_%28v2%29.png" width="350" height="220"><p>


Common typology for economic systems categorized by resource ownership and resource allocation mechanism



<br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/5/55/Communism.PNG/350px-Communism.PNG" width="350" height="162"><br>


Marxist-Leninist Communist states (red) and former Communist states (orange) of the world


</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/5/55/Communism.PNG/350px-Communism.PNG" width="350" height="162"><br><p>
	There are several basic questions that must be answered in order for an economy to run satisfactorily. The scarcity problem, for example, requires answers to basic questions, such as: what to produce, how to produce it, and who gets what is produced. An economic system is a way of answering these basic questions, and different economic systems answer them differently. Many different objectives may be seen as desirable for an economy, like efficiency, growth, liberty, and equality.[9]</p><div class='pageBreak' ></div><p>Economic systems are commonly segmented by their property rights regime for the means of production and by their dominant resource allocation mechanism. Economies that combine private ownership with market allocation are called market capitalism, and economies that combine private ownership with economic planning are labelled command capitalism or dirigisme. Likewise, systems that mix public or cooperative ownership of the means of production with economic planning are called socialist planned economies, and systems that combine public or cooperative ownership with markets are called market socialism.[10] Some perspectives build upon this basic nomenclature to take other variables into account, such as class processes within an economy. This leads some economists to categorize, for example, the Soviet Union's economy as state capitalism based on the analysis that the working class was exploited by the party leadership. Instead of looking at nominal ownership, this perspective takes into account the organizational form within economic enterprises.[11]</p><p>In a capitalist economic system, production is carried out for private profit, and decisions regarding investment and allocation of factor inputs are determined by business owners in factor markets. The means of production are primarily owned by private enterprises, and decisions regarding production and investment are determined by private owners in capital markets. Capitalist systems range from laissez-faire, with minimal government regulation and state enterprise, to regulated and social market systems, with the aims of ameliorating market failures (see economic intervention) or supplementing the private marketplace with social policies to promote equal opportunities (see welfare state), respectively.</p><p>In socialist economic systems (socialism), production for use is carried out; decisions regarding the use of the means of production are adjusted to satisfy economic demand; and investment is determined through economic planning procedures. There is a wide range of proposed planning procedures and ownership structures for socialist systems, with the common feature among them being the social ownership of the means of production. This might take the form of public ownership by all of society, or ownership cooperatively by their employees. A socialist economic system that features social ownership but is based on the process of capital accumulation and utilization of capital markets for the allocation of capital goods between socially-owned enterprises falls under the subcategory of market socialism.[12]</p><h3>Allocation mechanism</h3><p>The basic and general economic systems segmented by allocation are:</p><h3>Types</h3><p>Capitalism generally features the private ownership of the means of production (capital), and a market economy for coordination. Corporate capitalism refers to a capitalist marketplace characterized by the dominance of hierarchical, bureaucratic corporations.</p><p>Mercantilism was the dominant model in Western Europe from the 16th to 18th century. This encouraged imperialism and colonialism until economic and political changes resulted in global decolonization. Modern capitalism has favored free trade to take advantages of increased efficiency due to national comparative advantage and economies of scale in a larger, more universal market. Some critics[who?] have applied the term neo-colonialism to the power imbalance between multi-national corporations operating in a free market vs. seemingly impoverished people in developing countries.</p><p>There is no precise definition of a mixed economy. Theoretically, it may refer to an economic system that combines one of three characteristics: public and private ownership of industry, market-based allocation with economic planning, or free-markets with state interventionism.</p><p>In practice, mixed economy generally refers to market economies with substantial state interventionism and/or sizable public sector alongside a dominant private sector. Actual mixed economies gravitate more heavily to one end of the spectrum. Notable economic models and theories that have been described as a mixed economy include:</p><p>Socialist economic systems (all of which feature social ownership of the means of production) can be subdivided by their coordinating mechanism (planning and markets) into planned socialist and market socialist systems. Additionally, socialism can be divided based on their property structures between those that are based on public ownership, worker or consumer cooperatives and common ownership (i.e., non-ownership). Communism is a hypothetical stage of Socialist development articulated by Marx as second stage Socialism in Critique of the Gotha Program, whereby economic output is distributed based on need and not simply on the basis of labor contribution.</p><p>The original conception of socialism involved the substitution of money as a unit of calculation and monetary prices as a whole with calculation in kind (or valuation based on natural units), with business and financial decisions replaced by engineering and technical criteria for managing the economy. Fundamentally, this meant that socialism would operate under different economic dynamics than those of capitalism and the price system.[13] Later models of socialism developed by neoclassical economists (most notably Oskar Lange and Abba Lerner) were based on the use of notional prices derived from a trial-and-error approach to achieve market clearing prices on the part of a planning agency. These models of socialism were called market socialism because they included a role for markets, money and prices.</p><p>The primary emphasis of socialist planned economies is to coordinate production to produce economic output to directly satisfy economic demand as opposed to the indirect mechanism of the profit system where satisfying needs is subordinate to the pursuit of profit; and to advance the productive forces of the economy in a more efficient manner while being immune to the perceived systemic inefficiencies (cyclical processes) and crisis of overproduction so that production would be subject to the needs of society as opposed to being ordered around capital accumulation.[14][15]</p><p>In a pure socialist planned economy that involves different processes of resource allocation, production and means of quantifying value, the use of money would be replaced with a different measure of value and accounting tool that would embody more accurate information about an object or resource.</p><p>In practice, the economic system of the former Soviet Union and Eastern bloc operated as a command economy, featuring a combination of state owned enterprises and central planning using the material balances method. The extent to which these economic systems achieved socialism or represented a viable alternative to capitalism is subject to debate.[16]</p><p>In orthodox Marxism, the mode of production is tantamount to the subject of this article, determining with a superstructure of relations the entirety of a given culture or stage of human development.</p><h3>Other aspects</h3><p>Corporatism refers to economic tripartite involving negotiations between business, labor, and state interest groups to establish economic policy, or more generally to assigning people to political groups based on their occupational affiliation.</p><p>Certain subsets of an economy, or the particular goods, services, techniques of production, or moral rules can also be described as an economy. For example, some terms emphasize specific sectors or externalizes:</p><p>Others emphasize a particular religion:</p><div class='pageBreak' ></div><h2>Evolutionary economics</h2><p>Karl Marx's theory of economic development was based on the premise of evolving economic systems; specifically, in his view, over the course of history superior economic systems would replace inferior ones. Inferior systems were beset by internal contradictions and inefficiencies that make them impossible to survive over the long term. In Marx's scheme, feudalism was replaced by capitalism, which would eventually be superseded by socialism.[17] Joseph Schumpeter had an evolutionary conception of economic development, but unlike Marx, he de-emphasized the role of class struggle in contributing to qualitative change in the economic mode of production. In subsequent world history, Communist states run according to Marxist-Leninist ideologies have either collapsed or gradually reformed their centrally-planned economies toward market-based economies, for example with perestroika and the dissolution of the Soviet Union, Chinese economic reform, and Ð?i M?i in Vietnam.</p><p>Mainstream evolutionary economics continues to study economic change in modern times. There has also been renewed interest in understanding economic systems as evolutionary systems in the emerging field of Complexity economics.</p><h2>Context in society</h2><p>An economic system can be considered a part of the social system and hierarchically equal to the law system, political system, cultural, etc. There is often a strong correlation between certain ideologies, political systems and certain economic systems (for example, consider the meanings of the term communism). Many economic systems overlap each other in various areas (for example, the term mixed economy can be argued to include elements from various systems). There are also various mutually exclusive hierarchical categorizations.</p><h2>Political ideologies</h2><h3>Anarchist and libertarianism</h3><p>Various strains of anarchism advocate different economic systems, all of which have very small or no government involvement. These include:</p><p>Libertarianism also advocates a minimal role for government, including economic systems like:</p><h2>List of economic systems</h2><p>(merge in progress)</p><p>Unsorted:</p><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Economic_system&amp;oldid=784081125"					
				Categories:  Hidden categories:</p><br><h1 lang="en">Post-scarcity economy</h1><p> From Wikipedia, the free encyclopedia</p><p>Post-scarcity is a hypothetical economy in which most goods can be produced in great abundance with minimal human labor needed, so that they become available to all very cheaply or even freely.[1][2] Post-scarcity is not generally taken to mean that scarcity has been eliminated for all consumer goods and services; instead, it is often taken to mean that all people can easily have their basic survival needs met along with some significant proportion of their desires for goods and services,[3] with writers on the topic often emphasizing that certain commodities are likely to remain scarce in a post-scarcity society.[4][5][6][7]</p><p>In the paper “The Post-Scarcity World of 2050-2075”[8], authors defend that we are currently living an age of scarcity resulted from neglect behavior with the future from the 19th and 20th centuries. The period between 1975 and 2005 was characterized by relative abundance of resources (oil, water, energy, food, credit, among others) which boosted industrialization and development in the western economies. An increased demand of resources combined with a rising population led to resource exhaustion.[8]</p><p>One of the main traces of the scarcity periods is the increase and fluctuation of prices. To deal with that situation, technology advancements come into play, driving an efficient use of resources to a certain extent that costs will be considerably reduced (almost everything will be free). Consequently, authors forecast that the period between 2050 and 2075 will be a post-scarcity age in which scarcity will no longer exist.[8]</p><h2>Contents</h2><h2>The post-scarcity model</h2><h3>Speculative technology</h3><p>Today, futurists who speak of post-scarcity suggest economies based on advances in automated manufacturing technologies,[4] often including the idea of self-replicating machines, the adoption of division of labour[9] which in theory could produce nearly all goods in abundance, given adequate raw materials and energy. More speculative forms of nanotechnology (such as molecular assemblers or nanofactories, which do not currently exist) raise the possibility of devices that can automatically manufacture any specified goods given the correct instructions and the necessary raw materials and energy,[10] and so many nanotechnology enthusiasts have suggested it will usher in a post-scarcity world.[11][12] In the more near-term future, the increasing automation of physical labor using robots is often discussed as means of creating a post-scarcity economy.[13][14] Increasingly versatile forms of rapid prototyping machines, and a hypothetical self-replicating version of such a machine known as a RepRap, have also been predicted to help create the abundance of goods needed for a post-scarcity economy.[15] Advocates of self-replicating machines such as Adrian Bowyer, the creator of the RepRap project, argue that once a self-replicating machine is designed, then since anyone who owns one can make more copies to sell (and would also be free to ask for a lower price than other sellers), market competition will naturally drive the cost of such machines down to the bare minimum needed to make a profit,[16][17] in this case just above the cost of the physical materials and energy that must be fed into the machine as input, and the same should go for any other goods that the machine can build.</p><p>Even with fully automated production, limitations on the number of goods produced would arise from the availability of raw materials and energy, as well as ecological damage associated with manufacturing technologies.[4] Advocates of technological abundance often argue for more extensive use of renewable energy and greater recycling in order to prevent future drops in availability of energy and raw materials, and reduce ecological damage.[4] Solar energy in particular is often emphasized, as the cost of solar panels continues to drop[4] (and could drop far more with automated production by self-replicating machines), and advocates point out the total solar power striking the Earth's surface annually exceeds our civilization's current annual power usage by a factor of thousands.[18][19] Advocates also sometimes argue that the energy and raw materials available could be greatly expanded if we looked to resources beyond the Earth. For example, asteroid mining is sometimes discussed as a way of greatly reducing scarcity for many useful metals such as nickel.[20] While early asteroid mining might involve manned missions, advocates hope that eventually humanity could have automated mining done by self-replicating machines.[20][21] If this were done, then the only capital expenditure would be a single self-replicating unit (whether robotic or nanotechnological), after which the number of units could replicate at no further cost, limited only by the available raw materials needed to build more.[21]</p><h3>Digital abundance</h3><p>Richard Stallman, the founder of the GNU project, has cited the eventual creation of a post-scarcity society as one of his motivations:[22]</p><div class='pageBreak' ></div><p>In the long run, making programs free is a step toward the post-scarcity world, where nobody will have to work very hard just to make a living. People will be free to devote themselves to activities that are fun, such as programming, after spending the necessary ten hours a week on required tasks such as legislation, family counseling, robot repair and asteroid prospecting. There will be no need to be able to make a living from programming.</p><h3>Marxism</h3><p>Karl Marx, in a section of his Grundrisse that came to be known as the Fragment on Machines,[23][24] argued that the transition to a post-capitalist society combined with advances in automation would allow for significant reductions in labor needed to produce necessary goods, eventually reaching a point where all people would have significant amounts of leisure time to pursue science, the arts, and creative activities; a state some commentators later labeled as post-scarcity.[25] Marx argued that capitalism—the dynamic of economic growth based on capital accumulation—depends on exploiting the surplus labor of workers, but a post-capitalist society would allow for:</p><p>The free development of individualities, and hence not the reduction of necessary labour time so as to posit surplus labour, but rather the general reduction of the necessary labour of society to a minimum, which then corresponds to the artistic, scientific etc. development of the individuals in the time set free, and with the means created, for all of them.[26]</p><p>Marx's concept of a post-capitalist communist society involves the free distribution of goods made possible by the abundance provided by automation.[27] The fully developed communist economic system is postulated to develop from a preceding socialist system. Marx held the view that socialism—a system based on social ownership of the means of production—would enable progress toward the development of fully developed communism by further advancing productive technology. Under socialism, with its increasing levels of automation, an increasing proportion of goods would be distributed freely.[28]</p><p>Marx did not believe in the elimination of most physical labor through technological advancements alone in a capitalist society, because he believed capitalism contained within it certain tendencies which countered increasing automation and prevented it from developing beyond a limited point, so that manual industrial labor could not be eliminated until the overthrow of capitalism.[29] Some commentators on Marx have argued that at the time he wrote the Grundrisse, he thought that the collapse of capitalism due to advancing automation was inevitable despite these counter-tendencies, but that by the time of his major work Capital: Critique of Political Economy he had abandoned this view, and came to believe that capitalism could continually renew itself unless overthrown.[30][31][32]</p><h2>Fiction</h2><h3>Science fiction</h3><h3>Books</h3><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Post-scarcity_economy&amp;oldid=780541834"					
				Categories:  Hidden categories:</p><br><h1 lang="en">National accounts</h1><p> From Wikipedia, the free encyclopedia</p><p>National accounts or national account systems (NAS) are the implementation of complete and consistent accounting techniques for measuring the economic activity of a nation. These include detailed underlying measures that rely on double-entry accounting. By design, such accounting makes the totals on both sides of an account equal even though they each measure different characteristics, for example production and the income from it. As a method, the subject is termed national accounting or, more generally, social accounting.[1] Stated otherwise, national accounts as systems may be distinguished from the economic data associated with those systems.[2] While sharing many common principles with business accounting, national accounts are based on economic concepts.[3] One conceptual construct for representing flows of all economic transactions that take place in an economy is a social accounting matrix with accounts in each respective row-column entry.[4]</p><p>National accounting has developed in tandem with macroeconomics from the 1930s with its relation of aggregate demand to total output through interaction of such broad expenditure categories as consumption and investment.[5] Economic data from national accounts are also used for empirical analysis of economic growth and development.[1][6]</p><h2>Contents</h2><h2>Scope</h2><p>National accounts broadly present output, expenditure, and income activities of the economic actors (households, corporations, government) in an economy, including their relations with other countries' economies, and their wealth (net worth). They present both flows (measured over a period) and stocks (measured at the end of a period), ensuring that the flows are reconciled with the stocks. As to flows, the national income and product accounts (in U.S. terminology) provide estimates for the money value of income and output per year or quarter, including GDP. As to stocks, the 'capital accounts' are a balance-sheet approach that has assets on one side (including values of land, the capital stock, and financial assets) and liabilities and net worth on the other, measured as of the end of the accounting period. National accounts also include measures of the changes in assets, liabilities, and net worth per accounting period. These may refer to flow of funds accounts or, again, capital accounts.[1]</p><p>There are a number of aggregate measures in the national accounts, notably including gross domestic product or GDP, perhaps the most widely cited measure of aggregate economic activity. Ways of breaking down GDP include as types of income (wages, profits, etc.) or expenditure (consumption, investment/saving, etc.). Measures of these are examples of macro-economic data.[7][8][9][10] Such aggregate measures and their change over time are generally of strongest interest to economic policymakers, although the detailed national accounts contain a source of information for economic analysis, for example in the input-output tables which show how industries interact with each other in the production process.</p><p>National accounts can be presented in nominal or real amounts, with real amounts adjusted to remove the effects of price changes over time.[11] A corresponding price index can also be derived from national output. Rates of change of the price level and output may also be of interest. An inflation rate (growth rate of the price level) may be calculated for national output or its expenditure components. Economic growth rates (most commonly the growth rate of GDP) are generally measured in real (constant-price) terms. One use of economic-growth data from the national accounts is in growth accounting across longer periods of time for a country or across to estimate different sources of growth, whether from growth of factor inputs or technological change.[12]</p><p>The accounts are derived from a wide variety of statistical source data including surveys, administrative and census data, and regulatory data, which are integrated and harmonized in the conceptual framework. They are usually compiled by national statistical offices and/or central banks in each country, though this is not always the case, and may be released on both an annual and (less detailed) quarterly frequency. Practical issues include inaccuracies from differences between economic and accounting methodologies, lack of controlled experiments on quality of data from diverse sources, and measurement of intangibles and services of the banking and financial sectors.[13]</p><p>Two developments relevant to the national accounts since the 1980s include the following. Generational accounting is a method for measuring redistribution of lifetime tax burdens across generations from social insurance, including social security and social health insurance. It has been proposed as a better guide to the sustainability of a fiscal policy than budget deficits, which reflect only taxes minus spending in the current year.[14] Environmental or green national accounting is the method of valuing environmental assets, which are usually not counted in measuring national wealth, in part due to the difficulty of valuing them. The method has been proposed as an alternative to an implied zero valuation of environmental assets and as a way of measuring the sustainability of welfare levels in the presence of environmental degradation.[15]</p><div class='pageBreak' ></div><p>Macroeconomic data not derived from the national accounts are also of wide interest, for example some cost-of-living indexes, the unemployment rate, and the labor force participation rate.[16] In some cases, a national-accounts counterpart of these may be estimated, such as a price index computed from the personal consumption expenditures and the GDP gap (the difference between observed GDP and potential GDP).[17]</p><h2>Main components</h2><p>The presentation of national accounts data may vary by country (commonly, aggregate measures are given greatest prominence), however the main national accounts include the following accounts for the economy as a whole and its main economic actors.</p><p>The accounts may be measured as gross or net of consumption of fixed capital (a concept in national accounts similar to depreciation in business accounts).</p><p>Notably absent from these components, however, is unpaid work, because its value is not included in any of the aforementioned categories of accounts, just as it is not included in calculating gross domestic product (GDP). An Australian study has shown the value of this uncounted work to be approximately 50% of GDP, making its exclusion rather significant.[18] As GDP is tied closely to the national accounts system,[19] this may lead to a distorted view of national accounts. Because national accounts are widely used by governmental policy-makers in implementing controllable economic agendas,[20] some analysts have advocated for either a change in the makeup of national accounts or adjustments in the formulation of public policy.[21]</p><h2>History</h2><p>The original motivation for the development of national accounts and the systematic measurement of employment was the need for accurate measures of aggregate economic activity. This was made more pressing by the Great Depression and as a basis for Keynesian macroeconomic stabilisation policy and wartime economic planning. The first efforts to develop such measures were undertaken in the late 1920s and 1930s, notably by Colin Clark and Simon Kuznets. Richard Stone of the U.K. led later contributions during World War II and thereafter. The first formal national accounts were published by the United States in 1947. Many European countries followed shortly thereafter, and the United Nations published A System of National Accounts and Supporting Tables in 1952.[1][22] International standards for national accounting are defined by the United Nations System of National Accounts, with the most recent version released for 2008.[23]</p><p>Even before that in early 1920s there were national economic accounts tables. One of such systems was called Balance of national economy and was used in USSR and other socialistic countries to measure the efficiency of socialistic production.Economic theory.[24]</p><p>In Europe, the worldwide System of National Accounts has been adapted in the European System of Accounts (ESA), which is applied by members of the European Union and many other European countries. Research on the subject continues from its beginnings through today.[25]</p><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=National_accounts&amp;oldid=768273936"					
				Categories:  Hidden categories:</p><br><h1 lang="en">Behavioral economics</h1><p> From Wikipedia, the free encyclopedia</p><p>Behavioral economics, along with the related sub-field behavioral finance, studies the effects of psychological, social, cognitive, and emotional factors on the economic decisions of individuals and institutions and the consequences for market prices, returns, and resource allocation, although not always that narrowly, but also more generally, of the impact of different kinds of behavior, in different environments of varying experimental values.[1]</p><p>Risk tolerance is a crucial factor in personal financial decision making. Risk tolerance is defined as individuals willingness to engage in a financial activity whose outcome is uncertain.[2]</p><p>Behavioral economics is primarily concerned with the bounds of rationality of economic agents. Behavioral models typically integrate insights from psychology, neuroscience and microeconomic theory; in so doing, these behavioral models cover a range of concepts, methods, and fields.[3][4]</p><p>The study of behavioral economics includes how market decisions are made and the mechanisms that drive public choice. The use of the term behavioral economics in U.S. scholarly papers has increased in the past few years, as shown by a recent study.[5]</p><p>There are three prevalent themes in behavioral finances:[6]</p><h2>Contents</h2><h2>History</h2><p>During the classical period of economics, microeconomics was closely linked to psychology. For example, Adam Smith wrote The Theory of Moral Sentiments, which proposed psychological explanations of individual behavior, including concerns about fairness and justice,[7] and Jeremy Bentham wrote extensively on the psychological underpinnings of utility. However, during the development of neo-classical economics economists sought to reshape the discipline as a natural science, deducing economic behavior from assumptions about the nature of economic agents. They developed the concept of homo economicus, whose psychology was fundamentally rational.</p><p>However, many important neo-classical economists employed more sophisticated psychological explanations, including Francis Edgeworth, Vilfredo Pareto, and Irving Fisher. Economic psychology emerged in the 20th century in the works of Gabriel Tarde,[8] George Katona,[9] and Laszlo Garai.[10] Expected utility and discounted utility models began to gain acceptance, generating testable hypotheses about decision-making given uncertainty and intertemporal consumption, respectively. Observed and repeatable anomalies eventually challenged those hypotheses, and further steps were taken by the Nobel Prize-winner Maurice Allais, for example, in setting out the Allais paradox, a decision problem he first presented in 1953 that contradicts the expected utility hypothesis.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/c/c8/Daniel_KAHNEMAN.jpg" width="150" height="179"><p>In the 1960s cognitive psychology began to shed more light on the brain as an information processing device (in contrast to behaviorist models). Psychologists in this field, such as Ward Edwards,[11] Amos Tversky, and Daniel Kahneman began to compare their cognitive models of decision-making under risk and uncertainty to economic models of rational behavior. In mathematical psychology, there is a longstanding interest in the transitivity of preference and what kind of measurement scale utility constitutes.[12]</p><div class='pageBreak' ></div><h3>Prospect theory</h3><p>In 1979, Kahneman and Tversky wrote Prospect Theory: An Analysis of Decision Under Risk, an important paper that used cognitive psychology to explain various divergences of economic decision making from neo-classical theory.[13] Prospect theory has two stages: an editing stage and an evaluation stage.</p><p>In the editing stage, risky situations are simplified using various heuristics of choice. In the evaluation phase, risky alternatives are evaluated using various psychological principles that include the following:</p><p>Prospect theory is able to explain everything that the two main existing decision theories—expected utility theory and rank dependent utility theory—can explain. However, the converse is false. Prospect theory has been used to explain a range of phenomena that existing decision theories have great difficulty in explaining. These include backward bending labor supply curves, asymmetric price elasticities, tax evasion, co-movement of stock prices and consumption, etc.</p><p>In 1992, in the Journal of Risk and Uncertainty, Kahneman and Tversky gave their revised account of prospect theory that they called cumulative prospect theory.[verification needed] The new theory eliminated the editing phase in prospect theory and focused just on the evaluation phase. Its main feature was that it allowed for non-linear probability weighting in a cumulative manner, which was originally suggested in John Quiggin's rank dependent utility theory.</p><p>Psychological traits such as overconfidence, projection bias, and the effects of limited attention are now part of the theory. Other developments include a conference at the University of Chicago,[14] a special behavioral economics edition of the Quarterly Journal of Economics (In Memory of Amos Tversky), and Kahneman's 2002 Nobel Prize for having integrated insights from psychological research into economic science, especially concerning human judgment and decision-making under uncertainty.[15]</p><h3>Intertemporal choice</h3><p>Behavioral economics has also been applied to intertemporal choice. Intertemporal choice is defined as making a decision and having the effects of such decision happening in a different time. Intertemporal choice behavior is largely inconsistent, as exemplified by George Ainslie's hyperbolic discounting—one of the prominently studied observations—and further developed by David Laibson, Ted O'Donoghue, and Matthew Rabin. Hyperbolic discounting describes the tendency to discount outcomes in the near future more than for outcomes in the far future. This pattern of discounting is dynamically inconsistent (or time-inconsistent), and therefore inconsistent with basic models of rational choice, since the rate of discount between time t and t+1 will be low at time t-1 when t is the near future, but high at time t when t is the present and time t+1 is the near future.</p><p>The pattern can also be explained through models of sub-additive discounting that distinguish the delay and interval of discounting: people are less patient (per-time-unit) over shorter intervals regardless of when they occur.</p><h3>Other areas of research</h3><p>Other branches of behavioral economics enrich the model of the utility function without implying inconsistency in preferences. Ernst Fehr, Armin Falk, and Matthew Rabin studied fairness, inequity aversion, and reciprocal altruism, weakening the neoclassical assumption of perfect selfishness. This work is particularly applicable to wage setting. The work on intrinsic motivation by Gneezy and Rustichini and identity by Akerlof and Kranton assumes that agents derive utility from adopting personal and social norms in addition to conditional expected utility. According to Aggarwal, in addition to behavioral deviations from rational equilibrium, markets are also likely to suffer from lagged responses, search costs, externalities of the commons, and other frictions making it difficult to disentangle behavioral effects in market behavior.[16]</p><p>Conditional expected utility is a form of reasoning where the individual has an illusion of control, and calculates the probabilities of external events and hence their utility as a function of their own action, even when they have no causal ability to affect those external events.[17][18]</p><p>Behavioral economics caught on among the general public with the success of books such as Dan Ariely's Predictably Irrational. Practitioners of the discipline have studied quasi-public policy topics such as broadband mapping.[19][20]</p><p>Taxation from a behavioral economics viewpoint is illustrated in the book The Darwin Economy by Robert H. Frank where he invokes the concept of 'positional consumption' vs 'non-positional consumption'. Positional consumption is the consumption we do that is relative to other people, while non-positional consumption is absolute. Good houses and good schools are essentially positional, and savings for retirement are essentially non-positional. Frank argues that since most of our consumption is positional, tax policies must reflect it, and that it's not possible to form coherent societies without some form of progressive taxation.[21]</p><h2>Criticism</h2><p>Critics of behavioral economics typically stress the rationality of economic agents.[22] They contend that experimentally observed behavior has limited application to market situations, as learning opportunities and competition ensure at least a close approximation of rational behavior.</p><p>Others note that cognitive theories, such as prospect theory, are models of decision making, not generalized economic behavior, and are only applicable to the sort of once-off decision problems presented to experiment participants or survey respondents.[citation needed]</p><p>A notable concern is that despite a great deal of rhetoric, there is no real consistent behavioral theory yet. Behavioral economics scholars also have no unified theory. Until that happens, it is a collection of loosely related or unrelated observations. What is missing is a foundational behavioral theory that can be tested in many domains as a competitor to neoclassical theory.[citation needed]</p><p>Traditional economists are also skeptical of the experimental and survey-based techniques which behavioral economics uses extensively. Economists typically stress revealed preferences over stated preferences (from surveys) in the determination of economic value. Experiments and surveys are at risk of systemic biases, strategic behavior and lack of incentive compatibility.[citation needed]</p><h3>Responses</h3><p>Rabin[23] dismisses these criticisms, claiming that consistent results are typically obtained in multiple situations and geographies and can produce good theoretical insight. Behavioral economists have also responded to these criticisms by focusing on field studies rather than lab experiments. Some economists see a fundamental schism between experimental economics and behavioral economics, but prominent behavioral and experimental economists tend to share techniques and approaches in answering common questions. For example, behavioral economists are investigating neuroeconomics, which is entirely experimental and cannot yet be verified in the field.[citation needed]</p><p>Other proponents of behavioral economics note that neoclassical models often fail to predict outcomes in real world contexts. Behavioral insights can influence neoclassical models. Behavioral economists note that these revised models not only reach the same correct predictions as the traditional models, but also correctly predict some outcomes where the traditional models failed.[citation needed]</p><div class='pageBreak' ></div><p>According to some researchers,[24] when studying the mechanisms that form the basis of decision-making, especially financial decision-making, it is necessary to recognize that most decisions are made under stress[25] because, Stress is the nonspecific body response to any demands presented to it.[26]</p><p>From a biological point of view, human behaviors are essentially the same during crises accompanied by stock market crashes and during bubble growth when share prices exceed historic highs. During those periods, most market participants see something new for themselves, and this inevitably induces a stress response in them with accompanying changes in their endocrine profiles and motivations. The result is quantitative and qualitative changes in behavior. However, this is only one example of where behavior affecting economics and finance can be observed and variably-contrasted using behavioral economics, and it is a mistake to think of its usefulness as only applying within such environments tested-in or -of conditions similar to stock exchanges specifically. Also, often selfish-reasoning, 'adult behaviors', and similar, can be identified within criminal-concealment(s), and legal-deficiencies and neglect of different types can be observed and discovered. Awareness of indirect consequence (or lack of), at least in potential with different experimental models and methods, can be used as well—behavioral economics' potential uses are broad, but its reliability need scrutiny. An underestimation of the role of novelty as a stressor is the primary shortcoming of current approaches for market research. So, it is necessary to account for the biologically determined diphasisms of human behavior in everyday low-stress conditions and in response to stressors.[24]</p><h2>Applied issues</h2><h3>Behavioral finance</h3><p>The central issue in behavioral finance is explaining why market participants make irrational systematic errors contrary to assumption of rational market participants.[1] Such errors affect prices and returns, creating market inefficiencies. The study of behavioral finance also investigates how other participants take advantage (arbitrage) of such errors and market inefficiencies.</p><p>Behavioral finance highlights inefficiencies, such as under- or over-reactions to information, as causes of market trends and, in extreme cases, of bubbles and crashes. Such reactions have been attributed to limited investor attention, overconfidence, overoptimism, mimicry (herding instinct) and noise trading. Technical analysts consider behavioral finance to be behavioral economics' academic cousin and the theoretical basis for technical analysis.[27]</p><p>Other key observations include the asymmetry between decisions to acquire or keep resources, known as the bird in the bush paradox, and loss aversion, the unwillingness to let go of a valued possession. Loss aversion appears to manifest itself in investor behavior as a reluctance to sell shares or other equity if doing so would result in a nominal loss.[28] It may also help explain why housing prices rarely/slowly decline to market clearing levels during periods of low demand.</p><p>Benartzi and Thaler, applying a version of prospect theory, claim to have solved the equity premium puzzle, something conventional finance models so far have been unable to do.[29] Experimental finance applies the experimental method, e.g., creating an artificial market through some kind of simulation software to study people's decision-making process and behavior in financial markets.</p><p>Quantitative behavioral finance uses mathematical and statistical methodology to understand behavioral biases. In marketing research, a study shows little evidence that escalating biases impact marketing decisions.[30] Leading contributors include Gunduz Caginalp (Editor of the Journal of Behavioral Finance from 2001–04), and collaborators include 2002 Nobel Laureate Vernon Smith, David Porter, Don Balenovich,[31] Vladimira Ilieva and Ahmet Duran,[32] and Ray Sturm.[33]</p><h3>Financial models</h3><p>Some financial models used in money management and asset valuation incorporate behavioral finance parameters. Examples:</p><p>Critics such as Eugene Fama typically support the efficient-market hypothesis. They contend that behavioral finance is more a collection of anomalies than a true branch of finance and that these anomalies are either quickly priced out of the market or explained by appealing to market microstructure arguments. However, individual cognitive biases are distinct from social biases; the former can be averaged out by the market, while the other can create positive feedback loops that drive the market further and further from a fair price equilibrium. Similarly, for an anomaly to violate market efficiency, an investor must be able to trade against it and earn abnormal profits; this is not the case for many anomalies.[35]</p><p>A specific example of this criticism appears in some explanations of the equity premium puzzle. It is argued that the cause is entry barriers (both practical and psychological) and that returns between stocks and bonds should equalize as electronic resources open up the stock market to more traders.[36] In response, others contend that most personal investment funds are managed through superannuation funds, minimizing the effect of these putative entry barriers.[citation needed] In addition, professional investors and fund managers seem to hold more bonds than one would expect given return differentials.[citation needed]</p><h3>Game theory</h3><p> Main article: Behavioral game theory</p><p>Behavioral game theory, Invented by Colin Camerer, analyzes interactive strategic decisions and behavior using the methods of game theory,[37] experimental economics, and experimental psychology. Experiments include testing deviations from typical simplifications of economic theory such as the independence axiom[38] and neglect of altruism,[39] fairness,[40] and framing effects.[41] On the positive side, the method has been applied to interactive learning[42] and social preferences.[43] As a research program, the subject is a development of the last three decades.[44]</p><h3>Economic reasoning in non-human animals</h3><p>A handful of comparative psychologists have attempted to demonstrate quasi-economic reasoning in non-human animals. Early attempts along these lines focus on the behavior of rats and pigeons. These studies draw on the tenets of comparative psychology, where the main goal is to discover analogs to human behavior in experimentally-tractable non-human animals. They are also methodologically similar to the work of Ferster and Skinner.[45] Methodological similarities aside, early researchers in non-human economics deviate from behaviorism in their terminology. Although such studies are set up primarily in an operant conditioning chamber using food rewards for pecking/bar-pressing behavior, the researchers describe pecking and bar-pressing not in terms of reinforcement and stimulus-response relationships but instead in terms of work, demand, budget, and labor. Recent studies have adopted a slightly different approach, taking a more evolutionary perspective, comparing economic behavior of humans to a species of non-human primate, the capuchin monkey.[46]</p><p>Many early studies of non-human economic reasoning were performed on rats and pigeons in an operant conditioning chamber. These studies looked at things like peck rate (in the case of the pigeon) and bar-pressing rate (in the case of the rat) given certain conditions of reward. Early researchers claim, for example, that response pattern (pecking/bar-pressing rate) is an appropriate analogy to human labor supply.[47] Researchers in this field advocate for the appropriateness of using animal economic behavior to understand the elementary components of human economic behavior.[48] In a paper by Battalio, Green, and Kagel,[47] they write,</p><div class='pageBreak' ></div><p>The typical laboratory environment to study labor supply in pigeons is set up as follows. Pigeons are first deprived of food. Since the animals become hungry, food becomes highly desired. The pigeons are then placed in an operant conditioning chamber and through orienting and exploring the environment of the chamber they discover that by pecking a small disk located on one side of the chamber, food is delivered to them. In effect, pecking behavior becomes reinforced, as it is associated with food. Before long, the pigeon pecks at the disk (or stimulus) regularly.</p><p>In this circumstance, the pigeon is said to work for the food by pecking. The food, then, is thought of as the currency. The value of the currency can be adjusted in several ways, including the amount of food delivered, the rate of food delivery and the type of food delivered (some foods are more desirable than others).</p><p>Economic behavior similar to that observed in humans is discovered when the hungry pigeons stop working/work less when the reward is reduced. Researchers argue that this is similar to labor supply behavior in humans. That is, like humans (who, even in need, will only work so much for a given wage), the pigeons demonstrate decreases in pecking (work) when the reward (value) is reduced.[47]</p><p>In human economics, a typical demand curve has negative slope. This means that as the price of a certain good increases, the amount that consumers are willing and able to purchase decreases. Researchers studying the demand curves of non-human animals, such as rats, also find downward slopes.</p><p>Researchers have studied demand in rats in a manner distinct from studying labor supply in pigeons. Specifically, in an operant conditioning chamber containing rats as experimental subjects, we require them to press a bar, instead of pecking a small disk, to receive a reward. The reward can be food (reward pellets), water, or a commodity drink such as cherry cola. Unlike in previous pigeon studies, where the work analog was pecking and the monetary analog was reward, the work analog in this experiment is bar-pressing. Under these circumstances, the researchers claim that changing the number of bar presses required to obtain a commodity item is analogous to changing the price of a commodity item in human economics.[49]</p><p>In effect, results of demand studies in non-human animals show that, as the bar-pressing requirement (cost) increases, the number of times an animal presses the bar equal to or greater than the bar-pressing requirement (payment) decreases.</p><h3>Evolutionary psychology</h3><p>An evolutionary psychology perspective states that many of the perceived limitations in rational choice can be explained as being rational in the context of maximizing biological fitness in the ancestral environment, but not necessarily in the current one. Thus, when living at subsistence level where a reduction of resources may result in death, it may have been rational to place a greater value on preventing losses than on obtaining gains. It may also explain behavioral differences between groups, such as males being less risk-averse than females since males have more variable reproductive success than females. While unsuccessful risk-seeking may limit reproductive success for both sexes, males may potentially increase their reproductive success from successful risk-seeking much more than females can.[50]</p><h2>Notable theorists</h2><h3>Economics</h3><h3>Psychology</h3><h3>Finance</h3><h2>Citations</h2><p>Description and preview.</p><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Behavioral_economics&amp;oldid=779832385"					
				Categories:  Hidden categories:</p><br><h1 lang="en">Demographic economics</h1><p> From Wikipedia, the free encyclopedia</p><p>Demographic economics or population economics is the application of economic analysis to demography, the study of human populations, including size, growth, density, distribution, and vital statistics.[1][2]</p><p>Aspects of the subject include</p><p>Other subfields include measuring value of life[53][54] and the economics of the elderly[55][56][57] and the handicapped[58][59][60] and of gender,[61][62][63] race, minorities, and non-labor discrimination.[64][65] In coverage and subfields, it complements labor economics[66][67] and implicates a variety of other economics subjects.[68][69][70]</p><h2>Subareas</h2><p>The Journal of Economic Literature classification codes are a way of categorizing subjects in economics. There, Demographic Economics is paired with Labor Economics as one of 19 primary classifications at JEL: J.[71] It has 8 subareas, which are listed below with JEL-code links to corresponding available article-preview links of The New Palgrave Dictionary of Economics (2008) Online:</p><p>Related:</p><h2>Notes</h2><h2>Journals</h2><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Demographic_economics&amp;oldid=783362262"					
				Categories:  Hidden categories:</p><br><div class='pageBreak' ></div><h1 lang="en">Economics of digitization</h1><p> From Wikipedia, the free encyclopedia</p><p>The economics of digitization is the field of economics that studies how digitization affects markets and how digital data can be used to study economics. Digitization is the process by which technology lowers the costs of storing, sharing, and analyzing data. This process has changed how consumers behave, how industrial activity is organized, and how governments operate. The economics of digitization exists as a distinct field of economics for two reasons. First, new economic models are needed because many traditional assumptions about information no longer holds in a digitized world. Second, the new types of data generated by digitization require new methods to analyze.</p><p>Research in the economics of digitization touches on several fields of economics including industrial organization, labor economics, and intellectual property. Consequently, many of the contributions to the economics of digitization have also found an intellectual home in these fields. An underlying theme in much of the work in the field is that existing government regulation of copyright, security, and antitrust is inappropriate in the modern world. For example, information goods, such as news articles and movies, now have zero marginal costs of production and sharing. This has made the redistribution without permission common and has increased competition between providers of information goods. Research in the economics of digitization studies how policy should adapt in response to these changes.</p><h2>Contents</h2><h2>Information technology and access to networks</h2><h3>Technological standards</h3><p>The Internet is a multi-layered network which is operated by a variety of participants. The Internet has come to mean a combination of standards, networks, and web applications (such as streaming and file-sharing) that have accumulated around networking technology. The emergence of the Internet coincided with the growth of a new type of organizational structure, the standards committee.[1][2] Standards committees are responsible for designing critical standards for the Internet such as TCP/IP, HTML, and CSS. These committees are composed of representatives from firms, academia, and non-profit organizations. Their goal is to make decisions that advance technology while retaining interoperability between Internet components. Economists are interested in how these organizational structures make decisions and whether those decisions are optimal.</p><h3>The supply of Internet access</h3><p>The commercial supply of Internet access began when the National Science Foundation removed restrictions for using the Internet for commercial purposes. During the 90's internet access was provided by numerous regional and national Internet service providers (ISPs). However, by 2014, the provision of high-speed broadband access was consolidated. About 80% of Americans can only buy 25Mbit/s from one provider and a majority only have a choice of two providers for 10Mbit/s service. Economists are particularly interested by competition and network effects within this industry.[3] Furthermore, the availability of broadband may affect other economic outcomes such as the relative wages of skilled and unskilled workers.[4]</p><h3>Demand for the Internet</h3><p>A key issue in the economics of digitization is the economic value of Internet-based services. The motivation for this question is two-fold. First, economists are interested in understanding digitization related policies such as network infrastructure investment and subsidies for Internet access. Second, economists want to measure the gains to consumers from the Internet. The revenues of Internet Service Providers provided one direct measure of the growth in the Internet economy.[5][6] This is an important topic because many economists believe that traditional measures of economic growth, such as GDP, understate the true benefits of improving technology. The modern digital economy also tends to lead to rely on inputs with zero price.[7]</p><h2>The effects of digitization on industrial organization</h2><h3>Platforms and online marketplaces</h3><p>Digitization has coincided with the increased prominence of platforms and marketplaces that connect diverse agents in social and economic activity. A platform is defined by Bresnahan and Greenstein (1999)[8] as a reconfigurable base of compatible components on which users build applications. Platforms are most readily identified with their technical standards, i.e., engineering specifications for hardware and standards for software. The pricing and product strategies that platforms use differ from those of traditional firms because of the presence of network effects. Network effects arise within platforms because participation by one group affects the utility of another group. Many online platforms replicate identical process or algorithms at virtually no cost, allowing them to scale the network effect without encountering diminishing returns. Large scale network effects make the analysis of competition between platforms more complex than the analysis of competition between traditional firms. Much work in the economics of digitization studies the question of how these firms should operate and how they compete with each other.[9][10] A particularly important issue is whether markets for online platforms have a tendency towards winner-takes-all competitive outcomes, and should be subject to antitrust actions.</p><p>Online platforms often drastically reduce transactions costs, especially in markets where the quality of a good or trading partner is uncertain.[11] For example, eBay drastically increased the market for used consumer goods by offering a search engine, reputation system, and other services that make trade less risky. Other online marketplaces of this type include Airbnb for accommodations, Prosper for lending, and Odesk for labor. Economists are interested in quantifying the gains from these marketplaces and studying how they should be designed. For example, eBay, Odesk, and other marketplaces have adapted the use of auctions as a selling mechanisms. This has prompted a large literature on the comparative advantages of selling goods via auction versus using a fixed price.[12][13][14][15]</p><h3>User-generated content and open source production</h3><p>Digitization has coincided with the production of software and content by users who are not directly compensated for their work. Furthermore, those goods are typically distributed for free on the Internet. Prominent examples of open-source software include the Apache HTTP Server, Mozilla Firefox, and the Linux operating system. Economists are interested in the incentives of users to produce this software and how this software either substitutes or complements existing production processes.[16] Another area of study is estimating the degree to which GDP and other measures of economic activity are mis-measured due to open source software. For example, Greenstein and Nagle (2014)[17] estimate that Apache alone accounts for a mis-measurement between $2 billion and $12 billion.</p><p>In addition, open source production can be used for hardware, known as open hardware, normally by sharing digital designs such as CAD files.[18] Sharing of open hardware designs can generate significant value because of the ability to digitally replicate products for approximately the cost of materials using technologies such as 3D printers.[19][20]</p><p>Another active area of research studies the incentives to produce user-generated content such as Wikipedia articles, digital videos, blogs, podcasts, etc. For example, Zhang and Zhu (2011)[21] show that Wikipedia contributors are motivated by the social interaction with other contributors. Greenstein and Zhu (2012)[22] show that while many Wikipedia articles exhibit slant, the overall level of slant across articles on Wikipedia has diminished over time.</p><h3>Advertising</h3><p>Advertising is an important source of revenue for information goods, both online and offline. Given the prevalence of advertising-supported information goods online, it is important to understand how online advertising works. Economists have spent much effort in trying to quantify the returns to online advertising. One especially interesting aspect of online advertising is its ability to target customers using fine demographic and behavioral data.[23] This ability potentially affects the ability of new and small firms to gain exposure to customers and to grow. However, targeted advertising is also controversial because it sometimes uses private data about individuals obtained through third-party sources. Quantifying the costs and benefits of using this type of data is an active research area in the field.</p><div class='pageBreak' ></div><h2>The effects of digitization on consumer choice</h2><h3>Search, search engines and recommendation systems</h3><p>Perhaps the oldest and largest stream of research on the Internet and market frictions emphasizes reduced search costs. This literature builds on an older theory literature in economics[24][25][26] that examines how search costs affect prices. Digitization of retail and marketing meant that consumers could easily compare prices across stores, so the empirical work on Internet pricing examined the impact on prices and price dispersion. Initially hypothesized by Bakos (1997),[27] the first wave of this research empirically documented lower prices, but still substantial dispersion.[28][29][30]</p><p>The newest wave of this research collects data about online searches to examine the actual search process that consumers undertake when looking for a product online.[31][32] This question also emphasizes that the final stage of purchase is often controlled by a more familiar retail environment, and it raises questions about the growing importance of standards and platforms in the distribution of creative content.</p><p>As noted earlier, near-zero marginal costs of distribution for information goods might change where and how information goods get consumed. Geographic boundaries might be less important if information can travel long distances for free.[33][34][35] One open question concerns the incidence of the impact of low distribution costs. The benefits might vary by location, with locations with fewer offline options generating a larger benefit from digitization.[36][37]</p><p>Furthermore, online retailers of digital goods can carry many more products and never worry about running out of inventory. Even if a song only sells a handful of times, it is still profitable to be offered for sale on the Internet. At the same time, the zero marginal costs of distribution mean that top-selling (superstar) items never go out of stock and therefore can achieve even higher sales (Anderson, 2006). Several papers in the literature attempt to quantify the economic impact of increased product variety made available through electronic markets.[38][39] Bar-Isaac et al. (2012)[40] derive a theory of when lower search costs will result in 'superstar' and 'long-tail' effects.</p><h3>Reputation systems</h3><p>One particularly important aspect of digitization for consumers is the increased use of reputation systems on retail websites and online marketplaces. Sixty-eight percent of respondents in a 2013 Nielsen survey said that they trusted online reviews. Numerous papers have shown that these review systems affect consumer demand for restaurants[41] books,[42] and hotels. A key area of research in digitization studies whether online reputations accurately reveal both the vertical and horizontal quality of a good. For example, Forman et al. (2008)[43] show that local reviews have more effect than reviews from distant reviewers, suggesting that reviews provide information about both vertical and horizontal differentiation. On the other hand, several show that online review are biased because not everyone leaves reviews,[44] because reviewers are afraid of retaliation,[45] and because sellers may promote their own products using the review system.[46] Newer research proposes designs for reputation systems that more efficiently aggregate information about the experiences of users.[47]</p><h2>The effects of digitization on labor markets</h2><p>Digitization has partially or fully replaced many tasks that were previously done by human laborers. At the same time, computers have made some workers much more productive. Economists are interested in understanding how these two forces interact in determining labor market outcomes. For example, a large literature studies the magnitude and causes of skill-biased technical change, the process by which technology improves wages for educated workers. Alternatively, Author (2014)[48] describes a framework for classifying jobs into those more or less prone to replacement by computers. Furthermore, the use of information technology only increases productivity when it's complemented by organization changes. For example, Garicano and Heation (2010)[49] show that IT increases the productivity of police departments only when those police departments increased training and expanded support personnel.</p><p>Another consequence of digitization is that it has drastically reduced the costs of communication between workers across different organizations and locations. This has led to a change in the geographic and contractual organization of production. Economists are interested in the magnitude of this change and its effect on local labor markets. A recent study found that the potential of manufacturing sector jobs to be offshored did not reduce wages in the US. However, survey evidence suggests that 25% of American jobs are potentially offshorable in the future.[50]</p><p>Online labor market platforms like Odesk and Amazon Mechanical Turk represent a particularly interesting form of labor production arising out of digitization. Economists who study these platforms are interested in how they compete with or complement more traditional firms. Another active area of research is how to incentivize workers on these platforms to produce more efficiently.[51] While workers engaged in routine, lower-skill tasks such as data entry are particularly susceptible to competition from online labor markets, creative professions are also exposed, as many online platforms now provide opportunities to crowdsource creative work.</p><h2>Government policy and digitization</h2><h3>Intellectual property and digitization</h3><p>One main area of policy interest related to digitization concerns intellectual property. The justification for giving copyright and patent right relies on the theory that the potential to gain these rights encourages the production and sharing of intellectual property. However, digitization and ease of copying has made it difficult to defend intellectual property rights, especially in the case of copyright. Varian (2005)[52] supplies a theoretical framework for thinking about this change from an economics perspective. Usually, the economic effect on copyright-holders in the context of free copying is considered to be negative. However, Varian suggests an important counter-argument. If the value a consumer puts on the right to copy is greater than the reduction in sales, a seller can increase profits by allowing that right. Varian also provides a detailed description of several business models which potentially address the greater difficulty of enforcing copyrights as digitization increases. Alternative business models for intellectual property holders include selling complementary goods, subscriptions, personalization, and advertising.</p><p>Empirical research in this area studies the effects of Internet file-sharing on the supply and demand for paid content. For example, Danaher et al. 2010[53] show that the removal of NBC content from iTunes increased the illicit copying of NBC shows by 11.4%. This result shows that licensed and unlicensed content are substitutes. Giorcelli and Moser (2014)[54] show that the spread of copyright in Italy between 1770 and 1900 increased the production of new and better operas. Sill, there is little work on how these empirical results should inform copyright rules and security practices.</p><h3>Net neutrality</h3><p> Main article: Net neutrality</p><h3>Privacy, security, and digitization</h3><p>Privacy and data security is an area where digitization has substantially changed the costs and benefits to various economic actors. Traditional policies regarding privacy circumscribed the ability of government agencies to access individual data. However, the large-scale ability of firms to collect, parse, and analyze detailed micro-level data about consumers has shifted the policy focus. Now, the concern is whether firms' access consumer data should be regulation and restricted. In the past decade, theoretical work on commercial privacy has tended to focus on behavioral price discrimination as being a potential application of a context where researchers can model privacy concerns from an economics perspective.[55][56]</p><p>Goldfarb and Tucker (2011a)[57] wrote the first paper to empirically study the economic effects of privacy regulation for the advertising-supported Internet. The implementation of privacy regulation in Europe has made it more difficult for firms to collect and use consumer browsing data to target their ads more accurately; the field test data shows these policies are associated with a 65 percent reduction in the influence banner ads have on purchase intent. As well as this main effect, their research also suggests that privacy regulation might change the web landscape in unanticipated ways, with advertising becoming even more intrusive. It also might lead marketers to shift their media buys away from newspapers because of difficulties in finding relevant advertising to show.</p><div class='pageBreak' ></div><p>Another related concern is what precautions should firms take to prevent data breaches such as those at Target and Staples. Arora et al. (2010)[58] models the firm's effort in securing data from an economics perspective. They find that direct competition reduces the time that a firm takes to patch a vulnerability to its software. Other attempts at measuring the consequences of information security policy from an economics perspective are Miller and Tucker (2011),[59] who look at policies mandating encryption, and Romanosky et al. (2011),[60] who look at mandatory breach notification laws.</p><h3>Other issues</h3><p>There are many other policies related to digitization that are of interest to economists. For example, digitization may affect government effectiveness and accountability.[61] Digitization also makes it easier for firms in one jurisdiction to supply consumers in another. This creates challenges for tax enforcement.[62] Another issue is that companies with new, Internet based business models, such as Airbnb and Uber, pose challenges for regulation aimed at traditional service providers. Many safety and quality enforcement regulations may no longer be necessary with the advent of online reputation systems. Lastly, digitization is of great importance to health care policy. For example, electronic medical records have the potential to make healthcare more effective but pose challenges to privacy policy.[63][64]</p><h2>Books</h2><p>In May 2015 the National Bureau of Economic Research published a book with University of Chicago Press entitled Economic Analysis of the Digital Economy. The editors for the book are Avi Goldfarb, Shane Greenstein, and Catherine Tucker. The volume brings together leading scholars to explore this emerging area of research.[65] This follows on a book that collected twenty-five important articles in the area, published by Edward Elgar Publishing, titled Economics of Digitization.[66]</p><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Economics_of_digitization&amp;oldid=779577722"					
				Categories:  Hidden categories:</p><br><h1 lang="en">Computational economics</h1><p> From Wikipedia, the free encyclopedia</p><p>Computational economics is a research discipline at the interface of computer science, economics, and management science.[1] This subject encompasses computational modeling of economic systems, whether agent-based,[2] general-equilibrium,[3] macroeconomic,[4] or rational-expectations,[5] computational econometrics and statistics,[6] computational finance, computational tools for the design of automated internet markets, programming tools specifically designed for computational economics, and pedagogical tools for the teaching of computational economics. Some of these areas are unique to computational economics, while others extend traditional areas of economics by solving problems that are difficult to study without the use of computers and associated numerical methods.[7]</p><p>Computational economics uses computer-based economic modeling for the solution of analytically and statistically formulated economic problems. A research program, to that end, is agent-based computational economics (ACE), the computational study of economic processes, including whole economies, as dynamic systems of interacting agents.[8] As such, it is an economic adaptation of the complex adaptive systems paradigm.[9] Here the agent refers to computational objects modeled as interacting according to rules, not real people.[2] Agents can represent social, biological, and/or physical entities. The theoretical assumption of mathematical optimization by agents in equilibrium is replaced by the less restrictive postulate of agents with bounded rationality adapting to market forces,[10] including game-theoretical contexts.[11] Starting from initial conditions determined by the modeler, an ACE model develops forward through time driven solely by agent interactions. The ultimate scientific objective of the method is to ... test theoretical ?ndings against real-world data in ways that permit empirically supported theories to cumulate over time, with each researcher’s work building appropriately on the work that has gone before.[12]</p><p>Computational solution tools include for example software for carrying out various matrix operations (e.g. matrix inversion) and for solving systems of linear and nonlinear equations. For a repository of public-domain computational solution tools, visit here.</p><p>The following journals specialize in computational economics: ACM Transactions on Economics and Computation, [13] Computational Economics,[1] Journal of Applied Econometrics,[14] Journal of Economic Dynamics and Control,[15] and the Journal of Economic Interaction and Coordination.[16]</p><li>^ a b Computational Economics. About This Journal and Aims and Scope.</li><li>^ a b Scott E. Page, 2008. agent-based models, The New Palgrave Dictionary of Economics, 2nd Edition. Abstract.</li><li>^ The New Palgrave Dictionary of Economics, 2008. 2nd Edition:
&nbsp; • computation of general equilibria by Herbert E. Scarf. Abstract.
&nbsp; • computation of general equilibria (new developments) by Felix Kubler. Abstract.</li><li>^ • Hans M. Amman, David A. Kendrick, and John Rust, ed., 1996. Handbook of Computational Economics, v. 1, ch. 1-6, preview links.</li><li>^ Ray C. Fair Computational Methods for Macroeconometric Models, Hans M. Amman, David A. Kendrick, and John Rust, ed., 1996. Handbook of Computational Economics, v. 1, ch. , pp. 143-169. Outline.</li><li>^ • Vassilis A. Hajivassiliou, 2008. computational methods in econometrics, The New Palgrave Dictionary of Economics, 2nd Edition. Abstract.
&nbsp;&nbsp; • Keisuke Hirano, 2008. decision theory in econometrics, The New Palgrave Dictionary of Economics, 2nd Edition. Abstract.
&nbsp;&nbsp; • James O. Berger, 2008. statistical decision theory, The New Palgrave Dictionary of Economics, 2nd Edition. Abstract.</li><li>^ • Hans M. Amman, David A. Kendrick, and John Rust, ed., 1996. Handbook of Computational Economics, v. 1, Elsevier. Description &amp; chapter-preview links.
&nbsp;&nbsp; • Kenneth L. Judd, 1998. Numerical Methods in Economics, MIT Press. Links to description and chapter previews.</li><li>^ • Scott E. Page, 2008. agent-based models, The New Palgrave Dictionary of Economics, 2nd Edition. Abstract.
&nbsp;&nbsp; • Leigh Tesfatsion, 2006. Agent-Based Computational Economics: A Constructive Approach to Economic Theory, ch. 16, Handbook of Computational Economics, v. 2, [pp. 831-880]. Abstract and pre-pub PDF.
&nbsp;&nbsp; • Kenneth L. Judd, 2006. Computationally Intensive Analyses in Economics, Handbook of Computational Economics, v. 2, ch. 17, pp. 881- 893. Pre-pub PDF.
&nbsp;&nbsp; • L. Tesfatsion and K. Judd, ed., 2006. Handbook of Computational Economics, v. 2, Agent-Based Computational Economics, Elsevier. Description &amp; and chapter-preview links.
&nbsp;&nbsp; • Thomas J. Sargent, 1994. Bounded Rationality in Macroeconomics, Oxford. Description and chapter-preview 1st-page links.</li><li>^ • W. Brian Arthur, 1994. Inductive Reasoning and Bounded Rationality, American Economic Review, 84(2), pp. 406-411.
&nbsp;&nbsp; • Leigh Tesfatsion, 2003. Agent-based Computational Economics: Modeling Economies as Complex Adaptive Systems, Information Sciences, 149(4), pp. 262-268 Archived April 26, 2012, at the Wayback Machine..
&nbsp;&nbsp; • _____, 2002. Agent-Based Computational Economics: Growing Economies from the Bottom Up, Artificial Life, 8(1), pp.55-82. Abstract and pre-pub PDF.</li><li>^ • W. Brian Arthur, 1994. Inductive Reasoning and Bounded Rationality, American Economic Review, 84(2), pp. 406-411.
&nbsp;&nbsp; • John H. Holland and John H. Miller (1991). Artificial Adaptive Agents in Economic Theory, American Economic Review, 81(2), pp. 365-370.
&nbsp;&nbsp; • Thomas C. Schelling, 1978 [2006]. Micromotives and Macrobehavior, Norton. Description, preview.
&nbsp;&nbsp; • Thomas J. Sargent, 1994. Bounded Rationality in Macroeconomics, Oxford. Description and chapter-preview 1st-page links.</li><li>^ • Joseph Y. Halpern, 2008. computer science and game theory, The New Palgrave Dictionary of Economics, 2nd Edition. Abstract.
&nbsp;&nbsp; • Yoav Shoham, 2008. Computer Science and Game Theory, Communications of the ACM, 51(8), pp. 75-79.
&nbsp;&nbsp; • Alvin E. Roth, 2002. The Economist as Engineer: Game Theory, Experimentation, and Computation as Tools for Design Economics, Econometrica, 70(4), pp. 1341–1378.</li><div class='pageBreak' ></div><li>^ Leigh Tesfatsion, 2006. Agent-Based Computational Economics: A Constructive Approach to Economic Theory, ch. 16, Handbook of Computational Economics, v. 2, sect. 5, p. 865 [pp. 831-880]. Abstract and pre-pub PDF.</li><li>^ http://teac.acm.org</li><li>^ Journal of Applied Econometrics - Wiley Online Library. onlinelibrary.wiley.com. 2011. Retrieved October 31, 2011.&nbsp;</li><li>^ Journal of Economic Dynamics and Control, including Aims &amp; scope link.
&nbsp;For a much-cited overview and issue, see:
&nbsp; • Leigh Tesfatsion, 2001. Introduction to the Special Issue on Agent-based Computational Economics, Journal of Economic Dynamics &amp; Control, pp. 281-293.
&nbsp; • [Special issue], 2001. Journal of Economic Dynamics and Control, Agent-based Computational Economics (ACE). 25(3-4), pp. 281-654. Abstract/outline links.</li><li>^ Journal of Economic Interaction and Coordination. springer.com. 2011. Retrieved October 31, 2011.&nbsp;</li><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Computational_economics&amp;oldid=783358046"					
				Categories:  Hidden categories:</p><br><h1 lang="en">Education economics</h1><p> From Wikipedia, the free encyclopedia</p><p>Education economics or the economics of education is the study of economic issues relating to education, including the demand for education, the financing and provision of education, and the comparative efficiency of various educational programs and policies. From early works on the relationship between schooling and labor market outcomes for individuals, the field of the economics of education has grown rapidly to cover virtually all areas with linkages to education.</p><h2>Contents</h2><h2>Education as an investment</h2><p>Economics distinguishes in addition to physical capital another form of capital that is no less critical as a means of production – human capital. With investments in human capital, such as education, three major economic effects can be expected:[1]</p><h3>Investment costs</h3><p>Investments in human capital entail an investment cost, just as any investment does. Typically in European countries most education expenditure takes the form of government consumption, although some costs are also borne by individuals. These investments can be rather costly. EU governments spent between 3% and 8% of GDP on education in 2005, the average being 5%.[2] However, measuring the spending this way alone greatly underestimates the costs because a more subtle form of costs is completely overlooked: the opportunity cost of forgone wages as students cannot work while they study. It has been estimated that the total costs, including opportunity costs, of education are as much as double the direct costs.[3] Including opportunity costs investments in education can be estimated to have been around 10% of GDP in the EU countries in 2005. In comparison investments in physical capital were 20% of GDP.[4] Thus the two are of similar magnitude.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/0/0e/Average_years_of_schooling_versus_GDP_per_capita.jpg/270px-Average_years_of_schooling_versus_GDP_per_capita.jpg" width="270" height="160"><p>


Average years of schooling versus GDP per capita (USD 2005).


</p><h3>Returns on investment</h3><p>
	Human capital in the form of education shares many characteristics with physical capital. Both require an investment to create and, once created, both have economic value. Physical capital earns a return because people are willing to pay to use a piece of physical capital in work as it allows them to produce more output. To measure the productive value of physical capital, we can simply measure how much of a return it commands in the market. In the case of human capital calculating returns is more complicated – after all, we cannot separate education from the person to see how much it rents for. To get around this problem, the returns to human capital are generally inferred from differences in wages among people with different levels of education. Hall and Jones have calculated from international data that on average that the returns on education are 13.4% per year for first four years of schooling (grades 1–4), 10.1% per year for the next four years (grades 5–8) and 6.8% for each year beyond eight years.[5] Thus someone with 12 years of schooling can be expected to earn, on average, 1.1344 × 1.1014 × 1.0684 = 3.161 times as much as someone with no schooling at all.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/6/62/Predicted_versus_actual_GDP_per_worker.jpg/270px-Predicted_versus_actual_GDP_per_worker.jpg" width="270" height="186"><p>


Predicted versus actual GDP per worker. The figure shows how much one would expect each country’s GDP to be higher based on the data on average years of schooling


</p><h3>Effects on productivity</h3><p>
	Economy-wide, the effect of human capital on incomes has been estimated to be rather significant: 65% of wages paid in developed countries is payments to human capital and only 35% to raw labor.[1] The higher productivity of well-educated workers is one of the factors that explain higher GDPs and, therefore, higher incomes in developed countries. A strong correlation between GDP and education is clearly visible among the countries of the world, as is shown by the upper left figure. It is less clear, however, how much of a high GDP is explained by education. After all, it is also possible that rich countries can simply afford more education.</p><p>To distinguish the part of GDP explained with education from other causes, Weil[1] has calculated how much one would expect each country’s GDP to be higher based on the data on average schooling. This was based on the above-mentioned calculations of Hall and Jones on the returns on education. GDPs predicted by Weil’s calculations can be plotted against actual GDPs, as is done in the figure on the left, demonstrating that the variation in education explains some, but not all, of the variation in GDP.</p><p>Finally, the matter of externalities should be considered. Usually when speaking of externalities one thinks of the negative effects of economic activities that are not included in market prices, such as pollution. These are negative externalities. However, there are also positive externalities – that is, positive effects of which someone can benefit without having to pay for it. Education bears with it major positive externalities: giving one person more education raises not only his or her output but also the output of those around him or her. Educated workers can bring new technologies, methods and information to the consideration of others. They can teach things to others and act as an example. The positive externalities of education include the effects of personal networks and the roles educated workers play in them.[6]</p><div class='pageBreak' ></div><p>Positive externalities from human capital are one explanation for why governments are involved in education. If people were left on their own, they would not take into account the full social benefit of education – in other words the rise in the output and wages of others – so the amount they would choose to obtain would be lower than the social optimum.[1]</p><h2>Demand for education</h2><h3>Liberal approaches</h3><p>The dominant model of the demand for education is based on human capital theory. The central idea is that undertaking education is investment in the acquisition of skills and knowledge which will increase earnings, or provide long-term benefits such as an appreciation of literature (sometimes referred to as cultural capital).[7] An increase in human capital can follow technological progress as knowledgeable employees are in demand due to the need for their skills, whether it be in understanding the production process or in operating machines. Studies from 1958 attempted to calculate the returns from additional schooling (the percent increase in income acquired through an additional year of schooling). Later results attempted to allow for different returns across persons or by level of education.[8]</p><p>Statistics have shown that countries with high enrollment/graduation rates have grown faster than countries without. The United States has been the world leader in educational advances, beginning with the high school movement (1910–1950). There also seems to be a correlation between gender differences in education with the level of growth; more development is observed in countries which have an equal distribution of the percentage of women versus men who graduated from high school. When looking at correlations in the data, education seems to generate economic growth; however, it could be that we have this causality relationship backwards. For example, if education is seen as a luxury good, it may be that richer households are seeking out educational attainment as a symbol of status, rather than the relationship of education leading to wealth.</p><p>Educational advance is not the only variable for economic growth, though, as it only explains about 14% of the average annual increase in labor productivity over the period 1915-2005. From lack of a more significant correlation between formal educational achievement and productivity growth, some economists see reason to believe that in today’s world many skills and capabilities come by way of learning outside of traditional education, or outside of schooling altogether.[9]</p><p>An alternative model of the demand for education, commonly referred to as screening, is based on the economic theory of signalling. The central idea is that the successful completion of education is a signal of ability.[10]</p><h3>Marxist critique</h3><p>Although Marx and Engels did not write widely about the social functions of education, their concepts and methods are theorized and criticized by the influence of Marx as education being used in reproduction of capitalist societies. Marx and Engels approached scholarship as revolutionary scholarship where education should serve as a propaganda for the struggle of the working class.[11] The classical Marxian paradigm sees education as serving the interest of capital and is seeking alternative modes of education that would prepare students and citizens for more progressive socialist mode of social organizations. Marx and Engels understood education and free time as essential to developing free individuals and creating many-sided human beings, thus for them education should become a more essential part of the life of people unlike capitalist society which is organized mainly around work and the production of commodities.[11]</p><h2>Financing and provision</h2><p>In most countries school education is predominantly financed and provided by governments. Public funding and provision also plays a major role in higher education. Although there is wide agreement on the principle that education, at least at school level, should be financed mainly by governments, there is considerable debate over the desirable extent of public provision of education. Supporters of public education argue that universal public provision promotes equality of opportunity and social cohesion. Opponents of public provision advocate alternatives such as vouchers.[12][13][14]</p><h3>Pre-primary education financing</h3><p>Compared to other areas of basic education, globally comparable data on pre-primary education financing remain scarce. While much of existing non-formal and private programmes may not be fully accounted for, it can be deduced from the level of provision that pre-primary financing remains inadequate, especially when considered against expected benefits. Globally, pre-primary education accounts for the lowest proportion of the total public expenditure on education, in spite of the much-documented positive impact of quality early childhood care and education on later learning and other social outcomes.[15]</p><h2>Education production function</h2><p>An education production function is an application of the economic concept of a production function to the field of education. It relates various inputs affecting a student’s learning (schools, families, peers, neighborhoods, etc.) to measured outputs including subsequent labor market success, college attendance, graduation rates, and, most frequently, standardized test scores. The original study that eventually prompted interest in the idea of education production functions was by a sociologist, James S. Coleman. The Coleman Report, published in 1966, concluded that the marginal effect of various school inputs on student achievement was small compared to the impact of families and friends.[16] Later work, by Eric A. Hanushek, Richard Murnane, and other economists introduced the structure of production to the consideration of student learning outcomes. Hanushek at al. (2008) reported a very high correlation between adjusted growth rate and adjusted test scores.[17]</p><p>A large number of successive studies, increasingly involving economists, produced inconsistent results about the impact of school resources on student performance, leading to considerable controversy in policy discussions.[18][19] The interpretation of the various studies has been very controversial, in part because the findings have directly influenced policy debates. Two separate lines of study have been particularly widely debated. The overall question of whether added funds to schools are likely to produce higher achievement (the “money doesn’t matter” debate) has entered into legislative debates and court consideration of school finance systems.[20][21][22] Additionally, policy discussions about class size reduction heightened academic study of the relationship of class size and achievement.[23][24][25]</p><h2>Sources</h2><h2>Notes</h2><p>Selected entries on education from The New Palgrave Dictionary of Economics, 2008), 2nd Edition:</p><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Education_economics&amp;oldid=783361491"					
				Categories:  Hidden categories:</p><br><h1 lang="en">Evolutionary economics</h1><p> From Wikipedia, the free encyclopedia</p><p>Evolutionary economics is part of mainstream economics[1] as well as a heterodox school of economic thought that is inspired by evolutionary biology. Much like mainstream economics, it stresses complex interdependencies, competition, growth, structural change, and resource constraints but differs in the approaches which are used to analyze these phenomena.[2]</p><div class='pageBreak' ></div><p>Evolutionary economics deals with the study of processes that transform economy for firms, institutions, industries, employment, production, trade and growth within, through the actions of diverse agents from experience and interactions, using evolutionary methodology. Evolutionary economics analyses the unleashing of a process of technological and institutional innovation by generating and testing a diversity of ideas which discover and accumulate more survival value for the costs incurred than competing alternatives. The evidence suggests that it could be adaptive efficiency that defines economic efficiency. Mainstream economic reasoning begins with the postulates of scarcity and rational agents (that is, agents modeled as maximizing their individual welfare), with the rational choice for any agent being a straightforward exercise in mathematical optimization. There has been renewed interest in treating economic systems as evolutionary systems in the developing field of Complexity economics.[citation needed]</p><p>Evolutionary economics does not take the characteristics of either the objects of choice or of the decision-maker as fixed. Rather its focus is on the non-equilibrium processes that transform the economy from within and their implications. The processes in turn emerge from actions of diverse agents with bounded rationality who may learn from experience and interactions and whose differences contribute to the change. The subject draws more recently on evolutionary game theory[3] and on the evolutionary methodology of Charles Darwin and the non-equilibrium economics principle of circular and cumulative causation. It is naturalistic in purging earlier notions of economic change as teleological or necessarily improving the human condition.[4]</p><p>A different approach is to apply evolutionary psychology principles to economics which is argued to explain problems such as inconsistencies and biases in rational choice theory. Basic economic concepts such as utility may be better viewed as due to preferences that maximized evolutionary fitness in the ancestral environment but not necessarily in the current one.[5]</p><h2>Contents</h2><h2>Predecessors</h2><p>In the mid-19th century, Karl Marx presented a schema of stages of historical development, by introducing the notion that human nature was not constant and was not determinative of the nature of the social system; on the contrary, he made it a principle that human behavior was a function of the social and economic system in which it occurred.</p><p>Marx based his theory of economic development on the premise of developing economic systems; specifically, over the course of history superior economic systems would replace inferior ones. Inferior systems were beset by internal contradictions and inefficiencies that make them impossible to survive over the long term. In Marx's scheme, feudalism was replaced by capitalism, which would eventually be superseded by socialism.[6]</p><p>At approximately the same time, Charles Darwin developed a general framework for comprehending any process whereby small, random variations could accumulate and predominate over time into large-scale changes that resulted in the emergence of wholly novel forms (speciation).</p><p>This was followed shortly after by the work of the American pragmatic philosophers (Peirce, James, Dewey) and the founding of two new disciplines, psychology and anthropology, both of which were oriented toward cataloging and developing explanatory frameworks for the variety of behavior patterns (both individual and collective) that were becoming increasingly obvious to all systematic observers. The state of the world converged with the state of the evidence to make almost inevitable the development of a more modern framework for the analysis of substantive economic issues.</p><h3>Veblen (1898)</h3><p>Thorstein Veblen (1898) coined the term evolutionary economics in English. He began his career in the midst of this period of intellectual ferment, and as a young scholar came into direct contact with some of the leading figures of the various movements that were to shape the style and substance of social sciences into the next century and beyond. Veblen saw the need for taking account of cultural variation in his approach; no universal human nature could possibly be invoked to explain the variety of norms and behaviors that the new science of anthropology showed to be the rule, rather than the exception. He emphasised the conflict between industrial and pecuniary or ceremonial values and this Veblenian dichotomy was interpreted in the hands of later writers as the ceremonial / instrumental dichotomy (Hodgson 2004);</p><p>Veblen saw that every culture is materially based and dependent on tools and skills to support the life process, while at the same time, every culture appeared to have a stratified structure of status (invidious distinctions) that ran entirely contrary to the imperatives of the instrumental (read: technological) aspects of group life. The ceremonial was related to the past, and conformed to and supported the tribal legends; instrumental was oriented toward the technological imperative to judge value by the ability to control future consequences. The Veblenian dichotomy was a specialized variant of the instrumental theory of value due to John Dewey, with whom Veblen was to make contact briefly at the University of Chicago.</p><p>Arguably the most important works by Veblen include, but are not restricted to, his most famous works (The Theory of the Leisure Class; The Theory of Business Enterprise), but his monograph Imperial Germany and the Industrial Revolution and the 1898 essay entitled Why is Economics not an Evolutionary Science have both been influential in shaping the research agenda for following generations of social scientists. TOLC and TOBE together constitute an alternative construction on the neoclassical marginalist theories of consumption and production, respectively.</p><p>Both are founded on his dichotomy, which is at its core a valuational principle. The ceremonial patterns of activity are not bound to any past, but to one that generated a specific set of advantages and prejudices that underlie the current institutions. Instrumental judgments create benefits according to a new criterion, and therefore are inherently subversive. This line of analysis was more fully and explicitly developed by Clarence E. Ayres of the University of Texas at Austin from the 1920s.</p><p>A seminal article by Armen Alchian (1950) argued for adaptive success of firms faced with uncertainty and incomplete information replacing profit maximization as an appropriate modeling assumption.[7] Kenneth Boulding was one of the advocates of the evolutionary methods in social science, as is evident from Kenneth Boulding's Evolutionary Perspective. Kenneth Arrow, Ronald Coase and Douglass North are some of the Bank of Sweden Prize in Economic Sciences in Memory of Alfred Nobel winners who are known for their sympathy to the field.</p><p>More narrowly the works Jack Downie[8] and Edith Penrose[9] offer many insights for those thinking about evolution at the level of the firm in an industry.</p><p>Joseph Schumpeter, who lived in the first half of 20th century, was the author of the book The Theory of Economic Development (1911, transl. 1934). It is important to note that for the word development he used in his native language, the German word Entwicklung, which can be translated as development or evolution. The translators of the day used the word development from the French développement, as opposed to evolution as this was used by Darwin. (Schumpeter, in his later writings in English as a professor at Harvard, used the word evolution.) The current term in common use is economic development.</p><p>In Schumpeter's book he proposed an idea radical for its time: the evolutionary perspective. He based his theory on the assumption of usual macroeconomic equilibrium, which is something like the normal mode of economic affairs. This equilibrium is being perpetually destroyed by entrepreneurs who try to introduce innovations. A successful introduction of an innovation (i.e. a disruptive technology) disturbs the normal flow of economic life, because it forces some of the already existing technologies and means of production to lose their positions within the economy.[citation needed]</p><h2>Present state of discussion</h2><div class='pageBreak' ></div><p>One of the major contributions to the emerging field of evolutionary economics has been the publication of An Evolutionary Theory of Economic Change by Richard Nelson and Sidney G. Winter. These authors have focused mostly on the issue of changes in technology and routines, suggesting a framework for their analysis. If the change occurs constantly in the economy, then some kind of evolutionary process must be in action, and there has been a proposal that this process is Darwinian in nature.</p><p>Then, mechanisms that provide selection, generate variation and establish self-replication, must be identified. The authors introduced the term 'steady change' to highlight the evolutionary aspect of economic processes and contrast it with the concept of 'steady state' popular in classical economics.[10] Their approach can be compared and contrasted with the population ecology or organizational ecology approach in sociology: see Douma &amp; Schreuder (2013, chapter 11).</p><p>Milton Friedman proposed that markets act as major selection vehicles. As firms compete, unsuccessful rivals fail to capture an appropriate market share, go bankrupt and have to exit.[11] The variety of competing firms is both in their products and practices, that are matched against markets. Both products and practices are determined by routines that firms use: standardized patterns of actions implemented constantly. By imitating these routines, firms propagate them and thus establish inheritance of successful practices.[12][13] A general theory of this process has been proposed by Kurt Dopfer, John Foster and Jason Potts as the micro meso macro framework.[14]</p><p>Economic processes, as part of life processes, are intrinsically evolutionary. From the evolutionary equation that describe life processes, an analytical formula on the main factors of economic processes, such as fixed cost and variable cost, can be derived. The economic return, or competitiveness, of economic entities of different characteristics under different kinds of environment can be calculated.[15] The change of environment causes the change of competitiveness of different economic entities and systems. This is the process of evolution of economic systems.</p><p>In recent years, evolutionary models have been used to assist decision making in applied settings and find solutions to problems such as optimal product design and service portfolio diversification.[16]</p><h2>Evolutionary psychology</h2><p>A different approach is to apply evolutionary psychology principles to economics which is argued to explain problems such as inconsistencies and biases in rational choice theory. A basic economic concept such as utility may be better viewed as due to preferences that maximized evolutionary fitness in the ancestral environment but not necessarily in the current one. Loss aversion may be explained as being rational when living at subsistence level where a reduction of resources may have meant death and it thus may have been rational to place a greater value on losses than on gains.[5]</p><p>People are sometimes more cooperative and altruistic than predicted by economic theory which may be explained by mechanisms such as reciprocal altruism and group selection for cooperative behavior. An evolutionary approach may also explain differences between groups such as males being less risk-averse than females since males have more variable reproductive success than females. While unsuccessful risk-seeking may limit reproductive success for both sexes, males may potentially increase their reproductive success much more than females from successful risk-seeking. Frequency-dependent selection may explain why people differ in characteristics such as cooperative behavior with cheating becoming an increasingly less successful strategy as the numbers of cheaters increase.[5]</p><p>Another argument is that humans have a poor intuitive grasp of the economics of the current environment which is very different from the ancestral environment. The ancestral environment likely had relatively little trade, division of labor, and capital goods. Technological change was very slow, wealth differences were much smaller, and possession of many available resources were likely zero-sum games where large inequalities were caused by various forms of exploitation. Humans therefore may have poor intuitive understanding the benefits of free trade (causing calls for protectionism), the value of capital goods (making the labor theory of value appealing), and may intuitively undervalue the benefits of technological development.[5]</p><p>There may be a tendency to see the number of available jobs as a zero-sum game with the total number of jobs being fixed which causes people to not realize that minimum wage laws reduce the number of jobs or to believe that an increased number of jobs in other nations necessarily decreases the number of jobs in their own nation. Large income inequality may easily be viewed as due to exploitation rather than as due to individual differences in productivity. This may easily cause poor economic policies, especially since individual voters have few incentives to make the effort of studying societal economics instead of relying on their intuitions since an individual's vote counts for so little and since politicians may be reluctant to take a stand against intuitive views that are incorrect but widely held.[5]</p><h3>Journals</h3><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Evolutionary_economics&amp;oldid=783350140"					
				Categories:  Hidden categories:</p><br><h1 lang="en">Economic geography</h1><p> From Wikipedia, the free encyclopedia</p><p>Economic geography is the study of the location, distribution and spatial organization of economic activities across the world. It represents a traditional subfield of the discipline of geography. However, many economists have also approached the field in ways more typical of the discipline of economics.[1]</p><p>Economic geography has taken a variety of approaches to many different subject matters, including the location of industries, economies of agglomeration (also known as linkages), transportation, international trade, development, real estate, gentrification, ethnic economies, gendered economies, core-periphery theory, the economics of urban form, the relationship between the environment and the economy (tying into a long history of geographers studying culture-environment interaction), and globalization.</p><h2>Contents</h2><h2>Theoretical background and influences</h2><p>The subject matter investigated is strongly influenced by the researcher's methodological approach. Neoclassical location theorists, following in the tradition of Alfred Weber, tend to focus on industrial location and use quantitative methods. Since the 1970s, two broad reactions against neoclassical approaches have significantly changed the discipline: Marxist political economy, growing out of the work of David Harvey; and the new economic geography which takes into account social, cultural, and institutional factors in the spatial economy.</p><p>Economists such as Paul Krugman and Jeffrey Sachs have also analyzed many traits related to economic geography. Krugman called his application of spatial thinking to international trade theory the new economic geography, which directly competes with an approach within the discipline of geography that is also called new economic geography.[2] The name geographical economics has been suggested as an alternative.[3]</p><h2>History</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/1/1e/ElSalvadorfairtradecoffee.jpg/220px-ElSalvadorfairtradecoffee.jpg" width="220" height="138"><div class='pageBreak' ></div><p>


The coffee trade is a worldwide industry


</p><p>
	Some of the first traces of the study of spatial aspects of economic activities can be found in seven Chinese maps of the State of Qin dating to the 4th century BC. Ancient writings can be attributed to the Greek geographer Strabo's Geographika compiled almost 2000 years ago. As the science of cartography developed, geographers illuminated many aspects used today in the field; maps created by different European powers described the resources likely to be found in American, African, and Asian territories. The earliest travel journals included descriptions of the native peoples, the climate, the landscape, and the productivity of various locations. These early accounts encouraged the development of transcontinental trade patterns and ushered in the era of mercantilism.</p><p>World War II contributed to the popularization of geographical knowledge generally, and post-war economic recovery and development contributed to the growth of economic geography as a discipline. During environmental determinism's time of popularity, Ellsworth Huntington and his theory of climatic determinism, while later greatly criticized, notably influenced the field. Valuable contributions also came from location theorists such as Johann Heinrich von Thünen or Alfred Weber. Other influential theories include Walter Christaller's Central place theory, the theory of core and periphery.[citation needed]</p><p>Fred K. Schaefer's article Exceptionalism in geography: A Methodological Examination, published in the American journal Annals of the Association of American Geographers, and his critique of regionalism, made a large impact on the field: the article became a rallying point for the younger generation of economic geographers who were intent on reinventing the discipline as a science, and quantitative methods began to prevail in research. Well-known economic geographers of this period include William Garrison, Brian Berry, Waldo Tobler, Peter Haggett and William Bunge.</p><p>Contemporary economic geographers tend to specialize in areas such as location theory and spatial analysis (with the help of geographic information systems), market research, geography of transportation, real estate price evaluation, regional and global development, planning, Internet geography, innovation, social networks.[4]</p><h2>Approaches to study</h2><p>As economic geography is a very broad discipline, with economic geographers using many different methodologies in the study of economic phenomena in the world some distinct approaches to study have evolved over time:</p><p>Economic geography is sometimes approached as a branch of anthropogeography that focuses on regional systems of human economic activity. An alternative description of different approaches to the study of human economic activity can be organized around spatiotemporal analysis, analysis of production/consumption of economic items, and analysis of economic flow. Spatiotemporal systems of analysis include economic activities of region, mixed social spaces, and development.</p><p>Alternatively, analysis may focus on production, exchange, distribution and consumption of items of economic activity. Allowing parameters of space-time and item to vary, a geographer may also examine material flow, commodity flow, population flow and information flow from different parts of the economic activity system. Through analysis of flow and production, industrial areas, rural and urban residential areas, transportation site, commercial service facilities and finance and other economic centers are linked together in an economic activity system.</p><h3>Branches</h3><p>Thematically, economic geography can be divided into these subdisciplines:</p><p>It is traditionally considered the branch of economic geography that investigates those parts of the Earth's surface that are transformed by humans through primary sector activities. It thus focuses on structures of agricultural landscapes and asks for the processes that lead to these spatial patterns. While most research in this area concentrates rather on production than on consumption,[1] a distinction can be made between nomothetic (e.g. distribution of spatial agricultural patterns and processes) and idiographic research (e.g. human-environment interaction and the shaping of agricultural landscapes). The latter approach of agricultural geography is often applied within regional geography.</p><p>These areas of study may overlap with other geographical sciences.</p><h3>Economists and economic geographers</h3><p>Generally, spatially interested economists study the effects of space on the economy. Geographers, on the other hand, are interested in the economic processes' impact on spatial structures.</p><p>Moreover, economists and economic geographers differ in their methods in approaching spatial-economic problems in several ways. An economic geographer will often take a more holistic approach in the analysis of economic phenomena, which is to conceptualize a problem in terms of space, place and scale as well as the overt economic problem that is being examined. The economist approach, according to some economic geographers, has the main drawback of homogenizing the economic world in ways economic geographers try to avoid.[7]</p><h2>New economic geography</h2><p>With the rise of the New Economy, economic inequalities are increasing spatially. The New Economy, generally characterized by globalization, increasing use of information and communications technology, growth of knowledge goods, and feminization, has enabled economic geographers to study social and spatial divisions caused by the arising New Economy, including the emerging digital divide.</p><p>The new economic geographies consist of primarily service-based sectors of the economy that use innovative technology, such as industries where people rely on computers and the internet. Within these is a switch from manufacturing-based economies to the digital economy. In these sectors, competition makes technological changes robust. These high technology sectors rely heavily on interpersonal relationships and trust, as developing things like software is very different from other kinds of industrial manufacturing—it requires intense levels of cooperation between many different people, as well as the use of tacit knowledge. As a result of cooperation becoming a necessity, there is a clustering in the high-tech new economy of many firms.</p><h3>Social and spatial divisions</h3><p>As characterized through the work of Diane Perrons,[8] in Anglo-American literature, the New Economy consists of two distinct types. New Economic Geography 1 (NEG1) is characterized by sophisticated spatial modelling. It seeks to explain uneven development and the emergence of industrial clusters. It does so through the exploration of linkages between centripetal and centrifugal forces, especially those of economies of scale.</p><p>New Economic Geography 2 (NEG2) also seeks to explain the apparently paradoxical emergence of industrial clusters in a contemporary context, however, it emphasizes relational, social, and contextual aspects of economic behaviour, particularly the importance of tacit knowledge. The main difference between these two types is NEG2's emphasis on aspects of economic behaviour that NEG1 considers intangible.</p><p>Both New Economic Geographies acknowledge transport costs, the importance of knowledge in a new economy, possible effects of externalities, and endogenous processes that generate increases in productivity. The two also share a focus on the firm as the most important unit and on growth rather than development of regions. As a result, the actual impact of clusters on a region is given far less attention, relative to the focus on clustering of related activities in a region.</p><div class='pageBreak' ></div><p>However, the focus on the firm as the main entity of significance hinders the discussion of New Economic Geography. It limits the discussion in a national and global context and confines it to a smaller scale context. It also places limits on the nature of activities carried out in the firm and their position within the global value chain. Further work done by Bjorn Asheim (2001) and Gernot Grabher (2002) challenges the idea of the firm through action-research approaches and mapping organizational forms and their linkages. In short, the focus on the firm in new economic geographies is undertheorized in NEG1 and undercontextualized in NEG2, which limits the discussion of its impact on spatial economic development.</p><p>Spatial divisions within these arising New Economic geographies are apparent in the form of the digital divide, as a result of regions attracting talented workers instead of developing skills at a local level (see Creative Class for further reading). Despite increasing inter-connectivity through developing information communication technologies, the contemporary world is still defined through its widening social and spatial divisions, most of which are increasingly gendered. Danny Quah explains these spatial divisions through the characteristics of knowledge goods in the New Economy: goods defined by their infinite expansibility, weightlessness, and nonrivalry. Social divisions are expressed through new spatial segregation that illustrates spatial sorting by income, ethnicity, abilities, needs, and lifestyle preferences. Employment segregation can be seen through the overrepresentation of women and ethnic minorities in lower-paid service sector jobs. These divisions in the new economy are much more difficult to overcome as a result of few clear pathways of progression to higher-skilled work.</p><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Economic_geography&amp;oldid=780980532"					
				Categories:  Hidden categories:</p><br><br><img alt="This is a good article. Click here for more information." src="http://upload.wikimedia.org/wikipedia/en/thumb/9/94/Symbol_support_vote.svg/19px-Symbol_support_vote.svg.png" width="19" height="20"><h1 lang="en">Mathematical economics</h1><p> From Wikipedia, the free encyclopedia</p><p>Mathematical economics is the application of mathematical methods to represent theories and analyze problems in economics. By convention, the applied methods refer to those beyond simple geometry, such as differential and integral calculus, difference and differential equations, matrix algebra, mathematical programming, and other computational methods.[1][2] An advantage claimed for the approach is its allowing formulation of theoretical relationships with rigor, generality, and simplicity.[3]</p><p>Mathematics allows economists to form meaningful, testable propositions about wide-ranging and complex subjects which could less easily be expressed informally. Further, the language of mathematics allows economists to make specific, positive claims about controversial or contentious subjects that would be impossible without mathematics.[4] Much of economic theory is currently presented in terms of mathematical economic models, a set of stylized and simplified mathematical relationships asserted to clarify assumptions and implications.[5]</p><p>Broad applications include:</p><p>Formal economic modeling began in the 19th century with the use of differential calculus to represent and explain economic behavior, such as utility maximization, an early economic application of mathematical optimization. Economics became more mathematical as a discipline throughout the first half of the 20th century, but introduction of new and generalized techniques in the period around the Second World War, as in game theory, would greatly broaden the use of mathematical formulations in economics.[8][7]</p><p>This rapid systematizing of economics alarmed critics of the discipline as well as some noted economists. John Maynard Keynes, Robert Heilbroner, Friedrich Hayek and others have criticized the broad use of mathematical models for human behavior, arguing that some human choices are irreducible to mathematics.</p><h2>Contents</h2><h2>History</h2><p> Main article: History of economic thought</p><p>The use of mathematics in the service of social and economic analysis dates back to the 17th century. Then, mainly in German universities, a style of instruction emerged which dealt specifically with detailed presentation of data as it related to public administration. Gottfried Achenwall lectured in this fashion, coining the term statistics. At the same time, a small group of professors in England established a method of reasoning by figures upon things relating to government and referred to this practice as Political Arithmetick.[9] Sir William Petty wrote at length on issues that would later concern economists, such as taxation, Velocity of money and national income, but while his analysis was numerical, he rejected abstract mathematical methodology. Petty's use of detailed numerical data (along with John Graunt) would influence statisticians and economists for some time, even though Petty's works were largely ignored by English scholars.[10]</p><p>The mathematization of economics began in earnest in the 19th century. Most of the economic analysis of the time was what would later be called classical economics. Subjects were discussed and dispensed with through algebraic means, but calculus was not used. More importantly, until Johann Heinrich von Thünen's The Isolated State in 1826, economists did not develop explicit and abstract models for behavior in order to apply the tools of mathematics. Thünen's model of farmland use represents the first example of marginal analysis.[11] Thünen's work was largely theoretical, but he also mined empirical data in order to attempt to support his generalizations. In comparison to his contemporaries, Thünen built economic models and tools, rather than applying previous tools to new problems.[12]</p><p>Meanwhile, a new cohort of scholars trained in the mathematical methods of the physical sciences gravitated to economics, advocating and applying those methods to their subject,[13] and described today as moving from geometry to mechanics.[14] These included W.S. Jevons who presented paper on a general mathematical theory of political economy in 1862, providing an outline for use of the theory of marginal utility in political economy.[15] In 1871, he published The Principles of Political Economy, declaring that the subject as science must be mathematical simply because it deals with quantities. Jevons expected the only collection of statistics for price and quantities would permit the subject as presented to become an exact science.[16] Others preceded and followed in expanding mathematical representations of economic problems.</p><h3>Marginalists and the roots of neoclassical economics</h3><p> Main article: Marginalism</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/e/eb/Economics_cournot_diag4_svg.svg/275px-Economics_cournot_diag4_svg.svg.png" width="275" height="275"><div class='pageBreak' ></div><p>


Equilibrium quantities as a solution to two reaction functions in Cournot duopoly. Each reaction function is expressed as a linear equation dependent upon quantity demanded.


</p><p>
	Augustin Cournot and Léon Walras built the tools of the discipline axiomatically around utility, arguing that individuals sought to maximize their utility across choices in a way that could be described mathematically.[17] At the time, it was thought that utility was quantifiable, in units known as utils.[18] Cournot, Walras and Francis Ysidro Edgeworth are considered the precursors to modern mathematical economics.[19]</p><p>Cournot, a professor of mathematics, developed a mathematical treatment in 1838 for duopoly—a market condition defined by competition between two sellers.[19] This treatment of competition, first published in Researches into the Mathematical Principles of Wealth,[20] is referred to as Cournot duopoly. It is assumed that both sellers had equal access to the market and could produce their goods without cost. Further, it assumed that both goods were homogeneous. Each seller would vary her output based on the output of the other and the market price would be determined by the total quantity supplied. The profit for each firm would be determined by multiplying their output and the per unit Market price. Differentiating the profit function with respect to quantity supplied for each firm left a system of linear equations, the simultaneous solution of which gave the equilibrium quantity, price and profits.[21] Cournot's contributions to the mathematization of economics would be neglected for decades, but eventually influenced many of the marginalists.[21][22] Cournot's models of duopoly and Oligopoly also represent one of the first formulations of non-cooperative games. Today the solution can be given as a Nash equilibrium but Cournot's work preceded modern game theory by over 100 years.[23]</p><p>While Cournot provided a solution for what would later be called partial equilibrium, Léon Walras attempted to formalize discussion of the economy as a whole through a theory of general competitive equilibrium. The behavior of every economic actor would be considered on both the production and consumption side. Walras originally presented four separate models of exchange, each recursively included in the next. The solution of the resulting system of equations (both linear and non-linear) is the general equilibrium.[24] At the time, no general solution could be expressed for a system of arbitrarily many equations, but Walras's attempts produced two famous results in economics. The first is Walras' law and the second is the principle of tâtonnement. Walras' method was considered highly mathematical for the time and Edgeworth commented at length about this fact in his review of Éléments d'économie politique pure (Elements of Pure Economics).[25]</p><p>Walras' law was introduced as a theoretical answer to the problem of determining the solutions in general equilibrium. His notation is different from modern notation but can be constructed using more modern summation notation. Walras assumed that in equilibrium, all money would be spent on all goods: every good would be sold at the market price for that good and every buyer would expend their last dollar on a basket of goods. Starting from this assumption, Walras could then show that if there were n markets and n-1 markets cleared (reached equilibrium conditions) that the nth market would clear as well. This is easiest to visualize with two markets (considered in most texts as a market for goods and a market for money). If one of two markets has reached an equilibrium state, no additional goods (or conversely, money) can enter or exit the second market, so it must be in a state of equilibrium as well. Walras used this statement to move toward a proof of existence of solutions to general equilibrium but it is commonly used today to illustrate market clearing in money markets at the undergraduate level.[26]</p><p>Tâtonnement (roughly, French for groping toward) was meant to serve as the practical expression of Walrasian general equilibrium. Walras abstracted the marketplace as an auction of goods where the auctioneer would call out prices and market participants would wait until they could each satisfy their personal reservation prices for the quantity desired (remembering here that this is an auction on all goods, so everyone has a reservation price for their desired basket of goods).[27]</p><p>Only when all buyers are satisfied with the given market price would transactions occur. The market would clear at that price—no surplus or shortage would exist. The word tâtonnement is used to describe the directions the market takes in groping toward equilibrium, settling high or low prices on different goods until a price is agreed upon for all goods. While the process appears dynamic, Walras only presented a static model, as no transactions would occur until all markets were in equilibrium. In practice very few markets operate in this manner.[28]</p><p>Edgeworth introduced mathematical elements to Economics explicitly in Mathematical Psychics: An Essay on the Application of Mathematics to the Moral Sciences, published in 1881.[29] He adopted Jeremy Bentham's felicific calculus to economic behavior, allowing the outcome of each decision to be converted into a change in utility.[30] Using this assumption, Edgeworth built a model of exchange on three assumptions: individuals are self-interested, individuals act to maximize utility, and individuals are free to recontract with another independently of...any third party.[31]</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/en/thumb/b/b9/Contract-curve-on-edgeworth-box.svg/350px-Contract-curve-on-edgeworth-box.svg.png" width="350" height="263"><p>


An Edgeworth box displaying the contract curve on an economy with two participants. Referred to as the "core" of the economy in modern parlance, there are infinitely many solutions along the curve for economies with two participants[32]


</p><p>
	Given two individuals, the set of solutions where the both individuals can maximize utility is described by the contract curve on what is now known as an Edgeworth Box. Technically, the construction of the two-person solution to Edgeworth's problem was not developed graphically until 1924 by Arthur Lyon Bowley.[33] The contract curve of the Edgeworth box (or more generally on any set of solutions to Edgeworth's problem for more actors) is referred to as the core of an economy.[34]</p><p>Edgeworth devoted considerable effort to insisting that mathematical proofs were appropriate for all schools of thought in economics. While at the helm of The Economic Journal, he published several articles criticizing the mathematical rigor of rival researchers, including Edwin Robert Anderson Seligman, a noted skeptic of mathematical economics.[35] The articles focused on a back and forth over tax incidence and responses by producers. Edgeworth noticed that a monopoly producing a good that had jointness of supply but not jointness of demand (such as first class and economy on an airplane, if the plane flies, both sets of seats fly with it) might actually lower the price seen by the consumer for one of the two commodities if a tax were applied. Common sense and more traditional, numerical analysis seemed to indicate that this was preposterous. Seligman insisted that the results Edgeworth achieved were a quirk of his mathematical formulation. He suggested that the assumption of a continuous demand function and an infinitesimal change in the tax resulted in the paradoxical predictions. Harold Hotelling later showed that Edgeworth was correct and that the same result (a diminution of price as a result of the tax) could occur with a discontinuous demand function and large changes in the tax rate.[36]</p><div class='pageBreak' ></div><h2>Modern mathematical economics</h2><p>From the later-1930s, an array of new mathematical tools from the differential calculus and differential equations, convex sets, and graph theory were deployed to advance economic theory in a way similar to new mathematical methods earlier applied to physics.[8][37] The process was later described as moving from mechanics to axiomatics.[38]</p><h3>Differential calculus</h3><p> Main articles: Foundations of Economic Analysis and Differential calculus</p><p>Vilfredo Pareto analyzed microeconomics by treating decisions by economic actors as attempts to change a given allotment of goods to another, more preferred allotment. Sets of allocations could then be treated as Pareto efficient (Pareto optimal is an equivalent term) when no exchanges could occur between actors that could make at least one individual better off without making any other individual worse off.[39] Pareto's proof is commonly conflated with Walrassian equilibrium or informally ascribed to Adam Smith's Invisible hand hypothesis.[40] Rather, Pareto's statement was the first formal assertion of what would be known as the first fundamental theorem of welfare economics.[41] These models lacked the inequalities of the next generation of mathematical economics.</p><p>In the landmark treatise Foundations of Economic Analysis (1947), Paul Samuelson identified a common paradigm and mathematical structure across multiple fields in the subject, building on previous work by Alfred Marshall. Foundations took mathematical concepts from physics and applied them to economic problems. This broad view (for example, comparing Le Chatelier's principle to tâtonnement) drives the fundamental premise of mathematical economics: systems of economic actors may be modeled and their behavior described much like any other system. This extension followed on the work of the marginalists in the previous century and extended it significantly. Samuelson approached the problems of applying individual utility maximization over aggregate groups with comparative statics, which compares two different equilibrium states after an exogenous change in a variable. This and other methods in the book provided the foundation for mathematical economics in the 20th century.[7][42]</p><h3>Linear models</h3><p>Restricted models of general equilibrium were formulated by John von Neumann in 1937.[43] Unlike earlier versions, the models of von Neumann had inequality constraints. For his model of an expanding economy, von Neumann proved the existence and uniqueness of an equilibrium using his generalization of Brouwer's fixed point theorem. Von Neumann's model of an expanding economy considered the matrix pencil&nbsp; A - ? B with nonnegative matrices&nbsp;A and B; von Neumann sought probability vectors&nbsp;p and&nbsp;q and a positive number&nbsp;? that would solve the complementarity equation</p><p>along with two inequality systems expressing economic efficiency. In this model, the (transposed) probability vector p represents the prices of the goods while the probability vector q represents the intensity at which the production process would run. The unique solution ? represents the rate of growth of the economy, which equals the interest rate. Proving the existence of a positive growth rate and proving that the growth rate equals the interest rate were remarkable achievements, even for von Neumann.[44][45][46] Von Neumann's results have been viewed as a special case of linear programming, where von Neumann's model uses only nonnegative matrices.[47] The study of von Neumann's model of an expanding economy continues to interest mathematical economists with interests in computational economics.[48][49][50]</p><p> Main article: Input-output model</p><p>In 1936, the Russian–born economist Wassily Leontief built his model of input-output analysis from the 'material balance' tables constructed by Soviet economists, which themselves followed earlier work by the physiocrats. With his model, which described a system of production and demand processes, Leontief described how changes in demand in one economic sector would influence production in another.[51] In practice, Leontief estimated the coefficients of his simple models, to address economically interesting questions. In production economics, Leontief technologies produce outputs using constant proportions of inputs, regardless of the price of inputs, reducing the value of Leontief models for understanding economies but allowing their parameters to be estimated relatively easily. In contrast, the von Neumann model of an expanding economy allows for choice of techniques, but the coefficients must be estimated for each technology.[52][53]</p><h3>Mathematical optimization</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/6/62/MaximumParaboloid.png/220px-MaximumParaboloid.png" width="220" height="165"><p>


Red dot in z direction as maximum for paraboloid function of (x, y) inputs



</p><p>
	 Main articles: Mathematical optimization and Dual problem</p><p>In mathematics, mathematical optimization (or optimization or mathematical programming) refers to the selection of a best element from some set of available alternatives.[54] In the simplest case, an optimization problem involves maximizing or minimizing a real function by selecting input values of the function and computing the corresponding values of the function. The solution process includes satisfying general necessary and sufficient conditions for optimality. For optimization problems, specialized notation may be used as to the function and its input(s). More generally, optimization includes finding the best available element of some function given a defined domain and may use a variety of different computational optimization techniques.[55]</p><p>Economics is closely enough linked to optimization by agents in an economy that an influential definition relatedly describes economics qua science as the study of human behavior as a relationship between ends and scarce means with alternative uses.[56] Optimization problems run through modern economics, many with explicit economic or technical constraints. In microeconomics, the utility maximization problem and its dual problem, the expenditure minimization problem for a given level of utility, are economic optimization problems.[57] Theory posits that consumers maximize their utility, subject to their budget constraints and that firms maximize their profits, subject to their production functions, input costs, and market demand.[58]</p><p>Economic equilibrium is studied in optimization theory as a key ingredient of economic theorems that in principle could be tested against empirical data.[7][59] Newer developments have occurred in dynamic programming and modeling optimization with risk and uncertainty, including applications to portfolio theory, the economics of information, and search theory.[58]</p><div class='pageBreak' ></div><p>Optimality properties for an entire market system may be stated in mathematical terms, as in formulation of the two fundamental theorems of welfare economics[60] and in the Arrow–Debreu model of general equilibrium (also discussed below).[61] More concretely, many problems are amenable to analytical (formulaic) solution. Many others may be sufficiently complex to require numerical methods of solution, aided by software.[55] Still others are complex but tractable enough to allow computable methods of solution, in particular computable general equilibrium models for the entire economy.[62]</p><p>Linear and nonlinear programming have profoundly affected microeconomics, which had earlier considered only equality constraints.[63] Many of the mathematical economists who received Nobel Prizes in Economics had conducted notable research using linear programming: Leonid Kantorovich, Leonid Hurwicz, Tjalling Koopmans, Kenneth J. Arrow, and Robert Dorfman, Paul Samuelson, and Robert Solow.[64] Both Kantorovich and Koopmans acknowledged that George B. Dantzig deserved to share their Nobel Prize for linear programming. Economists who conducted research in nonlinear programming also have won the Nobel prize, notably Ragnar Frisch in addition to Kantorovich, Hurwicz, Koopmans, Arrow, and Samuelson.</p><p> Main articles: Linear programming and Simplex algorithm</p><p>Linear programming was developed to aid the allocation of resources in firms and in industries during the 1930s in Russia and during the 1940s in the United States. During the Berlin airlift (1948), linear programming was used to plan the shipment of supplies to prevent Berlin from starving after the Soviet blockade.[65][66]</p><p>Extensions to nonlinear optimization with inequality constraints were achieved in 1951 by Albert W. Tucker and Harold Kuhn, who considered the nonlinear optimization problem:</p><br><img src="http:https://wikimedia.org/api/rest_v1/media/math/render/svg/132e57acb643253e7810ee9702d9581f159a1c61" aria-hidden="true" style="vertical-align: -0.671ex; width:1.289ex; height:2.509ex;" alt="f"><br><img src="http:https://wikimedia.org/api/rest_v1/media/math/render/svg/87f9e315fd7e2ba406057a97300593c4802b53e4" aria-hidden="true" style="vertical-align: -0.338ex; width:1.34ex; height:1.676ex;" alt="x"><br><img src="http:https://wikimedia.org/api/rest_v1/media/math/render/svg/d3556280e66fe2c0d0140df20935a6f057381d77" aria-hidden="true" style="vertical-align: -0.671ex; width:1.126ex; height:2.009ex;" alt="g"><br><img src="http:https://wikimedia.org/api/rest_v1/media/math/render/svg/87f9e315fd7e2ba406057a97300593c4802b53e4" aria-hidden="true" style="vertical-align: -0.338ex; width:1.34ex; height:1.676ex;" alt="x"><br><img src="http:https://wikimedia.org/api/rest_v1/media/math/render/svg/b26be3e694314bc90c3215047e4a2010c6ee184a" aria-hidden="true" style="vertical-align: -0.338ex; width:1.349ex; height:2.176ex;" alt="h"><br><img src="http:https://wikimedia.org/api/rest_v1/media/math/render/svg/87f9e315fd7e2ba406057a97300593c4802b53e4" aria-hidden="true" style="vertical-align: -0.338ex; width:1.34ex; height:1.676ex;" alt="x"><br><img src="http:https://wikimedia.org/api/rest_v1/media/math/render/svg/132e57acb643253e7810ee9702d9581f159a1c61" aria-hidden="true" style="vertical-align: -0.671ex; width:1.289ex; height:2.509ex;" alt="f"><br><img src="http:https://wikimedia.org/api/rest_v1/media/math/render/svg/d3556280e66fe2c0d0140df20935a6f057381d77" aria-hidden="true" style="vertical-align: -0.671ex; width:1.126ex; height:2.009ex;" alt="g"><br><img src="http:https://wikimedia.org/api/rest_v1/media/math/render/svg/2f461e54f5c093e92a55547b9764291390f0b5d0" aria-hidden="true" style="vertical-align: -0.671ex; margin-left: -0.016ex; width:0.985ex; height:2.509ex;" alt="j"><br><img src="http:https://wikimedia.org/api/rest_v1/media/math/render/svg/0a07d98bb302f3856cbabc47b2b9016692e3f7bc" aria-hidden="true" style="vertical-align: -0.338ex; width:2.051ex; height:1.676ex;" alt="m"><br><img src="http:https://wikimedia.org/api/rest_v1/media/math/render/svg/0a07d98bb302f3856cbabc47b2b9016692e3f7bc" aria-hidden="true" style="vertical-align: -0.338ex; width:2.051ex; height:1.676ex;" alt="m"><br><img src="http:https://wikimedia.org/api/rest_v1/media/math/render/svg/b26be3e694314bc90c3215047e4a2010c6ee184a" aria-hidden="true" style="vertical-align: -0.338ex; width:1.349ex; height:2.176ex;" alt="h"><br><img src="http:https://wikimedia.org/api/rest_v1/media/math/render/svg/2f461e54f5c093e92a55547b9764291390f0b5d0" aria-hidden="true" style="vertical-align: -0.671ex; margin-left: -0.016ex; width:0.985ex; height:2.509ex;" alt="j"><br><img src="http:https://wikimedia.org/api/rest_v1/media/math/render/svg/829091f745070b9eb97a80244129025440a1cfac" aria-hidden="true" style="vertical-align: -0.338ex; width:0.704ex; height:2.176ex;" alt="l"><br><img src="http:https://wikimedia.org/api/rest_v1/media/math/render/svg/829091f745070b9eb97a80244129025440a1cfac" aria-hidden="true" style="vertical-align: -0.338ex; width:0.704ex; height:2.176ex;" alt="l"><p>In allowing inequality constraints, the Kuhn–Tucker approach generalized the classic method of Lagrange multipliers, which (until then) had allowed only equality constraints.[67] The Kuhn–Tucker approach inspired further research on Lagrangian duality, including the treatment of inequality constraints.[68][69] The duality theory of nonlinear programming is particularly satisfactory when applied to convex minimization problems, which enjoy the convex-analytic duality theory of Fenchel and Rockafellar; this convex duality is particularly strong for polyhedral convex functions, such as those arising in linear programming. Lagrangian duality and convex analysis are used daily in operations research, in the scheduling of power plants, the planning of production schedules for factories, and the routing of airlines (routes, flights, planes, crews).[69]</p><p>Economic dynamics allows for changes in economic variables over time, including in dynamic systems. The problem of finding optimal functions for such changes is studied in variational calculus and in optimal control theory. Before the Second World War, Frank Ramsey and Harold Hotelling used the calculus of variations to that end.</p><p>Following Richard Bellman's work on dynamic programming and the 1962 English translation of L. Pontryagin et al.'s earlier work,[70] optimal control theory was used more extensively in economics in addressing dynamic problems, especially as to economic growth equilibrium and stability of economic systems,[71] of which a textbook example is optimal consumption and saving.[72] A crucial distinction is between deterministic and stochastic control models.[73] Other applications of optimal control theory include those in finance, inventories, and production for example.[74]</p><p>It was in the course of proving of the existence of an optimal equilibrium in his 1937 model of economic growth that John von Neumann introduced functional analytic methods to include topology in economic theory, in particular, fixed-point theory through his generalization of Brouwer's fixed-point theorem.[8][43][75] Following von Neumann's program, Kenneth Arrow and Gérard Debreu formulated abstract models of economic equilibria using convex sets and fixed–point theory. In introducing the Arrow–Debreu model in 1954, they proved the existence (but not the uniqueness) of an equilibrium and also proved that every Walras equilibrium is Pareto efficient; in general, equilibria need not be unique.[76] In their models, the (primal) vector space represented quantitites while the dual vector space represented prices.[77]</p><div class='pageBreak' ></div><p>In Russia, the mathematician Leonid Kantorovich developed economic models in partially ordered vector spaces, that emphasized the duality between quantities and prices.[78] Kantorovich renamed prices as objectively determined valuations which were abbreviated in Russian as o.&nbsp;o.&nbsp;o., alluding to the difficulty of discussing prices in the Soviet Union.[77][79][80]</p><p>Even in finite dimensions, the concepts of functional analysis have illuminated economic theory, particularly in clarifying the role of prices as normal vectors to a hyperplane supporting a convex set, representing production or consumption possibilities. However, problems of describing optimization over time or under uncertainty require the use of infinite–dimensional function spaces, because agents are choosing among functions or stochastic processes.[77][81][82][83]</p><h3>Differential decline and rise</h3><p>John von Neumann's work on functional analysis and topology in broke new ground in mathematics and economic theory.[43][84] It also left advanced mathematical economics with fewer applications of differential calculus. In particular, general equilibrium theorists used general topology, convex geometry, and optimization theory more than differential calculus, because the approach of differential calculus had failed to establish the existence of an equilibrium.</p><p>However, the decline of differential calculus should not be exaggerated, because differential calculus has always been used in graduate training and in applications. Moreover, differential calculus has returned to the highest levels of mathematical economics, general equilibrium theory (GET), as practiced by the GET-set (the humorous designation due to Jacques H. Drèze). In the 1960s and 1970s, however, Gérard Debreu and Stephen Smale led a revival of the use of differential calculus in mathematical economics. In particular, they were able to prove the existence of a general equilibrium, where earlier writers had failed, because of their novel mathematics: Baire category from general topology and Sard's lemma from differential topology. Other economists associated with the use of differential analysis include Egbert Dierker, Andreu Mas-Colell, and Yves Balasko.[85][86] These advances have changed the traditional narrative of the history of mathematical economics, following von Neumann, which celebrated the abandonment of differential calculus.</p><h3>Game theory</h3><p> Main article: Game Theory</p><p>John von Neumann, working with Oskar Morgenstern on the theory of games, broke new mathematical ground in 1944 by extending functional analytic methods related to convex sets and topological fixed-point theory to economic analysis.[8][84] Their work thereby avoided the traditional differential calculus, for which the maximum–operator did not apply to non-differentiable functions. Continuing von Neumann's work in cooperative game theory, game theorists Lloyd S. Shapley, Martin Shubik, Hervé Moulin, Nimrod Megiddo, Bezalel Peleg influenced economic research in politics and economics. For example, research on the fair prices in cooperative games and fair values for voting games led to changed rules for voting in legislatures and for accounting for the costs in public–works projects. For example, cooperative game theory was used in designing the water distribution system of Southern Sweden and for setting rates for dedicated telephone lines in the USA.</p><p>Earlier neoclassical theory had bounded only the range of bargaining outcomes and in special cases, for example bilateral monopoly or along the contract curve of the Edgeworth box.[87] Von Neumann and Morgenstern's results were similarly weak. Following von Neumann's program, however, John Nash used fixed–point theory to prove conditions under which the bargaining problem and noncooperative games can generate a unique equilibrium solution.[88] Noncooperative game theory has been adopted as a fundamental aspect of experimental economics,[89] behavioral economics,[90] information economics,[91] industrial organization,[92] and political economy.[93] It has also given rise to the subject of mechanism design (sometimes called reverse game theory), which has private and public-policy applications as to ways of improving economic efficiency through incentives for information sharing.[94]</p><p>In 1994, Nash, John Harsanyi, and Reinhard Selten received the Nobel Memorial Prize in Economic Sciences their work on non–cooperative games. Harsanyi and Selten were awarded for their work on repeated games. Later work extended their results to computational methods of modeling.[95]</p><h3>Agent-based computational economics</h3><p> Main article: Agent-based computational economics</p><p>Agent-based computational economics (ACE) as a named field is relatively recent, dating from about the 1990s as to published work. It studies economic processes, including whole economies, as dynamic systems of interacting agents over time. As such, it falls in the paradigm of complex adaptive systems.[96] In corresponding agent-based models, agents are not real people but computational objects modeled as interacting according to rules ... whose micro-level interactions create emergent patterns in space and time.[97] The rules are formulated to predict behavior and social interactions based on incentives and information. The theoretical assumption of mathematical optimization by agents markets is replaced by the less restrictive postulate of agents with bounded rationality adapting to market forces.[98]</p><p>ACE models apply numerical methods of analysis to computer-based simulations of complex dynamic problems for which more conventional methods, such as theorem formulation, may not find ready use.[99] Starting from specified initial conditions, the computational economic system is modeled as evolving over time as its constituent agents repeatedly interact with each other. In these respects, ACE has been characterized as a bottom-up culture-dish approach to the study of the economy.[100] In contrast to other standard modeling methods, ACE events are driven solely by initial conditions, whether or not equilibria exist or are computationally tractable. ACE modeling, however, includes agent adaptation, autonomy, and learning.[101] It has a similarity to, and overlap with, game theory as an agent-based method for modeling social interactions.[95] Other dimensions of the approach include such standard economic subjects as competition and collaboration,[102] market structure and industrial organization,[103] transaction costs,[104] welfare economics[105] and mechanism design,[94] information and uncertainty,[106] and macroeconomics.[107][108]</p><p>The method is said to benefit from continuing improvements in modeling techniques of computer science and increased computer capabilities. Issues include those common to experimental economics in general[109] and by comparison[110] and to development of a common framework for empirical validation and resolving open questions in agent-based modeling.[111] The ultimate scientific objective of the method has been described as test[ing] theoretical findings against real-world data in ways that permit empirically supported theories to cumulate over time, with each researcher's work building appropriately on the work that has gone before.[112]</p><h2>Mathematicization of economics</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/b/b1/Ivsrf.gif/275px-Ivsrf.gif" width="275" height="251"><div class='pageBreak' ></div><p>


The surface of the Volatility smile is a 3-D surface whereby the current market implied volatility (Z-axis) for all options on the underlier is plotted against strike price and time to maturity (X &amp; Y-axes).[113]


</p><p>
	Over the course of the 20th century, articles in core journals[114] in economics have been almost exclusively written by economists in academia. As a result, much of the material transmitted in those journals relates to economic theory, and economic theory itself has been continuously more abstract and mathematical.[115] A subjective assessment of mathematical techniques[116] employed in these core journals showed a decrease in articles that use neither geometric representations nor mathematical notation from 95% in 1892 to 5.3% in 1990.[117] A 2007 survey of ten of the top economic journals finds that only&nbsp;5.8% of the articles published in 2003 and 2004 both lacked statistical analysis of data and lacked displayed mathematical expressions that were indexed with numbers at the margin of the page.[118]</p><h2>Econometrics</h2><p> Main article: Econometrics</p><p>Between the world wars, advances in mathematical statistics and a cadre of mathematically trained economists led to econometrics, which was the name proposed for the discipline of advancing economics by using mathematics and statistics. Within economics, econometrics has often been used for statistical methods in economics, rather than mathematical economics. Statistical econometrics features the application of linear regression and time series analysis to economic data.</p><p>Ragnar Frisch coined the word econometrics and helped to found both the Econometric Society in 1930 and the journal Econometrica in 1933.[119][120] A student of Frisch's, Trygve Haavelmo published The Probability Approach in Econometrics in 1944, where he asserted that precise statistical analysis could be used as a tool to validate mathematical theories about economic actors with data from complex sources.[121] This linking of statistical analysis of systems to economic theory was also promulgated by the Cowles Commission (now the Cowles Foundation) throughout the 1930s and 1940s.[122]</p><p>The roots of modern econometrics can be traced to the American economist Henry L. Moore. Moore studied agricultural productivity and attempted to fit changing values of productivity for plots of corn and other crops to a curve using different values of elasticity. Moore made several errors in his work, some from his choice of models and some from limitations in his use of mathematics. The accuracy of Moore's models also was limited by the poor data for national accounts in the United States at the time. While his first models of production were static, in 1925 he published a dynamic moving equilibrium model designed to explain business cycles—this periodic variation from overcorrection in supply and demand curves is now known as the cobweb model. A more formal derivation of this model was made later by Nicholas Kaldor, who is largely credited for its exposition.[123]</p><h2>Application</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/b/b9/Islm.svg/300px-Islm.svg.png" width="300" height="300"><p>


The IS/LM model is a Keynesian macroeconomic model designed to make predictions about the intersection of "real" economic activity (e.g. spending, income, savings rates) and decisions made in the financial markets (Money supply and Liquidity preference). The model is no longer widely taught at the graduate level but is common in undergraduate macroeconomics courses.[124]


</p><p>
	Much of classical economics can be presented in simple geometric terms or elementary mathematical notation. Mathematical economics, however, conventionally makes use of calculus and matrix algebra in economic analysis in order to make powerful claims that would be more difficult without such mathematical tools. These tools are prerequisites for formal study, not only in mathematical economics but in contemporary economic theory in general. Economic problems often involve so many variables that mathematics is the only practical way of attacking and solving them. Alfred Marshall argued that every economic problem which can be quantified, analytically expressed and solved, should be treated by means of mathematical work.[125]</p><p>Economics has become increasingly dependent upon mathematical methods and the mathematical tools it employs have become more sophisticated. As a result, mathematics has become considerably more important to professionals in economics and finance. Graduate programs in both economics and finance require strong undergraduate preparation in mathematics for admission and, for this reason, attract an increasingly high number of mathematicians. Applied mathematicians apply mathematical principles to practical problems, such as economic analysis and other economics-related issues, and many economic problems are often defined as integrated into the scope of applied mathematics.[17]</p><p>This integration results from the formulation of economic problems as stylized models with clear assumptions and falsifiable predictions. This modeling may be informal or prosaic, as it was in Adam Smith's The Wealth of Nations, or it may be formal, rigorous and mathematical.</p><p>Broadly speaking, formal economic models may be classified as stochastic or deterministic and as discrete or continuous. At a practical level, quantitative modeling is applied to many areas of economics and several methodologies have evolved more or less independently of each other.[126]</p><h2>Classification</h2><p>According to the Mathematics Subject Classification (MSC), mathematical economics falls into the Applied mathematics/other classification of category 91:</p><p>with MSC2010 classifications for 'Game theory' at codes 91Axx and for 'Mathematical economics' at codes 91Bxx.</p><p>The Handbook of Mathematical Economics series (Elsevier), currently 4 volumes, distinguishes between mathematical methods in economics, v. 1, Part I, and areas of economics in other volumes where mathematics is employed.[127]</p><p>Another source with a similar distinction is The New Palgrave: A Dictionary of Economics (1987, 4 vols., 1,300 subject entries). In it, a Subject Index includes mathematical entries under 2 headings (vol. IV, pp.&nbsp;982–3):</p><p>A widely used system in economics that includes mathematical methods on the subject is the JEL classification codes. It originated in the Journal of Economic Literature for classifying new books and articles. The relevant categories are listed below (simplified below to omit Miscellaneous and Other JEL codes), as reproduced from JEL classification codes#Mathematical and quantitative methods JEL: C Subcategories. The New Palgrave Dictionary of Economics (2008, 2nd ed.) also uses the JEL codes to classify its entries. The corresponding footnotes below have links to abstracts of The New Palgrave Online for each JEL category (10 or fewer per page, similar to Google searches).</p><div class='pageBreak' ></div><h2>Criticisms and defences</h2><h3>Adequacy of mathematics for qualitative and complicated economics</h3><p>Friedrich Hayek contended that the use of formal techniques projects a scientific exactness that does not appropriately account for informational limitations faced by real economic agents. [139]</p><p>In an interview, the economic historian Robert Heilbroner stated:[140]</p><p>I guess the scientific approach began to penetrate and soon dominate the profession in the past twenty to thirty years. This came about in part because of the invention of mathematical analysis of various kinds and, indeed, considerable improvements in it. This is the age in which we have not only more data but more sophisticated use of data. So there is a strong feeling that this is a data-laden science and a data-laden undertaking, which, by virtue of the sheer numerics, the sheer equations, and the sheer look of a journal page, bears a certain resemblance to science . . . That one central activity looks scientific. I understand that. I think that is genuine. It approaches being a universal law. But resembling a science is different from being a science.</p><p>Heilbroner stated that some/much of economics is not naturally quantitative and therefore does not lend itself to mathematical exposition.[141]</p><h3>Testing predictions of mathematical economics</h3><p>Philosopher Karl Popper discussed the scientific standing of economics in the 1940s and 1950s. He argued that mathematical economics suffered from being tautological. In other words, insofar that economics became a mathematical theory, mathematical economics ceased to rely on empirical refutation but rather relied on mathematical proofs and disproof.[142] According to Popper, falsifiable assumptions can be tested by experiment and observation while unfalsifiable assumptions can be explored mathematically for their consequences and for their consistency with other assumptions.[143]</p><p>Sharing Popper's concerns about assumptions in economics generally, and not just mathematical economics, Milton Friedman declared that all assumptions are unrealistic. Friedman proposed judging economic models by their predictive performance rather than by the match between their assumptions and reality.[144]</p><h3>Mathematical economics as a form of pure mathematics</h3><p>Considering mathematical economics, J.M. Keynes wrote in The General Theory:[145]</p><p>It is a great fault of symbolic pseudo-mathematical methods of formalising a system of economic analysis ... that they expressly assume strict independence between the factors involved and lose their cogency and authority if this hypothesis is disallowed; whereas, in ordinary discourse, where we are not blindly manipulating and know all the time what we are doing and what the words mean, we can keep ‘at the back of our heads’ the necessary reserves and qualifications and the adjustments which we shall have to make later on, in a way in which we cannot keep complicated partial differentials ‘at the back’ of several pages of algebra which assume they all vanish. Too large a proportion of recent ‘mathematical’ economics are merely concoctions, as imprecise as the initial assumptions they rest on, which allow the author to lose sight of the complexities and interdependencies of the real world in a maze of pretentious and unhelpful symbols.</p><h3>Defense of mathematical economics</h3><p>In response to these criticisms, Paul Samuelson argued that mathematics is a language, repeating a thesis of Josiah Willard Gibbs. In economics, the language of mathematics is sometimes necessary for representing substantive problems. Moreover, mathematical economics has led to conceptual advances in economics.[146] In particular, Samuelson gave the example of microeconomics, writing that few people are ingenious enough to grasp [its] more complex parts... without resorting to the language of mathematics, while most ordinary individuals can do so fairly easily with the aid of mathematics.[147]</p><p>Some economists state that mathematical economics deserves support just like other forms of mathematics, particularly its neighbors in mathematical optimization and mathematical statistics and increasingly in theoretical computer science. Mathematical economics and other mathematical sciences have a history in which theoretical advances have regularly contributed to the reform of the more applied branches of economics. In particular, following the program of John von Neumann, game theory now provides the foundations for describing much of applied economics, from statistical decision theory (as games against nature) and econometrics to general equilibrium theory and industrial organization. In the last decade, with the rise of the internet, mathematical economicists and optimization experts and computer scientists have worked on problems of pricing for on-line services --- their contributions using mathematics from cooperative game theory, nondifferentiable optimization, and combinatorial games.</p><p>Robert M. Solow concluded that mathematical economics was the core infrastructure of contemporary economics:</p><p>Economics is no longer a fit conversation piece for ladies and gentlemen. It has become a technical subject. Like any technical subject it attracts some people who are more interested in the technique than the subject. That is too bad, but it may be inevitable. In any case, do not kid yourself: the technical core of economics is indispensable infrastructure for the political economy. That is why, if you consult [a reference in contemporary economics] looking for enlightenment about the world today, you will be led to technical economics, or history, or nothing at all.[148]</p><h2>Mathematical economists</h2><p>Prominent mathematical economists include, but are not limited to, the following (by century of birth).</p><h3>19th century</h3><h3>20th century</h3><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Mathematical_economics&amp;oldid=783711517"					
				Categories:  Hidden categories:</p><br><div class='pageBreak' ></div><h1 lang="en">History of economic thought</h1><p> From Wikipedia, the free encyclopedia</p><p>The history of economic thought deals with different thinkers and theories in the subject that became political economy and economics, from the ancient world to the present day. It encompasses many disparate schools of economic thought. Ancient Greek writers such as the philosopher Aristotle examined ideas about the art of wealth acquisition, and questioned whether property is best left in private or public hands. In the Middle Ages, scholasticists such as Thomas Aquinas argued that it was a moral obligation of businesses to sell goods at a just price.</p><p>In the Western world, economics was not a separate discipline, but part of philosophy until the 18th–19th century Industrial Revolution and the 19th century Great Divergence, which accelerated economic growth.[1] Long before that, from the Renaissance at least, economics as an intellectual discipline or science was dominated by Western thinkers and their academic institutions, schooling economists from outside the West, although there are isolated instances in other societies.</p><h2>Contents</h2><h2>Ancient economic thought (before 500 AD)</h2><p> Main articles: Ancient economic thought, Arthashastra, Republic (dialogue), Credit theory of money, Politics (Aristotle), Nicomachean Ethics, Metallism, and Oeconomicus</p><h3>China</h3><p>Fan Li (also known as Tao Zhu Gong) (born 517 BC),[2] an adviser to King Goujian of Yue, wrote on economic issues and developed a set of golden business rules.[3]</p><h3>India</h3><p>Chanakya (born 350 BC) wrote the Arthashastra, a treatise on statecraft, economic policy and military strategy.[citation needed]</p><h3>Greco-Roman World</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/9/98/Sanzio_01_Plato_Aristotle.jpg/100px-Sanzio_01_Plato_Aristotle.jpg" width="100" height="131"><p>


Plato and his pupil Aristotle had an enduring effect on Western philosophy.


</p><p>
	Ancient Athens, a slave-based society, developed an embryonic model of democracy.[4]</p><p>Xenophon's (c. 430–354 BC) Oeconomicus (c. 360 BC) is a dialogue principally about household management and agriculture.</p><p>Plato's dialogue The Republic (c. 380–360 BC) describing an ideal city-state run by philosopher-kings contained references to specialization of labor and to production. Plato was the first to advocate the credit theory of money, that is, money as a unit of account for debt.[citation needed]</p><p>Aristotle's Politics (c. 350 BC) analyzed different forms of the state (monarchy, aristocracy, constitutional government, tyranny, oligarchy, and democracy) as a critique of Plato's model of a philosopher-kings. Of particular interest for economists, Plato provided a blueprint of a society based on common ownership of resources. Aristotle viewed this model as an oligarchical anathema. Though Aristotle did certainly advocate holding many things in common, he argued that not everything could be, simply because of the wickedness of human nature.[5]</p><p>It is clearly better that property should be private, wrote Aristotle, but the use of it common; and the special business of the legislator is to create in men this benevolent disposition. In Politics Book I, Aristotle discusses the general nature of households and market exchanges. For him there is a certain art of acquisition or wealth-getting, but because it[clarification needed] is the same many people are obsessed with its accumulation, and wealth-getting for one's household is necessary and honorable, while exchange on the retail trade for simple accumulation is justly censured, for it is dishonorable.[6] Writing of the people, Aristotle stated that they as a whole thought acquisition of wealth (chrematistike) as being either the same as, or a principle of oikonomia (household management – oikonomos),[7][8] with oikos meaning house and with nomos meaning custom or as law.[9] Aristotle himself highly disapproved of usury and cast scorn on making money through a monopoly.[10]</p><p>Aristotle discarded Plato's credit theory of money for metallism, the theory that money derives its value from the purchasing power of the commodity upon which it is based, and is only an instrument, its sole purpose being a medium of exchange, which means on its own it is worthless... not useful as a means to any of the necessities of life.[11]</p><h2>Economic thought in the Middle Ages (500–1500 AD)</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/c/cd/Gentile_da_Fabriano_052.jpg/100px-Gentile_da_Fabriano_052.jpg" width="100" height="137"><p>


Thomas Aquinas (1225–1274) taught that high prices in response to high demand is theft.



</p><p>
	 Main articles: Thomas Aquinas, Scholasticism, Duns Scotus, Ibn Khaldun, Muqaddimah, and Islamic economic jurisprudence</p><h3>Thomas Aquinas</h3><p>Thomas Aquinas (1225–1274) was an Italian theologian and economic writer. He taught in both Cologne and Paris, and was part of a group of Catholic scholars known as the Schoolmen, who moved their enquiries beyond theology to philosophical and scientific debates. In the treatise Summa Theologica Aquinas dealt with the concept of a just price, which he considered necessary for the reproduction of the social order. Similar in many ways to the modern concept of long run equilibrium, a just price was just sufficient to cover the costs of production, including the maintenance of a worker and his family. Aquinas argued it was immoral for sellers to raise their prices simply because buyers had a pressing need for a product.</p><p>Aquinas discusses a number of topics in the format of questions and replies, substantial tracts dealing with Aristotle's theory. Questions 77 and 78 concern economic issues, primarily what a just price might be, and the fairness of a seller dispensing faulty goods. Aquinas argued against any form of cheating and recommended always paying compensation in lieu of good service[clarification needed]. Whilst human laws might not impose sanctions for unfair dealing, divine law did, in his opinion.</p><div class='pageBreak' ></div><h3>Duns Scotus</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/7/73/John_Duns_Scotus_-_geograph.org.uk_-_1178460.jpg/100px-John_Duns_Scotus_-_geograph.org.uk_-_1178460.jpg" width="100" height="133"><p>


Duns Scotus (1265–1308)


</p><p>
	One of Aquinas' main critics[12] was Duns Scotus (1265–1308), originally from Duns Scotland, who taught in Oxford, Cologne, and Paris. In his work Sententiae (1295), he thought it possible to be more precise than Aquinas in calculating a just price, emphasizing the costs of labor and expenses, although he recognized that the latter might be inflated by exaggeration because buyer and seller usually have different ideas of a just price. If people did not benefit from a transaction, in Scotus' view, they would not trade. Scotus said merchants perform a necessary and useful social role by transporting goods and making them available to the public.[12]</p><h3>Jean Buridan</h3><p>Jean Buridan (French:&nbsp;[by?id?~]; Latin Johannes Buridanus; c. 1300 – after 1358) was a French priest. Buridanus looked at money from two angles: its metal value and its purchasing power, which he acknowledged can vary. He argued that aggregated, not individual, demand and supply determine market prices. Hence, for him a just price was what the society collectively and not just one individual is willing to pay.</p><h3>Ibn Khaldun</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/b/b2/Ibn_Khaldoun-Kassus.jpg/100px-Ibn_Khaldoun-Kassus.jpg" width="100" height="164"><p>


Ibn Khaldun (1332–1406)


 
</p><p>
	Until Joseph J. Spengler's 1964 work Economic Thought of Islam: Ibn Khaldun,[14] Adam Smith (1723–1790) was considered the Father of Economics. Now there is a second candidate, Arab Muslim scholar Ibn Khaldun (1332–1406) of Tunisia, although what influence Khaldun had in the West is unclear. Arnold Toynbee called Ibn Khaldun a genius who appears to have been inspired by no predecessors and to have found no kindred souls among his contemporaries...and yet, in the Prolegomena (Muqaddimat) to his Universal History he has conceived and formulated a philosophy of history which is undoubtedly the greatest work of its kind that has ever yet been created by any mind in any time or place.[15] Ibn Khaldoun expressed a theory of the lifecycle of civilizations, the specialization of labor, and the value of money as a means of exchange rather than as a store of inherent value. His ideas on taxes bore a striking resemblance to supply-side economics' Laffer curve, which posits that beyond a certain point higher taxes discourage production and actually cause revenues to fall.[16]</p><h3>Nicole Oresme</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/3/35/Oresme.jpg/100px-Oresme.jpg" width="100" height="97"><p>


Nicolas d'Oresme (1320–82)


</p><p>
	French philosopher and priest Nicolas d'Oresme (1320–1382) wrote De origine, natura, jure et mutationibus monetarum, about the origin, nature, law, and alterations of money. It is one of the earliest manuscripts on the concept of money.</p><h3>Antonin of Florence</h3><p>Saint Antoninus of Florence (1389–1459), O.P., was an Italian Dominican friar, who became Archbishop of Florence. Antoninus' writings address social and economic development, and argued that the state has a duty to intervene in mercantile affairs for the common good, and an obligation to help the poor and needy. In his primary work, summa theologica he was mainly concerned about price, justice and capital theory. Like Duns Scotus, he distinguishes between the natural value of a good and its practical value. The latter is determined by its suitability to satisfy needs (virtuositas), its rarity (raritas) and its subjective value (complacibilitas). Due to this subjective component there can not only be one just price, but a bandwidth of more or less just prices.</p><h2>Mercantilism and international trade (16th to 18th century)</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/8/81/Mirabeau_p%C3%A8re.jpg/100px-Mirabeau_p%C3%A8re.jpg" width="100" height="128"><p>


Marquis de Mirabeau (1715–1789)



</p><p>
	 Main article: Mercantilism</p><p>Mercantilism dominated Europe from the 16th to the 18th century.[17] Despite the localism of the Middle Ages, the waning of feudalism saw new national economic frameworks begin to strengthen. After the 15th century voyages of Christopher Columbus and other explorers opened up new opportunities for trade with the New World and Asia, newly-powerful monarchies wanted a more powerful military state to boost their status. Mercantilism was a political movement and an economic theory that advocated the use of the state's military power to ensure that local markets and supply sources were protected, spawning protectionism.</p><div class='pageBreak' ></div><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/2/29/Lorrain.seaport.jpg/200px-Lorrain.seaport.jpg" width="200" height="150"><p>


French seaport during the heyday of mercantilism


</p><p>
	Mercantile theorists held that international trade could not benefit all countries at the same time. Money and precious metals were the only source of riches in their view, and limited resources must be allocated between countries, therefore tariffs should be used to encourage exports, which bring money into the country, and discourage imports which send it abroad. In other words, a positive balance of trade ought to be maintained through a surplus of exports, often backed by military might. Despite the prevalence of the model, the term mercantilism was not coined until 1763, by Victor de Riqueti, marquis de Mirabeau (1715–1789), and popularized by Adam Smith in 1776, who vigorously opposed it.</p><h3>School of Salamanca</h3><p> Main article: School of Salamanca</p><p>In the 16th century the Jesuit School of Salamanca in Spain developed economic theory to a high level, only to have their contributions[clarification needed] forgotten until the 20th century.</p><h3>Sir Thomas More</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/d/d2/Hans_Holbein%2C_the_Younger_-_Sir_Thomas_More_-_Google_Art_Project.jpg/100px-Hans_Holbein%2C_the_Younger_-_Sir_Thomas_More_-_Google_Art_Project.jpg" width="100" height="124"><p>


Sir Thomas More (1478–1535)



</p><p>
	 Main article: Sir Thomas More</p><p>In 1516 English humanist Sir Thomas More (1478–1535) published Utopia, which describes an ideal society where land is owned in common and there is universal education and religious tolerance, inspiring the English Poor Laws (1587) and the communism-socialism movement[citation needed].</p><h3>Nicolaus Copernicus</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/7/77/Nicolaus_Copernicus.jpg/100px-Nicolaus_Copernicus.jpg" width="100" height="131"><p>


Nicolaus Copernicus (1473–1543)



</p><p>
	 Main articles: Nicolaus Copernicus and Quantity theory of money</p><p>In 1517 Polish astronomer Nicolaus Copernicus (1473–1543) published the first known argument for the quantity theory of money. In 1519 he also published the first known form of Gresham's Law: Bad money drives out good.</p><h3>Jean Bodin</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/e/e5/Jean_Bodin.jpg/100px-Jean_Bodin.jpg" width="100" height="126"><p>


Jean Bodin (1530–1596)



</p><p>
	 Main article: Jean Bodin</p><p>In 1568 Jean Bodin (1530–1596) of France published Reply to Malestroit, containing the first known analysis of inflation, which he claimed was caused by importation of gold and silver from South America, backing the quantity theory of money.</p><h3>Barthélemy de Laffemas</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/c/ca/Barth%C3%A9lemy_de_Laffemas.jpg/100px-Barth%C3%A9lemy_de_Laffemas.jpg" width="100" height="114"><p>


Barthélemy de Laffemas (1545–1612)


</p><p>
	In 1598 French mercantilist economist Barthélemy de Laffemas (1545–1612) published Les Trésors et richesses pour mettre l'Estat en splendeur, which blasted those who frowned on French silks because the industry created employment for the poor, the first known mention of underconsumption theory, which was later refined by John Maynard Keynes.</p><h3>Leonardus Lessius</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/1/1b/Leonardus_Lessius_%281554-1623%29.jpg/100px-Leonardus_Lessius_%281554-1623%29.jpg" width="100" height="156">

