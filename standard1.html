<html>
<head>
<script src="scripts/jquery-3.2.1.js"></script>
<link rel="stylesheet" type="text/css" href="styles/style.css">
<script src="scripts/script2.js"></script>
<script src="scripts/sweetalert.min.js"></script>

</head>
<body>
	<div id="logContainer" >
	
	</div>
 	<div id="modal">
		<center>
			</br/>
			<p id="modal-msg" > This is the message </p> 
			<button id="modal-btn" > OK </button>
			<input type="hidden" id="modal-type" />
		</center>
	</div>
	<div id="modal">
		<b>Select Icon</b>
		<b id="timer" ></b>
		<hr/>
		<img class="icon" id="icon1" src="icons/1.png" />
		<img class="icon" id="icon2" src="icons/2.png" />
		<img class="icon" id="icon3" src="icons/3.png" />
		<img class="icon" id="icon4" src="icons/4.png" />
		<img class="icon" id="icon5" src="icons/5.png" />
		<img class="icon" id="icon6" src="icons/6.png" />
		<img class="icon" id="icon7" src="icons/7.png" />
		<img class="icon" id="icon8" src="icons/8.png" />
		<img class="icon" id="icon9" src="icons/9.png" />
		<img class="icon" id="icon10" src="icons/10.png" />
		<img class="icon" id="icon11" src="icons/11.png" />
		<img class="icon" id="icon12" src="icons/12.png" />
		<img class="icon" id="icon13" src="icons/13.png" />
		<img class="icon" id="icon14" src="icons/14.png" />
		<img class="icon" id="icon15" src="icons/15.png" />
		<img class="icon" id="icon16" src="icons/16.png" />
		<img class="icon" id="icon17" src="icons/17.png" />
		<img class="icon" id="icon18" src="icons/18.png" />
		<img class="icon" id="icon19" src="icons/19.png" />
		<img class="icon" id="icon20" src="icons/20.png" />
		<img class="icon" id="icon21" src="icons/21.png" />
		<img class="icon" id="icon22" src="icons/22.png" />
		<img class="icon" id="icon23" src="icons/23.png" />
		<img class="icon" id="icon24" src="icons/24.png" />
		<img class="icon" id="icon25" src="icons/25.png" />
		<img class="icon" id="icon26" src="icons/26.png" />
		<img class="icon" id="icon27" src="icons/27.png" />
		<img class="icon" id="icon28" src="icons/28.png" />
		<img class="icon" id="icon29" src="icons/29.png" />
		<img class="icon" id="icon30" src="icons/30.png" />
		<img class="icon" id="icon31" src="icons/31.png" />
		<img class="icon" id="icon32" src="icons/32.png" />
	</div>
	<div id="hiddenVals" >
		<input type="hidden" id="logId" value="0" />
		<input type="hidden" id="subjectNumber" value="1111" />
		<input type="hidden" id="interfaceNumber" value="2222" />
		<input type="hidden" id="documentNumber" value="3333" />
		<input type="hidden" id="target" value="4444" />
		<input type="hidden" id="visitNumber" value="5555" />
		<input type="hidden" id="trail" value="6666" />
		<input type="hidden" id="block" value="7777" />
		<input type="hidden" id="finishedByUser" value="8888" />
	</div>
	<div class="main" >
	
				<div class="content">
				<p>


				Leonardus Lessius (1554–1623)



				</p><p>
					 Main article: Leonardus Lessius</p><p>In 1605 Flemish Jesuit theologian Leonardus Lessius (1554–1623) published On Justice and Law, the deepest moral-theological study of economics since Aquinas, whose just price approach he claimed was no longer workable. After comparing money's growth via avarice to the propagation of hares, he made the first statement of the price of insurance as being based on risk.</p><h3>Edward Misselden and Gerard Malynes</h3><p> Main articles: Edward Misselden and Gerard Malynes</p><p>In 1622 English merchants Edward Misselden and Gerard Malynes began a dispute over free trade and the desirability of government regulation of companies, with Malynes arguing against foreign exchange as under the control of bankers[clarification needed], and Misselden arguing that international money exchange and fluctuations in the exchange rate depend upon international trade and not bankers, and that the state should regulate trade to insure export surpluses.</p><h3>Thomas Mun</h3><p> Main article: Thomas Mun</p><p>English economist Thomas Mun (1571–1641) describes early mercantilist policy in his book England's Treasure by Foreign Trade, which was not published until 1664, although it was widely circulated in manuscript form during his lifetime. A member of the East India Company, he wrote about his experiences in A Discourse of Trade from England unto the East Indies (1621).</p><h3>Sir William Petty</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/8/84/Sir_William_Petty.jpg/100px-Sir_William_Petty.jpg" width="100" height="135"><p>


				Sir William Petty (1623–1687)



				</p><p>
					 Main article: William Petty</p><p>In 1662 English economist Sir William Petty (1623–1687) began publishing short works applying the rational scientific tradition of Francis Bacon to economics, requiring that it only use measurable phenomena and seek quantitative precision, coining the term political arithmetic, introducing statistical mathematics, and becoming the first scientific economist.</p><h3>Philipp von Hörnigk</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/5/50/%C3%96sterreich_uber_alles_wann_es_nur_will.jpg/100px-%C3%96sterreich_uber_alles_wann_es_nur_will.jpg" width="100" height="170"><p>


				The title page to Philipp von Hörnigk's statement of mercantilist philosophy.



				</p><p>
					 Main article: Philipp von Hörnigk</p><p>Philipp von Hörnigk (1640–1712, sometimes spelt Hornick or Horneck) was born in Frankfurt and became an Austrian civil servant writing in a time when his country was constantly threatened by Ottoman invasion. In Österreich Über Alles, Wann es Nur Will (1684, Austria Over All, If She Only Will) he laid out one of the clearest statements of mercantile policy, listing nine principal rules of national economy:</p><p>To inspect the country's soil with the greatest care, and not to leave the agricultural possibilities of a single corner or clod of earth unconsidered... All commodities found in a country, which cannot be used in their natural state, should be worked up within the country... Attention should be given to the population, that it may be as large as the country can support... gold and silver once in the country are under no circumstances to be taken out for any purpose... The inhabitants should make every effort to get along with their domestic products... [Foreign commodities] should be obtained not for gold or silver, but in exchange for other domestic wares... and should be imported in unfinished form, and worked up within the country... Opportunities should be sought night and day for selling the country's superfluous goods to these foreigners in manufactured form... No importation should be allowed under any circumstances of which there is a sufficient supply of suitable quality at home.</p><p>Nationalism, self-sufficiency and national power were the basic policies proposed.[18]</p><h3>Jean-Baptiste Colbert and Pierre Le Pesant, Sieur de Boisguilbert</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/4/49/Colbert_mg_8447_cropped.jpg/100px-Colbert_mg_8447_cropped.jpg" width="100" height="118"><p>


				Jean-Baptiste Colbert (1619–1683)



				</p><p>
					 Main articles: Jean-Baptiste Colbert and Pierre Le Pesant, sieur de Boisguilbert</p><p>In 1665–1683 Jean-Baptiste Colbert (1619–1683) was minister of finance under King Louis XIV of France, and set up national guilds to regulate major industries. Silk, linen, tapestry, furniture manufacture and wine were examples of the crafts in which France specialized, all of which came to require membership in a guild to operate in until the French Revolution. According to Colbert, It is simply and solely the abundance of money within a state [which] makes the difference in its grandeur and power.[citation needed]</p><div class="gradientback"></div></div>
					 
					 <div class="content"><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/d/da/Boisguilbert.gif/100px-Boisguilbert.gif" width="100" height="143"><p>


				Pierre Le Pesant, sieur de Boisguilbert (1646–1714)


				</p><p>
					In 1695 French economist Pierre Le Pesant, sieur de Boisguilbert (1646–1714) wrote a plea to Louis XIV to end Colbert's mercantilist program, containing the first notion of an economical market, becoming the first economist to question mercantile economic policy and value the wealth of a country by its production and exchange of goods instead its assets.</p><h3>Charles Davenant</h3><p> Main article: Charles Davenant</p><p>In 1696 British mercantilist Tory Member of parliament Charles Davenant (1656–1714) published Essay on the East India Trade, displaying the first understanding of consumer demand and perfect competition.</p><h3>Sir James Steuart</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/0/07/Sir_James_Denham_Steuart._1713-1780.gif/100px-Sir_James_Denham_Steuart._1713-1780.gif" width="100" height="135"><p>


				Sir James Steuart (1713–1780)



				</p><p>
					 Main article: Sir James Steuart</p><p>In 1767 Scottish mercantilist economist Sir James Steuart (1713–1780) published An Inquiry into the Principles of Political Economy, the first book in English with the term political economy in the title, and the first complete economics treatise.</p><h2>Pre-Classical (17th and 18th century)</h2><h3>The British Enlightenment</h3><p>In the 17th century Britain went through troubling times, enduring not only political and religious division in the English Civil War, King Charles I's execution, and the Cromwellian dictatorship, but also the Great Plague of London and Great Fire of London. The restoration of the monarchy under Charles II, who had Roman Catholic sympathies, led to turmoil and strife, and his Catholic-leaning successor King James II was swiftly ousted. Invited in his place were Protestant William of Orange and Mary, who assented to the Bill of Rights 1689, ensuring that the Parliament was dominant in what became known as the Glorious Revolution.</p><p>The upheaval was accompanied by a number of major scientific advances, including Robert Boyle's discovery of the gas pressure constant (1660) and Sir Isaac Newton's publication of Philosophiae Naturalis Principia Mathematica (1687), which described Newton's laws of motion and his universal law of gravitation.</p><p>All these factors spurred the advancement of economic thought. For instance, Richard Cantillon (1680–1734) consciously imitated Newton's forces of inertia and gravity in the natural world with human reason and market competition in the economic world.[19] In his Essay on the Nature of Commerce in General, he argued rational self-interest in a system of freely-adjusting markets would lead to order and mutually-compatible prices. Unlike the mercantilist thinkers however, wealth was found not in trade but in human labor. The first person to tie these ideas into a political framework was John Locke.</p><p> Main article: John Locke</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/d/d1/JohnLocke.png/100px-JohnLocke.png" width="100" height="129"><p>


				John Locke (1632–1704) combined philosophy, politics and economics into one coherent framework.


				</p><p>
					John Locke (1632–1704) was born near Bristol, and educated in London and Oxford. He is considered one of the most significant philosophers of his era mainly for his critique of Thomas Hobbes' defense of absolutism in Leviathan (1651) and of his social contract theory. Locke believed that people contracted into society, which was bound to protect their property rights.[20] He defined property broadly to include people's lives and liberties, as well as their wealth. When people combined their labor with their surroundings, that created property rights. In his words from his Second Treatise on Civil Government (1689):</p><p>God hath given the world to men in common... Yet every man has a property in his own person. The labour of his body and the work of his hands we may say are properly his. Whatsoever, then, he removes out of the state that nature hath provided and left it in, he hath mixed his labour with, and joined to it something that is his own, and thereby makes it his property.[21]</p><p>Locke argued that not only should the government cease interference with people's property (or their lives, liberties and estates), but also that it should positively work to ensure their protection. His views on price and money were laid out in a letter to a Member of Parliament in 1691 entitled Some Considerations on the Consequences of the Lowering of Interest and the Raising of the Value of Money (1691), arguing that the price of any commodity rises or falls, by the proportion of the number of buyers and sellers, a rule which holds universally in all things that are to be bought and sold.[22]</p><p> Main article: Dudley North (economist)</p><br><div class="gradientback"></div></div><div class="content"><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/1/13/Dudley_North.jpg/100px-Dudley_North.jpg" width="100" height="117"><p>


				Dudley North (1641–1691) argued that the results of mercantile policy are undesirable.


				</p><p>
					Dudley North (1641–1691) was a wealthy merchant and landowner who worked for Her Majesty's Treasury and opposed most mercantile policy. His Discourses upon trade (1691), published anonymously, argued against assuming a need for a favorable balance of trade. Trade, he argued, benefits both sides, promotes specialization, division of labor and wealth for everyone. Regulation of trade interferes with these benefits, he said.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/2/21/David_Hume.jpg/100px-David_Hume.jpg" width="100" height="121"><p>


				David Hume (1711–76)



				</p><p>
					 Main article: David Hume</p><p>David Hume (1711–1776) agreed with North's philosophy and denounced mercantilist assumptions. His contributions were set down in Political Discourses (1752), and later consolidated in his Essays, Moral, Political, Literary (1777). Adding to the argument that it was undesirable to strive for a favourable balance of trade, Hume argued that it is, in any case, impossible.</p><p>Hume held that any surplus of exports would be paid for by imports of gold and silver. This would increase the money supply, causing prices to rise. That in turn would cause a decline in exports until the balance with imports is restored.</p><p> Main article: Bernard Mandeville</p><p>Bernard Mandeville, (15 November 1670 – 21 January 1733), was an Anglo-Dutch philosopher, political economist and satirist. His main thesis is that the actions of men cannot be divided into lower and higher. The higher life of man is a mere fiction introduced by philosophers and rulers to simplify government and the relations of society. In fact, virtue (which he defined as every performance by which man, contrary to the impulse of nature, should endeavour the benefit of others, or the conquest of his own passions, out of a rational ambition of being good) is actually detrimental to the state in its commercial and intellectual progress. This is because it is the vices (i.e., the self-regarding actions of men) which alone, by means of inventions and the circulation of capital (economics) in connection with luxurious living, stimulate society into action and progress.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/1/16/Francis_Hutcheson_b1694.jpg/100px-Francis_Hutcheson_b1694.jpg" width="100" height="132"><p>


				Francis Hutcheson (1694–1746)



				</p><p>
					 Main article: Francis Hutcheson (philosopher)</p><p>Francis Hutcheson (1694–1746), the teacher of Adam Smith from 1737 to 1740[23] is considered the end of a long tradition of thought on economics as household or family (?????) management,[24] [25] [26] stemming from Xenophon's work Oeconomicus.[27] [28]</p><h3>The Physiocrats and the circular flow</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/5/59/Pierre_Samuel_du_Pont_de_Nemours.jpg/100px-Pierre_Samuel_du_Pont_de_Nemours.jpg" width="100" height="155"><p>


				Pierre Samuel du Pont de Nemours, a prominent Physiocrat, emigrated to the United States, and his son founded DuPont, the world's second biggest chemicals company.



				<br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/6/60/Fran%C3%A7ois_Quesnay.jpg/100px-Fran%C3%A7ois_Quesnay.jpg" width="100" height="127"><br>


				Francois Quesnay (1694–1774)



				</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/6/60/Fran%C3%A7ois_Quesnay.jpg/100px-Fran%C3%A7ois_Quesnay.jpg" width="100" height="127"><br><p>
					 Main article: Physiocracy</p><p>Similarly disenchanted with regulation on trade inspired by mercantilism, a Frenchman named Vincent de Gournay (1712–1759) is reputed to have asked why it was so hard to laissez faire (let it be), laissez passer (let it pass), advocating free enterprise and free trade. He was one of the early Physiocrats, a Greek word meaning Government of nature, who held that agriculture was the source of wealth. As historian David B. Danbom wrote, the Physiocrats damned cities for their artificiality and praised more natural styles of living. They celebrated farmers.[29] Over the end of the seventeenth and beginning of the eighteenth century big advances in natural science and anatomy included discovery of blood circulation through the human body. This concept was mirrored in the physiocrats' economic theory, with the notion of a circular flow of income throughout the economy.</p><p>François Quesnay (1694–1774) was the court physician to King Louis XV of France. He believed that trade and industry were not sources of wealth, and instead in his book Tableau économique (1758, Economic Table) argued that agricultural surpluses, by flowing through the economy in the form of rent, wages, and purchases were the real economic movers. Firstly, said Quesnay, regulation impedes the flow of income throughout all social classes and therefore economic development. Secondly, taxes on the productive classes, such as farmers, should be reduced in favour of rises for unproductive classes, such as landowners, since their luxurious way of life distorts the income flow. David Ricardo later showed that taxes on land are non-transferable to tenants in his Law of Rent.</p><div class="gradientback"></div></div><div class="content"><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/c/c8/Anne_Robert_Jacques_Turgot.jpg/100px-Anne_Robert_Jacques_Turgot.jpg" width="100" height="117"><p>


				Anne Robert Jacques Turgot (1727–1781)


				</p><p>
					Jacques Turgot (1727–1781) was born in Paris to an old Norman family. His best known work, Réflexions sur la formation et la distribution des richesses (Reflections on the Formation and Distribution of Wealth) (1766) developed Quesnay's theory that land is the only source of wealth. Turgot viewed society in terms of three classes: the productive agricultural class, the salaried artisan class (classe stipendice) and the landowning class (classe disponible). He argued that only the net product of land should be taxed and advocated the complete freedom of commerce and industry.</p><p>In August 1774 Turgot was appointed to be minister of finance, and in the space of two years he introduced many anti-mercantile and anti-feudal measures supported by the king. A statement of his guiding principles, given to the king were no bankruptcy, no tax increases, no borrowing. Turgot's ultimate wish was to have a single tax on land and abolish all other indirect taxes, but measures he introduced before that were met with overwhelming opposition from landed interests. Two edicts in particular, one suppressing corvées (charges from farmers to aristocrats) and another renouncing privileges given to guilds, inflamed influential opinion. He was forced from office in 1776.</p><h2>Classical (18th and 19th century)</h2><h3>Ferdinando Galiani and On Money</h3><p>In 1751, Neapolitan philosopher Ferdinando Galiani published a nearly exhaustive treatise on money called Della Moneta, 25 years before Adam Smith's The Wealth of Nations, and therefore is seen as possibly the first truly modern economic analysis. In its five sections, Della Moneta covered all modern aspects of monetary theory, including the value and origin of money, its regulation, and inflation. This text remained cited by various economists for centuries, as wide-ranging a list as Karl Marx and Austrian economist Joseph Schumpeter.</p><h3>Adam Smith and The Wealth of Nations</h3><p> Main articles: The Wealth of Nations, Adam Smith, Pitt the Younger, and Edmund Burke</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/7/7d/Adamsmithout.jpg/100px-Adamsmithout.jpg" width="100" height="117"><p>


				Adam Smith (1723–1790), father of modern political economy.


				</p><p>
					Adam Smith (1723–1790) is popularly seen as the father of modern political economy. His 1776 publication An Inquiry Into the Nature and Causes of the Wealth of Nations happened to coincide not only with the American Revolution, shortly before the Europe-wide upheavals of the French Revolution, but also the dawn of a new industrial revolution that allowed more wealth to be created on a larger scale than ever before.</p><p>Smith was a Scottish moral philosopher, whose first book was The Theory of Moral Sentiments (1759). He argued in it that people's ethical systems develop through personal relations with other individuals, that right and wrong are sensed through others' reactions to one's behaviour. This gained Smith more popularity than his next work, The Wealth of Nations, which the general public initially ignored.[30] Yet Smith's political economic magnum opus was successful in circles that mattered.</p><h3>Adam Smith's Invisible Hand</h3><p> Main article: Invisible hand</p><p>Smith argued for a system of natural liberty[32] where individual effort was the producer of social good. Smith believed even the selfish within society were kept under restraint and worked for the good of all when acting in a competitive market. Prices are often unrepresentative of the true value of goods and services. Following John Locke, Smith thought true value of things derived from the amount of labour invested in them.</p><p>Every man is rich or poor according to the degree in which he can afford to enjoy the necessaries, conveniencies, and amusements of human life. But after the division of labour has once thoroughly taken place, it is but a very small part of these with which a man's own labour can supply him. The far greater part of them he must derive from the labour of other people, and he must be rich or poor according to the quantity of that labour which he can command, or which he can afford to purchase. The value of any commodity, therefore, to the person who possesses it, and who means not to use or consume it himself, but to exchange it for other commodities, is equal to the quantity of labour which it enables him to purchase or command. Labour, therefore, is the real measure of the exchangeable value of all commodities. The real price of every thing, what every thing really costs to the man who wants to acquire it, is the toil and trouble of acquiring it.</p><p>When the butchers, the brewers and the bakers acted under the restraint of an open market economy, their pursuit of self-interest, thought Smith, paradoxically drives the process to correct real life prices to their just values. His classic statement on competition goes as follows.</p><p>When the quantity of any commodity which is brought to market falls short of the effectual demand, all those who are willing to pay... cannot be supplied with the quantity which they want... Some of them will be willing to give more. A competition will begin among them, and the market price will rise... When the quantity brought to market exceeds the effectual demand, it cannot be all sold to those who are willing to pay the whole value of the rent, wages and profit, which must be paid to bring it thither... The market price will sink...[34]</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/d/de/Wealth_of_Nations_title.jpg/100px-Wealth_of_Nations_title.jpg" width="100" height="143"><p>


				Adam Smith's title page of The Wealth of Nations.


				</p><div class="gradientback"></div></div><div class="content"><p>
					Smith's vision of a free market economy, based on secure property, capital accumulation, widening markets and a division of labour contrasted with the mercantilist tendency to attempt to regulate all evil human actions.[32] Smith believed there were precisely three legitimate functions of government. The third function was...</p><p>...erecting and maintaining certain public works and certain public institutions, which it can never be for the interest of any individual or small number of individuals, to erect and maintain... Every system which endeavours... to draw towards a particular species of industry a greater share of the capital of the society than what would naturally go to it... retards, instead of accelerating, the progress of the society toward real wealth and greatness.</p><p>In addition to the necessity of public leadership in certain sectors Smith argued, secondly, that cartels were undesirable because of their potential to limit production and quality of goods and services.[35] Thirdly, Smith criticised government support of any kind of monopoly which always charges the highest price which can be squeezed out of the buyers.[36] The existence of monopoly and the potential for cartels, which would later form the core of competition law policy, could distort the benefits of free markets to the advantage of businesses at the expense of consumer sovereignty.</p><h3>William Pitt the Younger</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/e/e8/OlderPittThe_Younger.jpg/100px-OlderPittThe_Younger.jpg" width="100" height="128"><p>


				William Pitt the Younger (1759–1806)


				</p><p>
					William Pitt the Younger (1759–1806), Tory Prime Minister in 1783–1801 based his tax proposals on Smith's ideas, and advocated free trade as a devout disciple of The Wealth of Nations.[37] Smith was appointed a commissioner of customs and within twenty years Smith had a following of new generation writers who were intent on building the science of political economy.[30]</p><h3>Edmund Burke</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/1/14/Edmund_Burke2_c.jpg/100px-Edmund_Burke2_c.jpg" width="100" height="129"><p>


				Edmund Burke (1729–1797)


				</p><p>
					Adam Smith expressed an affinity to the opinions of Irish MP Edmund Burke (1729–1797), known widely as a political philosopher:</p><p>Burke is the only man I ever knew who thinks on economic subjects exactly as I do without any previous communication having passed between us.[38]</p><p>Burke was an established political economist himself, known for his book Thoughts and Details on Scarcity. He was widely critical of liberal politics, and condemned the French Revolution which began in 1789. In Reflections on the Revolution in France (1790) he wrote that the age of chivalry is dead, that of sophisters, economists and calculators has succeeded, and the glory of Europe is extinguished forever. Smith's contemporary influences included François Quesnay and Jacques Turgot whom he met on a visit to Paris, and David Hume, his Scottish compatriot. The times produced a common need among thinkers to explain social upheavals of the Industrial revolution taking place, and in the seeming chaos without the feudal and monarchical structures of Europe, show there was order still.</p><h3>Jeremy Bentham</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/c/c8/Jeremy_Bentham_by_Henry_William_Pickersgill_detail.jpg/100px-Jeremy_Bentham_by_Henry_William_Pickersgill_detail.jpg" width="100" height="136"><p>


				Jeremy Bentham (1748–1832) believed in "the greatest good for the greatest number".



				</p><p>
					 Main article: Jeremy Bentham</p><p>Jeremy Bentham (1748–1832) was perhaps the most radical thinker of his time, and developed the concept of utilitarianism. Bentham was an atheist, a prison reformer, animal rights activist, believer in universal suffrage, freedom of speech, free trade and health insurance at a time when few dared to argue for any of these ideas. He was schooled rigorously from an early age, finishing university and being called to the bar at 18. His first book, A Fragment on Government (1776), published anonymously, was a trenchant critique of William Blackstone's Commentaries on the Laws of England. This gained wide success until it was found that the young Bentham, and not a revered Professor had penned it. In An Introduction to the Principles of Morals and Legislation (1789) Bentham set out his theory of utility.[39][40]</p><h3>Jean-Baptiste Say</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/1/1f/Jean-Baptiste_Say.gif/100px-Jean-Baptiste_Say.gif" width="100" height="138"><p>


				Say's Law, by Jean-Baptiste Say (1767–1832), which states that supply always equals demand, was rarely challenged until the 20th century.



				</p><p>
					 Main article: Jean-Baptiste Say</p><p>Jean-Baptiste Say (1767–1832) was a Frenchman born in Lyon who helped popularize Adam Smith's work in France.[41] His book A Treatise on Political Economy (1803) contained a brief passage, which later became orthodoxy in political economics until the Great Depression, now known as Say's Law of markets. Say argued that there could never be a general deficiency of demand or a general glut of commodities in the whole economy. People produce things, to fulfill their own wants rather than those of others, therefore production is not a question of supply but an indication of producers demanding goods.</p><div class="gradientback"></div></div><div class="content"><p>Say agreed that a part of income is saved by households, but in the long term, savings are invested. Investment and consumption are the two elements of demand, so that production is demand, therefore it is impossible for production to outrun demand, or for there to be a general glut of supply. Say also argued that money was neutral, because its sole role is to facilitate exchanges, therefore, people demand money only to buy commodities; money is a veil.[42]</p><h3>David Ricardo</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/d/dc/Portrait_of_David_Ricardo_by_Thomas_Phillips.jpg/100px-Portrait_of_David_Ricardo_by_Thomas_Phillips.jpg" width="100" height="129"><p>


				David Ricardo (1772–1823) is renowned for his law of comparative advantage.



				</p><p>
					 Main article: David Ricardo</p><p>David Ricardo (1772–1823) was born in London. By the age of 26, he had become a wealthy stock market trader, and bought himself a constituency seat in Ireland to gain a platform in the British parliament's House of Commons.[43] Ricardo's best known work is On the Principles of Political Economy and Taxation (1817), which contains his critique of barriers to international trade and a description of the manner in which income is distributed in the population. Ricardo made a distinction between workers, who received a wage fixed to a level at which they could survive, the landowners, who earn a rent, and capitalists, who own capital and receive a profit, a residual part of the income.[44]</p><p>If population grows, it becomes necessary to cultivate additional land, whose fertility is lower than that of already cultivated fields, because of the law of decreasing productivity. Therefore, the cost of the production of the wheat increases, as well as the price of the wheat: The rents increase also, the wages, indexed to inflation (because they must allow workers to survive) as well. Profits decrease, until the capitalists can no longer invest. The economy, Ricardo concluded, is bound to tend towards a steady state.[42]</p><h3>Jean Charles Léonard de Sismondi</h3><p> Main article: Jean_Charles_Léonard_de_Sismondi</p><p>Jean_Charles_Léonard_de_Sismondi(a.k.a. Jean Charles Leonard Simonde de Sismondi) (French: [sism?~di]; May 19, 1773 in Geneva – June 25, 1842 The earliest author of systemic Crisis theory.</p><h3>John Stuart Mill</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/en/thumb/9/9b/John-stuart-mill-sized.jpg/100px-John-stuart-mill-sized.jpg" width="100" height="116"><p>


				John Stuart Mill (1806–1873), weaned on the philosophy of Jeremy Bentham, wrote the most authoritative economics text of his time.



				</p><p>
					 Main articles: Principles of Political Economy and John Stuart Mill</p><p>John Stuart Mill (1806–1873) was the dominant figure of political economic thought of his time, as well as a Member of parliament for the seat of Westminster, and a leading political philosopher. Mill was a child prodigy, reading Ancient Greek from the age of 3, and being vigorously schooled by his father James Mill.[45] Jeremy Bentham was a close mentor and family friend, and Mill was heavily influenced by David Ricardo. Mill's textbook, first published in 1848 and titled Principles of Political Economy was essentially a summary of the economic thought of the mid-nineteenth century.[46]</p><p>Principles of Political Economy (1848) was used as the standard text by most universities well into the beginning of the twentieth century[citation needed]. On the question of economic growth Mill tried to find a middle ground between Adam Smith's view of ever-expanding opportunities for trade and technological innovation and Thomas Malthus' view of the inherent limits of population. In his fourth book Mill set out a number of possible future outcomes, rather than predicting one in particular.[42]</p><h3>Classical political economy</h3><p> Main article: Classical economics</p><p>The classical economists were referred to as a group for the first time by Karl Marx.[47] One unifying part of their theories was the labour theory of value, contrasting to value deriving from a general equilibrium theory of supply and demand. These economists had seen the first economic and social transformation brought by the Industrial Revolution: rural depopulation, precariousness, poverty, apparition of a working class.</p><p>They wondered about population growth, because demographic transition had begun in Great Britain at that time. They also asked many fundamental questions, about the source of value, the causes of economic growth and the role of money in the economy. They supported a free-market economy, arguing it was a natural system based upon freedom and property. However, these economists were divided and did not make up a unified current of thought.</p><p>A notable current within classical economics was underconsumption theory, as advanced by the Birmingham School and Thomas Robert Malthus in the early 19th century. These argued for government action to mitigate unemployment and economic downturns, and were an intellectual predecessor of what later became Keynesian economics in the 1930s. Another notable school was Manchester capitalism, which advocated free trade, against the previous policy of mercantilism.</p><h3>Capitalism, Communism, and Karl Marx</h3><p> Main article: Marxian economics</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/a/a2/Marx_old.jpg/100px-Marx_old.jpg" width="100" height="134"><p>


				Karl Marx (1818–1883) published a fundamental critique of classical economics based on the labor theory of value.



				<br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/7/7b/Engels_1856.jpg/100px-Engels_1856.jpg" width="100" height="123"><br>


				With Marx, Friedrich Engels (1820–1895) co-authored The Communist Manifesto and the second volume of Das Kapital.


				Key people: Karl Marx and Friedrich Engels

				<br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/b/b6/G.W.F._Hegel_%28by_Sichling%2C_after_Sebbers%29.jpg/100px-G.W.F._Hegel_%28by_Sichling%2C_after_Sebbers%29.jpg" width="100" height="115"><br>


				George Wilhelm Friedrich Hegel (1770–1831)


				</p><div class="gradientback"></div></div><div class="content"><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/7/7b/Engels_1856.jpg/100px-Engels_1856.jpg" width="100" height="123"><br><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/b/b6/G.W.F._Hegel_%28by_Sichling%2C_after_Sebbers%29.jpg/100px-G.W.F._Hegel_%28by_Sichling%2C_after_Sebbers%29.jpg" width="100" height="115"><br><p>
					Just as the term mercantilism had been coined and popularized by critics like Adam Smith, so the term capitalism coined by Karl Marx (1818–1883) was used by its critics. Socialism emerged in response to the miserable living and working conditions of the working class in the new industrial era, and the classical economics from which it sprang. The economic and political theory published in The Communist Manifesto (1848) and Das Kapital (1867) combined with the dialectic theory of history inspired by Friedrich Hegel (1770–1831) to provide a revolutionary critique of nineteenth-century capitalism.[citation needed]</p><p>In 1845 German radical Friedrich Engels (1820–1895) published The Condition of the Working Class in England in 1844,[48] describing workers in Manchester as the most unconcealed pinnacle of social misery in our day. After Marx died, Engels completed the second volume of Das Kapital from his notes.</p><p> Main articles: Das Kapital; Capital, Volume I; and Karl Marx</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/8/8d/Zentralbibliothek_Z%C3%BCrich_Das_Kapital_Marx_1867.jpg/120px-Zentralbibliothek_Z%C3%BCrich_Das_Kapital_Marx_1867.jpg" width="120" height="202"><p>


				The title page of the first edition of Das Kapital (1867) in German.


				</p><p>
					Marx wrote his magnum opus Das Kapital (1867) at the British Museum's library in London. Karl Marx begins with the concept of commodities. Before capitalism, says Marx, production was based on slavery—in ancient Rome for example—then serfdom in the feudal societies of medieval Europe. The current mode of labor exchange[clarification needed] has produced an erratic and unstable situation allowing the conditions for revolution. People buy and sell their labor as people buy and sell goods and services. People themselves have become disposable commodities. As Marx wrote in The Communist Manifesto,</p><p>The history of all hitherto existing society is the history of class struggles. Freeman and slave, patrician and plebeian, lord and serf, guildmaster and journeyman, in a word, oppressor and oppressed, stood in constant opposition to one another... The modern bourgeois society that has sprouted from the ruins of feudal society has not done away with class antagonisms. It has but established new classes, new conditions of oppression, new forms of struggle in place of the old ones.</p><p>From the first page of Das Kapital:</p><p>The wealth of those societies in which the capitalist mode of production prevails, presents itself as an immense accumulation of commodities, its unit being a single commodity. Our investigation must therefore begin with the analysis of a commodity.[49]</p><p>Marx uses the word commodity in an extensive metaphysical discussion of the nature of material wealth, how the objects of wealth are perceived and how they can be used. A commodity contrasts to objects of the natural world. When people mix their labor with an object it becomes a commodity. In the natural world there are trees, diamonds, iron ore and people. In the economic world they become chairs, rings, factories and workers. However, says Marx, commodities have a dual nature, a dual value. He distinguishes the use value of a thing from its exchange value, which can be entirely different.[50] The use value of a commodity exists only as that commodity is used or consumed. If commodities are considered absolutely isolated from their useful qualities the common property is human labor in the abstract. In this sense, value is human labor and is the most abstract and common property embodied in commodities. This follows the classical economists in the labor theory of value. He believed value can derive too from natural goods and refined his definition of value to socially necessary labor time, by which he meant the time people need to produce things when they are not lazy or inefficient.[51] Furthermore, people subjectively inflate the value of things, for instance because there's a commodity fetish for glimmering diamonds,[52] and oppressive power relations involved in commodity production. These two factors mean exchange values differ greatly. An oppressive power relation, says Marx applying the use/exchange distinction to labor itself, in work-wage bargains derives from the fact that employers pay their workers less in exchange value than the workers produce in use value. The difference makes up the capitalist's profit, or in Marx's terminology, surplus value.[53] Therefore, says Marx, capitalism is a system of exploitation.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/e/e8/Panic_of_1873_bank_run.jpg/100px-Panic_of_1873_bank_run.jpg" width="100" height="130"><p>


				Marx explained the booms and busts, like the Panic of 1873, as part of an inherent instability in capitalist economies.


				</p><p>
					Marx's work turned the labor theory of value, as the classicists called it, on its head. His dark irony goes deeper by asking what is the socially necessary labor time for the production of labor (i.e. working people) itself. Marx answers that this is the bare minimum for people to subsist and to reproduce with skills necessary in the economy.[54]</p><p>People are therefore alienated from both the fruits of production and the means to realize their potential, psychologically, by their oppressed position in the labor market. But the tale told alongside exploitation and alienation is one of capital accumulation and economic growth. Employers are constantly under pressure from <br>
							

											 
										

							</p><br><h1 lang="en">Industrial organization</h1><p> From Wikipedia, the free encyclopedia</p><div class="gradientback"></div></div><div class="content"><p> This article is about the field of economics. For the field of psychology, see Industrial and organizational psychology.</p><p>In economics, industrial organization or Industrial economy is a field that builds on the theory of the firm by examining the structure of (and, therefore, the boundaries between) firms and markets. Industrial organization adds real-world complications to the perfectly competitive model, complications such as transaction costs,[1] limited information, and barriers to entry of new firms that may be associated with imperfect competition. It analyzes determinants of firm and market organization and behavior as between competition[2] and monopoly,[3] including from government actions.</p><p>There are different approaches to the subject. One approach is descriptive in providing an overview of industrial organization, such as measures of competition and the size-concentration of firms in an industry. A second approach uses microeconomic models to explain internal firm organization and market strategy, which includes internal research and development along with issues of internal reorganization and renewal.[4] A third aspect is oriented to public policy as to economic regulation,[5] antitrust law,[6] and, more generally, the economic governance of law in defining property rights, enforcing contracts, and providing organizational infrastructure.[7][8]</p><p>The subject has a theoretical side and a practical side. According to one textbook: On one plane the field is abstract, a set of analytical concepts about competition and monopoly. On a second plane the topic is about real markets, teeming with the excitement and drama of struggles among real firms (Shepherd, W.; 1985; 1).</p><p>The extensive use of game theory in industrial economics has led to the export of this tool to other branches of microeconomics, such as behavioral economics and corporate finance. Industrial organization has also had significant practical impacts on antitrust law and competition policy.[9]</p><p>The development of industrial organization as a separate field owes much to Edward Chamberlin,[10] Edward S. Mason,[11] J. M. Clark,[12] and particularly Joe S. Bain[13] among others.[14][15]</p><p>Assessments of the subject have differed over time. The preface to a related research volume in 1972 remarked on Whither industrial organization?: That all is not well with this in this once flourishing field is readily apparent.[16] A response came 15 years later: [T]oday's verdict is that industrial organization is alive and well and the queen of applied microeconomics.[17]</p><h2>Contents</h2><h2>Subareas</h2><p>The Journal of Economic Literature (JEL) classification codes are one way of representing the range of economics subjects and subareas. There, Industrial Organization, one of 20 primary categories, has 9 secondary categories, each with multiple tertiary categories.[18] The secondary categories are listed below with corresponding available article-preview links of The New Palgrave Dictionary of Economics Online and footnotes to their respective JEL-tertiary categories and associated New-Palgrave links.</p><h2>Market structures</h2><p>The common market structures studied in this field are the following:</p><h2>Areas of study</h2><p>Industrial organization investigates the outcomes of these market structures in environments with</p><h2>History of the field</h2><p>A 2009 book Pioneers of Industrial Organization traces the development of the field from Adam Smith to recent times and includes dozens of short biographies of major figures in Europe and North America who contributed to the growth and development of the discipline.[28]</p><p>Other reviews by publication year and earliest available cited works those in 1970/1937,[14] 1972/1933,[29] 1974,[30] 1987/1937-1956 (3 cites), 1968-9 (7 cites).[31] 2009/c. 1900,[32] and 2010/1951.[33]</p><p> Main article: Outline of industrial organization</p><h2>Notes</h2><h2>Journals</h2><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Industrial_organization&amp;oldid=777775018"					
								Categories:  Hidden categories:</p><br><h1 lang="en">International economics</h1><p> From Wikipedia, the free encyclopedia</p><p>International economics is concerned with the effects upon economic activity from international differences in productive resources and consumer preferences and the international institutions that affect them. It seeks to explain the patterns and consequences of transactions and interactions between the inhabitants of different countries, including trade, investment and migration.</p><h2>Contents</h2><h2>International trade</h2><h3>Scope and methodology</h3><p>The economic theory of international trade differs from the remainder of economic theory mainly because of the comparatively limited international mobility of the capital and labour.[5] In that respect, it would appear to differ in degree rather than in principle from the trade between remote regions in one country. Thus the methodology of international trade economics differs little from that of the remainder of economics. However, the direction of academic research on the subject has been influenced by the fact that governments have often sought to impose restrictions upon international trade, and the motive for the development of trade theory has often been a wish to determine the consequences of such restrictions.</p><p>The branch of trade theory which is conventionally categorized as classical consists mainly of the application of deductive logic, originating with Ricardo’s Theory of Comparative Advantage and developing into a range of theorems that depend for their practical value upon the realism of their postulates. Modern trade analysis, on the other hand, depends mainly upon empirical analysis.</p><h3>Classical theory</h3><p>The theory of comparative advantage provides a logical explanation of international trade as the rational consequence of the comparative advantages that arise from inter-regional differences - regardless of how those differences arise. Since its exposition by David Ricardo[6] the techniques of neo-classical economics have been applied to it to model the patterns of trade that would result from various postulated sources of comparative advantage. However, extremely restrictive (and often unrealistic) assumptions have had to be adopted in order to make the problem amenable to theoretical analysis.</p><div class="gradientback"></div></div><div class="content"><p>The best-known of the resulting models, the Heckscher-Ohlin theorem (H-O)[7] depends upon the assumptions of no international differences of technology, productivity, or consumer preferences; no obstacles to pure competition or free trade and no scale economies. On those assumptions, it derives a model of the trade patterns that would arise solely from international differences in the relative abundance of labour and capital (referred to as factor endowments). The resulting theorem states that, on those assumptions, a country with a relative abundance of capital would export capital-intensive products and import labour-intensive products. The theorem proved to be of very limited predictive value, as was demonstrated by what came to be known as the Leontief Paradox (the discovery that, despite its capital-rich factor endowment, America was exporting labour-intensive products and importing capital-intensive products[8]) Nevertheless, the theoretical techniques (and many of the assumptions) used in deriving the H-O model were subsequently used to derive further theorems.</p><p>The Stolper-Samuelson theorem,[9] which is often described as a corollary of the H-O theorem, was an early example. In its most general form it states that if the price of a good rises (falls) then the price of the factor used intensively in that industry will also rise (fall) while the price of the other factor will fall (rise). In the international trade context for which it was devised it means that trade lowers the real wage of the scarce factor of production, and protection from trade raises it.</p><p>Another corollary of the H-O theorem is Samuelson's factor price equalisation theorem[10] which states that as trade between countries tends to equalise their product prices, it tends also to equalise the prices paid to their factors of production. Those theories have sometimes been taken to mean that trade between an industrialised country and a developing country would lower the wages of the unskilled in the industrialised country. (But, as noted below, that conclusion depends upon the unlikely assumption that productivity is the same in the two countries). Large numbers of learned papers have been produced in attempts to elaborate on the H-O and Stolper-Samuelson theorems, and while many of them are considered to provide valuable insights, they have seldom proved to be directly applicable to the task of explaining trade patterns.</p><p>( the Rybczynski theorem[11][12])</p><h3>Modern analysis</h3><p>Modern trade analysis moves away from the restrictive assumptions of the H-O theorem and explores the effects upon trade of a range of factors, including technology and scale economies. It makes extensive use of econometrics to identify from the available statistics, the contribution of particular factors among the many different factors that affect trade. The contributions of differences of technology have been evaluated in several such studies. The temporary advantage arising from a country’s development of a new technology is seen as contributory factor in one study.[13]</p><p>Other researchers have found research and development expenditure, patents issued, and the availability of skilled labor, to be indicators of the technological leadership that enables some countries to produce a flow of such technological innovations[14] and have found that technology leaders tend to export hi-tech products to others and receive imports of more standard products from them. Another econometric study also established a correlation between country size and the share of exports made up of goods in the production of which there are scale economies.[15] The study further suggested that internationally traded goods fall into three categories, each with a different type of comparative advantage:</p><p>There is a strong presumption that any exchange that is freely undertaken will benefit both parties, but that does not exclude the possibility that it may be harmful to others. However (on assumptions that included constant returns and competitive conditions) Paul Samuelson has proved that it will always be possible for the gainers from international trade to compensate the losers.[16] Moreover, in that proof, Samuelson did not take account of the gains to others resulting from wider consumer choice, from the international specialisation of productive activities - and consequent economies of scale, and from the transmission of the benefits of technological innovation. An OECD study has suggested that there are further dynamic gains resulting from better resource allocation, deepening specialisation, increasing returns to R&amp;D, and technology spillover. The authors found the evidence concerning growth rates to be mixed, but that there is strong evidence that a 1 per cent increase in openness to trade increases the level of GDP per capita by between 0.9 per cent and 2.0 per cent.[17] They suggested that much of the gain arises from the growth of the most productive firms at the expense of the less productive. Those findings and others[18] have contributed to a broad consensus among economists that trade confers very substantial net benefits, and that government restrictions upon trade are generally damaging.</p><p>Nevertheless, there have been widespread misgivings about the effects of international trade upon wage earners in developed countries. Samuelson‘s factor price equalisation theorem indicates that, if productivity were the same in both countries, the effect of trade would be to bring about equality in wage rates. As noted above, that theorem is sometimes taken to mean that trade between an industrialised country and a developing country would lower the wages of the unskilled in the industrialised country. However, it is unreasonable to assume that productivity would be the same in a low-wage developing country as in a high-wage developed country. A 1999 study has found international differences in wage rates to be approximately matched by corresponding differences in productivity.[19] (Such discrepancies that remained were probably the result of over-valuation or under-valuation of exchange rates, or of inflexibilities in labour markets.) It has been argued that, although there may sometimes be short-term pressures on wage rates in the developed countries, competition between employers in developing countries can be expected eventually to bring wages into line with their employees' marginal products. Any remaining international wage differences would then be the result of productivity differences, so that there would be no difference between unit labour costs in developing and developed countries, and no downward pressure on wages in the developed countries.[20]</p><p>There has also been concern that international trade could operate against the interests of developing countries. Influential studies published in 1950 by the Argentine economist Raul Prebisch[21] and the British economist Hans Singer[22] suggested that there is a tendency for the prices of agricultural products to fall relative to the prices of manufactured goods; turning the terms of trade against the developing countries and producing an unintended transfer of wealth from them to the developed countries.</p><p>Their findings have been confirmed by a number of subsequent studies, although it has been suggested[23] that the effect may be due to quality bias in the index numbers used or to the possession of market power by manufacturers. The Prebisch/Singer findings remain controversial, but they were used at the time - and have been used subsequently - to suggest that the developing countries should erect barriers against manufactured imports in order to nurture their own “infant industries” and so reduce their need to export agricultural products. The arguments for and against such a policy are similar to those concerning the protection of infant industries in general.</p><p>The term infant industry is used to denote a new industry which has prospects of gaining comparative advantage in the long-term, but which would be unable to survive in the face of competition from imported goods. This situation can occur when time is needed either to achieve potential economies of scale, or to acquire potential learning curve economies. Successful identification of such a situation, followed by the temporary imposition of a barrier against imports can, in principle, produce substantial benefits to the country that applies it – a policy known as “import substitution industrialization”. Whether such policies succeed depends upon the governments’ skills in picking winners, with reasonably expectations of both successes and failures. It has been claimed that South Korea’s automobile industry owes its existence to initial protection against imports,[24] but a study of infant industry protection in Turkey reveals the absence of any association between productivity gains and degree of protection, such as might be expected of a successful import substitution policy. .[25]</p><p>Another study provides descriptive evidence suggesting that attempts at import substitution industrialisation since the 1970s have usually failed,[26] but the empirical evidence on the question has been contradictory and inconclusive.[27] It has been argued that the case against import substitution industrialisation is not that it is bound to fail, but that subsidies and tax incentives do the job better.[28] It has also been pointed out that, in any case, trade restrictions could not be expected to correct the domestic market imperfections that often hamper the development of infant industries.[29]</p><div class="gradientback"></div></div><div class="content"><h3>Trade policies</h3><p>Economists’ findings about the benefits of trade have often been rejected by government policy-makers, who have frequently sought to protect domestic industries against foreign competition by erecting barriers, such as tariffs and quotas, against imports. Average tariff levels of around 15 per cent in the late 19th century rose to about 30 percent in the 1930s, following the passage in the United States of the Smoot-Hawley Act.[30] Mainly as the result of international agreements under the auspices of the General Agreement on Tariffs and Trade (GATT) and subsequently the World Trade Organisation (WTO), average tariff levels were progressively reduced to about 7 per cent during the second half of the 20th century, and some other trade restrictions were also removed. The restrictions that remain are nevertheless of major economic importance: among other estimates[31] the World Bank estimated in 2004 that the removal of all trade restrictions would yield benefits of over $500 billion a year by 2015.[32]</p><p>The largest of the remaining trade-distorting policies are those concerning agriculture. In the OECD countries government payments account for 30 per cent of farmers’ receipts and tariffs of over 100 per cent are common.[33] OECD economists estimate that cutting all agricultural tariffs and subsidies by 50% would set off a chain reaction in realignments of production and consumption patterns that would add an extra $26 billion to annual world income.[34]</p><p>Quotas prompt foreign suppliers to raise their prices toward the domestic level of the importing country. That relieves some of the competitive pressure on domestic suppliers, and both they and the foreign suppliers gain at the expense of a loss to consumers, and to the domestic economy, in addition to which there is a deadweight loss to the world economy. When quotas were banned under the rules of the General Agreement on Tariffs and Trade (GATT), the United States, Britain and the European Union made use of equivalent arrangements known as voluntary restraint agreements (VRAs) or voluntary export restraints (VERs) which were negotiated with the governments of exporting countries (mainly Japan) - until they too were banned. Tariffs have been considered to be less harmful than quotas, although it can be shown that their welfare effects differ only when there are significant upward or downward trends in imports.[35] Governments also impose a wide range of non-tariff barriers[36] that are similar in effect to quotas, some of which are subject to WTO agreements.[37] A recent example has been the application of the precautionary principle to exclude innovatory products .[38]</p><h2>International finance</h2><h3>Scope and methodology</h3><p>The economics of international finance does not differ in principle from the economics of international trade, but there are significant differences of emphasis. The practice of international finance tends to involve greater uncertainties and risks because the assets that are traded are claims to flows of returns that often extend many years into the future. Markets in financial assets tend to be more volatile than markets in goods and services because decisions are more often revised and more rapidly put into effect. There is the share presumption that a transaction that is freely undertaken will benefit both parties, but there is a much greater danger that it will be harmful to others.</p><p>For example, mismanagement of mortgage lending in the United States led in 2008 to banking failures and credit shortages in other developed countries, and sudden reversals of international flows of capital have often led to damaging financial crises in developing countries. And, because of the incidence of rapid change, the methodology of comparative statics has fewer applications than in the theory of international trade, and empirical analysis is more widely employed. Also, the consensus among economists concerning its principal issues is narrower and more open to controversy than is the consensus about international trade.</p><h3>Exchange rates and capital mobility</h3><p>A major change in the organisation of international finance occurred in the latter years of the twentieth century, and economists are still debating its implications. At the end of the second world war the national signatories to the Bretton Woods Agreement had agreed to maintain their currencies each at a fixed exchange rate with the United States dollar, and the United States government had undertaken to buy gold on demand at a fixed rate of $35 per ounce. In support of those commitments, most signatory nations had maintained strict control over their nationals’ use of foreign exchange and upon their dealings in international financial assets.</p><p>But in 1971 the United States government announced that it was suspending the convertibility of the dollar, and there followed a progressive transition to the current regime of floating exchange rates in which most governments no longer attempt to control their exchange rates or to impose controls upon access to foreign currencies or upon access to international financial markets. The behaviour of the international financial system was transformed. Exchange rates became very volatile and there was an extended series of damaging financial crises. One study estimated that by the end of the twentieth century there had been 112 banking crises in 93 countries ,[39] another that there had been 26 banking crises, 86 currency crises and 27 mixed banking and currency crises[40] - many times more than in the previous post-war years.</p><p>The outcome was not what had been expected. In making an influential case for flexible exchange rates in the 1950s, Milton Friedman had claimed that if there were any resulting instability, it would mainly be the consequence of macroeconomic instability,[41] but an empirical analysis in 1999 found no apparent connection.[42]</p><p>Neoclassical theory had led them to expect capital to flow from the capital-rich developed economies to the capital-poor developing countries - because the returns to capital there would be higher. Flows of financial capital would tend to increase the level of investment in the developing countries by reducing their costs of capital, and the direct investment of physical capital would tend to promote specialisation and the transfer of skills and technology. However, theoretical considerations alone cannot determine the balance between those benefits and the costs of volatility, and the question has had to be tackled by empirical analysis.</p><p>A 2006 International Monetary Fund working paper offers a summary of the empirical evidence.[43] The authors found little evidence either of the benefits of the liberalisation of capital movements, or of claims that it is responsible for the spate of financial crises. They suggest that net benefits can be achieved by countries that are able to meet threshold conditions of financial competence but that for others, the benefits are likely to be delayed, and vulnerability to interruptions of capital flows is likely to be increased.</p><h3>Policies and institutions</h3><p>Although the majority of developed countries now have floating exchange rates, some of them – together with many developing countries – maintain exchange rates that are nominally fixed, usually with the US dollar or the euro. The adoption of a fixed rate requires intervention in the foreign exchange market by the country’s central bank, and is usually accompanied by a degree of control over its citizens’ access to international markets.</p><p>Some governments have abandoned their national currencies in favour of the common currency of a currency area such as the eurozone and some, such as Denmark, have retained their national currencies but have pegged them at a fixed rate to an adjacent common currency. On an international scale, the economic policies promoted by the International Monetary Fund (IMF) have had a major influence, especially upon the developing countries.</p><p>The IMF was set up in 1944 to encourage international cooperation on monetary matters, to stabilise exchange rates and create an international payments system. Its principal activity is the payment of loans to help member countries to overcome balance of payments problems, mainly by restoring their depleted currency reserves. Their loans are, however, conditional upon the introduction of economic measures by recipient governments that are considered by the Fund's economists to provide conditions favourable to recovery.</p><p>Their recommended economic policies are broadly those that have been adopted in the United States and the other major developed countries (known as the Washington Consensus) and have often included the removal of all restrictions upon incoming investment. The Fund has been severely criticised by Joseph Stiglitz and others for what they consider to be the inappropriate enforcement of those policies and for failing to warn recipient countries of the dangers that can arise from the volatility of capital movements.</p><div class="gradientback"></div></div><div class="content"><h3>International financial stability</h3><p>From the time of the Great Depression onwards, regulators and their economic advisors have been aware that economic and financial crises can spread rapidly from country to country, and that financial crises can have serious economic consequences. For many decades, that awareness led governments to impose strict controls over the activities and conduct of banks and other credit agencies, but in the 1980s many governments pursued a policy of deregulation in the belief that the resulting efficiency gains would outweigh any systemic risks. The extensive financial innovations that followed are described in the article on financial economics.</p><p>One of their effects has been greatly to increase the international inter-connectedness of the financial markets and to create an international financial system with the characteristics known in control theory as complex-interactive. The stability of such a system is difficult to analyse because there are many possible failure sequences. The internationally systemic crises that followed included the equity crash of October 1987,[44] the Japanese asset price collapse of the 1990s[45] the Asian financial crisis of 1997[46] the Russian government default of 1998[47](which brought down the Long-Term Capital Management hedge fund) and the 2007-8 sub-prime mortgages crisis.[48] The symptoms have generally included collapses in asset prices, increases in risk premiums, and general reductions in liquidity.</p><p>Measures designed to reduce the vulnerability of the international financial system have been put forward by several international institutions. The Bank for International Settlements made two successive recommendations (Basel I and Basel II[49]) concerning the regulation of banks, and a coordinating group of regulating authorities, and the Financial Stability Forum, that was set up in 1999 to identify and address the weaknesses in the system, has put forward some proposals in an interim report.[50]</p><h2>Migration</h2><p>Elementary considerations lead to a presumption that international migration results in a net gain in economic welfare. Wage differences between developed and developing countries have been found to be mainly due to productivity differences[19] which may be assumed to arise mostly from differences in the availability of physical, social and human capital. And economic theory indicates that the move of a skilled worker from a place where the returns to skill are relatively low to a place where they are relatively high should produce a net gain (but that it would tend to depress the wages of skilled workers in the recipient country).</p><p>There have been many econometric studies intended to quantify those gains. A Copenhagen Consensus study suggests that if the share of foreign workers grew to 3% of the labour force in the rich countries there would be global benefits of $675 billion a year by 2025.[51] However, a survey of the evidence led a House of Lords committee to conclude that any benefits of immigration to the United Kingdom are relatively small.[52] Evidence from the United States also suggests that the economic benefits to the receiving country are relatively small ,[53] and that the presence of immigrants in its labour market results in only a small reduction in local wages.[54]</p><p>From the standpoint of a developing country, the emigration of skilled workers represents a loss of human capital (known as brain drain), leaving the remaining workforce without the benefit of their support. That effect upon the welfare of the parent country is to some extent offset by the remittances that are sent home by the emigrants, and by the enhanced technical know-how with which some of them return. One study introduces a further offsetting factor to suggest that the opportunity to migrate fosters enrolment in education thus promoting a brain gain that can counteract the lost human capital associated with emigration .[55]</p><p>Whereas some studies suggest that parent countries can benefit from the emigration of skilled workers,[56] generally it is emigration of unskilled and semi-skilled workers that is of economic benefit to countries of origin, by reducing pressure for employment creation. Where skilled emigration is concentrated in specific highly skilled sectors, such as medicine, the consequences are severe and even catastrophic in cases where 50% or so of trained doctors have emigrated. The crucial issues, as recently acknowledged by the OECD, is the matter of return and reinvestment in their countries of origin by the migrants themselves: thus, government policies in Europe are increasingly focused upon facilitating temporary skilled migration alongside migrant remittances.</p><p>Unlike movement of capital and goods, since 1973 government policies have tried to restrict migration flows, often without any economic rationale. Such restrictions have had diversionary effects, channeling the great majority of migration flows into illegal migration and false asylum-seeking. Since such migrants work for lower wages and often zero social insurance costs, the gain from labour migration flows is actually higher than the minimal gains calculated for legal flows; accompanying side-effects are significant, however, and include political damage to the idea of immigration, lower unskilled wages for the host population, and increased policing costs alongside lower tax receipts.</p><h2>Globalization</h2><p>The term globalization has acquired a variety of meanings, but in economic terms it refers to the move that is taking place in the direction of complete mobility of capital and labour and their products, so that the world's economies are on the way to becoming totally integrated. The driving forces of the process are reductions in politically imposed barriers and in the costs of transport and communication (although, even if those barriers and costs were eliminated, the process would be limited by inter-country differences in social capital).</p><p>It is a process which has ancient origins[citation needed], which has gathered pace in the last fifty years, but which is very far from complete. In its concluding stages, interest rates, wage rates and corporate and income tax rates would become the same everywhere, driven to equality by competition, as investors, wage earners and corporate and personal taxpayers threatened to migrate in search of better terms. In fact, there are few signs of international convergence of interest rates, wage rates or tax rates. Although the world is more integrated in some respects, it is possible to argue that on the whole it is now less integrated than it was before the first world war,[57] and that many middle-east countries are less globalised than they were 25 years ago.[58]</p><p>Of the moves toward integration that have occurred, the strongest has been in financial markets, in which globalisation is estimated to have tripled since the mid-1970s.[59] Recent research has shown that it has improved risk-sharing, but only in developed countries, and that in the developing countries it has increased macroeconomic volatility. It is estimated to have resulted in net welfare gains worldwide, but with losers as well as gainers. .[60]</p><p>Increased globalisation has also made it easier for recessions to spread from country to country. A reduction in economic activity in one country can lead to a reduction in activity in its trading partners as a result of its consequent reduction in demand for their exports, which is one of the mechanisms by which the business cycle is transmitted from country to country. Empirical research confirms that the greater the trade linkage between countries the more coordinated are their business cycles.[61]</p><p>Globalisation can also have a significant influence upon the conduct of macroeconomic policy. The Mundell–Fleming model and its extensions[62] are often used to analyse the role of capital mobility (and it was also used by Paul Krugman to give a simple account of the Asian financial crisis[63]). Part of the increase in income inequality that has taken place within countries is attributable - in some cases - to globalisation. A recent IMF report demonstrates that the increase in inequality in the developing countries in the period 1981 to 2004 was due entirely to technological change, with globalisation making a partially offsetting negative contribution, and that in the developed countries globalisation and technological change were equally responsible.[64]</p><h3>Opposition</h3><p>Globalisation is seen as contributing to economic welfare by most economists – but not all. Professor Joseph Stiglitz[65] of the School of International and Public Affairs, Columbia University has advanced the infant industry case for protection in developing countries and criticised the conditions imposed for help by the International Monetary Fund.[66] Professor Dani Rodrik of Harvard[67] has noted that the benefits of globalisation are unevenly spread, and that it has led to income inequalities, and to damaging losses of social capital in the parent countries and to social stresses resulting from immigration in the receiving countries.[68] An extensive critical analysis of these contentions has been made by Martin Wolf,[69] and a lecture by Professor Jagdish Bhagwati has surveyed the debate that has taken place among economists[70]</p><div class="gradientback"></div></div><div class="content"><h2>Notes</h2><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=International_economics&amp;oldid=775007268"					
								Categories:  Hidden categories:</p><br><h1 lang="en">Labour economics</h1><p> From Wikipedia, the free encyclopedia</p><p>Labour economics seeks to understand the functioning and dynamics of the markets for wage labour.</p><p>Labour markets or job markets function through the interaction of workers and employers. Labour economics looks at the suppliers of labour services (workers) and the demanders of labour services (employers), and attempts to understand the resulting pattern of wages, employment, and income.</p><p>In economics, labour is a measure of the work done by human beings. It is conventionally contrasted with such other factors of production as land and capital. There are theories which have developed a concept called human capital (referring to the skills that workers possess, not necessarily their actual work).</p><h2>Contents</h2><h2>Macro and micro analysis of labour markets</h2><p>There are two sides to labour economics. Labour economics can generally be seen as the application of microeconomic or macroeconomic techniques to the labour market. Microeconomic techniques study the role of individuals and individual firms in the labour market. Macroeconomic techniques look at the interrelations between the labour market, the goods market, the money market, and the foreign trade market. It looks at how these interactions influence macro variables such as employment levels, participation rates, aggregate income and gross domestic product.</p><h2>The macroeconomics of labour markets</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/7/76/Job_Advertisement_Board_in_Shenzhen_-01.jpg/200px-Job_Advertisement_Board_in_Shenzhen_-01.jpg" width="200" height="150"><p>


				Job advertisement board in Shenzhen.


				</p><p>
					The labour force is defined as the number of people of working age, who are either employed or actively looking for work. The participation rate is the number of people in the labour force divided by the size of the adult civilian noninstitutional population (or by the population of working age that is not institutionalized). The non-labour force includes those who are not looking for work, those who are institutionalised such as in prisons or psychiatric wards, stay-at home spouses, children, and those serving in the military. The unemployment level is defined as the labour force minus the number of people currently employed. The unemployment rate is defined as the level of unemployment divided by the labour force. The employment rate is defined as the number of people currently employed divided by the adult population (or by the population of working age). In these statistics, self-employed people are counted as employed.</p><p>Variables like employment level, unemployment level, labour force, and unfilled vacancies are called stock variables because they measure a quantity at a point in time. They can be contrasted with flow variables which measure a quantity over a duration of time. Changes in the labour force are due to flow variables such as natural population growth, net immigration, new entrants, and retirements from the labour force. Changes in unemployment depend on inflows made up of non-employed people starting to look for jobs and of employed people who lose their jobs and look for new ones, and outflows of people who find new employment and of people who stop looking for employment. When looking at the overall macroeconomy, several types of unemployment have been identified, including:</p><h2>Neoclassical microeconomics of labour markets</h2><p>Neoclassical economists view the labour market as similar to other markets in that the forces of supply and demand jointly determine price (in this case the wage rate) and quantity (in this case the number of people employed).</p><p>However, the labour market differs from other markets (like the markets for goods or the financial market) in several ways. In particular, the labour market may act as a non-clearing market. While according to neoclassical theory most markets quickly attain a point of equilibrium without excess supply or demand, this may not be true of the labour market: it may have a persistent level of unemployment. Contrasting the labour market to other markets also reveals persistent compensating differentials among similar workers.</p><p>Models that assume perfect competition in the labour market, as discussed below, conclude that workers earn their marginal product of labour.[1]</p><h3>Neoclassical microeconomic model – Supply</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/0/0e/Tompkins_Square_Park_Central_Knoll.jpg/220px-Tompkins_Square_Park_Central_Knoll.jpg" width="220" height="165"><p>


				The neoclassical model analyzes the trade-off between leisure hours and working hours



				<br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/2/2a/RAILROAD_WORK_CREW_IMPROVES_THE_TRACKS_AND_BED_OF_THE_ATCHISON%2C_TOPEKA_AND_SANTA_FE_RAILROAD_NEAR_BELLEFONT%2C_KANSAS..._-_NARA_-_556012.jpg/220px-RAILROAD_WORK_CREW_IMPROVES_THE_TRACKS_AND_BED_OF_THE_ATCHISON%2C_TOPEKA_AND_SANTA_FE_RAILROAD_NEAR_BELLEFONT%2C_KANSAS..._-_NARA_-_556012.jpg" width="220" height="149"><br>


				Railroad work.


				</p><div class="gradientback"></div></div><div class="content"><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/2/2a/RAILROAD_WORK_CREW_IMPROVES_THE_TRACKS_AND_BED_OF_THE_ATCHISON%2C_TOPEKA_AND_SANTA_FE_RAILROAD_NEAR_BELLEFONT%2C_KANSAS..._-_NARA_-_556012.jpg/220px-RAILROAD_WORK_CREW_IMPROVES_THE_TRACKS_AND_BED_OF_THE_ATCHISON%2C_TOPEKA_AND_SANTA_FE_RAILROAD_NEAR_BELLEFONT%2C_KANSAS..._-_NARA_-_556012.jpg" width="220" height="149"><br><p>
					Households are suppliers of labour. In microeconomic theory, people are assumed to be rational and seeking to maximize their utility function. In the labour market model, their utility function expresses trade-offs in preference between leisure time and income from time used for labour. However, they are constrained by the hours available to them.</p><p>Let w denote the hourly wage, k denote total hours available for labour and leisure, L denote the chosen number of working hours, p denote income from non-labour sources, and A denote leisure hours chosen. The individual's problem is to maximise utility U, which depends on total income available for spending on consumption and also depends on time spent in leisure, subject to a time constraint, with respect to the chooses of labour time and leisure time:</p><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Labour_economics&amp;oldid=783362165"					
								Categories:  Hidden categories:</p><br><h1 lang="en">Managerial economics</h1><p> From Wikipedia, the free encyclopedia</p><p>Managerial economics is the application of the economic concepts and economic analysis to the problems of formulating rational managerial decisions.[1] It is sometimes referred to as business economics and is a branch of economics that applies microeconomic analysis to decision methods of businesses or other management units. As such, it bridges economic theory and economics in practice.[2] It draws heavily from quantitative techniques such as regression analysis, correlation and calculus.[3] If there is a unifying theme that runs through most of managerial economics, it is the attempt to optimize business decisions given the firm's objectives and given constraints imposed by scarcity, for example through the use of operations research, mathematical programming, game theory for strategic decisions,[4] and other computational methods.[5]</p><p>Managerial decision areas include:</p><p>Almost any business decision can be analyzed with managerial economics techniques, but it is most commonly applied to:</p><p>At universities, the subject is taught primarily to advanced undergraduates and graduate business schools. It is approached as an integration subject. That is, it integrates many concepts from a wide variety of prerequisite courses. In many countries it is possible to read for a degree in Business Economics which often covers managerial economics, financial economics, game theory, business forecasting and industrial economics.</p><h2>Contents</h2><h2>Scope</h2><p>Managerial economics to a certain degree is prescriptive in nature as it suggests course of action to a managerial problem. Problems can be related to various departments in a firm like production, accounts, sales, etc.</p><li>Demand decision.</li><li>Production decision.</li><li>Theory of exchange or price theory.</li><li>All human economic activity.</li><h2>Demand decision</h2><p>Demand is the willingness of potential customers to buy a commodity. It defines the market size for a commodity, and at a disaggregated level the composition of the customer base. Analysis of demand is important for a firm as its revenue, profits, and income of its employees depend on it.[8]</p><h2>Notes</h2><h2>Journals</h2><p>1. http://www.edushareonline.in/Management/eco%20new.pdf 2.http://www.swlearning.com/economics/hirschey/managerial_econ/chap01.pdf</p><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Managerial_economics&amp;oldid=776262047"					
								Categories:  Hidden categories:</p><br><h1 lang="en">Financial economics</h1><p> From Wikipedia, the free encyclopedia</p><p>Financial economics is the branch of economics characterized by a concentration on monetary activities, in which money of one type or another is likely to appear on both sides of a trade.[1] Its concern is thus the interrelation of financial variables, such as prices, interest rates and shares, as opposed to those concerning the real economy. It has two main areas of focus:[2] asset pricing (or investment theory) and corporate finance; the first being the perspective of providers of capital and the second of users of capital.</p><p>The subject is concerned with the allocation and deployment of economic resources, both spatially and across time, in an uncertain environment.[3] It therefore centers on decision making under uncertainty in the context of the financial markets, and the resultant economic and financial models and principles, and is concerned with deriving testable or policy implications from acceptable assumptions. It is built on the foundations of microeconomics and decision theory.</p><p>Financial econometrics is the branch of financial economics that uses econometric techniques to parameterise these relationships. Mathematical finance is related in that it will derive and extend the mathematical or numerical models suggested by financial economics. Note though that the emphasis there is mathematical consistency, as opposed to compatibility with economic theory.</p><p>Financial economics is usually taught at the postgraduate level; see Master of Financial Economics. Recently, specialist undergraduate degrees are offered in the discipline.[4]</p><p>Note that this article provides an overview and survey of the field: for derivations and more technical discussion, see the specific articles linked.</p><h2>Contents</h2><h2>Underlying economics</h2><p>As above, the discipline essentially explores how rational investors would apply decision theory to the problem of investment. The subject is thus built on the foundations of microeconomics and decision theory, and derives several key results for the application of decision making under uncertainty to the financial markets.</p><h3>Present value, expectation and utility</h3><p>Underlying all of financial economics are the concepts of present value and expectation.[6]Calculating their present value allows the decision maker to aggregate the cashflows (or other returns) to be produced by the asset in the future, to a single value at the date in question, and to thus more readily compare two opportunities; this concept is therefore the starting point for financial decision making. Its history is correspondingly early: Richard Witt discusses compound interest already in 1613, in his book Arithmeticall Questions;[7] further developed by Johan de Witt and Edmond Halley.</p><div class="gradientback"></div></div><div class="content"><p>An immediate extension is to combine probabilities with present value, leading to the expected value criterion which sets asset value as a function of the sizes of the expected payouts and the probabilities of their occurrence. These ideas originate with Blaise Pascal and Pierre de Fermat.</p><p>This decision method, however, fails to consider risk aversion (as any student of finance knows[6]). In other words, since individuals receive greater utility from an extra dollar when they are poor and less utility when comparatively rich, the approach is to therefore adjust the weight assigned to the various outcomes (states) correspondingly. (Some investors may in fact be risk seeking as opposed to risk averse, but the same logic would apply).</p><p>Choice under uncertainty here, may then be characterized as the maximization of expected utility. More formally, the resulting expected utility hypothesis states that, if certain axioms are satisfied, the subjective value associated with a gamble by an individual is that individual's statistical expectation of the valuations of the outcomes of that gamble.</p><p>The impetus for these ideas arise from various inconsistencies observed under the expected value framework, such as the St. Petersburg paradox ( Ellsberg paradox). The development here originally due to Daniel Bernoulli, and later formalized by John von Neumann and Oskar Morgenstern.</p><h3>Arbitrage-free pricing and equilibrium</h3><p>The concepts of arbitrage-free, rational, pricing and equilibrium are then coupled with the above to derive classical[8] financial economics. Rational pricing is the assumption that asset prices (and hence asset pricing models) will reflect the arbitrage-free price of the asset, as any deviation from this price will be arbitraged away. This assumption is useful in pricing fixed income securities, particularly bonds, and is fundamental to the pricing of derivative instruments.</p><p>Economic equilibrium is, in general, a state in which economic forces such as supply and demand are balanced, and, in the absence of external influences these equilibrium values of economic variables will not change. General equilibrium deals with the behavior of supply, demand, and prices in a whole economy with several or many interacting markets, by seeking to prove that a set of prices exists that will result in an overall equilibrium. (This is in contrast to partial equilibrium, which only analyzes single markets.)</p><p>The two concepts are linked as follows: where market prices do not allow for profitable arbitrage, i.e. they comprise an arbitrage-free market, then these prices are also said to constitute an arbitrage equilibrium. Intuitively, this may be seen by considering that where an arbitrage opportunity does exist, then prices can be expected to change, and are therefore not in equilibrium.[9] An arbitrage equilibrium is thus a precondition for a general economic equilibrium.</p><p>The immediate, and formal, extension of this idea, the Fundamental theorem of asset pricing, shows that where markets are as above—and are additionally (implicitly and correspondingly) complete—one may then make financial decisions by constructing a risk neutral probability measure corresponding to the market.</p><p>Complete here means that there is a price for every asset in every possible state of the world, and that the complete set of possible bets on future states-of-the-world can therefore be constructed with existing assets (assuming no friction), essentially solving simultaneously for n probabilities, given n prices. The formal derivation will proceed by arbitrage arguments.[6][9] For a worked example see Rational pricing#Risk neutral valuation, where, in a simplified environment, the economy has only two possible states—up and down—and where p and (1-p) are the two corresponding (i.e. implied) probabilities, and in turn, the derived distribution, or measure.</p><p>With this measure in place, the expected, i.e. required, return of any security (or portfolio) will then equal the riskless return, plus an adjustment for risk,[6] i.e. a security-specific risk premium, compensating for the extent to which its cashflows are unpredictable. All pricing models are then essentially variants of this, given specific assumptions and/or conditions.[6][10] This approach is consistent with the above, but with the expectation based on the market (i.e. arbitrage-free, and, per the theorem, therefore in equilibrium) as opposed to individual preferences.</p><p>Thus, continuing the example, to value a specific security, its forecasted cashflows in the up- and down-states are multiplied through by p and (1-p) respectively, and are then discounted at the risk-free interest rate plus an appropriate premium. In general, this premium may be derived by the CAPM (or extensions) as will be seen under #Uncertainty.</p><h3>State prices</h3><p>With the above relationship established, the further specialized Arrow–Debreu model may be derived. This important result suggests that, under certain economic conditions, there must be a set of prices such that aggregate supplies will equal aggregate demands for every commodity in the economy. The analysis here is often undertaken assuming a Representative agent.</p><p>The Arrow–Debreu model applies to economies with maximally complete markets, in which there exists a market for every time period and forward prices for every commodity at all time periods. A direct extension, then, is the concept of a state price security (also called an Arrow–Debreu security), a contract that agrees to pay one unit of a numeraire (a currency or a commodity) if a particular state occurs (up and down in the simplified example above) at a particular time in the future and pays zero numeraire in all the other states. The price of this security is the state price of this particular state of the world.</p><p>In the above example, the state prices would equate to the present values of $p and $(1-p): i.e. what one would pay today, respectively, for the up- and down-state securities; the state price vector is the vector of state prices for all states. Applied to valuation, the price of the derivative today would simply be [up-state-price × up-state-payoff + down-state-price × down-state-payoff]; see below regarding the absence of any risk premium here. For a continuous random variable indicating a continuum of possible states, the value is found by integrating over the state price density; see Stochastic discount factor. These concepts are extended to Martingale pricing and the related Risk-neutral measure.</p><p>State prices find immediate application as a conceptual tool;[6] but can also be applied to valuation problems.[11] Given the pricing mechanism described, one can decompose the derivative value as a linear combination of its state-prices; i.e. back-solve for the state-prices corresponding to observed derivative prices[12][11]. These recovered state-prices can then be used for valuation of other instruments with exposure to the underlyer (true in fact for every security [2]), or for other decision making relating to the underlyer itself. (Breeden and Litzenberger's work in 1978 [13] established the use of state prices in financial economics.)</p><h2>Resultant models</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/7/74/MM2.png/220px-MM2.png" width="220" height="167"><p>


				Modigliani–Miller Proposition II with risky debt. As leverage (D/E) increases, the WACC (k0) stays constant.



				<br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/e/e1/Markowitz_frontier.jpg/220px-Markowitz_frontier.jpg" width="220" height="121"><br>


				Efficient Frontier. The hyperbola is sometimes referred to as the 'Markowitz Bullet', and its upward sloped portion is the efficient frontier if no risk-free asset is available. With a risk-free asset, the straight line is the efficient frontier. The graphic displays the CAL, Capital allocation line, formed when the risky asset is a single-asset rather than the market, in which case the line is the CML.



				<br><img alt="" src="http://upload.wikimedia.org/wikipedia/en/thumb/7/7d/CML-plot.PNG/220px-CML-plot.PNG" width="220" height="180"><br>


				The Capital market line is the tangent line drawn from the point of the risk-free asset to the feasible region for risky assets. The tangency point M represents the market portfolio. The CML results from the combination of the market portfolio and the risk-free asset (the point L). Addition of leverage (the point R) creates levered portfolios that are also on the CML.


				 

				<br><img alt="" src="http://upload.wikimedia.org/wikipedia/en/thumb/f/f3/SML-chart.png/220px-SML-chart.png" width="220" height="180"><br>


				Security market line: the representation of the CAPM displaying the expected rate of return of an individual security as a function of its systematic, non-diversifiable risk.



				<br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/f/f2/Stockpricesimulation.jpg/220px-Stockpricesimulation.jpg" width="220" height="167"><br>


				Simulated geometric Brownian motions with parameters from market data.


				 
				 
				</p><div class="gradientback"></div></div><div class="content"><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/e/e1/Markowitz_frontier.jpg/220px-Markowitz_frontier.jpg" width="220" height="121"><br><br><img alt="" src="http://upload.wikimedia.org/wikipedia/en/thumb/7/7d/CML-plot.PNG/220px-CML-plot.PNG" width="220" height="180"><br><br><img alt="" src="http://upload.wikimedia.org/wikipedia/en/thumb/f/f3/SML-chart.png/220px-SML-chart.png" width="220" height="180"><br><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/f/f2/Stockpricesimulation.jpg/220px-Stockpricesimulation.jpg" width="220" height="167"><br><p>
					Applying the preceding economic concepts, we may then derive various economic- and financial models and principles. As above, the two usual areas of focus are Asset Pricing and Corporate Finance, the first being the perspective of providers of capital, the second of users of capital. Here, and for (almost) all other financial economics models, the questions addressed are typically framed in terms of time, uncertainty, options, and information,[1] as will be seen below.</p><p>Applying this framework, with the above concepts, leads to the required models. This derivation begins with the assumption of no uncertainty and is then expanded to incorporate the other considerations. (This division sometimes denoted deterministic and random,[14] or stochastic.)</p><h3>Certainty</h3><p>A starting point here is “Investment under certainty. The Fisher separation theorem, asserts that the objective of a corporation will be the maximization of its present value, regardless of the preferences of its shareholders. Related is the Modigliani–Miller theorem, which shows that, under certain conditions, the value of a firm is unaffected by how that firm is financed, and depends neither on its dividend policy nor its decision to raise capital by issuing stock or selling debt. The proof here proceeds using arbitrage arguments, and acts as a benchmark for evaluating the effects of factors outside the model that do affect value.</p><p>The mechanism for determining (corporate) value is provided by The Theory of Investment Value (John Burr Williams), which proposes that the value of an asset should be calculated using evaluation by the rule of present worth. Thus, for a common stock, the intrinsic, long-term worth is the present value of its future net cashflows, in the form of dividends. What remains to be determined is the appropriate discount rate. Later developments show that, rationally, i.e. in the formal sense, the appropriate discount rate here will (should) depend on the asset's riskiness relative to the overall market, as opposed to its owners' preferences; see below. Net present value (NPV), a direct extension of these ideas, was first formally applied to Corporate Finance decisioning by Joel Dean in 1951.</p><p>Bond valuation, in that cashflows (coupons and return of principal) are deterministic, may proceed in the same fashion.[14] An immediate extension, Arbitrage-free bond pricing, discounts each cashflow at the market derived rate — i.e. at each coupon's corresponding zero-rate — as opposed to an overall rate.</p><p>Note that in many treatments bond valuation precedes equity valuation, where cashflows (dividends) are not known per se. Williams and onward allow for forecasting assumptions—based on historic ratios or published policy—as to these, and cashflows are then treated as essentially deterministic; see below under #Corporate finance theory.</p><p>These certainty results are all commonly employed under corporate finance; uncertainty is the focus of asset pricing models, as follows.</p><h3>Uncertainty</h3><p>For choice under uncertainty, the twin assumptions of rationality and market efficiency lead to modern portfolio theory (MPT) with its Capital asset pricing model (CAPM)—an equilibrium-based result—and to the Black–Scholes–Merton theory (BSM; often, simply Black–Scholes) for option pricing—an arbitrage-free result.</p><p>Briefly, and intuitively—and consistent with #Arbitrage-free pricing and equilibrium above—the linkage is as follows.[15] Given the ability to profit from private information, self-interested traders are motivated to acquire and act on their private information. In doing so, traders contribute to more and more correct, i.e. efficient, prices: the efficient market hypothesis, or EMH. The EMH (implicitly) assumes that average expectations constitute an optimal forecast, i.e. prices using all available information, are identical to the best guess of the future: the assumption of rational expectations. The EMH does allow that when faced with new information, some investors may overreact and some may underreact, but what is required, however, is that investors' reactions follow a normal distribution—so that the net effect on market prices cannot be reliably exploited to make an abnormal profit. In the competitive limit, then, market prices will reflect all available information and prices can only move in response to news, which, of course, may be good or bad, major or minor:[16] the random walk hypothesis. Thus, if prices of financial assets are (broadly) efficient, then deviations from these (equilibrium) values could not last for long.</p><p>Under these conditions investors can then be assumed to act rationally: their investment decision must be calculated or a loss is sure to follow; correspondingly, where an arbitrage opportunity presents itself, then arbitrageurs will exploit it, reinforcing this equilibrium. Here, as under the certainty-case above, the specific assumption as to pricing is that prices are calculated as the present value of expected future dividends,[10][16] as based on currently available information. What is required though is a theory for determining the appropriate discount rate given this uncertainty: this is provided by the MPT and its CAPM. Relatedly, rationality—in the sense of arbitrage-exploitation—gives rise to Black–Scholes; option values here ultimately consistent with the CAPM.</p><div class="gradientback"></div></div><div class="content"><p>In general, then, while portfolio theory studies how investors should balance risk and return when investing in many assets or securities, the CAPM is more focused, describing how, in equilibrium, markets set the prices of assets in relation to how risky they are. Importantly, this result will be independent of the investor's level of risk aversion, and / or assumed utility function, thus providing a readily determined discount rate for corporate finance decision makers as above,[17] and for other investors. The argument proceeds as follows: If one can construct an efficient frontier—i.e. each combination of assets offering the best possible expected level of return for its level of risk, see diagram—then mean-variance efficient portfolios can be formed simply as a combination of holdings of the risk-free asset and the market portfolio (the Mutual fund separation theorem), with the combinations here plotting as the capital market line, or CML. Then, given this CML, the required return on risky securities will be independent of the investor's utility function, and solely determined by their covariance with aggregate, i.e. market, risk (beta). As seen in the formula aside, this result is consistent with the preceding, equaling the riskless return plus an adjustment for risk.[10] (The efficient frontier was introduced by Harry Markowitz. The CAPM was derived by Jack Treynor (1961, 1962), William F. Sharpe (1964), John Lintner (1965) and Jan Mossin (1966) independently.)</p><p>Black–Scholes provides a mathematical model of a financial market containing derivative instruments, and the resultant formula for the price of European-styled options. The model is expressed as the Black–Scholes equation, a partial differential equation describing the changing price of the option over time; it is derived assuming log-normal, geometric Brownian motion. The key financial insight behind the model is that one can perfectly hedge the option by buying and selling the underlying asset in just the right way and consequently eliminate risk, absenting the risk adjustment from the pricing (
				  
					
					  
						V
					  
					
					{\displaystyle V}
				  
				, the value, or price, of the option, grows at 
				  
					
					  
						r
					  
					
					{\displaystyle r}
				  
				, the risk-free rate; see Black–Scholes equation §&nbsp;Financial interpretation).[6][10] This hedge, in turn, implies that there is only one right price—in an arbitrage-free sense—for the option. And this price is returned by the Black–Scholes option pricing formula. (The formula, and hence the price, is consistent with the equation, as the formula is the solution to the equation.) Since the formula is without reference to the share's expected return, Black–Scholes entails (assumes) risk neutrality, consistent with the elimination of risk here. Relatedly, therefore, the pricing formula may also be derived directly via risk neutral expectation; see Brownian model of financial markets. (BSM is consistent with previous versions of the formula of Louis Bachelier and Edward O. Thorp.[18]  Paul Samuelson (1965).[19])</p><p>As mentioned, it can be shown that the two models are consistent; then, as is to be expected, classical[8] financial economics is thus unified. Here, the Black Scholes equation may alternatively be derived from the CAPM, and the price obtained from the Black–Scholes model is thus consistent with the expected return from the CAPM.[20] The Black–Scholes theory, although built on Arbitrage-free pricing, is therefore consistent with the equilibrium based capital asset pricing. Both models, in turn, are ultimately consistent with the Arrow–Debreu theory, and may be derived via state-pricing,[6] further explaining, and if required demonstrating, this unity.</p><h2>Extensions</h2><p>More recent work further generalizes and / or extends these models.</p><h3>Portfolio theory</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/0/08/Pareto_Efficient_Frontier_for_the_Markowitz_Portfolio_selection_problem..png/200px-Pareto_Efficient_Frontier_for_the_Markowitz_Portfolio_selection_problem..png" width="200" height="134"><p>


				Plot of two criteria when maximizing return and minimizing risk in financial portfolios (Pareto-optimal points in red)



				: Post-modern portfolio theory; Mathematical finance#Risk and portfolio management: the P world.

				</p><p>
					The majority of developments here relate to required return, extending the basic CAPM. Multi-factor models such as the Fama–French three-factor model and the Carhart four-factor model, propose factors other than market return as relevant in pricing. The Intertemporal CAPM and Consumption-based CAPM similarly extend the model. With intertemporal portfolio choice, the investor now repeatedly optimizes her portfolio; while the inclusion of consumption (in the economic sense) then incorporates all sources of wealth, and not just market-based investments, into the investor's calculation of required return.</p><p>Whereas the above extend the CAPM, the single-index model is a more simple model. It assumes, only, a correlation between security and market returns, without (numerous) other economic assumptions. It is useful in that it simplifies the estimation of correlation between securities, significantly reducing the inputs for building the correlation matrix required for portfolio optimization. The arbitrage pricing theory (APT) similarly differs as regards its assumptions. Instead of assuming equilibrium, it returns the required (expected) return of a financial asset as a linear function of various macro-economic factors, and assumes that arbitrage should bring incorrectly priced assets back into line.</p><p>As regards Portfolio optimization, the Black–Litterman model departs from the original Markowitz approach of constructing portfolios via an efficient frontier. Black–Litterman instead starts with an equilibrium assumption, and is then modified to take into account the 'views' (i.e., the specific opinions about asset returns) of the investor in question to arrive at a bespoke asset allocation. Where factors additional to volatility are considered (kurtosis, skew...) then multiple-criteria decision analysis can be applied; here deriving a Pareto efficient portfolio. The universal portfolio algorithm (Thomas M. Cover) applies machine learning to asset selection, learning adaptively from historical data. See Portfolio optimization#Improving portfolio optimization for other techniques and / or objectives.</p><h3>Derivative pricing</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/2/2e/Arbre_Binomial_Options_Reelles.png/220px-Arbre_Binomial_Options_Reelles.png" width="220" height="129"><p>


				Binomial Lattice with CRR formulae


				: Mathematical finance §&nbsp;Derivatives pricing: the Q world
				</p><p>
					As regards derivative pricing, the binomial options pricing model provides a discretized version of Black–Scholes, useful for the valuation of American styled options. Discretized models of this type are built—at least implicitly—using state-prices (as above); relatedly, a large number of researchers have used options to extract state-prices for a variety of other applications in financial economics.[6][20][12] For path dependent derivatives, Monte Carlo methods for option pricing are employed; here the modelling is in continuous time, but similarly uses risk neutral expected value. Various other numeric techniques have also been developed. The theoretical framework too has been extended such that martingale pricing is now the standard approach. Developments relating to complexities in return and / or volatility are discussed below.</p><p>Drawing on these techniques, derivative models for various other underlyings and applications have also been developed, all based on the same logic. Real options valuation allows that option holders can influence the option's underlying; models for employee stock option valuation explicitly assume non-rationality on the part of option holders; Credit derivatives allow that payment obligations and / or delivery requirements might not be honored. Exotic derivatives are now routinely valued.</p><div class="gradientback"></div></div><div class="content"><p>Similarly, beginning with Oldrich Vasicek, various short rate models, as well as the HJM and BGM forward rate-based techniques, allow for an extension of these to fixed income- and interest rate derivatives. (The Vasicek and CIR models are equilibrium-based, while Ho–Lee and subsequent models are based on arbitrage-free pricing.) Bond valuation is relatedly extended: the Stochastic calculus approach, employing these methods, allows for rates that are random (while returning a price that is arbitrage free, as above); lattice models for hybrid securities allow for non-deterministic cashflows (and stochastic rates).</p><p>As above, (OTC) derivative pricing has relied on the BSM risk neutral pricing framework, under the assumptions of funding at the risk free rate and the ability to perfectly replicate cashflows so as to fully hedge. This, in turn, is built on the assumption of a credit-risk-free environment. Post the financial crisis of 2008, therefore, issues such as counterparty credit risk, funding costs and costs of capital are additionally considered,[21] and a Credit Valuation Adjustment, or CVA—and potentially other valuation adjustments, collectively xVA—is generally added to the risk-neutral derivative value. Swap pricing is relatedly and further modified. Previously, swaps were valued off a single self discounting interest rate curve; while post crisis, to accommodate credit risk, valuation is now under a multi-curve framework; see Interest rate swap §&nbsp;Valuation and pricing.</p><h3>Corporate finance theory</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/c/c6/Manual_decision_tree.jpg/220px-Manual_decision_tree.jpg" width="220" height="260"><p>


				Project valuation via decision tree.


				</p><p>
					Corporate finance theory has also been extended: mirroring the above developments, asset-valuation and decisioning no longer need assume certainty. As discussed, Monte Carlo methods in finance, introduced by David B. Hertz in 1964, allow financial analysts to construct stochastic or probabilistic corporate finance models, as opposed to the traditional static and deterministic models;[22] see Corporate finance#Quantifying uncertainty. Relatedly, Real Options theory allows for owner—i.e. managerial—actions that impact underlying value: by incorporating option pricing logic, these actions are then applied to a distribution of future outcomes, changing with time, which then determine the project's valuation today.[23]</p><p>More traditionally, decision trees—which are complementary—have been used to evaluate projects, by incorporating in the valuation (all) possible events (or states) and consequent management decisions.[22] (This technique predates the use of real options in corporate finance; it is borrowed from operations research, and is not a financial economics development per se.) Related to this, is the treatment of forecasted cashflows in equity valuation. In many cases, following Williams above, the most likely cash-flows were discounted, as opposed to a more correct state-by-state treatment under uncertainty; see comments under Financial modeling#Accounting. In more modern treatments, then, it is the expected cashflows (in the mathematical sense) combined into an overall value per forecast period which are discounted.[24][25][22] (And using the CAPM—or extensions—the discounting here is at the risk-free rate plus a premium linked to the uncertainty of the entity's cash flows.)</p><p>Other extensions here include[26] agency theory, which analyses the difficulties in motivating corporate management (the agent) to act in the best interests of shareholders (the principal), rather than in their own interests. Clean surplus accounting and the related residual income valuation provide a model that returns price as a function of earnings, expected returns, and change in book value, as opposed to dividends. This approach, to some extent, arises due to the implicit contradiction of seeing value as a function of dividends, while also holding that dividend policy cannot influence value per Modigliani and Miller's Irrelevance principle; see Dividend policy#Irrelevance of dividend policy.</p><p>The typical application of real options is to capital budgeting type problems as described. However, they are also applied to questions of capital structure and dividend policy, and to the related design of corporate securities; and since stockholder and bondholders have different objective functions, in the analysis of the related agency problems.[23] In all of these cases, state-prices can provide the market-implied information relating to the corporate, as above, which is then applied to the analysis. For example, convertible bonds can (must) be priced consistent with the state-prices of the corporate's equity.[11]</p><h2>Challenges and criticism</h2><p>As above, there is a very close link between the random walk hypothesis, with the associated expectation that price changes should follow a normal distribution, on the one hand, and market efficiency and rational expectations, on the other. Note, however, that (wide) departures from these are commonly observed, and there are thus, respectively, two main sets of challenges.</p><h3>Departures from normality</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/b/b1/Ivsrf.gif/220px-Ivsrf.gif" width="220" height="201"><p>


				Implied volatility surface. The Z-axis represents implied volatility in percent, and X and Y axes represent the option delta, and the days to maturity.


				: Capital asset pricing model §&nbsp;Problems of CAPM, Modern portfolio theory §&nbsp;Criticisms, and Black–Scholes model §&nbsp;Criticism and comments
				</p><p>
					The first set of challenges: As discussed, the assumptions that market prices follow a random walk and / or that asset returns are normally distributed are fundamental. Empirical evidence, however, suggests that these assumptions may not hold (see Kurtosis risk, Skewness risk, Long tail) and that in practice, traders, analysts and risk managers frequently modify the standard models (see Model risk). In fact, Benoît Mandelbrot had discovered already in the 1960s that changes in financial prices do not follow a Gaussian distribution, the basis for much option pricing theory, although this observation was slow to find its way into mainstream financial economics.</p><p>Financial models with long-tailed distributions and volatility clustering have been introduced to overcome problems with the realism of the above classical financial models; while jump diffusion models allow for (option) pricing incorporating jumps in the spot price. Risk managers, similarly, complement (or substitute) the standard value at risk models with historical simulations, mixture models, principal component analysis, extreme value theory, as well as models for volatility clustering.[27] For further discussion see Fat-tailed distribution §&nbsp;Applications in economics, and Value at risk §&nbsp;Criticism.</p><div class="gradientback"></div></div><div class="content"><p>Closely related is the volatility smile, where implied volatility—the volatility corresponding to the BSM price—is observed to differ as a function of strike price (i.e. moneyness), true only if the price-change distribution is non-normal, unlike that assumed by BSM. The term structure of volatility describes how (implied) volatility differs for related options with different maturities. An implied volatility surface is then a three-dimensional surface plot of volatility smile and term structure. These empirical phenomena negate the assumption of constant volatility—and log-normality—upon which Black–Scholes is built;[18] see Black–Scholes model §&nbsp;The volatility smile.</p><p>Approaches developed here in response include local volatility and stochastic volatility (the Heston, SABR and CEV models, amongst others). Alternatively, implied-binomial and -trinomial trees instead of directly modelling volatility, return a lattice consistent with observed prices in an arbitrage-free sense (essentially recovering state-prices, as described above) facilitating the pricing of other, i.e. non-quoted, strike/maturity combinations. Edgeworth binomial trees allow for a specified (i.e. non-Gaussian) skew and kurtosis in the spot price. Priced here, options with differing strikes will return differing implied volatilities, and the tree can thus be calibrated to the smile if required.[28] Similarly purposed closed-form models include: Jarrow and Rudd (1982); Corrado and Su (1996); Backus, Foresi, and Wu (2004).[29]</p><p>As above, additional to log-normality in returns, BSM - and, typically, other derivative models - assume the ability to perfectly replicate cashflows so as to fully hedge, and hence to discount at the risk-free rate. This, in turn, is built on the assumption of a credit-risk-free environment. The post crisis reality, however, differs, necessitating the various x-value adjustments to the derivative valuation, as described. Note that these adjustments are additional to any smile or surface effect. This is valid as the surface is built on price data relating to fully collateralized positions, and there is therefore no double counting of credit risk (etc.) when including xVA. (Also, were this not the case, then each counterparty would have its own surface...)</p><h3>Departures from rationality</h3><p>The second set of challenges: As seen, a common assumption is that financial decision makers act rationally; see Homo economicus. Recently, however, researchers in experimental economics and experimental finance have challenged this assumption empirically. These assumptions are also challenged theoretically, by behavioral finance, a discipline primarily concerned with the limits to rationality of economic agents.</p><p>Consistent with, and complementary to these findings, various persistent market anomalies have been documented, these being price and/or return distortions—e.g. size premiums—which appear to contradict the efficient-market hypothesis; calendar effects are the best known group here. Related to these are various of the economic puzzles, concerning phenomena similarly contradicting the theory. The equity premium puzzle, as one example, arises in that the difference between the observed returns on stocks as compared to government bonds is consistently higher than the risk premium rational equity investors should demand, an abnormal return. For further context see Random walk hypothesis § A non-random walk hypothesis, and sidebar for specific instances.</p><p>More generally, and particularly following the financial crisis of 2007–2010, financial economics and mathematical finance have been subjected to deeper criticism; notable here is Nassim Nicholas Taleb, who claims that the prices of financial assets cannot be characterized by the simple models currently in use, rendering much of current practice at best irrelevant, and, at worst, dangerously misleading; see Black swan theory, Taleb distribution. A topic of general interest studied in recent years has thus been financial crises,[30] and the failure of financial economics to model these. (A related problem is systemic risk: where companies hold securities in each other then this interconnectedness may entail a valuation chain - and the performance of one company, or security, here will impact all, a phenomenon not easily modeled, regardless of whether the individual models are correct; see Systemic risk § Inadequacy of classic valuation models.)</p><p>Areas of research attempting to explain (or at least model) these phenomena, and crises, include noise trading, market microstructure, and Heterogeneous agent models. The latter is extended to agent-based computational economics, where price is treated as an emergent phenomenon, resulting from the interaction of the various market participants (agents). The noisy market hypothesis argues that prices can be influenced by speculators and momentum traders, as well as by insiders and institutions that often buy and sell stocks for reasons unrelated to fundamental value; see Noise (economic). The adaptive market hypothesis is an attempt to reconcile the efficient market hypothesis with behavioral economics, by applying the principles of evolution to financial interactions. An information cascade, alternatively, shows market participants engaging in the same acts as others (herd behavior), despite contradictions with their private information.  Hyman Minsky's financial instability hypothesis, as well as George Soros' approach, #Reflexivity, financial markets, and economic theory.</p><p>Note however, that on the obverse, various studies have shown that despite these departures from efficiency, asset prices do typically exhibit a random walk and that one cannot therefore consistently outperform market averages (alpha). [31] The practical implication, therefore, is that passive investing (e.g. via low-cost index funds) should, on average, serve better than any other active strategy.[32] Burton Malkiel's A Random Walk Down Wall Street—first published in 1973, and in its 11th edition as of 2015—is a widely read popularization of these arguments. ( John C. Bogle's Common Sense on Mutual Funds; but compare Warren Buffett's The Superinvestors of Graham-and-Doddsville.) Note also that institutionally inherent limits to arbitrage—as opposed to factors directly contradictory to the theory—are sometimes proposed as an explanation for these departures from efficiency.</p><p>Financial economics</p><p>Asset pricing</p><p>Corporate finance</p><p>Theory</p><p>Links and portals</p><p>Actuarial resources</p><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Financial_economics&amp;oldid=783724594"					
								Categories:  Hidden categories:</p><br><h1 lang="en">Public economics</h1><p> From Wikipedia, the free encyclopedia</p><p>Public economics (or economics of the public sector) is the study of government policy through the lens of economic efficiency and equity. At its most basic level, public economics provides a framework for thinking about whether or not the government should participate in economic markets and to what extent it should do so. In order to do this, microeconomic theory is utilized to assess whether the private market is likely to provide efficient outcomes in the absence of governmental interference. Inherently, this study involves the analysis of government taxation and expenditures. This subject encompasses a host of topics including market failures, externalities, and the creation and implementation of government policy. Public economics builds on the theory of welfare economics and is ultimately used as a tool to improve social welfare.[1]</p><p>Broad methods and topics include:</p><p>Emphasis is on analytical and scientific methods and normative-ethical analysis, as distinguished from ideology. Examples of topics covered are tax incidence,[7] optimal taxation,[8] and the theory of public goods.[9]</p><div class="gradientback"></div></div><div class="content"><h2>Contents</h2><h2>Subject range</h2><p>The Journal of Economic Literature (JEL) classification codes are one way categorizing the range of economics subjects. There, Public Economics, one of 19 primary classifications, has 8 categories. They are listed below with JEL-code links to corresponding available article-preview links of The New Palgrave Dictionary of Economics Online (2008) and with similar footnote links for each respective subcategory if available:[10]</p><h2>Taxation</h2><h3>Diamond–Mirrlees efficiency theorem</h3><p>In 1971, Peter A. Diamond and James A. Mirrlees published a seminal paper which showed that even when lump-sum taxation is not available, production efficiency is still desirable. This finding is known as the Diamond–Mirrlees efficiency theorem, and it is widely credited with having modernized Ramsey's analysis by considering the problem of income distribution with the problem of raising revenue. Joseph E. Stiglitz and Partha Dasgupta (1971) have criticized this theorem as not being robust on the grounds that production efficiency will not necessarily be desirable if certain tax instruments cannot be used.</p><h3>Pigouvian taxes</h3><p> Main article: Pigouvian tax</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/0/01/A.C._Pigou.jpg/100px-A.C._Pigou.jpg" width="100" height="152"><p>


				A.C. Pigou (1877-1959).


				</p><p>
					One of the achievements for which the great English economist A.C. Pigou is known, was his work on the divergences between marginal private costs and marginal social costs (externalities). In his book, The Economics of Welfare (1932), Pigou describes how these divergences come about:</p><p>...one person A, in the course of rendering some service, for which payment is made, to a second person B, incidentally also renders services or disservices to other persons (not producers of like services), of such a sort that payment cannot be extracted from the benefited parties or compensation enforced on behalf of the injured parties (Pigou p. 183).</p><p>In particular, Pigou is known for his advocacy of what are known as corrective taxes, or Pigouvian taxes:</p><p>It is plain that divergences between private and social net product of the kinds we have so far been considering cannot, like divergences due to tenancy laws, be mitigated by a modification of the contractual relation between any two contracting parties, because the divergence arises out of a service or disservice to persons other than the contracting parties. It is, however, possible for the State, if it so chooses, to remove the divergence in any field by extraordinary encouragements or extraordinary restraints upon investments in that field. The most obvious forms which these encouragements and restraints may assume are, of course, those of bounties and taxes (Pigou p. 192).</p><p>Pigou describes as positive externalities, examples such as resources invested in private parks that improve the surrounding air, and scientific research from which discoveries of high practical utility often grow. Alternatively, he describes negative externalities, such as the factory that destroys a great part of the amenities of neighboring sites.</p><p>In 1960, the economist Ronald H. Coase proposed an alternative scheme whereby negative externalities are dealt with through the appropriate assignment of property rights. This result is known as the Coase theorem.</p><h2>Public goods</h2><p> Main article: Public goods</p><p>Public goods, or collective consumption goods, exhibit two properties; non-rivalry and non-excludability. Something is non-rivaled if one person's consumption of it does not deprive another person, (to a point) a firework display is non-rivaled - since one person watching a firework display does not prevent another person from doing so. Something is non-excludable if its use cannot be limited to a certain group of people. Again, since one cannot prevent people from viewing a firework display it is non-excludable.[9] Conceptually, another example of public good is the service that is provided by law enforcement organizations, such as sheriffs and police.[19] Typically, cities and towns are served by only one police department, and the police department serves all of the people within its jurisdiction.</p><h2>Cost–benefit analysis</h2><p> Main article: Cost benefit analysis</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/5/5a/Julesdupuit.jpg/100px-Julesdupuit.jpg" width="100" height="141"><p>


				Jules Dupuit (1804-1866).


				</p><p>
					While the origins of cost–benefit analysis can be traced back to Jules Dupuit's classic article On the Measurement of the Utility of Public Works (1844), much of the subsequent scholarly development occurred in the United States and arose from the challenges of water-resource development. In 1950, the U.S. Federal Interagency River Basin Committee’s Subcommittee on Benefits and Costs published a report entitled, Proposed Practices for Economic Analysis of River Basin Projects (also known as the Green Book), which became noteworthy for bringing in the language of welfare economics.[20] In 1958, Otto Eckstein published Water-Resource Development: The Economics of Project Evaluation, and Roland McKean published his Efficiency in Government Through Systems Analysis: With Emphasis on Water Resources Development. The latter book is also considered a classic in the field of operations research. In subsequent years, several other important works appeared: Jack Hirshleifer, James DeHaven, and Jerome W. Milliman published a volume entitled Water Supply: Economics, Technology, and Policy (1960); and a group of Harvard scholars including Robert Dorfman, Stephen Marglin, and others published Design of Water-Resource Systems: New Techniques for Relating Economic Objectives, Engineering Analysis, and Governmental Planning (1962).[21]</p><div class="gradientback"></div></div><div class="content"><h2>Notes</h2><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Public_economics&amp;oldid=772499146"					
								Categories:  Hidden categories:</p><br><h1 lang="en">Organizational economics</h1><p> From Wikipedia, the free encyclopedia</p><p>Organizational economics (also referred to as economics of organization) involves the use of economic logic and methods to understand the existence, nature, design, and performance of organizations, especially managed ones.</p><p>Organizational economics is primarily concerned with the obstacles to coordination of activities inside and between organizations (firms, alliances, institutions, and market as a whole).</p><p>Organizational economics is known for its contribution to and its use of:</p><p>Notable theorists and contributors in the field of organizational economics:[1][2][3]</p><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Organizational_economics&amp;oldid=766902827"					
								Categories:  Hidden categories:</p><br><h1 lang="en">Service economy</h1><p> From Wikipedia, the free encyclopedia</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/3/3d/Gdp-and-labour-force-by-sector.png/300px-Gdp-and-labour-force-by-sector.png" width="300" height="278"><p>


				GDP Composition By Sector and Labour Force By Occupation


				</p><p>
					Service economy can refer to one or both of two recent economic developments:</p><p>The old dichotomy between product and service has been replaced by a service-product continuum. Many products are being transformed into services.</p><p>For example, IBM treats its business as a service business. Although it still manufactures computers, it sees the physical goods as a small part of the business solutions industry. They have found that the price elasticity of demand for business solutions is much less than for hardware. There has been a corresponding shift to a subscription pricing model. Rather than receiving a single payment for a piece of manufactured equipment, many manufacturers are now receiving a steady stream of revenue for ongoing contracts.</p><p>Full cost accounting and most accounting reform and monetary reform measures are usually thought to be impossible to achieve without a good model of the service economy.</p><h2>Contents</h2><h2>Environmental effects of the service economy</h2><p>This is seen, especially in green economics and more specific theories within it such as Natural Capitalism, as having these benefits:</p><p>Product stewardship or product take-back are words for a specific requirement or measure in which the service of waste disposal is included in the distribution chain of an industrial product and is paid for at time of purchase. That is, paying for the safe and proper disposal when you pay for the product, and relying on those who sold it to you to dispose of it.</p><p>Those who advocate it are concerned with the later phases of product lifecycle and the comprehensive outcome of the whole production process. It is considered a pre-requisite to a strict service economy interpretation of (fictional, national, legal) commodity and product relationships.</p><p>It is often applied to paint, tires, and other goods that become toxic waste if not disposed of properly. It is most familiar as the container deposit charged for a deposit bottle. One pays a fee to buy the bottle, separately from the fee to buy what it contains. If one returns the bottle, the fee is returned, and the supplier must return the bottle for re-use or recycling. If not, one has paid the fee, and presumably this can pay for landfill or litter control measures that dispose of diapers or a broken bottle. Also, since the same fee can be collected by anyone finding and returning the bottle, it is common for people to collect these and return them as a means of gaining a small income. This is quite common for instance among homeless people in U.S. cities. Legal requirements vary: the bottle itself may be considered the property of the purchaser of the contents, or, the purchaser may have some obligation to return the bottle to some depot so it can be recycled or re-used.</p><p>In some countries, such as Germany, law requires attention to the comprehensive outcome of the whole extraction, production, distribution, use and waste of a product, and holds those profiting from these legally responsible for any outcome along the way. This is also the trend in the UK and EU generally. In the United States, there have been many class action suits that are effectively product stewardship liability - holding companies responsible for things the product does which it was never advertised to do.</p><p>Rather than let liability for these problems be taken up by the public sector or be haphazardly assigned one issue at a time to companies via lawsuits, many accounting reform efforts focus on achieving full cost accounting. This is the financial reflection of the comprehensive outcome - noting the gains and losses to all parties involved, not just those investing or purchasing. Such moves have made moral purchasing more attractive, as it avoids liability and future lawsuits.</p><p>The United States Environmental Protection Agency advocates product stewardship to reduce the life-cycle environmental effects of products. The ideal of product stewardship, as administered by the EPA in 2004, taps the shared ingenuity and responsibility of businesses, consumers, governments, and others, the EPA states at a Web site.</p><h2>Role of the service economy in development</h2><p>Services constitute over 50% of GDP in low income countries and as their economies continue to develop, the importance of services in the economy continues to grow.[1] The service economy is also key to growth, for instance it accounted for 47% of economic growth in sub-Saharan Africa over the period 2000–2005 (industry contributed 37% and agriculture 16% in the same period).[1] This means that recent economic growth in Africa relies as much on services as on natural resources or textiles, despite many of those countries benefiting from trade preferences in primary and secondary goods. As a result, employment is also adjusting to the changes and people are leaving the agricultural sector to find work in the service economy. This job creation is particularly useful as often it provides employment for low skilled labour in the tourism and retail sectors, thus benefiting the poor in particular and representing an overall net increase in employment.[1] The service economy in developing countries is most often made up of the following:</p><div class="gradientback"></div></div><div class="content"><p>The export potential of many of these products is already well understood, e.g. in tourism, financial services and transport, however, new opportunities are arising in other sectors, such as the health sector. For example:</p><p>[1]</p><li>^ Shelp, Ronald (January 1982). Beyond Industrialization: Ascendancy of the Global Service Economy. Praeger Publishers. ISBN&nbsp;978-0030593048.&nbsp;</li><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Service_economy&amp;oldid=761815411"					
								Categories:  				
											
						<br>
							

											 
										

							</p><br><h1 lang="en">Welfare</h1><p> From Wikipedia, the free encyclopedia</p><p>Welfare is the provision of a minimal level of well-being and social support for citizens without current means to support basic needs. In most developed countries, welfare is largely provided by the government from tax income, and to a lesser extent by charities, informal social groups, religious groups, and inter-governmental organizations.</p><p>The welfare state expands on this concept to include services such as universal healthcare and unemployment insurance.</p><h2>Contents</h2><h2>History</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/c/c7/Abbey_of_Port-Royal%2C_Distributing_Alms_to_the_Poor_by_Louise-Magdeleine_Hortemels_c._1710.jpg/240px-Abbey_of_Port-Royal%2C_Distributing_Alms_to_the_Poor_by_Louise-Magdeleine_Hortemels_c._1710.jpg" width="240" height="188"><p>


				Distributing alms to the poor, abbey of Port-Royal des Champs c. 1710.


				</p><p>
					In the Roman Empire, the first emperor Augustus provided the Cura Annonae or grain dole for citizens who could not afford to buy food every month. Social welfare was enlarged by the Emperor Trajan.[1] Trajan's program brought acclaim from many, including Pliny the Younger.[2] The Song dynasty government (c.1000AD in China) supported multiple programs which could be classified as social welfare, including the establishment of retirement homes, public clinics, and paupers' graveyards. According to economist Robert Henry Nelson, The medieval Roman Catholic Church operated a far-reaching and comprehensive welfare system for the poor...[3][4]</p><p>Early welfare programs in Europe included the English Poor Law of 1601, which gave parishes the responsibility for providing welfare payments to the poor.[5] This system was substantially modified by the 19th-century Poor Law Amendment Act, which introduced the system of workhouses.</p><p>Public assistance programs were not called welfare until the early 20th century when the term was quickly adopted to avoid the negative connotations that had become associated with older terms such as charity.[6]</p><p>It was predominantly in the late 19th and early 20th centuries that an organized system of state welfare provision was introduced in many countries. Otto von Bismarck, Chancellor of Germany, introduced one of the first welfare systems for the working classes. In Great Britain the Liberal government of Henry Campbell-Bannerman and David Lloyd George introduced the National Insurance system in 1911,[7] a system later expanded by Clement Attlee. The United States inherited England's poor house laws and has had a form of welfare since before it won its independence[citation needed]. During the Great Depression, when emergency relief measures were introduced under President Franklin D. Roosevelt, Roosevelt's New Deal focused predominantly on a program of providing work and stimulating the economy through public spending on projects, rather than on cash payment.</p><p>Modern welfare states include Germany, France, the Netherlands,[8] as well as the Nordic countries, such as Iceland, Sweden, Norway, Denmark, and Finland[9] which employ a system known as the Nordic model. Esping-Andersen classified the most developed welfare state systems into three categories; Social Democratic, Conservative, and Liberal.[10]</p><p>In the Islamic world, Zakat (charity), one of the Five Pillars of Islam, has been collected by the government since the time of the Rashidun caliph Umar in the 7th century. The taxes were used to provide income for the needy, including the poor, elderly, orphans, widows, and the disabled. According to the Islamic jurist Al-Ghazali (Algazel, 1058–111), the government was also expected to store up food supplies in every region in case a disaster or famine occurred.[11][12] (See Bayt al-mal for further information.)</p><h2>Forms</h2><p>Welfare can take a variety of forms, such as monetary payments, subsidies and vouchers, or housing assistance. Welfare systems differ from country to country, but welfare is commonly provided to individuals who are unemployed, those with illness or disability, the elderly, those with dependent children, and veterans. A person's eligibility for welfare may also be constrained by means testing or other conditions.</p><h2>Provision and funding</h2><p>Welfare is provided by governments or their agencies, by private organizations, or a combination of both. Funding for welfare usually comes from general government revenue, but when dealing with charities or NGOs, donations may be used. Some countries run conditional cash transfer welfare programs where payment is conditional on behaviour of the recipients.[13][14][15][16]</p><h2>Welfare systems</h2><p> Further information: Welfare state</p><h3>Australia</h3><p> Main article: Social security in Australia</p><p>Prior to 1900 in Australia, charitable assistance from benevolent societies, sometimes with financial contributions from the authorities, was the primary means of relief for people not able to support themselves.[17] The 1890s economic depression and the rise of the trade unions and the Labor parties during this period led to a movement for welfare reform.[18]</p><div class="gradientback"></div></div><div class="content"><p>In 1900, the states of New South Wales and Victoria enacted legislation introducing non-contributory pensions for those aged 65 and over. Queensland legislated a similar system in 1907 before the Australian labor Commonwealth government led by Andrew Fisher introduced a national aged pension under the Invalid and Old-Aged Pensions Act 1908. A national invalid disability pension was started in 1910, and a national maternity allowance was introduced in 1912.[17][19]</p><p>During the Second World War, Australia under a labor government created a welfare state by enacting national schemes for: child endowment in 1941 (superseding the 1927 New South Wales scheme); a widows’ pension in 1942 (superseding the New South Wales 1926 scheme); a wife’s allowance in 1943; additional allowances for the children of pensioners in 1943; and unemployment, sickness, and special benefits in 1945 (superseding the Queensland 1923 scheme).[17][19]</p><h3>Canada</h3><p> Main article: Social programs in Canada</p><p>Canada has a welfare state in the European tradition; however, it is not referred to as welfare, but rather as social programs. In Canada, welfare usually refers specifically to direct payments to poor individuals (as in the American usage) and not to healthcare and education spending (as in the European usage).[20]</p><p>The Canadian social safety net covers a broad spectrum of programs, and because Canada is a federation, many are run by the provinces. Canada has a wide range of government transfer payments to individuals, which totaled $145 billion in 2006.[21] Only social programs that direct funds to individuals are included in that cost; programs such as medicare and public education are additional costs.</p><p>Generally speaking, before the Great Depression, most social services were provided by religious charities and other private groups. Changing government policy between the 1930s and 1960s saw the emergence of a welfare state, similar to many Western European countries. Most programs from that era are still in use, although many were scaled back during the 1990s as government priorities shifted towards reducing debt and deficits.</p><h3>Denmark</h3><p>Characteristics of the Danish welfare is that it is handled by the state through a series of policies (and the like) that seeks to provide welfare services to citizens, hence the term welfare state. This refers not only to social benefits, but also tax-funded education, public child care, medical care, etc. A number of these services are not provided by the state directly, but administered by municipalities, regions or private providers through outsourcing. This sometimes gives a source of tension between the state and municipalities, as there is not always consistency between the promises of welfare provided by the state (i.e. parliament) and local perception of what it would cost to fulfill these promises.</p><h3>France</h3><p> Main articles: Poverty in France, Social protection in France, French Fifth Risk Plan, Revenu de solidarité active, and Revenu minimum d'insertion</p><p>Solidarity is a strong value of the French Social Protection system. The first article of the French Code of Social Security describes the principle of solidarity. Solidarity is commonly comprehended in relations of similar work, shared responsibility and common risks. Existing solidarities in France caused the expansion of health and social security.[22]</p><h3>Germany</h3><p> Main articles: Welfare in Germany and Hartz_concept §&nbsp;Hartz_IV</p><p>The welfare state has a long tradition in Germany dating back to the industrial revolution. Due to the pressure of the workers' movement in the late 19th century, Reichskanzler Otto von Bismarck introduced the first rudimentary state social insurance scheme. Under Adolf Hitler, the National Socialist Program stated We demand an expansion on a large scale of old age welfare.[23] Today, the social protection of all its citizens is considered a central pillar of German national policy. 27.6 percent of Germany's GDP is channeled into an all-embracing system of health, pension, accident, longterm care and unemployment insurance, compared to 16.2 percent in the US. In addition, there are tax-financed services such as child benefits (Kindergeld, beginning at €184 per month for the first and second child, €190 for the third and €215 for each child thereafter, until they attain 25 years or receive their first professional qualification),[24] and basic provisions for those unable to work or anyone with an income below the poverty line.[25]</p><p>Since 2005, reception of full unemployment pay (60–67% of the previous net salary) has been restricted to 12 months in general and 18 months for those over 55. This is now followed by (usually much lower) Arbeitslosengeld II (ALG II) or Sozialhilfe, which is independent of previous employment (Hartz IV concept).</p><p>Under ALG II, a single person receives €391 per month plus the cost of 'adequate' housing and health insurance. ALG II can also be paid partially to supplement a low work income.</p><h3>Italy</h3><p> Main article: Italian welfare state</p><p>The Italian welfare state's foundations were laid along the lines of the corporatist-conservative model, or of its Mediterranean variant.[citation needed] Later, in the 1960s and 1970s, increases in public spending and a major focus on universality brought it on the same path as social-democratic systems. In 1978, a universalistic welfare model was introduced in Italy, offering a number of universal and free services such as a National Health Fund.[26]</p><h3>Japan</h3><p> Main article: Welfare in Japan</p><p>Social welfare, assistance for the ill or otherwise disabled and for the old, has long been provided in Japan by both the government and private companies. Beginning in the 1920s, the government enacted a series of welfare programs, based mainly on European models, to provide medical care and financial support. During the postwar period, a comprehensive system of social security was gradually established.[27][28]</p><h3>Latin America</h3><p>The 1980s marked a change in the structure of Latin American social protection programs. Social protection embraces three major areas: social insurance, financed by workers and employers; social assistance to the population’s poorest, financed by the state; and labor market regulations to protect worker rights.[29] Although diverse, recent Latin American social policy has tended to concentrate on social assistance.</p><p>The 1980s had a significant effect on social protection policies. Prior to the 1980s, most Latin American countries focused on social insurance policies involving formal sector workers, assuming that the informal sector would disappear with economic development. The economic crisis of the 1980s and the liberalization of the labor market led to a growing informal sector and a rapid increase in poverty and inequality. Latin American countries did not have the institutions and funds to properly handle such a crisis, both due to the structure of the social security system, and to the previously implemented structural adjustment policies (SAPs) that had decreased the size of the state.</p><div class="gradientback"></div></div><div class="content"><p>New Welfare programs have integrated the multidimensional, social risk management, and capabilities approaches into poverty alleviation. They focus on income transfers and service provisions while aiming to alleviate both long- and short-term poverty through, among other things, education, health, security, and housing. Unlike previous programs that targeted the working class, new programs have successfully focused on locating and targeting the very poorest.</p><p>The impacts of social assistance programs vary between countries, and many programs have yet to be fully evaluated. According to Barrientos and Santibanez, the programs have been more successful in increasing investment in human capital than in bringing households above the poverty line. Challenges still exist, including the extreme inequality levels and the mass scale of poverty; locating a financial basis for programs; and deciding on exit strategies or on the long-term establishment of programs.[29]</p><p>The economic crisis of the 1980s led to a shift in social policies, as understandings of poverty and social programs evolved (24). New, mostly short-term programs emerged. These include:[30]</p><h3>New Zealand</h3><p> Main article: Welfare in New Zealand</p><p>New Zealand is often regarded as having one of the first comprehensive welfare systems in the world. During the 1890s a Liberal government adopted many social programmes to help the poor who had suffered from a long economic depression in the 1880s. One of the most far reaching was the passing of tax legislation that made it difficult for wealthy sheep farmers to hold onto their large land holdings. This and the invention of refrigeration led to a farming revolution where many sheep farms were broken up and sold to become smaller dairy farms. This enabled thousands of new farmers to buy land and develop a new and vigorous industry that has become the backbone of New Zealand's economy to this day. This liberal tradition flourished with increased enfranchisement for indigenous Maori in the 1880s and women. Pensions for the elderly, the poor and war casualties followed, with State-run schools, hospitals and subsidized medical and dental care. By 1960 New Zealand was able to afford one of the best-developed and most comprehensive welfare systems in the world, supported by a well-developed and stable economy.</p><h3>Sweden</h3><p> Main articles: Welfare in Sweden and Social security in Sweden</p><p>Social welfare in Sweden is made up of several organizations and systems dealing with welfare. It is mostly funded by taxes, and executed by the public sector on all levels of government as well as private organisations. It can be separated into three parts falling under three different ministries; social welfare, falling under the responsibility of Ministry of Health and Social Affairs; education, under the responsibility of the Ministry of Education and Research and labour market, under the responsibility of Ministry of Employment.[31]</p><p>Government pension payments are financed through an 18.5% pension tax on all taxed incomes in the country, which comes partly from a tax category called a public pension fee (7% on gross income), and 30% of a tax category called employer fees on salaries (which is 33% on a netted income). Since January 2001 the 18.5% is divided in two parts: 16% goes to current payments, and 2.5% goes into individual retirement accounts, which were introduced in 2001. Money saved and invested in government funds, and IRAs for future pension costs, are roughly 5 times annual government pension expenses (725/150).</p><h3>United Kingdom</h3><p> Main article: Welfare state in the United Kingdom</p><p>The United Kingdom has a long history of welfare, notably including the English Poor laws which date back to 1536. After various reforms to the program, which involved workhouses, it was eventually abolished and replaced with a modern system by laws such as National Assistance Act 1948.</p><p>In more recent times, comparing the first Cameron ministry's austerity measures with the Opposition's, the respected Financial Times commentator Martin Wolf commented that the big shift from Labour ... is the cuts in welfare benefits.[33] The government's austerity programme, which involves reduction in government policy, has been linked to a rise in food banks. A study published in the British Medical Journal in 2015 found that each 1 percentage point increase in the rate of Jobseeker's Allowance claimants sanctioned was associated with a 0.09 percentage point rise in food bank use.[34] The austerity programme has faced opposition from disability rights groups for disproportionately affecting disabled people. The bedroom tax is an austerity measure that has attracted particular criticism, with activists arguing that two thirds of council houses affected by the policy are occupied with a person with a disability.[35]</p><h3>United States</h3><p> Main article: Social programs in the United States</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/2/28/Signing_Of_The_Social_Security_Act.jpg/250px-Signing_Of_The_Social_Security_Act.jpg" width="250" height="196"><p>


				President Roosevelt signs the Social Security Act, August 14, 1935.


				</p><p>
					In the United States, depending on the context, the term “welfare” can be used to refer to means-tested cash benefits, especially the Aid to Families with Dependent Children (AFDC) program and its successor, the Temporary Assistance for Needy Families Block Grant, or it can be used to refer to all means-tested programs that help individuals or families meet basic needs, including, for example, health care through Medicaid, Supplemental Security Income (SSI) benefits and food and nutrition programs (SNAP). It can also include Social Insurance programs such as Unemployment Insurance, Social Security, and Medicare.</p><p>AFDC (originally called Aid to Dependent Children) was created during the Great Depression to alleviate the burden of poverty for families with children and allow widowed mothers to maintain their households. The New Deal employment program such as the Works Progress Administration primarily served men. Prior to the New Deal, anti-poverty programs were primarily operated by private charities or state or local governments; however, these programs were overwhelmed by the depth of need during the Depression.[36] The United States has no national program of cash assistance for non-disabled poor individuals who are not raising children.</p><p>Race is brought up constantly in policies as to categorize whether it is a Black or White issue and in welfare's history there's a switch in the way the public is educated through news media. Until early in the year of 1965, the news media was conveying only Whites as living in poverty however that perception had changed to Blacks.[37] Some of the influences in this shift could have been the civil rights movement and urban riots from the mid 60s. Welfare had then shifted from being a White issue to a Black issue and during this time frame the war on poverty had already begun.[37] Subsequently, news media portrayed stereotypes of Blacks as lazy, undeserving and welfare queens. These shifts in media don't necessarily establish the population living in poverty decreasing.[37]</p><div class="gradientback"></div></div><div class="content"><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/6/66/Welfare_Benefits_Payments_Graph.gif/250px-Welfare_Benefits_Payments_Graph.gif" width="250" height="129"><p>


				A chart showing the overall decline of average monthly welfare benefits (AFDC then TANF) per recipient 1962–2006 (in 2006 dollars).[38]


				</p><p>
					In 1996, the Personal Responsibility and Work Opportunity Reconciliation Act changed the structure of Welfare payments and added new criteria to states that received Welfare funding. After reforms, which President Clinton said would end Welfare as we know it,[39] amounts from the federal government were given out in a flat rate per state based on population.[40] Each state must meet certain criteria to ensure recipients are being encouraged to work themselves out of Welfare. The new program is called Temporary Assistance for Needy Families (TANF).[41][42] It encourages states to require some sort of employment search in exchange for providing funds to individuals, and imposes a five-year lifetime limit on cash assistance.[39][41][43] In FY 2010, 31.8% of TANF families were white, 31.9% were African-American, and 30.0% were Hispanic.[42]</p><p>According to the U.S. Census Bureau data released September 13, 2011, the nation's poverty rate rose to 15.1% (46.2 million) in 2010,[44] up from 14.3% (approximately 43.6 million) in 2009 and to its highest level since 1993. In 2008, 13.2% (39.8 million) Americans lived in relative poverty.[45]</p><p>In a 2011 op-ed in Forbes, Peter Ferrara stated that, The best estimate of the cost of the 185 federal means tested Welfare programs for 2010 for the federal government alone is nearly $700 billion, up a third since 2008, according to the Heritage Foundation. Counting state spending, total Welfare spending for 2010 reached nearly $900 billion, up nearly one-fourth since 2008 (24.3%).[46] California, with 12% of the U.S. population, has one-third of the nation's welfare recipients.[47]</p><p>In FY 2011, federal spending on means-tested welfare, plus state contributions to federal programs, reached $927 billion per year. Roughly half of this welfare assistance, or $462 billion went to families with children, most of which are headed by single parents.[48]</p><p>The United States has also typically relied on charitable giving through non-profit agencies and fundraising instead of direct monetary assistance from the government itself. According to Giving USA, Americans gave $358.38 billion to charity in 2014. This is rewarded by the United States government through tax incentives for individuals and companies that are not typically seen in other countries.</p><h2>Criticism</h2><p> Main article: Criticisms of welfare</p><p>Income transfers can be either conditional or unconditional. Conditionalities are sometimes criticised as being paternalistic and unnecessary.</p><p>Current programs have been built as short-term rather than as permanent institutions, and many of them have rather short time spans (around five years). Some programs have time frames that reflect available funding. One example of this is Bolivia’s Bonosol, which is financed by proceeds from the privatization of utilities—an unsustainable funding source. Some see Latin America’s social assistance programs as a way to patch up high levels of poverty and inequalities, partly brought on by the current economic system.</p><p>Some opponents of welfare argue that it affects work incentives. They also argue that the taxes levied can also affect work incentives. A good example of this would be the reform of the Aid to Families with Dependent Children (AFDC) program. Per AFDC, some amount per recipient is guaranteed. However, for every dollar the recipient earns the monthly stipend is decreased by an equivalent amount. For most persons, this reduces their incentive to work. This program was replaced by Temporary Aid to Needy Families (TANF). Under TANF, people were required to actively seek employment while receiving aid and they could only receive aid for a limited amount of time. However, states can choose the amount of resources they will devote to the program.</p><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Welfare&amp;oldid=783361522"					
								Categories:  Hidden categories:</p><br><h1 lang="en">Regional science</h1><p> From Wikipedia, the free encyclopedia</p><p>Regional science is a field of the social sciences concerned with analytical approaches to problems that are specifically urban, rural, or regional. Topics in regional science include, but are not limited to location theory or spatial economics, location modeling, transportation, migration analysis, land use and urban development, interindustry analysis, environmental and ecological analysis, resource management, urban and regional policy analysis, geographical information systems, and spatial data analysis. In the broadest sense, any social science analysis that has a spatial dimension is embraced by regional scientists.</p><h2>Contents</h2><h2>Origins</h2><p>Regional science was founded in the late 1940s when some economists began to become dissatisfied with the low level of regional economic analysis and felt an urge to upgrade it. But even in this early era, the founders of regional science expected to catch the interest of people from a wide variety of disciplines. Regional science's formal roots date to the aggressive campaigns by Walter Isard and his supporters to promote the objective and scientific analysis of settlement, industrial location, and urban development. Isard targeted key universities and campaigned tirelessly. Accordingly, the Regional Science Association was founded in 1954, when the core group of scholars and practitioners held its first meetings independent from those initially held as sessions of the annual meetings of the American Economics Association.[1] A reason for meeting independently undoubtedly was the group's desire to extend the new science beyond the rather restrictive world of economists and have natural scientists, psychologists, anthropologists, lawyers, sociologists, political scientists, planners, and geographers join the club.[2] Now called the Regional Science Association International (RSAI), it maintains subnational and international associations, journals, and a conference circuit (notably in North America, continental Europe, Japan, and South Korea). Membership in the RSAI continues to grow.</p><h2>Seminal publications</h2><p>Topically speaking, regional science took off in the wake of Walter Christaller's book Die Zentralen Orte in Suddeutschland (Verlag von Gustav Fischer, Jena, 1933; transl. Central Places in Southern Germany, 1966), soon followed by Tord Palander's (1935) Beiträge zur Standortstheorie; August Lösch's Die räumliche Ordnung der Wirtschaft (Verlag von Gustav Fischer, Jena, 1940; 2nd rev. edit., 1944; transl. The Economics of Location, 1954)&nbsp;; and Edgar M. Hoover's two books--Location Theory and the Shoe and Leather Industry (1938) and The Location of Economic Activity (1948). Other important early publications include: Edward H. Chamberlin's (1950) The Theory of Monopolistic Competition&nbsp;; François Perroux's (1950) Economic Spaces: Theory and Application; Torsten Hägerstrand's (1953) Innovationsförloppet ur Korologisk Synpunkt; Edgar S. Dunn's (1954)The Location of Agricultural Production&nbsp;; Martin J. Beckmann, C.B McGuire, and Clifford B. Winston's (1956) Studies in the Economics of Transportation; Melvin L. Greenhut's (1956) Plant Location in Theory and Practice; Gunnar Myrdal's (1957) Economic Theory and Underdeveloped Regions; Albert O. Hirschman's (1958) The Strategy of Economic Development; and Claude Ponsard's (1958) Histoire des Théories Économiques Spatiales. Nonetheless, Walter Isard's first book in 1956, Location and Space Economy, apparently captured the imagination of many, and his third, Methods of Regional Analysis, published in 1960, only sealed his position as the father of the field.</p><div class="gradientback"></div></div><div class="content"><p>As is typically the case, the above works were built on the shoulders of giants. Much of this predecessor work is documented well in Walter Isard's Location and Space Economy[3] as well as Claude Ponsard's Histoire des Théorie Économique Spatiales.[4] Particularly important was the contribution by 19th century German economists to location theory. The early German hegemony more or less starts with Johann Heinrich von Thünen and runs through both Wilhelm Launhardt and Alfred Weber to Walter Christaller and August Lösch.</p><h2>Core journals</h2><p>If an academic discipline is identified by its journals, then technically regional science began in 1955 with the publication of the first volume of the Papers and Proceedings, Regional Science Association (now Papers in Regional Science published by Springer). In 1958, the Journal of Regional Science followed. Since the 1970s, the number of journals serving the field has exploded. The RSAI website displays most of them.</p><p>Most recently the journal Spatial Economic Analysis has been published by the RSAI British and Irish Section with the Regional Studies Association. The latter is a separate and growing organisation involving economists, planners, geographers, political scientists, management academics, policymakers, and practitioners.[5]</p><h2>Academic programs</h2><p>Walter Isard's efforts culminated in the creation of a few academic departments and several university-wide programs in regional science. At Walter Isard's suggestion, the University of Pennsylvania started the Regional Science Department in 1956. It featured as its first graduate William Alonso and was looked upon by many to be the international academic leader for the field. Another important graduate and faculty member of the department is Masahisa Fujita. The core curriculum of this department was microeconomics, input-output analysis, location theory, and statistics. Faculty also taught courses in mathematical programming, transportation economics, labor economics, energy and ecological policy modeling, spatial statistics, spatial interaction theory and models, benefit/cost analysis, urban and regional analysis, and economic development theory, among others. But the department's unusual multidisciplinary orientation undoubtedly encouraged its demise, and it lost its department status in 1993.[6]</p><p>With a few exceptions, such as Cornell University, which awards graduate degrees in Regional Science,[7] most practitioners hold positions in departments such as economics, geography, civil engineering, agricultural economics, rural sociology, urban planning, public policy, or demography. The diversity of disciplines participating in regional science have helped make it one of the most interesting and fruitful fields of academic specialization, but it has also made it difficult to fit the many perspectives into a curriculum for an academic major. It is even difficult for authors to write regional science textbooks, since what is elementary knowledge for one discipline might be entirely novel for another.[8]</p><h2>Public policy impact</h2><p>Part of the movement was, and continues to be, associated with the political and economic realities of the role of the local community. On any occasion where public policy is directed at the sub-national level, such as a city or group of counties, the methods of regional science can prove useful. Traditionally, regional science has provided policymakers with guidance on the following issues:[9]</p><p>By targeting federal resources to specific geographic areas the Kennedy administration realized that political favors could be bought. This is also evident in Europe and other places where local economic areas do not coincide with political boundaries. In the more current era of devolution knowledge about local solutions to local problems has driven much of the interest in regional science. Thus, there has been much political impetus to the growth of the discipline.</p><h2>Developments after 1980</h2><p>Regional science has enjoyed mixed fortunes since the 1980s. While it has gained a larger following among economists and public policy practitioners, the discipline has fallen out of favor among more radical and post-modernist geographers. In an apparent effort to secure a larger share of research funds, geographers had the National Science Foundation's Geography and Regional Science Program renamed Geography and Spatial Sciences.</p><h3>New economic geography</h3><p>In 1991, Paul Krugman, as a highly regarded international trade theorist, put out a call for economists to pay more attention to economic geography in a book entitled Geography and Trade, focusing largely on the core regional science concept of agglomeration economies. Krugman's call renewed interest by economists in regional science and, perhaps more importantly, founded what some term the new economic geography, which enjoys much common ground with regional science. Broadly trained new economic geographers combine quantitative work with other research techniques, for example at the London School of Economics. The unification of Europe and the increased internationalization of the world's economic, social, and political realms has further induced interest in the study of regional, as opposed to national, phenomena. The new economic geography appears to have garnered more interest in Europe than in America where amenities, notably climate, have been found to better predict human location and re-location patterns, as emphasized in recent work by Mark Partridge.[10] In 2008 Krugman won the Nobel Memorial Prize in Economic Sciences and his Prize Lecture has references both to work in regional science's location theory as well as economic's trade theory.[11]</p><h3>Criticisms</h3><p>Today there are dwindling numbers of regional scientists from academic planning programs and mainstream geography departments. Attacks on regional science's practitioners by radical critics began as early as the 1970s, notably David Harvey who believed it lacked social and political commitment. Regional science's founder, Walter Isard, never envisioned regional scientists would be political or planning activists. In fact, he suggested that they will seek to be sitting in front of a computer and surrounded by research assistants. Trevor J. Barnes suggests the decline of regional science practice among planners and geographers in North America could have been avoided. He says It is unreflective, and consequently inured to change, because of a commitment to a God’s eye view. It is so convinced of its own rightness, of its Archimedean position, that it remained aloof and invariant, rather than being sensitive to its changing local context. [12]</p><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Regional_science&amp;oldid=777035392"					
								Categories:  Hidden categories:</p><br><br><img alt="Permanently protected page" src="http://upload.wikimedia.org/wikipedia/commons/thumb/f/fc/Padlock-silver.svg/20px-Padlock-silver.svg.png" width="20" height="20"><h1 lang="en">Help:IPA for English</h1><div class="gradientback"></div></div><div class="content"><p> From Wikipedia, the free encyclopedia</p><p>Throughout Wikipedia, the pronunciation of words is indicated by means of the International Phonetic Alphabet (IPA). The following tables list the IPA symbols used for English words and pronunciations. Please note that several of these symbols are used in ways that are specific to Wikipedia and differ from those used by dictionaries.</p><p>If the IPA symbols are not displayed properly by your browser, see the links below.</p><p>If you are adding a pronunciation using this key, such pronunciations should generally be formatted using the template {{IPAc-en}}. The template provides tooltips for each symbol in the pronunciation. See the template page for instructions.</p><h2>Key</h2><p>If the words given as examples for two different symbols sound the same to you (for example, if you pronounce cot and caught the same, or do and dew, or marry and merry), you can pronounce those symbols the same in explanations of all words. The footnotes explain some of these mergers. ( Dialect variation below.)</p><p>If there is an IPA symbol you are looking for that you do not see here, see Help:IPA, which is a more complete list. For a table listing all spellings of the sounds on this page, see English orthography §&nbsp;Sound-to-spelling correspondences. For help converting spelling to pronunciation, see English orthography §&nbsp;Spelling-to-sound correspondences.</p><p>Notes</p><h2>Dialect variation</h2><p> Main article: International Phonetic Alphabet chart for English dialects</p><p>This key represents diaphonemes, abstractions of speech sounds that accommodate General American (GenAm), Received Pronunciation (RP), Canadian English, South African, Australian, and New Zealand pronunciations. Therefore, not all of the distinctions shown here are relevant to a particular dialect:</p><p>On the other hand, there are some distinctions which you might make but which this key does not encode, as they are seldom reflected in the dictionaries used as sources for Wikipedia articles:</p><p>Other words may have different vowels depending on the speaker.</p><p>The pronunciation of the /æ/ vowel in most dialects of Scotland, Northern Ireland, northern England and Wales has always been closer to [a]. BBC English has moved away from the traditional near-open front realization [æ] towards almost fully open front realization [a], and both the Oxford English Dictionary and the 2014 edition of Gimson's Pronunciation of English transcribe the vowel in lad, bad, cat, trap with /a/.[33]</p><p>For more extensive information on dialect variations, you may wish to see the IPA chart for English dialects.</p><p>Note that place names are not generally exempted from being transcribed in this abstracted system, so rules such as the above must be applied in order to recover the local pronunciation. Examples include place names in much of England ending -ford, which although locally pronounced [-f?d] are transcribed /-f?rd/. This is best practice for editors. However, readers should be aware that not all editors may have followed this consistently, so for example if /-f?d/ is encountered for such a place name, it should not be interpreted as a claim that the /r/ would be absent even in a rhotic dialect.</p><h2>Other transcriptions</h2><p>If you feel it is necessary to add a pronunciation respelling using another convention, then please use the conventions of Wikipedia's pronunciation respelling key.</p><h2>Notes</h2><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Help:IPA_for_English&amp;oldid=784078373"					
								Categories:  Hidden categories:</p><br><br><img alt="Permanently protected page" src="http://upload.wikimedia.org/wikipedia/commons/thumb/f/fc/Padlock-silver.svg/20px-Padlock-silver.svg.png" width="20" height="20"><h1 lang="en">Help:IPA for English</h1><p> From Wikipedia, the free encyclopedia</p><p>Throughout Wikipedia, the pronunciation of words is indicated by means of the International Phonetic Alphabet (IPA). The following tables list the IPA symbols used for English words and pronunciations. Please note that several of these symbols are used in ways that are specific to Wikipedia and differ from those used by dictionaries.</p><p>If the IPA symbols are not displayed properly by your browser, see the links below.</p><p>If you are adding a pronunciation using this key, such pronunciations should generally be formatted using the template {{IPAc-en}}. The template provides tooltips for each symbol in the pronunciation. See the template page for instructions.</p><h2>Key</h2><p>If the words given as examples for two different symbols sound the same to you (for example, if you pronounce cot and caught the same, or do and dew, or marry and merry), you can pronounce those symbols the same in explanations of all words. The footnotes explain some of these mergers. ( Dialect variation below.)</p><p>If there is an IPA symbol you are looking for that you do not see here, see Help:IPA, which is a more complete list. For a table listing all spellings of the sounds on this page, see English orthography §&nbsp;Sound-to-spelling correspondences. For help converting spelling to pronunciation, see English orthography §&nbsp;Spelling-to-sound correspondences.</p><p>Notes</p><h2>Dialect variation</h2><p> Main article: International Phonetic Alphabet chart for English dialects</p><p>This key represents diaphonemes, abstractions of speech sounds that accommodate General American (GenAm), Received Pronunciation (RP), Canadian English, South African, Australian, and New Zealand pronunciations. Therefore, not all of the distinctions shown here are relevant to a particular dialect:</p><div class="gradientback"></div></div><div class="content"><p>On the other hand, there are some distinctions which you might make but which this key does not encode, as they are seldom reflected in the dictionaries used as sources for Wikipedia articles:</p><p>Other words may have different vowels depending on the speaker.</p><p>The pronunciation of the /æ/ vowel in most dialects of Scotland, Northern Ireland, northern England and Wales has always been closer to [a]. BBC English has moved away from the traditional near-open front realization [æ] towards almost fully open front realization [a], and both the Oxford English Dictionary and the 2014 edition of Gimson's Pronunciation of English transcribe the vowel in lad, bad, cat, trap with /a/.[33]</p><p>For more extensive information on dialect variations, you may wish to see the IPA chart for English dialects.</p><p>Note that place names are not generally exempted from being transcribed in this abstracted system, so rules such as the above must be applied in order to recover the local pronunciation. Examples include place names in much of England ending -ford, which although locally pronounced [-f?d] are transcribed /-f?rd/. This is best practice for editors. However, readers should be aware that not all editors may have followed this consistently, so for example if /-f?d/ is encountered for such a place name, it should not be interpreted as a claim that the /r/ would be absent even in a rhotic dialect.</p><h2>Other transcriptions</h2><p>If you feel it is necessary to add a pronunciation respelling using another convention, then please use the conventions of Wikipedia's pronunciation respelling key.</p><h2>Notes</h2><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Help:IPA_for_English&amp;oldid=784078373"					
								Categories:  Hidden categories:</p><br><br><img alt="Permanently protected page" src="http://upload.wikimedia.org/wikipedia/commons/thumb/f/fc/Padlock-silver.svg/20px-Padlock-silver.svg.png" width="20" height="20"><h1 lang="en">Help:IPA for English</h1><p> From Wikipedia, the free encyclopedia</p><p>Throughout Wikipedia, the pronunciation of words is indicated by means of the International Phonetic Alphabet (IPA). The following tables list the IPA symbols used for English words and pronunciations. Please note that several of these symbols are used in ways that are specific to Wikipedia and differ from those used by dictionaries.</p><p>If the IPA symbols are not displayed properly by your browser, see the links below.</p><p>If you are adding a pronunciation using this key, such pronunciations should generally be formatted using the template {{IPAc-en}}. The template provides tooltips for each symbol in the pronunciation. See the template page for instructions.</p><h2>Key</h2><p>If the words given as examples for two different symbols sound the same to you (for example, if you pronounce cot and caught the same, or do and dew, or marry and merry), you can pronounce those symbols the same in explanations of all words. The footnotes explain some of these mergers. ( Dialect variation below.)</p><p>If there is an IPA symbol you are looking for that you do not see here, see Help:IPA, which is a more complete list. For a table listing all spellings of the sounds on this page, see English orthography §&nbsp;Sound-to-spelling correspondences. For help converting spelling to pronunciation, see English orthography §&nbsp;Spelling-to-sound correspondences.</p><p>Notes</p><h2>Dialect variation</h2><p> Main article: International Phonetic Alphabet chart for English dialects</p><p>This key represents diaphonemes, abstractions of speech sounds that accommodate General American (GenAm), Received Pronunciation (RP), Canadian English, South African, Australian, and New Zealand pronunciations. Therefore, not all of the distinctions shown here are relevant to a particular dialect:</p><p>On the other hand, there are some distinctions which you might make but which this key does not encode, as they are seldom reflected in the dictionaries used as sources for Wikipedia articles:</p><p>Other words may have different vowels depending on the speaker.</p><p>The pronunciation of the /æ/ vowel in most dialects of Scotland, Northern Ireland, northern England and Wales has always been closer to [a]. BBC English has moved away from the traditional near-open front realization [æ] towards almost fully open front realization [a], and both the Oxford English Dictionary and the 2014 edition of Gimson's Pronunciation of English transcribe the vowel in lad, bad, cat, trap with /a/.[33]</p><p>For more extensive information on dialect variations, you may wish to see the IPA chart for English dialects.</p><p>Note that place names are not generally exempted from being transcribed in this abstracted system, so rules such as the above must be applied in order to recover the local pronunciation. Examples include place names in much of England ending -ford, which although locally pronounced [-f?d] are transcribed /-f?rd/. This is best practice for editors. However, readers should be aware that not all editors may have followed this consistently, so for example if /-f?d/ is encountered for such a place name, it should not be interpreted as a claim that the /r/ would be absent even in a rhotic dialect.</p><h2>Other transcriptions</h2><p>If you feel it is necessary to add a pronunciation respelling using another convention, then please use the conventions of Wikipedia's pronunciation respelling key.</p><h2>Notes</h2><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Help:IPA_for_English&amp;oldid=784078373"					
								Categories:  Hidden categories:</p><br><h1 lang="en">Production (economics)</h1><p> From Wikipedia, the free encyclopedia</p><p>Production is a process of workers combining various material inputs and immaterial inputs (plans, know-how) in order to make something for consumption (the output). It is the act of creating output, a good or service which has value and contributes to the utility of individuals.[1]</p><div class="gradientback"></div></div><div class="content"><p>Economic well-being is created in a production process, meaning all economic activities that aim directly or indirectly to satisfy human wants and needs. The degree to which the needs are satisfied is often accepted as a measure of economic well-being. In production there are two features which explain increasing economic well-being. They are improving quality-price-ratio of goods and services and increasing incomes from growing and more efficient market production.</p><p>The most important forms of production are</p><p>In order to understand the origin of the economic well-being we must understand these three production processes. All of them produce commodities which have value and contribute to well-being of individuals.</p><p>The satisfaction of needs originates from the use of the commodities which are produced. The need satisfaction increases when the quality-price-ratio of the commodities improves and more satisfaction is achieved at less cost. Improving the quality-price-ratio of commodities is to a producer an essential way to improve the competitiveness of products but this kind of gains distributed to customers cannot be measured with production data. Improving the competitiveness of products means often to the producer lower product prices and therefore losses in incomes which are to compensated with the growth of sales volume.</p><p>Economic well-being also increases due to the growth of incomes that are gained from the growing and more efficient market production. Market production is the only production form which creates and distributes incomes to stakeholders. Public production and household production are financed by the incomes generated in market production. Thus market production has a double role in creating well-being, i.e. the role of producing goods and services and the role of creating income. Because of this double role market production is the “primus motor” of economic well-being and therefore here under review.[citation needed]</p><h2>Contents</h2><h2>As a source of economic well-being</h2><p>In principle there are two main activities in an economy, production and consumption. Similarly there are two kinds of actors, producers and consumers. Well-being is made possible by efficient production and by the interaction between producers and consumers. In the interaction, consumers can be identified in two roles both of which generate well-being. Consumers can be both customers of the producers and suppliers to the producers. The customers’ well-being arises from the commodities they are buying and the suppliers’ well-being is related to the income they receive as compensation for the production inputs they have delivered to the producers.</p><h3>Stakeholders of production</h3><p>Stakeholders of production are persons, groups or organizations with an interest in a producing company. Economic well-being originates in efficient production and it is distributed through the interaction between the company’s stakeholders. The stakeholders of companies are economic actors which have an economic interest in a company. Based on the similarities of their interests, stakeholders can be classified into three groups in order to differentiate their interests and mutual relations. The three groups are as follows:</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/0/02/Interactive_contributions_of_a_company%E2%80%99s_stakeholders.png/400px-Interactive_contributions_of_a_company%E2%80%99s_stakeholders.png" width="400" height="199"><p>


				Interactive contributions of a company’s stakeholders (Saari, 2011,4)


				 
				</p><p>
					The interests of these stakeholders and their relations to companies are described briefly below. Our purpose is to establish a framework for further analysis.</p><p>Customers</p><p>The customers of a company are typically consumers, other market producers or producers in the public sector. Each of them has their individual production functions. Due to competition, the price-quality-ratios of commodities tend to improve and this brings the benefits of better productivity to customers. Customers get more for less. In households and the public sector this means that more need satisfaction is achieved at less cost. For this reason the productivity of customers can increase over time even though their incomes remain unchanged.</p><p>Suppliers</p><p>The suppliers of companies are typically producers of materials, energy, capital, and services. They all have their individual production functions. The changes in prices or qualities of supplied commodities have an effect on both actors’ (company and suppliers) production functions. We come to the conclusion that the production functions of the company and its suppliers are in a state of continuous change.</p><p>Producer community</p><p>The incomes are generated for those participating in production, i.e., the labour force, society and owners. These stakeholders are referred to here as producer communities or, in shorter form, as producers. The producer communities have a common interest in maximizing their incomes. These parties that contribute to production receive increased incomes from the growing and developing production.</p><p>The well-being gained through commodities stems from the price-quality relations of the commodities. Due to competition and development in the market, the price-quality relations of commodities tend to improve over time. Typically the quality of a commodity goes up and the price goes down over time. This development favourably affects the production functions of customers. Customers get more for less. Consumer customers get more satisfaction at less cost. This type of well-being generation can only partially be calculated from the production data. The situation is presented in this study. The producer community (labour force, society, and owners) earns income as compensation for the inputs they have delivered to the production. When the production grows and becomes more efficient, the income tends to increase. In production this brings about an increased ability to pay salaries, taxes and profits. The growth of production and improved productivity generate additional income for the producing community. Similarly the high income level achieved in the community is a result of the high volume of production and its good performance. This type of well-being generation – as mentioned earlier - can be reliably calculated from the production data.</p><h3>Main processes of a producing company</h3><p>A producing company can be divided into sub-processes in different ways; yet, the following five are identified as main processes, each with a logic, objectives, theory and key figures of its own. It is important to examine each of them individually, yet, as a part of the whole, in order to be able to measure and understand them. The main processes of a company are as follows:</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/3/37/Main_processes_of_a_company.png/400px-Main_processes_of_a_company.png" width="400" height="223"><div class="gradientback"></div></div><div class="content"><p>


				Main processes of a producing company (Saari 2006,3)


				 
				</p><p>
					Production output is created in the real process, gains of production are distributed in the income distribution process and these two processes constitute the production process. The production process and its sub-processes, the real process and income distribution process occur simultaneously, and only the production process is identifiable and measurable by the traditional accounting practices. The real process and income distribution process can be identified and measured by extra calculation, and this is why they need to be analyzed separately in order to understand the logic of production and its performance.</p><p>Real process generates the production output from input, and it can be described by means of the production function. It refers to a series of events in production in which production inputs of different quality and quantity are combined into products of different quality and quantity. Products can be physical goods, immaterial services and most often combinations of both. The characteristics created into the product by the producer imply surplus value to the consumer, and on the basis of the market price this value is shared by the consumer and the producer in the marketplace. This is the mechanism through which surplus value originates to the consumer and the producer likewise. It is worth noting that surplus values to customers cannot be measured from any production data. Instead the surplus value to a producer can be measured. It can be expressed both in terms of nominal and real values. The real surplus value to the producer is an outcome of the real process, real income, and measured proportionally it means productivity.</p><p>The concept “real process” in the meaning quantitative structure of production process was introduced in Finnish management accounting in 1960´s. Since then it has been a cornerstone in the Finnish management accounting theory. (Riistama et al. 1971)</p><p>Income distribution process of the production refers to a series of events in which the unit prices of constant-quality products and inputs alter causing a change in income distribution among those participating in the exchange. The magnitude of the change in income distribution is directly proportionate to the change in prices of the output and inputs and to their quantities. Productivity gains are distributed, for example, to customers as lower product sales prices or to staff as higher income pay.</p><p>The production process consists of the real process and the income distribution process. A result and a criterion of success of the owner is profitability. The profitability of production is the share of the real process result the owner has been able to keep to himself in the income distribution process. Factors describing the production process are the components of profitability, i.e., returns and costs. They differ from the factors of the real process in that the components of profitability are given at nominal prices whereas in the real process the factors are at periodically fixed prices.</p><p>Monetary process refers to events related to financing the business. Market value process refers to a series of events in which investors determine the market value of the company in the investment markets.</p><h3>Production growth and performance</h3><p> Main article: Economic growth</p><p>Economic growth is often defined as a production increase of an output of a production process. It is usually expressed as a growth percentage depicting growth of the real production output. The real output is the real value of products produced in a production process and when we subtract the real input from the real output we get the real income. The real output and the real income are generated by the real process of production from the real inputs.</p><p>The real process can be described by means of the production function. The production function is a graphical or mathematical expression showing the relationship between the inputs used in production and the output achieved. Both graphical and mathematical expressions are presented and demonstrated. The production function is a simple description of the mechanism of income generation in production process. It consists of two components. These components are a change in production input and a change in productivity.[2]</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/0/00/Components_of_economic_growth.png/300px-Components_of_economic_growth.png" width="300" height="224"><p>


				Components of economic growth (Saari 2006,2)


				</p><p>
					The figure illustrates an income generation process(exaggerated for clarity). The Value T2 (value at time 2) represents the growth in output from Value T1 (value at time 1). Each time of measurement has its own graph of the production function for that time (the straight lines). The output measured at time 2 is greater than the output measured at time one for both of the components of growth: an increase of inputs and an increase of productivity. The portion of growth caused by the increase in inputs is shown on line 1 and does not change the relation between inputs and outputs. The portion of growth caused by an increase in productivity is shown on line 2 with a steeper slope. So increased productivity represents greater output per unit of input.</p><p>The growth of production output does not reveal anything about the performance of the production process. The performance of production measures production’s ability to generate income. Because the income from production is generated in the real process, we call it the real income. Similarly, as the production function is an expression of the real process, we could also call it “income generated by the production function”.</p><p>The real income generation follows the logic of the production function. Two components can also be distinguished in the income change: the income growth caused by an increase in production input (production volume) and the income growth caused by an increase in productivity. The income growth caused by increased production volume is determined by moving along the production function graph. The income growth corresponding to a shift of the production function is generated by the increase in productivity. The change of real income so signifies a move from the point 1 to the point 2 on the production function (above). When we want to maximize the production performance we have to maximize the income generated by the production function.</p><p>The sources of productivity growth and production volume growth are explained as follows. Productivity growth is seen as the key economic indicator of innovation. The successful introduction of new products and new or altered processes, organization structures, systems, and business models generates growth of output that exceeds the growth of inputs. This results in growth in productivity or output per unit of input. Income growth can also take place without innovation through replication of established technologies. With only replication and without innovation, output will increase in proportion to inputs. (Jorgenson et al. 2014,2) This is the case of income growth through production volume growth.</p><div class="gradientback"></div></div><div class="content"><p>Jorgenson et al. (2014,2) give an empiric example. They show that the great preponderance of economic growth in the US since 1947 involves the replication of existing technologies through investment in equipment, structures, and software and expansion of the labor force. Further they show that innovation accounts for only about twenty percent of US economic growth.</p><p>In the case of a single production process (described above) the output is defined as an economic value of products and services produced in the process. When we want to examine an entity of many production processes we have to sum up the value-added created in the single processes. This is done in order to avoid the double accounting of intermediate inputs. Value-added is obtained by subtracting the intermediate inputs from the outputs. The most well-known and used measure of value-added is the GDP (Gross Domestic Product). It is widely used as a measure of the economic growth of nations and industries.</p><h3>Absolute (total) and average income</h3><p>The production performance can be measured as an average or an absolute income. Expressing performance both in average (avg.) and absolute (abs.) quantities is helpful for understanding the welfare effects of production. For measurement of the average production performance, we use the known productivity ratio</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/f/f7/Average_and_marginal_productivity.png/400px-Average_and_marginal_productivity.png" width="400" height="267"><p>


				Average and marginal productivity (Saari 2011,8)


				 
				</p><p>
					The absolute income of performance is obtained by subtracting the real input from the real output as follows:</p><p>The growth of the real income is the increase of the economic value which can be distributed between the production stakeholders. With the aid of the production model we can perform the average and absolute accounting in one calculation. Maximizing production performance requires using the absolute measure, i.e. the real income and its derivatives as a criterion of production performance.</p><p>The differences between the absolute and average performance measures can be illustrated by the following graph showing marginal and average productivity. The figure is a traditional expression of average productivity and marginal productivity. The maximum for production performance is achieved at the volume where marginal productivity is zero. The maximum for production performance is the maximum of the real incomes. In this illustrative example the maximum real income is achieved, when the production volume is 7.5 units. The maximum average productivity is reached when the production volume is 3.0 units. It is worth noting that the maximum average productivity is not the same as the maximum of real income.</p><p>Figure above is a somewhat exaggerated depiction because the whole production function is shown. In practice, decisions are made in a limited range of the production functions, but the principle is still the same; the maximum real income is aimed for. An important conclusion can be drawn. When we try to maximize the welfare effects of production we have to maximize real income formation. Maximizing productivity leads to a suboptimum, i.e. to losses of incomes.</p><p>Maximizing productivity also leads to the phenomenon called jobless growth This refers to economic growth as a result of productivity growth but without creation of new jobs and new incomes from them. A practical example illustrates the case. When a jobless person obtains a job in market production we may assume it is a low productivity job. As a result, average productivity decreases but the real income per capita increases. Furthermore, the well-being of the society also grows. This example reveals the difficulty to interpret the total productivity change correctly. The combination of volume increase and total productivity decrease leads in this case to the improved performance because we are on the “diminishing returns” area of the production function. If we are on the part of “increasing returns” on the production function, the combination of production volume increase and total productivity increase leads to improved production performance. Unfortunately we do not know in practice on which part of the production function we are. Therefore, a correct interpretation of a performance change is obtained only by measuring the real income change.</p><h2>Production models</h2><p>A production model is a numerical description of the production process and is based on the prices and the quantities of inputs and outputs. There are two main approaches to operationalize the concept of production function. We can use mathematical formulae, which are typically used in macroeconomics (in growth accounting) or arithmetical models, which are typically used in microeconomics and management accounting. We do not present the former approach here but refer to the survey “Growth accounting” by Hulten 2009.</p><p>We use here arithmetical models because they are like the models of management accounting, illustrative and easily understood and applied in practice. Furthermore, they are integrated to management accounting, which is a practical advantage. A major advantage of the arithmetical model is its capability to depict production function as a part of production process. Consequently, production function can be understood, measured, and examined as a part of production process.</p><p>There are different production models according to different interests. Here we use a production income model and a production analysis model in order to demonstrate production function as a phenomenon and a measureable quantity.</p><h3>Production income model</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/0/0f/Profitability_of_production_measured_by_surplus_value.png/400px-Profitability_of_production_measured_by_surplus_value.png" width="400" height="245"><p>


				Profitability of production measured by surplus value (Saari 2006,3)


				</p><p>
					The scale of success run by a going concern is manifold, and there are no criteria that might be universally applicable to success. Nevertheless, there is one criterion by which we can generalise the rate of success in production. This criterion is the ability to produce surplus value. As a criterion of profitability, surplus value refers to the difference between returns and costs, taking into consideration the costs of equity in addition to the costs included in the profit and loss statement as usual. Surplus value indicates that the output has more value than the sacrifice made for it, in other words, the output value is higher than the value (production costs) of the used inputs. If the surplus value is positive, the owner’s profit expectation has been surpassed.</p><div class="gradientback"></div></div><div class="content"><p>The table presents a surplus value calculation. We call this set of production data a basic example and we use the data through the article in illustrative production models. The basic example is a simplified profitability calculation used for illustration and modelling. Even as reduced, it comprises all phenomena of a real measuring situation and most importantly the change in the output-input mix between two periods. Hence, the basic example works as an illustrative “scale model” of production without any features of a real measuring situation being lost. In practice, there may be hundreds of products and inputs but the logic of measuring does not differ from that presented in the basic example.</p><p>In this context we define the quality requirements for the production data used in productivity accounting. The most important criterion of good measurement is the homogenous quality of the measurement object. If the object is not homogenous, then the measurement result may include changes in both quantity and quality but their respective shares will remain unclear. In productivity accounting this criterion requires that every item of output and input must appear in accounting as being homogenous. In other words, the inputs and the outputs are not allowed to be aggregated in measuring and accounting. If they are aggregated, they are no longer homogenous and hence the measurement results may be biased.</p><p>Both the absolute and relative surplus value have been calculated in the example. Absolute value is the difference of the output and input values and the relative value is their relation, respectively. The surplus value calculation in the example is at a nominal price, calculated at the market price of each period.</p><h3>Production analysis model</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/e/e2/Productivity_model.png/350px-Productivity_model.png" width="350" height="459"><p>


				Production Model Saari 2004 (Saari 2006,4)


				</p><p>
					A model [3] used here is a typical production analysis model by help of which it is possible to calculate the outcome of the real process, income distribution process and production process. The starting point is a profitability calculation using surplus value as a criterion of profitability. The surplus value calculation is the only valid measure for understanding the connection between profitability and productivity or understanding the connection between real process and production process. A valid measurement of total productivity necessitates considering all production inputs, and the surplus value calculation is the only calculation to conform to the requirement. If we omit an input in productivity or income accounting, this means that the omitted input can be used unlimitedly in production without any cost impact on accounting results.</p><h3>Accounting and interpreting</h3><p>The process of calculating is best understood by applying the term ceteris paribus, i.e. all other things being the same, stating that at a time only the impact of one changing factor be introduced to the phenomenon being examined. Therefore, the calculation can be presented as a process advancing step by step. First, the impacts of the income distribution process are calculated, and then, the impacts of the real process on the profitability of the production.</p><p>The first step of the calculation is to separate the impacts of the real process and the income distribution process, respectively, from the change in profitability (285.12&nbsp;– 266.00 = 19.12). This takes place by simply creating one auxiliary column (4) in which a surplus value calculation is compiled using the quantities of Period 1 and the prices of Period 2. In the resulting profitability calculation, Columns 3 and 4 depict the impact of a change in income distribution process on the profitability and in Columns 4 and 7 the impact of a change in real process on the profitability.</p><p>The accounting results are easily interpreted and understood. We see that the real income has increased by 58.12 units from which 41.12 units come from the increase of productivity growth and the rest 17.00 units come from the production volume growth. The total increase of real income (58.12) is distributed to the stakeholders of production, in this case 39.00 units to the customers and to the suppliers of inputs and the rest 19.12 units to the owners.</p><p>Here we can make an important conclusion. Income formation of production is always a balance between income generation and income distribution. The income change created in a real process (i.e. by production function) is always distributed to the stakeholders as economic values within the review period. Accordingly, the changes in real income and income distribution are always equal in terms of economic value.</p><p>Based on the accounted changes of productivity and production volume values we can explicitly conclude on which part of the production function the production is. The rules of interpretations are the following:</p><p>The production is on the part of “increasing returns” on the production function, when</p><p>The production is on the part of “diminishing returns” on the production function, when</p><p>In the basic example the combination of volume growth (+17.00) and productivity growth (+41.12) reports explicitly that the production is on the part of “increasing returns” on the production function (Saari 2006 a, 138–144).</p><p>Another production model (Production Model Saari 1989) also gives details of the income distribution (Saari 2011,14). Because the accounting techniques of the two models are different, they give differing, although complementary, analytical information. The accounting results are, however, identical. We do not present the model here in detail but we only use its detailed data on income distribution, when the objective functions are formulated in the next section.</p><h2>Objective functions</h2><p>An efficient way to improve the understanding of production performance is to formulate different objective functions according to the objectives of the different interest groups. Formulating the objective function necessitates defining the variable to be maximized (or minimized). After that other variables are considered as constraints or free variables. The most familiar objective function is profit maximization which is also included in this case. Profit maximization is an objective function that stems from the owner’s interest and all other variables are constraints in relation to maximizing of profits.</p><div class="gradientback"></div></div><div class="content"><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/d/da/Income_formation.png/300px-Income_formation.png" width="300" height="152"><p>


				Summary of objective function formulations (Saari 2011,17)


				</p><h3>The procedure for formulating objective functions</h3><p>
					The procedure for formulating different objective functions, in terms of the production model, is introduced next. In the income formation from production the following objective functions can be identified:</p><p>These cases are illustrated using the numbers from the basic example. The following symbols are used in the presentation: The equal sign (=) signifies the starting point of the computation or the result of computing and the plus or minus sign (+ / -) signifies a variable that is to be added or subtracted from the function. A producer means here the producer community, i.e. labour force, society and owners.</p><p>Objective function formulations can be expressed in a single calculation which concisely illustrates the logic of the income generation, the income distribution and the variables to be maximized.</p><p>The calculation resembles an income statement starting with the income generation and ending with the income distribution. The income generation and the distribution are always in balance so that their amounts are equal. In this case it is 58.12 units. The income which has been generated in the real process is distributed to the stakeholders during the same period. There are three variables which can be maximized. They are the real income, the producer income and the owner income. Producer income and owner income are practical quantities because they are addable quantities and they can be computed quite easily. Real income is normally not an addable quantity and in many cases it is difficult to calculate.</p><h3>The dual approach for the formulation</h3><p>Here we have to add that the change of real income can also be computed from the changes in income distribution. We have to identify the unit price changes of outputs and inputs and calculate their profit impacts (i.e. unit price change x quantity). The change of real income is the sum of these profit impacts and the change of owner income. This approach is called the dual approach because the framework is seen in terms of prices instead of quantities (ONS 3, 23).</p><p>The dual approach has been recognized in growth accounting for long but its interpretation has remained unclear. The following question has remained unanswered: “Quantity based estimates of the residual are interpreted as a shift in the production function, but what is the interpretation of the price-based growth estimates?” (Hulten 2009, 18). We have demonstrated above that the real income change is achieved by quantitative changes in production and the income distribution change to the stakeholders is its dual. In this case the duality means that the same accounting result is obtained by accounting the change of the total income generation (real income) and by accounting the change of the total income distribution.</p><h2>Footnotes</h2><h2>Further references and external links</h2><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Production_(economics)&amp;oldid=776641833"					
								Categories:  Hidden categories:</p><br><h1 lang="en">Consumption (economics)</h1><p> From Wikipedia, the free encyclopedia</p><p>Consumption is major concept in economics and is also studied by many other social sciences. Economists are particularly interested in the relationship between consumption and income, as modeled with the consumption function.</p><p>Different schools of economists define production and consumption differently. According to mainstream economists, only the final purchase of goods and services by individuals constitutes consumption, while other types of expenditure — in particular, fixed investment, intermediate consumption, and government spending — are placed in separate categories (See consumer choice). Other economists define consumption much more broadly, as the aggregate of all economic activity that does not entail the design, production and marketing of goods and services (e.g. the selection, adoption, use, disposal and recycling of goods and services).[citation needed]</p><h2>Contents</h2><h2>Consumption function</h2><p> Main article: Consumption function</p><p>The consumption function is a mathematical function that expresses consumer spending in terms of its determinants, such as income and accumulated wealth.</p><h2>Behavioural economics and consumption</h2><p>The Keynesian consumption function is also known as the absolute income hypothesis, as it only bases consumption on current income and ignores potential future income (or lack of). Criticism of this assumption led to the development of Milton Friedman's permanent income hypothesis and Franco Modigliani's life cycle hypothesis. More recent theoretical approaches are based on behavioral economics and suggest that a number of behavioural principles can be taken as microeconomic foundations for a behaviourally-based aggregate consumption function.[1]</p><h2>Consumption and household production</h2><p>Consumption is defined in part by comparison to production. In the tradition of the Columbia School of Household Economics, also known as the New Home Economics, commercial consumption has to be analyzed in the context of household production. The opportunity cost of time affects the cost of home-produced substitutes and therefore demand for commercial goods and services.[2][3] The elasticity of demand for consumption goods is also a function of who performs chores in households and how their spouses compensate them for opportunity costs of home production.[4]</p><p>Different schools of economists define production and consumption differently. According to mainstream economists, only the final purchase of goods and services by individuals constitutes consumption, while other types of expenditure — in particular, fixed investment, intermediate consumption, and government spending — are placed in separate categories (See consumer choice). Other economists define consumption much more broadly, as the aggregate of all economic activity that does not entail the design, production and marketing of goods and services (e.g. the selection, adoption, use, disposal and recycling of goods and services).[citation needed]</p><div class="gradientback"></div></div><div class="content"><p>Consumption can also be measured by a variety of different ways such as energy in energy economics metrics.</p><h2>Effects of consumption</h2><p>Aggregate consumption is a component of aggregate demand.[5] According to the UN, today’s consumption is undermining the environmental resource base. It is exacerbating inequalities. And the dynamics of the consumption-poverty-inequality-environment nexus are accelerating. If the trends continue without change — not redistributing from high-income to low-income consumers, not shifting from polluting to cleaner goods and production technologies, not shifting priority from consumption for conspicuous display to meeting basic needs — today’s problems of consumption and human development will worsen. Developing countries like India, as they move down the path of copying the consumption patterns of developed economies, will basically create demands that earth will not be able to fulfill. Some economists[who?] talk about putting a price on using earth's resources which is in addition to the cost of just extracting them.</p><h2>Old-age spending</h2><p>Spending the Kids' Inheritance (originally the title of a book on the subject by Annie Hulley) and the acronyms SKI and SKI'ing refer to the growing number of older people in Western society spending their money on travel, cars and property, in contrast to previous generations who tended to leave that money to their children.</p><p>Die Broke (from the book Die Broke: A Radical Four-Part Financial Plan by Stephen Pollan and Mark Levine) is a similar idea.</p><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Consumption_(economics)&amp;oldid=781344074"					
								Categories:  Hidden categories:</p><br><h1 lang="en">Production (economics)</h1><p> From Wikipedia, the free encyclopedia</p><p>Production is a process of workers combining various material inputs and immaterial inputs (plans, know-how) in order to make something for consumption (the output). It is the act of creating output, a good or service which has value and contributes to the utility of individuals.[1]</p><p>Economic well-being is created in a production process, meaning all economic activities that aim directly or indirectly to satisfy human wants and needs. The degree to which the needs are satisfied is often accepted as a measure of economic well-being. In production there are two features which explain increasing economic well-being. They are improving quality-price-ratio of goods and services and increasing incomes from growing and more efficient market production.</p><p>The most important forms of production are</p><p>In order to understand the origin of the economic well-being we must understand these three production processes. All of them produce commodities which have value and contribute to well-being of individuals.</p><p>The satisfaction of needs originates from the use of the commodities which are produced. The need satisfaction increases when the quality-price-ratio of the commodities improves and more satisfaction is achieved at less cost. Improving the quality-price-ratio of commodities is to a producer an essential way to improve the competitiveness of products but this kind of gains distributed to customers cannot be measured with production data. Improving the competitiveness of products means often to the producer lower product prices and therefore losses in incomes which are to compensated with the growth of sales volume.</p><p>Economic well-being also increases due to the growth of incomes that are gained from the growing and more efficient market production. Market production is the only production form which creates and distributes incomes to stakeholders. Public production and household production are financed by the incomes generated in market production. Thus market production has a double role in creating well-being, i.e. the role of producing goods and services and the role of creating income. Because of this double role market production is the “primus motor” of economic well-being and therefore here under review.[citation needed]</p><h2>Contents</h2><h2>As a source of economic well-being</h2><p>In principle there are two main activities in an economy, production and consumption. Similarly there are two kinds of actors, producers and consumers. Well-being is made possible by efficient production and by the interaction between producers and consumers. In the interaction, consumers can be identified in two roles both of which generate well-being. Consumers can be both customers of the producers and suppliers to the producers. The customers’ well-being arises from the commodities they are buying and the suppliers’ well-being is related to the income they receive as compensation for the production inputs they have delivered to the producers.</p><h3>Stakeholders of production</h3><p>Stakeholders of production are persons, groups or organizations with an interest in a producing company. Economic well-being originates in efficient production and it is distributed through the interaction between the company’s stakeholders. The stakeholders of companies are economic actors which have an economic interest in a company. Based on the similarities of their interests, stakeholders can be classified into three groups in order to differentiate their interests and mutual relations. The three groups are as follows:</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/0/02/Interactive_contributions_of_a_company%E2%80%99s_stakeholders.png/400px-Interactive_contributions_of_a_company%E2%80%99s_stakeholders.png" width="400" height="199"><p>


				Interactive contributions of a company’s stakeholders (Saari, 2011,4)


				 
				</p><p>
					The interests of these stakeholders and their relations to companies are described briefly below. Our purpose is to establish a framework for further analysis.</p><p>Customers</p><p>The customers of a company are typically consumers, other market producers or producers in the public sector. Each of them has their individual production functions. Due to competition, the price-quality-ratios of commodities tend to improve and this brings the benefits of better productivity to customers. Customers get more for less. In households and the public sector this means that more need satisfaction is achieved at less cost. For this reason the productivity of customers can increase over time even though their incomes remain unchanged.</p><p>Suppliers</p><p>The suppliers of companies are typically producers of materials, energy, capital, and services. They all have their individual production functions. The changes in prices or qualities of supplied commodities have an effect on both actors’ (company and suppliers) production functions. We come to the conclusion that the production functions of the company and its suppliers are in a state of continuous change.</p><div class="gradientback"></div></div><div class="content"><p>Producer community</p><p>The incomes are generated for those participating in production, i.e., the labour force, society and owners. These stakeholders are referred to here as producer communities or, in shorter form, as producers. The producer communities have a common interest in maximizing their incomes. These parties that contribute to production receive increased incomes from the growing and developing production.</p><p>The well-being gained through commodities stems from the price-quality relations of the commodities. Due to competition and development in the market, the price-quality relations of commodities tend to improve over time. Typically the quality of a commodity goes up and the price goes down over time. This development favourably affects the production functions of customers. Customers get more for less. Consumer customers get more satisfaction at less cost. This type of well-being generation can only partially be calculated from the production data. The situation is presented in this study. The producer community (labour force, society, and owners) earns income as compensation for the inputs they have delivered to the production. When the production grows and becomes more efficient, the income tends to increase. In production this brings about an increased ability to pay salaries, taxes and profits. The growth of production and improved productivity generate additional income for the producing community. Similarly the high income level achieved in the community is a result of the high volume of production and its good performance. This type of well-being generation – as mentioned earlier - can be reliably calculated from the production data.</p><h3>Main processes of a producing company</h3><p>A producing company can be divided into sub-processes in different ways; yet, the following five are identified as main processes, each with a logic, objectives, theory and key figures of its own. It is important to examine each of them individually, yet, as a part of the whole, in order to be able to measure and understand them. The main processes of a company are as follows:</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/3/37/Main_processes_of_a_company.png/400px-Main_processes_of_a_company.png" width="400" height="223"><p>


				Main processes of a producing company (Saari 2006,3)


				 
				</p><p>
					Production output is created in the real process, gains of production are distributed in the income distribution process and these two processes constitute the production process. The production process and its sub-processes, the real process and income distribution process occur simultaneously, and only the production process is identifiable and measurable by the traditional accounting practices. The real process and income distribution process can be identified and measured by extra calculation, and this is why they need to be analyzed separately in order to understand the logic of production and its performance.</p><p>Real process generates the production output from input, and it can be described by means of the production function. It refers to a series of events in production in which production inputs of different quality and quantity are combined into products of different quality and quantity. Products can be physical goods, immaterial services and most often combinations of both. The characteristics created into the product by the producer imply surplus value to the consumer, and on the basis of the market price this value is shared by the consumer and the producer in the marketplace. This is the mechanism through which surplus value originates to the consumer and the producer likewise. It is worth noting that surplus values to customers cannot be measured from any production data. Instead the surplus value to a producer can be measured. It can be expressed both in terms of nominal and real values. The real surplus value to the producer is an outcome of the real process, real income, and measured proportionally it means productivity.</p><p>The concept “real process” in the meaning quantitative structure of production process was introduced in Finnish management accounting in 1960´s. Since then it has been a cornerstone in the Finnish management accounting theory. (Riistama et al. 1971)</p><p>Income distribution process of the production refers to a series of events in which the unit prices of constant-quality products and inputs alter causing a change in income distribution among those participating in the exchange. The magnitude of the change in income distribution is directly proportionate to the change in prices of the output and inputs and to their quantities. Productivity gains are distributed, for example, to customers as lower product sales prices or to staff as higher income pay.</p><p>The production process consists of the real process and the income distribution process. A result and a criterion of success of the owner is profitability. The profitability of production is the share of the real process result the owner has been able to keep to himself in the income distribution process. Factors describing the production process are the components of profitability, i.e., returns and costs. They differ from the factors of the real process in that the components of profitability are given at nominal prices whereas in the real process the factors are at periodically fixed prices.</p><p>Monetary process refers to events related to financing the business. Market value process refers to a series of events in which investors determine the market value of the company in the investment markets.</p><h3>Production growth and performance</h3><p> Main article: Economic growth</p><p>Economic growth is often defined as a production increase of an output of a production process. It is usually expressed as a growth percentage depicting growth of the real production output. The real output is the real value of products produced in a production process and when we subtract the real input from the real output we get the real income. The real output and the real income are generated by the real process of production from the real inputs.</p><p>The real process can be described by means of the production function. The production function is a graphical or mathematical expression showing the relationship between the inputs used in production and the output achieved. Both graphical and mathematical expressions are presented and demonstrated. The production function is a simple description of the mechanism of income generation in production process. It consists of two components. These components are a change in production input and a change in productivity.[2]</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/0/00/Components_of_economic_growth.png/300px-Components_of_economic_growth.png" width="300" height="224"><div class="gradientback"></div></div><div class="content"><p>


				Components of economic growth (Saari 2006,2)


				</p><p>
					The figure illustrates an income generation process(exaggerated for clarity). The Value T2 (value at time 2) represents the growth in output from Value T1 (value at time 1). Each time of measurement has its own graph of the production function for that time (the straight lines). The output measured at time 2 is greater than the output measured at time one for both of the components of growth: an increase of inputs and an increase of productivity. The portion of growth caused by the increase in inputs is shown on line 1 and does not change the relation between inputs and outputs. The portion of growth caused by an increase in productivity is shown on line 2 with a steeper slope. So increased productivity represents greater output per unit of input.</p><p>The growth of production output does not reveal anything about the performance of the production process. The performance of production measures production’s ability to generate income. Because the income from production is generated in the real process, we call it the real income. Similarly, as the production function is an expression of the real process, we could also call it “income generated by the production function”.</p><p>The real income generation follows the logic of the production function. Two components can also be distinguished in the income change: the income growth caused by an increase in production input (production volume) and the income growth caused by an increase in productivity. The income growth caused by increased production volume is determined by moving along the production function graph. The income growth corresponding to a shift of the production function is generated by the increase in productivity. The change of real income so signifies a move from the point 1 to the point 2 on the production function (above). When we want to maximize the production performance we have to maximize the income generated by the production function.</p><p>The sources of productivity growth and production volume growth are explained as follows. Productivity growth is seen as the key economic indicator of innovation. The successful introduction of new products and new or altered processes, organization structures, systems, and business models generates growth of output that exceeds the growth of inputs. This results in growth in productivity or output per unit of input. Income growth can also take place without innovation through replication of established technologies. With only replication and without innovation, output will increase in proportion to inputs. (Jorgenson et al. 2014,2) This is the case of income growth through production volume growth.</p><p>Jorgenson et al. (2014,2) give an empiric example. They show that the great preponderance of economic growth in the US since 1947 involves the replication of existing technologies through investment in equipment, structures, and software and expansion of the labor force. Further they show that innovation accounts for only about twenty percent of US economic growth.</p><p>In the case of a single production process (described above) the output is defined as an economic value of products and services produced in the process. When we want to examine an entity of many production processes we have to sum up the value-added created in the single processes. This is done in order to avoid the double accounting of intermediate inputs. Value-added is obtained by subtracting the intermediate inputs from the outputs. The most well-known and used measure of value-added is the GDP (Gross Domestic Product). It is widely used as a measure of the economic growth of nations and industries.</p><h3>Absolute (total) and average income</h3><p>The production performance can be measured as an average or an absolute income. Expressing performance both in average (avg.) and absolute (abs.) quantities is helpful for understanding the welfare effects of production. For measurement of the average production performance, we use the known productivity ratio</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/f/f7/Average_and_marginal_productivity.png/400px-Average_and_marginal_productivity.png" width="400" height="267"><p>


				Average and marginal productivity (Saari 2011,8)


				 
				</p><p>
					The absolute income of performance is obtained by subtracting the real input from the real output as follows:</p><p>The growth of the real income is the increase of the economic value which can be distributed between the production stakeholders. With the aid of the production model we can perform the average and absolute accounting in one calculation. Maximizing production performance requires using the absolute measure, i.e. the real income and its derivatives as a criterion of production performance.</p><p>The differences between the absolute and average performance measures can be illustrated by the following graph showing marginal and average productivity. The figure is a traditional expression of average productivity and marginal productivity. The maximum for production performance is achieved at the volume where marginal productivity is zero. The maximum for production performance is the maximum of the real incomes. In this illustrative example the maximum real income is achieved, when the production volume is 7.5 units. The maximum average productivity is reached when the production volume is 3.0 units. It is worth noting that the maximum average productivity is not the same as the maximum of real income.</p><p>Figure above is a somewhat exaggerated depiction because the whole production function is shown. In practice, decisions are made in a limited range of the production functions, but the principle is still the same; the maximum real income is aimed for. An important conclusion can be drawn. When we try to maximize the welfare effects of production we have to maximize real income formation. Maximizing productivity leads to a suboptimum, i.e. to losses of incomes.</p><p>Maximizing productivity also leads to the phenomenon called jobless growth This refers to economic growth as a result of productivity growth but without creation of new jobs and new incomes from them. A practical example illustrates the case. When a jobless person obtains a job in market production we may assume it is a low productivity job. As a result, average productivity decreases but the real income per capita increases. Furthermore, the well-being of the society also grows. This example reveals the difficulty to interpret the total productivity change correctly. The combination of volume increase and total productivity decrease leads in this case to the improved performance because we are on the “diminishing returns” area of the production function. If we are on the part of “increasing returns” on the production function, the combination of production volume increase and total productivity increase leads to improved production performance. Unfortunately we do not know in practice on which part of the production function we are. Therefore, a correct interpretation of a performance change is obtained only by measuring the real income change.</p><h2>Production models</h2><div class="gradientback"></div></div><div class="content"><p>A production model is a numerical description of the production process and is based on the prices and the quantities of inputs and outputs. There are two main approaches to operationalize the concept of production function. We can use mathematical formulae, which are typically used in macroeconomics (in growth accounting) or arithmetical models, which are typically used in microeconomics and management accounting. We do not present the former approach here but refer to the survey “Growth accounting” by Hulten 2009.</p><p>We use here arithmetical models because they are like the models of management accounting, illustrative and easily understood and applied in practice. Furthermore, they are integrated to management accounting, which is a practical advantage. A major advantage of the arithmetical model is its capability to depict production function as a part of production process. Consequently, production function can be understood, measured, and examined as a part of production process.</p><p>There are different production models according to different interests. Here we use a production income model and a production analysis model in order to demonstrate production function as a phenomenon and a measureable quantity.</p><h3>Production income model</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/0/0f/Profitability_of_production_measured_by_surplus_value.png/400px-Profitability_of_production_measured_by_surplus_value.png" width="400" height="245"><p>


				Profitability of production measured by surplus value (Saari 2006,3)


				</p><p>
					The scale of success run by a going concern is manifold, and there are no criteria that might be universally applicable to success. Nevertheless, there is one criterion by which we can generalise the rate of success in production. This criterion is the ability to produce surplus value. As a criterion of profitability, surplus value refers to the difference between returns and costs, taking into consideration the costs of equity in addition to the costs included in the profit and loss statement as usual. Surplus value indicates that the output has more value than the sacrifice made for it, in other words, the output value is higher than the value (production costs) of the used inputs. If the surplus value is positive, the owner’s profit expectation has been surpassed.</p><p>The table presents a surplus value calculation. We call this set of production data a basic example and we use the data through the article in illustrative production models. The basic example is a simplified profitability calculation used for illustration and modelling. Even as reduced, it comprises all phenomena of a real measuring situation and most importantly the change in the output-input mix between two periods. Hence, the basic example works as an illustrative “scale model” of production without any features of a real measuring situation being lost. In practice, there may be hundreds of products and inputs but the logic of measuring does not differ from that presented in the basic example.</p><p>In this context we define the quality requirements for the production data used in productivity accounting. The most important criterion of good measurement is the homogenous quality of the measurement object. If the object is not homogenous, then the measurement result may include changes in both quantity and quality but their respective shares will remain unclear. In productivity accounting this criterion requires that every item of output and input must appear in accounting as being homogenous. In other words, the inputs and the outputs are not allowed to be aggregated in measuring and accounting. If they are aggregated, they are no longer homogenous and hence the measurement results may be biased.</p><p>Both the absolute and relative surplus value have been calculated in the example. Absolute value is the difference of the output and input values and the relative value is their relation, respectively. The surplus value calculation in the example is at a nominal price, calculated at the market price of each period.</p><h3>Production analysis model</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/e/e2/Productivity_model.png/350px-Productivity_model.png" width="350" height="459"><p>


				Production Model Saari 2004 (Saari 2006,4)


				</p><p>
					A model [3] used here is a typical production analysis model by help of which it is possible to calculate the outcome of the real process, income distribution process and production process. The starting point is a profitability calculation using surplus value as a criterion of profitability. The surplus value calculation is the only valid measure for understanding the connection between profitability and productivity or understanding the connection between real process and production process. A valid measurement of total productivity necessitates considering all production inputs, and the surplus value calculation is the only calculation to conform to the requirement. If we omit an input in productivity or income accounting, this means that the omitted input can be used unlimitedly in production without any cost impact on accounting results.</p><h3>Accounting and interpreting</h3><p>The process of calculating is best understood by applying the term ceteris paribus, i.e. all other things being the same, stating that at a time only the impact of one changing factor be introduced to the phenomenon being examined. Therefore, the calculation can be presented as a process advancing step by step. First, the impacts of the income distribution process are calculated, and then, the impacts of the real process on the profitability of the production.</p><p>The first step of the calculation is to separate the impacts of the real process and the income distribution process, respectively, from the change in profitability (285.12&nbsp;– 266.00 = 19.12). This takes place by simply creating one auxiliary column (4) in which a surplus value calculation is compiled using the quantities of Period 1 and the prices of Period 2. In the resulting profitability calculation, Columns 3 and 4 depict the impact of a change in income distribution process on the profitability and in Columns 4 and 7 the impact of a change in real process on the profitability.</p><div class="gradientback"></div></div><div class="content"><p>The accounting results are easily interpreted and understood. We see that the real income has increased by 58.12 units from which 41.12 units come from the increase of productivity growth and the rest 17.00 units come from the production volume growth. The total increase of real income (58.12) is distributed to the stakeholders of production, in this case 39.00 units to the customers and to the suppliers of inputs and the rest 19.12 units to the owners.</p><p>Here we can make an important conclusion. Income formation of production is always a balance between income generation and income distribution. The income change created in a real process (i.e. by production function) is always distributed to the stakeholders as economic values within the review period. Accordingly, the changes in real income and income distribution are always equal in terms of economic value.</p><p>Based on the accounted changes of productivity and production volume values we can explicitly conclude on which part of the production function the production is. The rules of interpretations are the following:</p><p>The production is on the part of “increasing returns” on the production function, when</p><p>The production is on the part of “diminishing returns” on the production function, when</p><p>In the basic example the combination of volume growth (+17.00) and productivity growth (+41.12) reports explicitly that the production is on the part of “increasing returns” on the production function (Saari 2006 a, 138–144).</p><p>Another production model (Production Model Saari 1989) also gives details of the income distribution (Saari 2011,14). Because the accounting techniques of the two models are different, they give differing, although complementary, analytical information. The accounting results are, however, identical. We do not present the model here in detail but we only use its detailed data on income distribution, when the objective functions are formulated in the next section.</p><h2>Objective functions</h2><p>An efficient way to improve the understanding of production performance is to formulate different objective functions according to the objectives of the different interest groups. Formulating the objective function necessitates defining the variable to be maximized (or minimized). After that other variables are considered as constraints or free variables. The most familiar objective function is profit maximization which is also included in this case. Profit maximization is an objective function that stems from the owner’s interest and all other variables are constraints in relation to maximizing of profits.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/d/da/Income_formation.png/300px-Income_formation.png" width="300" height="152"><p>


				Summary of objective function formulations (Saari 2011,17)


				</p><h3>The procedure for formulating objective functions</h3><p>
					The procedure for formulating different objective functions, in terms of the production model, is introduced next. In the income formation from production the following objective functions can be identified:</p><p>These cases are illustrated using the numbers from the basic example. The following symbols are used in the presentation: The equal sign (=) signifies the starting point of the computation or the result of computing and the plus or minus sign (+ / -) signifies a variable that is to be added or subtracted from the function. A producer means here the producer community, i.e. labour force, society and owners.</p><p>Objective function formulations can be expressed in a single calculation which concisely illustrates the logic of the income generation, the income distribution and the variables to be maximized.</p><p>The calculation resembles an income statement starting with the income generation and ending with the income distribution. The income generation and the distribution are always in balance so that their amounts are equal. In this case it is 58.12 units. The income which has been generated in the real process is distributed to the stakeholders during the same period. There are three variables which can be maximized. They are the real income, the producer income and the owner income. Producer income and owner income are practical quantities because they are addable quantities and they can be computed quite easily. Real income is normally not an addable quantity and in many cases it is difficult to calculate.</p><h3>The dual approach for the formulation</h3><p>Here we have to add that the change of real income can also be computed from the changes in income distribution. We have to identify the unit price changes of outputs and inputs and calculate their profit impacts (i.e. unit price change x quantity). The change of real income is the sum of these profit impacts and the change of owner income. This approach is called the dual approach because the framework is seen in terms of prices instead of quantities (ONS 3, 23).</p><p>The dual approach has been recognized in growth accounting for long but its interpretation has remained unclear. The following question has remained unanswered: “Quantity based estimates of the residual are interpreted as a shift in the production function, but what is the interpretation of the price-based growth estimates?” (Hulten 2009, 18). We have demonstrated above that the real income change is achieved by quantitative changes in production and the income distribution change to the stakeholders is its dual. In this case the duality means that the same accounting result is obtained by accounting the change of the total income generation (real income) and by accounting the change of the total income distribution.</p><h2>Footnotes</h2><h2>Further references and external links</h2><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Production_(economics)&amp;oldid=776641833"					
								Categories:  Hidden categories:</p><br><h1 lang="en">Agent (economics)</h1><p> From Wikipedia, the free encyclopedia</p><p>In economics, an agent is an actor and more specifically a decision maker in a model of some aspect of the economy. Typically, every agent makes decisions by solving a well or ill-defined optimization or choice problem.</p><p>For example, buyers and sellers are two common types of agents in partial equilibrium models of a single market. Macroeconomic models, especially dynamic stochastic general equilibrium models that are explicitly based on microfoundations, often distinguish households, firms, and governments or central banks as the main types of agents in the economy. Each of these agents may play multiple roles in the economy; households, for example, might act as consumers, as workers, and as voters in the model. Some macroeconomic models distinguish even more types of agents, such as workers and shoppers[1] or commercial banks.[2]</p><div class="gradientback"></div></div><div class="content"><p>The term agent is also used in relation to principal–agent models; in this case it refers specifically to someone delegated to act on behalf of a principal.[3]</p><p>In agent-based computational economics, corresponding agents are computational objects modeled as interacting according to rules over space and time, not real people. The rules are formulated to model behavior and social interactions based on stipulated incentives and information.[4] The concept of an agent may be broadly interpreted to be any persistent individual, social, biological, or physical entity interacting with other such entities in the context of a dynamic multi-agent economic system.</p><h2>Contents</h2><h2>Representative vs. heterogenous agents</h2><p>An economic model in which all agents of a given type (such as all consumers, or all firms) are assumed to be exactly identical is called a representative agent model. A model which recognizes differences among agents is called a heterogeneous agent model. Economists often use representative agent models when they want to describe the economy in the simplest terms possible. In contrast, they may be obliged to use heterogeneous agent models when differences among agents are directly relevant for the question at hand.[5] For example, considering heterogeneity in age is likely to be necessary in a model used to study the economic effects of pensions;[6] considering heterogeneity in wealth is likely to be necessary in a model used to study precautionary saving[7] or redistributive taxation.[8]</p><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Agent_(economics)&amp;oldid=780715784"					
								Categories:  				
											
						<br>
							

											 
										

							</p><br><h1 lang="en">Microeconomics</h1><p> From Wikipedia, the free encyclopedia</p><p> Further information: Evolution of microeconomics</p><p>Microeconomics (from Greek prefix mikro- meaning small) is a branch of economics that studies the behavior of individuals and firms in making decisions regarding the allocation of scarce resources and the interactions among these individuals and firms.[1][2][3]</p><p>One goal of microeconomics is to analyze the market mechanisms that establish relative prices among goods and services and allocate limited resources among alternative uses. Microeconomics shows conditions under which free markets lead to desirable allocations. It also analyzes market failure, where markets fail to produce efficient results.</p><p>Microeconomics stands in contrast to macroeconomics, which involves the sum total of economic activity, dealing with the issues of growth, inflation, and unemployment and with national policies relating to these issues.[2] Microeconomics also deals with the effects of economic policies (such as changing taxation levels) on the aforementioned aspects of the economy.[4] Particularly in the wake of the Lucas critique, much of modern macroeconomic theory has been built upon 'microfoundations'—i.e. based upon basic assumptions about micro-level behavior.</p><h2>Contents</h2><h2>Assumptions and definitions</h2><p>Microeconomic theory typically begins with the study of a single rational and utility maximizing individual. To economists, rationality means an individual possesses stable preferences that are both complete and transitive. The technical assumption that preference relations are continuous is needed to ensure the existence of a utility function. Although microeconomic theory can continue without this assumption, it would make comparative statics impossible since there is no guarantee that the resulting utility function would be differentiable.</p><p>Microeconomic theory progresses by defining a competitive budget set which is a subset of the consumption set. It is at this point that economists make the technical assumption that preferences are locally non-satiated. Without the assumption of LNS (local non-satiation) there is no guarantee that a rational individual would maximize utility. With the necessary tools and assumptions in place the utility maximization problem (UMP) is developed.</p><p>The utility maximization problem is the heart of consumer theory. The utility maximization problem attempts to explain the action axiom by imposing rationality axioms on consumer preferences and then mathematically modeling and analyzing the consequences. The utility maximization problem serves not only as the mathematical foundation of consumer theory but as a metaphysical explanation of it as well. That is, the utility maximization problem is used by economists to not only explain what or how individuals make choices but why individuals make choices as well.</p><p>The utility maximization problem is a constrained optimization problem in which an individual seeks to maximize utility subject to a budget constraint. Economists use the extreme value theorem to guarantee that a solution to the utility maximization problem exists. That is, since the budget constraint is both bounded and closed, a solution to the utility maximization problem exists. Economists call the solution to the utility maximization problem a Walrasian demand function or correspondence.</p><p>The utility maximization problem has so far been developed by taking consumer tastes (i.e. consumer utility) as the primitive. However, an alternative way to develop microeconomic theory is by taking consumer choice as the primitive. This model of microeconomic theory is referred to as Revealed preference theory.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/e/eb/Supply-demand-right-shift-demand.svg/220px-Supply-demand-right-shift-demand.svg.png" width="220" height="220"><p>


				The supply and demand model describes how prices vary as a result of a balance between product availability at each price (supply) and the desires of those with purchasing power at each price (demand). The graph depicts a right-shift in demand from D1 to D2 along with the consequent increase in price and quantity required to reach a new market-clearing equilibrium point on the supply curve (S).


				</p><p>
					The theory of supply and demand usually assumes that markets are perfectly competitive. This implies that there are many buyers and sellers in the market and none of them have the capacity to significantly influence prices of goods and services. In many real-life transactions, the assumption fails because some individual buyers or sellers have the ability to influence prices. Quite often, a sophisticated analysis is required to understand the demand-supply equation of a good model. However, the theory works well in situations meeting these assumptions.</p><p>Mainstream economics does not assume a priori that markets are preferable to other forms of social organization. In fact, much analysis is devoted to cases where market failures lead to resource allocation that is suboptimal and creates deadweight loss. A classic example of suboptimal resource allocation is that of a public good. In such cases, economists may attempt to find policies that avoid waste, either directly by government control, indirectly by regulation that induces market participants to act in a manner consistent with optimal welfare, or by creating missing markets to enable efficient trading where none had previously existed.</p><p>This is studied in the field of collective action and public choice theory. Optimal welfare usually takes on a Paretian norm, which is a mathematical application of the Kaldor–Hicks method. This can diverge from the Utilitarian goal of maximizing utility because it does not consider the distribution of goods between people. Market failure in positive economics (microeconomics) is limited in implications without mixing the belief of the economist and their theory.</p><div class="gradientback"></div></div><div class="content"><p>The demand for various commodities by individuals is generally thought of as the outcome of a utility-maximizing process, with each individual trying to maximize their own utility under a budget constraint and a given consumption set.</p><p>
				Microeconomic theories are involved with the choices that households and firms make. Some of these microeconomic concepts include elasticity of demand and supply, market structures and utility. Microeconomic looks into the way individuals and businesses behave in coming up with decisions to do with the distribution of rare resources and collaborations between these individuals and the firm. A production possibility frontier illustrates the maximum probable output combinations of two services or goods an economy may realise while all other resources are efficiently and wholly engaged. A production possibility frontier is used to explain the models of opportunity cost, illustrate the effects of economic development and demonstrate the theory of trade-offs.</p><p>Supply and demand is possibly amongst the most crucial conceptions of economics and it is the pillar of the economy of a market. Demand can be explained as the extent to which a service or a good is desired by users. The amount demanded is the sum of a commodity individuals are ready to purchase at a certain given price. Supply on the other hand refers to how much of a product a market can provide. The supplied quantity is the volume of a particular commodity manufacturers are willing to supply at a certain price. The relationship between demand and supply trigger the forces as a result of the sharing of resources. The law of demand states that when all other influences stay constant the higher the price of a good, the lesser the demand of the given produce. In other word the greater the price the lower the amount needed. The amount of a good bought by customers at a greater price is lower as the price rises the opportunity cost of buying a commodity. People will therefore naturally evade buying a commodity that will need them to sacrifice the use of something else that is more significant to them. Similar to the law of demand, the law of supply reveals the amounts that will be traded at a certain given price. Contrasting the law of demand, the supply relationship gives a rising slope. This means that the bigger the price the greater the quantity in supply. Manufacturers supply more at a high price because selling a quantity at a higher price rises income. Where demand and supply are the same, the economy is held to be at equilibrium. At the point of equilibrium the distribution of goods is at its most effectual because the amount of goods at supply is precisely the same as the volume of goods in demand. Therefore every individual is contented with prevailing state of the economy.</p><p>Elasticity is defined as the degree of receptiveness in demand and supply in relation to fluctuations in price. If a curve is more elastic then lesser alterations in price will result to a higher change in quantity used up. If a curve is less elastic it will then cause higher deviations in price to affect a change in amount consumed. Price elasticity of demand is the extent of responsiveness in quantity demanded in relation to price. Utility on the other hand is the amount of contentment resulting from the consumption of a commodity or services at a particular period. Utility is a psychological satisfaction not inherent. It is dependent on the persons own subjective approximate of satisfaction to be acquired from the consumption of a commodity. Utility is further divided into marginal utility, total utility and maximizing utility. Marginal utility refers to the extra utility resulting from the consumption of one extra unit of a commodity, the consumption of the rest of the goods remaining unaffected. Total utility is refers to as the number of units of utility that a consumer gains from consuming a given quantity of a good, service, or activity during a particular time period. The greater a consumers total utility, the larger the customer’s level of consumption. The cost to any firm of producing any output evidently depends upon the physical amounts of real resources. For instance material, labour and machine hours used in production. As the larger output needs a larger amount of resources, the total cost for larger output becomes high. Whereas the smaller output requires the smaller resources. The total cost for smaller output becomes smaller. A company can produce at lower cost when it produces better new techniques to products. Production with traditional and old method implicates high cost. The maximisation of returns includes the use of a definite technique to produce that can facilitate the optimal combination of factors. Production cost is defined as the expenditures by a business in producing a commodity. There are several kinds of cost concepts, these are marginal cost, total cost and average cost. Total is the cost of producing a certain output of the product in question. Total cost can be classified into variable cost and fixed cost. Fixed costs is also known as overhead cost. These are costs which do not differ with output. The costs will be the same whether the output is ten or twenty or a thousand of a product. Fixed costs entails interest on bank loans, depreciation of machinery, insurance charges and rent of factory. Variable costs are also called prime cost. Variable costs differ with alterations in output. The greater the output, the bigger the variable costs. Average cost is the cost of each unit of output and is achieved by dividing the total cost by the level of output. It is further divided into two parts, average fixed cost and average variable cost. Marginal cost is defined as the extra cost incurred by increasing output by one unit. It is the added cost of producing an additional unit of output. Perfect competition is a market structure in which the following characteristics are met. All businesses trade the same commodity, all firms will have a comparatively small market share, all firms are price takers meaning they cannot control the market price of their goods, the industry is characterized by freedom of entry and exit, and buyers have complete information about the product being sold and the prices charged by each firm. Perfect competition is a hypothetical market structure. Under perfect competition there are numerous buyers and sellers and prices reveal supply and demand. Customers will have several substitutes when the commodity they wish to buy quality begins to reduce or if it becomes more expensive. News firms can as well simply enter the market, leading to an extra competition. Monopoly on the other hand is where there is only one supplier in the market. For the reasons of regulation, monopoly power occurs where a single business owns 25% or more of a particular market. Monopolies can form for a number of reasons. For example, government can grant a business monopoly powers, if a firm has exclusive ownership of a limited resource, producers may have patents over designs for instance, giving them rights to trade a good or a service and a merger of two or more firms would create a monopoly. Monopolies have basic characteristics such as, they can maintain super normal returns in the long run, a monopolist with no substitute would be able to develop the greatest monopoly power and with no close substitutes, the monopolist can therefore derive supernormal profits.</p><p>In conclusion, microeconomics tries in any way not to explain what ought to happen in a market. Instead it will explains what to anticipate if some conditions are altered. For instance if producers increase the price of a commodity, customers will opt to purchase fewer of a product than before.</p><h2>Topics</h2><p>The study of microeconomics involves several key areas:</p><h3>Demand, supply, and equilibrium</h3><p> Main article: Supply and demand</p><p>Supply and demand is an economic model of price determination in a perfectly competitive market. It concludes that in a perfectly competitive market with no externalities, per unit taxes, or price controls, the unit price for a particular good is the price at which the quantity demanded by consumers equals the quantity supplied by producers. This price results in a stable economic equilibrium.</p><h3>Measurement of elasticities</h3><p> Main article: Elasticity (economics)</p><p>Elasticity is the measurement of how responsive an economic variable is to a change in another variable. Elasticity can be quantified as the ratio of the percentage change in one variable to the percentage change in another variable, when the later variable has a causal influence on the former. It is a tool for measuring the responsiveness of a variable, or of the function that determines it, to changes in causative variables in unitless ways. Frequently used elasticities include price elasticity of demand, price elasticity of supply, income elasticity of demand, elasticity of substitution between factors of production and elasticity of intertemporal substitution.</p><h3>Consumer demand theory</h3><p> Main article: Consumer choice</p><div class="gradientback"></div></div><div class="content"><p>Consumer demand theory relates preferences for the consumption of both goods and services to the consumption expenditures; ultimately, this relationship between preferences and consumption expenditures is used to relate preferences to consumer demand curves. The link between personal preferences, consumption and the demand curve is one of the most closely studied relations in economics. It is a way of analyzing how consumers may achieve equilibrium between preferences and expenditures by maximizing utility subject to consumer budget constraints.</p><h3>Theory of production</h3><p> Main article: Production theory</p><p>Production theory is the study of production, or the economic process of converting inputs into outputs. Production uses resources to create a good or service that is suitable for use, gift-giving in a gift economy, or exchange in a market economy. This can include manufacturing, storing, shipping, and packaging. Some economists define production broadly as all economic activity other than consumption. They see every commercial activity other than the final purchase as some form of production.</p><h3>Costs of production</h3><p> Main article: Cost-of-production theory of value</p><p>The cost-of-production theory of value states that the price of an object or condition is determined by the sum of the cost of the resources that went into making it. The cost can comprise any of the factors of production: labour, capital, land. Technology can be viewed either as a form of fixed capital (ex:plant) or circulating capital (ex:intermediate goods).</p><h3>Perfect competition</h3><p> Main article: Perfect competition</p><p>Perfect competition describes markets such that no participants are large enough to have the market power to set the price of a homogeneous product. A good example would be that of digital marketplaces, such as eBay, on which many different sellers sell similar products to many different buyers.</p><p>Benefits of Perfect Competition- All the knowledge such as price and information pertaining goods is equally dispersed among all buyers and sellers. As there are no barriers to enter into the market, monopoly does not usually occur. As all goods and products are same, advertisement is not required and it helps save the advertisement cost.in perfect competition products are identical</p><h3>Monopoly</h3><p> Main article: monopoly</p><p>A monopoly (from Greek monos µ???? (alone or single) + polein p??e?? (to sell)) exists when a single company is the only supplier of a particular commodity.</p><p>Benefits of Monopoly Market- Prices in monopoly market are stable as there is only one firm and so there is no competition. Due to the absence of competition there are high profits and leads to high number of sales monopoly firms tend to receive super profits from their operations.</p><h3>Oligopoly</h3><p> Main article: Oligopoly</p><p>An oligopoly is a market form in which a market or industry is dominated by a small number of sellers (oligopolists). Oligopolies can create the incentive for firms to engage in collusion and form cartels that reduce competition leading to higher prices for consumers and less overall market output.[5]</p><p>Benefits of oligopoly market-As there is less competition in the firm, it tends to have massive profit.It is also able to easily compare prices forces these companies to keep their prices in competition with the other companies involved in the market.Each company scrambles to come out with latest and greatest thing in order to sway consumers to go with their company over a different one.</p><h3>Market structure</h3><p>The market structure can have several types of interacting market systems. Different forms of markets are a feature of capitalism and advocates of socialism often criticize markets and aim to substitute markets with economic planning to varying degrees. Competition is the regulatory mechanism of the market system.</p><p>Examples of markets include but are not limited to: commodity markets, insurance markets, bond markets, energy markets, flea markets, debt markets, stock markets, online auctions, media exchange markets, real estate market.</p><h3>Game theory</h3><p> Main article: Game theory</p><p>Game theory is a major method used in mathematical economics and business for modeling competing behaviors of interacting agents. The term game here implies the study of any strategic interaction between people. Applications include a wide array of economic phenomena and approaches, such as auctions, bargaining, mergers &amp; acquisitions pricing, fair division, duopolies, oligopolies, social network formation, agent-based computational economics, general equilibrium, mechanism design,and voting systems, and across such broad areas as experimental economics, behavioral economics, information economics, industrial organization, and political economy.</p><h3>Labour economics</h3><p> Main article: Labour economics</p><p>Labour economics seeks to understand the functioning and dynamics of the markets for wage labour. Labour markets function through the interaction of workers and employers. Labour economics looks at the suppliers of labour services (workers), the demands of labour services (employers), and attempts to understand the resulting pattern of wages, employment, and income. In economics, labour is a measure of the work done by human beings. It is conventionally contrasted with such other factors of production as land and capital. There are theories which have developed a concept called human capital (referring to the skills that workers possess, not necessarily their actual work), although there are also counter posing macro-economic system theories that think human capital is a contradiction in terms.</p><h3>Welfare economics</h3><p> Main article: Welfare economics</p><p>Welfare economics is a branch of economics that uses microeconomics techniques to evaluate well-being from allocation of productive factors as to desirability and economic efficiency within an economy, often relative to competitive general equilibrium.[7] It analyzes social welfare, however measured, in terms of economic activities of the individuals that compose the theoretical society considered. Accordingly, individuals, with associated economic activities, are the basic units for aggregating to social welfare, whether of a group, a community, or a society, and there is no social welfare apart from the welfare associated with its individual units.</p><h3>Economics of information</h3><p> Main article: Information economics</p><div class="gradientback"></div></div><div class="content"><p>Information economics or the economics of information is a branch of microeconomic theory that studies how information and information systems affect an economy and economic decisions. Information has special characteristics. It is easy to create but hard to trust. It is easy to spread but hard to control. It influences many decisions. These special characteristics (as compared with other types of goods) complicate many standard economic theories.[8]</p><h2>Opportunity cost</h2><p> Main article: Opportunity cost</p><p>Opportunity cost of an activity (or goods) is equal to the best next alternative uses/forgone. Although opportunity cost can be hard to quantify, the effect of opportunity cost is universal and very real on the individual level. In fact, this principle applies to all decisions, not just economic ones.</p><p>Opportunity cost is one way to measure the cost of something. Rather than merely identifying and adding the costs of a project, one may also identify the next best alternative way to spend the same amount of money. The forgone profit of this next best alternative is the opportunity cost of the original choice. A common example is a farmer that chooses to farm their land rather than rent it to neighbors, wherein the opportunity cost is the forgone profit from renting. In this case, the farmer may expect to generate more profit alone. This kind of reasoning is a very important part of the calculation of discount rates in discounted cash flow investment valuation methodologies. Similarly, the opportunity cost of attending university is the lost wages a student could have earned in the workforce, rather than the cost of tuition, books, and other requisite items (whose sum makes up the total cost of attendance).</p><p>Note that opportunity cost is not the sum of the available alternatives, but rather the benefit of the single, best alternative. Possible opportunity costs of a city's decision to build a hospital on its vacant land are the loss of the land for a sporting center, or the inability to use the land for a parking lot, or the money that could have been made from selling the land, or the loss of any of the various other possible uses — but not all of these in aggregate. The true opportunity cost would be the forgone profit of the most lucrative of those listed.</p><p>One question that arises here is how to determine a money value for each alternative to facilitate comparison and assess opportunity cost, which may be more or less difficult depending on the things we are trying to compare. For example, many decisions involve environmental impacts whose monetary value is difficult to assess because of scientific uncertainty. Valuing a human life or the economic impact of an Arctic oil spill involves making subjective choices with ethical implications.</p><p>It is imperative to understand that no decision on allocating time is free. No matter what one chooses to do, they are always giving something up in return. An example of opportunity cost is deciding between going to a concert and doing homework. If one decides to go the concert, then they are giving up valuable time to study, but if they choose to do homework then the cost is giving up the concert. Any decision in allocating capital is likewise: there is an opportunity cost of capital, or a hurdle rate, defined as the expected rate one could get by investing in similar projects on the open market. Opportunity cost is vital in understanding microeconomics and decisions that are made.</p><h2>Applied</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/e/e8/United_States_Capitol_Building.jpg/220px-United_States_Capitol_Building.jpg" width="220" height="146"><p>


				United States Capitol Building: meeting place of the United States Congress, where many tax laws are passed, which directly impact economic welfare. This is studied in the subject of public economics.


				</p><p>
					Applied microeconomics includes a range of specialized areas of study, many of which draw on methods from other fields. Industrial organization examines topics such as the entry and exit of firms, innovation, and the role of trademarks. Labor economics examines wages, employment, and labor market dynamics. Financial economics examines topics such as the structure of optimal portfolios, the rate of return to capital, econometric analysis of security returns, and corporate financial behavior. Public economics examines the design of government tax and expenditure policies and economic effects of these policies (e.g., social insurance programs). Political economy examines the role of political institutions in determining policy outcomes. Health economics examines the organization of health care systems, including the role of the health care workforce and health insurance programs. Education economics examines the organization of education provision and its implication for efficiency and equity, including the effects of education on productivity. Urban economics, which examines the challenges faced by cities, such as sprawl, air and water pollution, traffic congestion, and poverty, draws on the fields of urban geography and sociology. Law and economics applies microeconomic principles to the selection and enforcement of competing legal regimes and their relative efficiencies. Economic history examines the evolution of the economy and economic institutions, using methods and techniques from the fields of economics, history, geography, sociology, psychology, and political science.</p><p>&lt;ref&gt;==References==</p><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Microeconomics&amp;oldid=783350389"					
								Categories:  Hidden categories:</p><br><h1 lang="en">Rational choice theory</h1><p> From Wikipedia, the free encyclopedia</p><p> This article is about a theory of economics. For rational choice theory as applied to criminology, see Rational choice theory (criminology).</p><p>Rational choice theory, also known as choice theory or rational action theory, is a framework for understanding and often formally modeling social and economic behavior.[1] The basic premise of rational choice theory is that aggregate social behavior results from the behavior of individual actors, each of whom is making their individual decisions. The theory also focuses on the determinants of the individual choices (methodological individualism).</p><p>Rational choice theory then assumes that an individual has preferences among the available choice alternatives that allow them to state which option they prefer. These preferences are assumed to be complete (the person can always say which of two alternatives they consider preferable or that neither is preferred to the other) and transitive (if option A is preferred over option B and option B is preferred over option C, then A is preferred over C). The rational agent is assumed to take account of available information, probabilities of events, and potential costs and benefits in determining preferences, and to act consistently in choosing the self-determined best choice of action.</p><p>Rationality is widely used as an assumption of the behavior of individuals in microeconomic models and analyses and appears in almost all economics textbook treatments of human decision-making. It is also used in political science,[2] sociology,[3] and philosophy. A particular version of rationality is instrumental rationality, which involves seeking the most cost-effective means to achieve a specific goal without reflecting on the worthiness of that goal. Gary Becker was an early proponent of applying rational actor models more widely.[4] Becker won the 1992 Nobel Memorial Prize in Economic Sciences for his studies of discrimination, crime, and human capital.[5]</p><h2>Contents</h2><h2>Definition and scope</h2><div class="gradientback"></div></div><div class="content"><p>The concept of rationality used in rational choice theory is different from the colloquial and most philosophical use of the word. Colloquially, rational behaviour typically means sensible, predictable, or in a thoughtful, clear-headed manner. Rational choice theory uses a narrower definition of rationality. At its most basic level, behavior is rational if it is goal-oriented, reflective (evaluative), and consistent (across time and different choice situations). This contrasts with behavior that is random, impulsive, conditioned, or adopted by (unevaluative) imitation.[citation needed]</p><p>Early neoclassical economists writing about rational choice, including William Stanley Jevons, assumed that agents make consumption choices so as to maximize their happiness, or utility. Contemporary theory bases rational choice on a set of choice axioms that need to be satisfied, and typically does not specify where the goal (preferences, desires) comes from. It mandates just a consistent ranking of the alternatives.[6]:501 Individuals choose the best action according to their personal preferences and the constraints facing them. E.g., there is nothing irrational in preferring fish to meat the first time, but there is something irrational in preferring fish to meat in one instant and preferring meat to fish in another, without anything else having changed.</p><p>Rational choice theorists do not claim that the theory describes the choice process, but rather that it predicts the outcome and pattern of choices. An assumption often added to the rational choice paradigm is that individual preferences are self-interested, in which case the individual can be referred to as a homo economicus. Such an individual acts as if balancing costs against benefits to arrive at action that maximizes personal advantage.[7] Proponents of such models, particularly those associated with the Chicago school of economics, do not claim that a model's assumptions are an accurate description of reality, only that they help formulate clear and falsifiable hypotheses.[citation needed] In this view, the only way to judge the success of a hypothesis is empirical tests.[7] To use an example from Milton Friedman, if a theory that says that the behavior of the leaves of a tree is explained by their rationality passes the empirical test, it is seen as successful.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/c/c8/Daniel_KAHNEMAN.jpg" width="150" height="179"><p>Without specifying the individual's goal or preferences it may not be possible to empirically test, or falsify, the rationality assumption. However, the predictions made by a specific version of the theory are testable. In recent years, the most prevalent version of rational choice theory, expected utility theory, has been challenged by the experimental results of behavioral economics. Economists are learning from other fields, such as psychology, and are enriching their theories of choice in order to get a more accurate view of human decision-making. For example, the behavioral economist and experimental psychologist Daniel Kahneman won the Nobel Memorial Prize in Economic Sciences in 2002 for his work in this field.</p><p>Rational choice theory has become increasingly employed in social sciences other than economics, such as sociology, evolutionary theory and political science in recent decades.[8][9] It has had far-reaching impacts on the study of political science, especially in fields like the study of interest groups, elections, behaviour in legislatures, coalitions, and bureaucracy.[10] In these fields, the use of the rational choice paradigm to explain broad social phenomena is the subject of active controversy.[11][12]</p><h2>Actions, assumptions, and individual preferences</h2><p>The premise of rational choice theory as a social science methodology is that the aggregate behavior in society reflects the sum of the choices made by individuals. Each individual, in turn, makes their choice based on their own preferences and the constraints (or choice set) they face.</p><p>At the individual level, rational choice theory stipulates that the agent chooses the action (or outcome) they most prefer. In the case where actions (or outcomes) can be evaluated in terms of costs and benefits, a rational individual chooses the action (or outcome) that provides the maximum net benefit, i.e., the maximum benefit minus cost.</p><p>The theory applies to more general settings than those identified by costs and benefit. In general, rational decision making entails choosing among all available alternatives the alternative that the individual most prefers. The alternatives can be a set of actions (what to do?) or a set of objects (what to choose/buy). In the case of actions, what the individual really cares about are the outcomes that results from each possible action. Actions, in this case, are only an instrument for obtaining a particular outcome.</p><h3>Formal statement</h3><p>The available alternatives are often expressed as a set of objects, for example a set of j exhaustive and exclusive actions:</p><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Rational_choice_theory&amp;oldid=770556981"					
								Categories:  Hidden categories:</p><br><h1 lang="en">Normative economics</h1><p> From Wikipedia, the free encyclopedia</p><p>Normative economics (as opposed to positive economics) is a part of economics that expresses value or normative judgments about economic fairness or what the outcome of the economy or goals of public policy ought to be.[1]</p><p>Economists commonly prefer to distinguish normative economics (what ought to be in economic matters) from positive economics (what is). Many normative (value) judgments, however, are held conditionally, to be given up if facts or knowledge of facts changes, so that a change of values may be purely scientific.[2] On the other hand, welfare economist Amartya Sen distinguishes basic (normative) judgments, which do not depend on such knowledge, from nonbasic judgments, which do. He finds it interesting to note that no judgments are demonstrably basic while some value judgments may be shown to be nonbasic. This leaves open the possibility of fruitful scientific discussion of value judgments.[3]</p><p>Positive and normative economics are often synthesized in the style of practical idealism. In this discipline, sometimes called the art of economics, positive economics is utilized as a practical tool for achieving normative objectives.</p><p>An example of a normative economic statement is as follows:</p><p>This is a normative statement, because it reflects value judgments. This specific statement makes the judgment that farmers need a higher living standard and that family farms need to be saved.[1]</p><p>Subfields of normative economics include social choice theory, cooperative game theory, and mechanism design.</p><p>Some earlier technical problems posed in welfare economics and the theory of justice have been sufficiently addressed as to leave room for consideration of proposals in applied fields such as resource allocation, public policy, social indicators, and inequality and poverty measurement.[4]</p><div class="gradientback"></div></div><div class="content"><h2>Notes</h2><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Normative_economics&amp;oldid=782036831"					
								Categories:  				
											
						<br>
							

											 
										

							</p><br><h1 lang="en">Business economics</h1><p> From Wikipedia, the free encyclopedia</p><p>Business economics is a field in applied economics which uses economic theory and quantitative methods to analyze business enterprises and the factors contributing to the diversity of organizational structures and the relationships of firms with labour, capital and product markets.[1] A professional focus of the journal Business Economics has been expressed as providing practical information for people who apply economics in their jobs.[2]</p><h2>Contents</h2><h2>Subject matter</h2><p>Business economics is concerned with economic issues and problems related to business organization, management, and strategy. Issues and problems include: an explanation of why corporate firms emerge and exist; why they expand: horizontally, vertically and spacially; the role of entrepreneurs and entrepreneurship; the significance of organizational structure; the relationship of firms with the employees, the providers of capital, the customers, the government; the interactions between firms and the business environment.[1]</p><h2>Ambiguity in the use of term</h2><p>The term 'business economics' is used in a variety of ways. Sometimes it is used as synonymously with industrial economics/industrial organisation, managerial economics, and economics for business. Still, there may be substantial differences in the usage of 'economics for business' and 'managerial economics' with the latter used more narrowly. One view of the distinctions between these would be that business economics is wider in its scope than industrial economics in that it would be concerned not only with industry but also businesses in the service sector. Economics for business looks at the major principles of economics but focuses on applying these economic principles to the real world of business.[3] Managerial economics is the application of economic methods in the managerial decision-making process.[4]</p><h2>Interpretations from various universities</h2><p>Many universities offer courses in business economics and offer a range of interpretations as to the meaning of the word.[5] The Bachelor of Business Economics (BBE) Program at University of Delhi is designed to meet the growing need for an analytical and quantitative approach to problem solving in the changing corporate world by the application of the latest techniques evolved in the fields of economics and business.[6]</p><p>The program at Harvard University uses economic methods to analyze practical aspects of business, including business administration, management, and related fields of business economics.[7]</p><p>The University of Miami defines business economics as involving the study of how we use our resources for the production, distribution, and consumption of goods and services. This requires business economists to analyze social institutions, banks, the stock market, the government and their relationships with labor negotiations, taxes, international trade, and urban and environmental issues.[8]</p><p>Courses at the University of Manchester interpret business economics to be concerned with the economic analysis of how businesses contribute to welfare of society rather than on the welfare of an individual or a business. This is done via an examination of the relationship between ownership, control and firm objectives; theories of the growth of the firm; the behavioural theory of the firm; theories of entrepreneurship; the factors that influence the structure, conduct and performance of business at the industry level.[9]</p><p>Italian Universities borrow their concept of business economics from the tradition of Gino Zappa, for example a standard course[10] at the Politecnico di Milano involves studying corporate governance, accounting, investment analysis, budgeting and business strategy.</p><p>La Trobe University of Melbourne, Australia associates business economics with the process of demand, supply and equilibrium coordinating the behaviour of individuals and businesses in the market. Also, business economics extends to government policy, economic variables and international factors which influence business and competition.</p><h2>Notes</h2><h2>Journals</h2><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Business_economics&amp;oldid=771210217"					
								Categories:  Hidden categories:</p><br><h1 lang="en">Mainstream economics</h1><p> From Wikipedia, the free encyclopedia</p><p>Mainstream economics is the body of knowledge, theories, and models of economics, as taught across prominent universities, that are widely accepted by scholars in the field. It can be contrasted to heterodox economics, which are various schools or approaches that are only accepted by their expositors, with little influence on the majority of academic economists. Mainstream economics has been associated with neoclassical economics[1] and with the neoclassical synthesis, which combines neoclassical methods and a Keynesian approach to macroeconomics.[2]</p><h2>Contents</h2><h2>United States</h2><p>In the United States, mainstream economists are not generally separated into schools, but two major contemporary economic schools of thought have been the saltwater and freshwater schools. In the early 1970s, so-called fresh-water economists challenged the prevailing consensus in macroeconomics research. Key elements of their approach were that macroeconomics had to be dynamic, quantitative, and based on how individuals and institutions make decisions under uncertainty. Many of the proponents of this radically new approach to macroeconomics were associated with Carnegie Mellon University, the University of Chicago, the University of Rochester and the University of Minnesota. They were referred to as the freshwater school since Pittsburgh, Chicago, Rochester, and Minneapolis are located nearer to the Great Lakes. The established consensus was primarily defended by economists at the universities and other institutions located near the east and west coast of the United States, such as Berkeley, Harvard, MIT, University of Pennsylvania, Princeton, Columbia, Stanford, and Yale. They were therefore often referred to as the saltwater schools. Today, mainstream economists do not, in general, identify themselves as members of a particular school.</p><h2>History</h2><p>Economics has always featured multiple schools of economic thought, with different schools having different prominence across countries and over time. The current use of the term mainstream economics is specific to the post–World War II era, particularly in the English-speaking world, and to a lesser extent globally.</p><p>Prior to the development of modern academic economics, the dominant school in Europe was mercantilism, which was rather a loose set of related ideas than an institutionalized school. With the development of modern economics, conventionally given as the late 18th-century The Wealth of Nations by Adam Smith, British economics developed and became dominated by what is now called the classical school. From The Wealth of Nations until the Great Depression, the dominant school within the English-speaking world was classical economics, and its successor, neoclassical economics.[3] In continental Europe, the earlier work of the physiocrats in France formed a distinct tradition, as did the later work of the historical school of economics in Germany, and throughout the 19th century there were debates in British economics, notably the opposition underconsumptionist school.</p><div class="gradientback"></div></div><div class="content"><p>During the Great Depression and the following Second World War, the school of Keynesian economics gained prominence, which built on the work of the underconsumptionist school, and present-day mainstream economics stems from the neoclassical synthesis, which was the post–World War II merger of Keynesian macroeconomics and neoclassical microeconomics.</p><p>In continental Europe, by contrast, Keynesian economics was rejected, with German thought dominated by the Freiburg school, whose political philosophy of ordoliberalism formed the intellectual basis of Germany's post-war social market economy. Within developing economies, which formed the majority of the world's population, various schools of development economics have been influential.</p><p>Since 2007, the financial crisis of 2007–2010 and the ensuing global economic crisis has publicly exposed divisions within mainstream economics and significantly intensified controversy about its status, with some arguing for radical overhaul or rejection of mainstream economics, others arguing for evolutionary change, and others still arguing that mainstream economics explains the crisis.[4]</p><h3>Term</h3><p>The term mainstream economics came into common use in the late 20th century. It appears in 2001 edition of the seminal textbook Economics by Samuelson and Nordhaus[5] on the inside back cover in the Family Tree of Economics, which depicts arrows into Modern Mainstream Economics from J.M. Keynes (1936) and neoclassical economics (1860–1910). The term neoclassical synthesis itself also first appears in the 1955 edition of Samuelson's textbook.[6]</p><h2>Scope</h2><p>Mainstream economics can be defined, as distinct from other schools of economics, by various criteria, notably by its assumptions, its methods, and its topics.</p><h3>Assumptions</h3><p>A number of assumptions may underpin many mainstream economic models, while being rejected by some heterodox schools. These include the neoclassical assumptions of rational choice theory, a representative agent, and, often, rational expectations. Much of modern economic modelling consists of exploring the effects that complicating factors have on models, such as imperfect and asymmetric information, incomplete markets, imperfect competition and transaction costs.</p><p>The starting point of orthodox economic analysis is the individual. People are generally defined as units with a common goal: maximisation through rational behaviour. The only differences consist of:</p><p>From this theoretical framework, orthodox economists derive that political action should not be used to solve the problems of the economic system. Instead, the solution ought to derive from an intervention on the above-mentioned maximisation objectives and constraints. It is in this context that economic capitalism finds its justification. Capitalism and its arguments seem logical because orthodox economics theories think of the aggregate economy as the sum of the agents trying to maximise their utility or profit through exchange.[7]</p><h3>Methods</h3><p>Mainstream economics has also been defined methodologically as work which mainstream economists are willing to engage, which requires conforming to the mainstream language of mathematical models,[8] featuring calculus, optimization, and comparative statics. Under this definition, areas of thought which are typically thought of as heterodox because they do not work under the typical neoclassical assumptions, such as econophysics, behavioral economics, and evolutionary economics, can be considered mainstream when they are engaged in the mainstream, using mainstream methods.[8] Geoffrey Hodgson has considered the possibility that evolutionary economics and institutional economics may eventually become a new mainstream.[9]</p><p>Additionally, some economic fields include elements of both mainstream economics and heterodox economics: for example, the Austrian economics[how?],[10] institutional economics, neuroeconomics and non-linear complexity theory.[11] They may use neoclassical economics as a point of departure. At least one institutionalist has argued that neoclassical economics no longer dominates a mainstream economics.[12]</p><p>A countervailing trend is the expansion of mainstream methods to such seemingly distant fields as crime, the family, law, politics, and religion. The latter phenomenon is sometimes referred to as economic imperialism.[13]</p><h3>Topics</h3><p>Mainstream economics includes theories of market and government failure and private and public goods. These developments suggest a range of views on the desirability or otherwise of government intervention.</p><h2>Criticisms</h2><p>Since the financial crisis of 2007–2010, considerable conflict has arisen, among both economic theorists and a wider cross-section of the public, regarding the status and future of mainstream economics.[4][14] Some critics have argued that potentially promising approaches have been excluded in major mainstream publications by a focus on problems amenable to formal modeling.[15][16]</p><p>Chartalists, who are generally considered part of the Post-Keynesian school of thought, criticise mainstream theory as failing to describe the actual mechanics of modern fiat monetary economies. Chartalism focuses on a detailed understanding of the way money actually flows through the different sectors of an economy. Specifically, Chartalism focuses on the interaction between central banks, treasury and the private banking system. Chartalism rejects critical mainstream theories such as the loanable funds market, the money multiplier, and the utility of fiscal austerity.</p><p>Some economists, in the vein of ecological economics, believe that the neoclassical holy trinity of rationality, greed, and equilibrium, is being replaced by the holy trinity of purposeful behavior, enlightened self-interest, and sustainability, considerably broadening the scope of what is mainstream.[8] Ecological economics addresses sustainability issues, such as public goods, natural capital and negative externalities (such as pollution).[17]</p><p>Energy related theories of economic concepts also exist within energy economics relating to thermodynamic concepts of economic thinking, such as energy accounting.[18] Biophysical economics relates to this area.[19]</p><h3>Survey articles</h3><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Mainstream_economics&amp;oldid=783714535"					
								Categories:  Hidden categories:</p><br><h1 lang="en">Green economy</h1><p> From Wikipedia, the free encyclopedia</p><p>The green economy is defined as an economy that aims at reducing environmental risks and ecological scarcities, and that aims for sustainable development without degrading the environment. It is closely related with ecological economics, but has a more politically applied focus.[1][2] The 2011 UNEP Green Economy Report argues that to be green, an economy must not only be efficient, but also fair. Fairness implies recognising global and country level equity dimensions, particularly in assuring a just transition to an economy that is low-carbon, resource efficient, and socially inclusive. [3]</p><div class="gradientback"></div></div><div class="content"><p>A feature distinguishing it from prior economic regimes is the direct valuation of natural capital and ecological services as having economic value (see The Economics of Ecosystems and Biodiversity and Bank of Natural Capital) and a full cost accounting regime in which costs externalized onto society via ecosystems are reliably traced back to, and accounted for as liabilities of, the entity that does the harm or neglects an asset.[4]</p><p>Green Sticker and ecolabel practices have emerged as consumer facing measurements of friendliness to the environment and sustainable development. Many industries are starting to adopt these standards as a viable way to promote their greening practices in a globalizing economy.</p><h2>Contents</h2><h2>Green economists and economics</h2><p>Green economics is loosely defined as any theory of economics by which an economy is considered to be component of the ecosystem in which it resides (after Lynn Margulis). A holistic approach to the subject is typical, such that economic ideas are commingled with any number of other subjects, depending on the particular theorist. Proponents of feminism, postmodernism, the ecology movement, peace movement, Green politics, green anarchism and anti-globalization movement have used the term to describe very different ideas, all external to some equally ill-defined mainstream economics.[citation needed]</p><p>The use of the term is further ambiguated by the political distinction of Green parties which are formally organized and claim the capital-G Green term as a unique and distinguishing mark. It is thus preferable to refer to a loose school of 'green economists' who generally advocate shifts towards a green economy, biomimicry and a fuller accounting for biodiversity. (see The Economics of Ecosystems and Biodiversity especially for current authoritative international work towards these goals and Bank of Natural Capital for a layperson's presentation of these.)[citation needed]</p><p>Some economists view green economics as a branch or subfield of more established schools. For instance, it is regarded as classical economics where the traditional land is generalized to natural capital and has some attributes in common with labor and physical capital (since natural capital assets like rivers directly substitute for man-made ones such as canals). Or, it is viewed as Marxist economics with nature represented as a form of Lumpenproletariat, an exploited base of non-human workers providing surplus value to the human economy, or as a branch of neoclassical economics in which the price of life for developing vs. developed nations is held steady at a ratio reflecting a balance of power and that of non-human life is very low.[citation needed]</p><p>An increasing commitment by the UNEP (and national governments such as the UK) to the ideas of natural capital and full cost accounting under the banner 'green economy' could blur distinctions between the schools and redefine them all as variations of green economics. As of 2010 the Bretton Woods institutions (notably the World Bank[5] and International Monetary Fund (via its Green Fund initiative) responsible for global monetary policy have stated a clear intention to move towards biodiversity valuation and a more official and universal biodiversity finance.[citation needed] Taking these into account targeting not less but radically zero emission and waste is what is promoted by the Zero Emissions Research and Initiatives.[citation needed] The UNEP 2011 Green Economy Report informs that [b]ased on existing studies, the annual financing demand to green the global economy was estimated to be in the range US$ 1.05 to US$ 2.59 trillion. To place this demand in perspective, it is about one-tenth of total global investment per year, as measured by global Gross Capital Formation. [3]</p><h2>Definition</h2><p>Karl Burkart defines a green economy as based on six main sectors:[6]</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/7/70/Sustainable_development.svg/300px-Sustainable_development.svg.png" width="300" height="191" usemap="#ImageMap_1_1484116788"><p>The International Chamber of Commerce (ICC) representing global business defines green economy as “an economy in which economic growth and environmental responsibility work together in a mutually reinforcing fashion while supporting progress on social development”.[7][8]</p><p>In 2012, the ICC published the Green Economy Roadmap, containing contributions from experts from around the globe brought together in a two-year consultation process. The Roadmap represents a comprehensive and multidisciplinary effort to clarify and frame the concept of “green economy”. It highlights the essential role of business in bringing solutions to common global challenges. It sets out the following 10 conditions which relate to business/intra-industry and collaborative action for a transition towards a green economy:</p><h2>Ecological measurements</h2><p>Measuring economic output and progress is done through the use of economic index indicators. Green indices emerged from the need to measure human ecological impact, efficiency sectors like transport, energy, buildings and tourism, as well as the investment flows targeted to areas like renewable energy and cleantech innovation.</p><li>2010 - 2016 Global Green Economy Index™ (GGEI),[9] published by consultancy Dual Citizen LLC is in its 5th edition. It measures the green economic performance and perceptions of it in 80 countries and 50 cities along four main dimensions of leadership &amp; climate change, efficiency sectors, markets &amp; investment and the environment.</li><li>2009 - 2012 Green City Index [10] A global study commissioned by Siemens</li><li>2009 - 2013 Circles of Sustainability project scored 5 cities in 5 separate countries.</li><p>Ecological footprint measurements are a way to gauge anthropogenic impact and are another standard used by municipal governments.[11]</p><h2>Green energy issues</h2><p>Green economies require green energy generation based on renewable energy to replace fossil fuels as well as energy conservation and efficient energy use.[citation needed]</p><p>There is justification for market failure to respond to environmental protection and climate protection needs with the excuse that high external costs and high initial costs for research, development, and marketing of green energy sources and green products prevents firms from voluntarily reducing their ecological footprints.[12] The green economy may need government subsidies as market incentives to motivate firms to invest and produce green products and services. The German Renewable Energy Act, legislations of many other member states of the European Union and the American Recovery and Reinvestment Act of 2009, all provide such market incentives.[citation needed] However, other experts[13] argue that green strategies can be highly profitable for corporations that understand the business case for sustainability and can market green products and services beyond the traditional green consumer.</p><div class="gradientback"></div></div><div class="content"><h2>Criticisms</h2><p>A number of organisations and individuals have criticised aspects of the 'Green Economy', particularly the mainstream conceptions of it based on using price mechanisms to protect nature, arguing that this will extend corporate control into new areas from forestry to water. The research organisation ETC Group argues that the corporate emphasis on bio-economy will spur even greater convergence of corporate power and unleash the most massive resource grab in more than 500 years.[14] Venezuelan professor Edgardo Lander says that the UNEP's report, Towards a Green Economy,[15] while well-intentioned ignores the fact that the capacity of existing political systems to establish regulations and restrictions to the free operation of the markets – even when a large majority of the population call for them – is seriously limited by the political and financial power of the corporations.[16] Ulrich Hoffmann, in a paper for UNCTAD also says that the focus on Green Economy and green growth in particular, based on an evolutionary (and often reductionist) approach will not be sufficient to cope with the complexities of climate change and may rather give much false hope and excuses to do nothing really fundamental that can bring about a U-turn of global greenhouse gas emissions.[17] Clive Spash, an ecological economist, has criticised the use of economic growth to address environmental losses,[18] and argued that the Green Economy, as advocated by the UN, is not a new approach at all and is actually a diversion from the real drivers of environmental crisis.[19] He has also criticised the UN's project on the economics of ecosystems and biodiversity (TEEB),[20] and the basis for valuing ecosystems services in monetary terms.[21]</p><h2>Notes and references</h2><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Green_economy&amp;oldid=781971723"					
								Categories:  Hidden categories:</p><br><p>Michael Grossman's 1972 model of health production[8] has been extremely influential in this field of study and has several unique elements that make it notable. Grossman's model views each individual as both a producer and a consumer of health. Health is treated as a stock which degrades over time in the absence of investments in health, so that health is viewed as a sort of capital. The model acknowledges that health is both a consumption good that yields direct satisfaction and utility, and an investment good, which yields satisfaction to consumers indirectly through fewer sick days. Investment in health is costly as consumers must trade off time and resources devoted to health, such as exercising at a local gym, against other goals. These factors are used to determine the optimal level of health that an individual will demand. The model makes predictions over the effects of changes in prices of healthcare and other goods, labour market outcomes such as employment and wages, and technological changes. These predictions and other predictions from models extending Grossman's 1972 paper form the basis of much of the econometric research conducted by health economists.</p><p>In Grossman's model, the optimal level of investment in health occurs where the marginal cost of health capital is equal to the marginal benefit. With the passing of time, health depreciates at some rate d. The interest rate faced by the consumer is denoted by r. The marginal cost of health capital can be found by adding these variables: 
				  
					
					  
						M
						
						  C
						  
							H
							K
						  
						
						=
						r
						+
						d
						
					  
					
					{\displaystyle MC_{HK}=r+\delta \,}
				  
				. The marginal benefit of health capital is the rate of return from this capital in both market and non-market sectors. In this model, the optimal health stock can be impacted by factors like age, wages and education. As an example, 
				  
					
					  
						d
						
					  
					
					{\displaystyle \delta \,}
				  
				 increases with age, so it becomes more and more costly to attain the same level of health capital or health stock as one ages. Age also decreases the marginal benefit of health stock. The optimal health stock will therefore decrease as one ages.</p><p>Beyond issues of the fundamental, real demand for medical care derived from the desire to have good health (and thus influenced by the production function for health) is the important distinction between the marginal benefit of medical care (which is always associated with this real demand curve based on derived demand), and a separate effective demand curve, which summarizes the amount of medical care demanded at particular market prices. Because most medical care is not purchased from providers directly, but is rather obtained at subsidized prices due to insurance, the out-of-pocket prices faced by consumers are typically much lower than the market price. The consumer sets MB=MC out of pocket, and so the effective demand will have a separate relationship between price and quantity than will the marginal benefit curve or real demand relationship. This distinction is often described under the rubric of ex-post moral hazard (which is again distinct from ex-ante moral hazard, which is found in any type of market with insurance).</p><h2>Health technology assessment</h2><p>Economic evaluation, and in particular cost-effectiveness analysis, has become a fundamental part of technology appraisal processes for agencies in a number of countries. The Institute for Quality and Economy in Health Services (Institut für Qualität und Wirtschaftlichkeit im Gesundheitswesen – IQWiG) in Germany and the National Institute for Health and Care Excellence (NICE) in the United Kingdom, for example, both consider the cost-effectiveness of new pharmaceuticals entering the market.</p><p>Some agencies, including NICE, recommend the use of cost–utility analysis (CUA). This approach measures outcomes in a composite metric of both length and quality of life, the Quality-adjusted life year (QALY).</p><h2>Healthcare markets</h2><p>The five health markets typically analyzed are:</p><p>Although assumptions of textbook models of economic markets apply reasonably well to healthcare markets, there are important deviations. Many states have created risk pools in which relatively healthy enrollees subsidise the care of the rest. Insurers must cope with adverse selection which occurs when they are unable to fully predict the medical expenses of enrollees; adverse selection can destroy the risk pool. Features of insurance market risk pools, such as group purchases, preferential selection (cherry-picking), and preexisting condition exclusions are meant to cope with adverse selection.</p><p>Insured patients are naturally less concerned about healthcare costs than they would if they paid the full price of care. The resulting moral hazard drives up costs, as shown by the famous RAND Health Insurance Experiment. Insurers use several techniques to limit the costs of moral hazard, including imposing copayments on patients and limiting physician incentives to provide costly care. Insurers often compete by their choice of service offerings, cost sharing requirements, and limitations on physicians.</p><p>Consumers in healthcare markets often suffer from a lack of adequate information about what services they need to buy and which providers offer the best value proposition. Health economists have documented a problem with supplier induced demand, whereby providers base treatment recommendations on economic, rather than medical criteria. Researchers have also documented substantial practice variations, whereby the treatment also on service availability to rein in inducement and practice variations.</p><p>Some economists argue that requiring doctors to have a medical license constrains inputs, inhibits innovation, and increases cost to consumers while largely only benefiting the doctors themselves.[9]</p><h2>Other issues</h2><h3>Medical economics</h3><p>Often used synonymously with health economics, medical economics, according to Culyer,[10] is the branch of economics concerned with the application of economic theory to phenomena and problems associated typically with the second and third health market outlined above. Typically, however, it pertains to cost–benefit analysis of pharmaceutical products and cost-effectiveness of various medical treatments. Medical economics often uses mathematical models to synthesise data from biostatistics and epidemiology for support of medical decision-making, both for individuals and for wider health policy.</p><h3>Behavioral economics</h3><div class="gradientback"></div></div><div class="content"><p>Peter Orszag has suggested that behavioral economics is an important factor for improving the healthcare system, but that relatively little progress has been made when compared to retirement policy.[11]</p><h3>Mental health economics</h3><p>Mental health economics incorporates a vast array of subject matters, ranging from pharmacoeconomics to labor economics and welfare economics. Mental health can be directly related to economics by the potential of affected individuals to contribute as human capital. In 2009 Currie and Stabile published Mental Health in Childhood and Human Capital in which they assessed how common childhood mental health problems may alter the human capital accumulation of affected children.[12] Externalities may include the influence that affected individuals have on surrounding human capital, such as at the workplace or in the home.[13] In turn, the economy also affects the individual, particularly in light of globalization. For example, studies in India, where there is an increasingly high occurrence of western outsourcing, have demonstrated a growing hybrid identity in young professionals who face very different sociocultural expectations at the workplace and in at home.[14]</p><p>Mental health economics presents a unique set of challenges to researchers. Individuals with cognitive disabilities may not be able to communicate preferences. These factors represent challenges in terms of placing value on the mental health status of an individual, especially in relation to the individual's potential as human capital. Further, employment statistics are often used in mental health economic studies as a means of evaluating individual productivity; however, these statistics do not capture presenteeism, when an individual is at work with a lowered productivity level, quantify the loss of non-paid working time, or capture externalities such as having an affected family member. Also, considering the variation in global wage rates or in societal values, statistics used may be contextually, geographically confined, and study results may not be internationally applicable.[13]</p><p>Though studies have demonstrated mental healthcare to reduce overall healthcare costs, demonstrate efficacy, and reduce employee absenteeism while improving employee functioning, the availability of comprehensive mental health services is in decline. Petrasek and Rapin (2002) cite the three main reasons for this decline as (1) stigma and privacy concerns, (2) the difficulty of quantifying medical savings and (3) physician incentive to medicate without specialist referral.[15] Evers et al. (2009) have suggested that improvements could be made by promoting more active dissemination of mental health economic analysis, building partnerships through policy-makers and researchers, and employing greater use of knowledge brokers.[13]</p><h2>Journals</h2><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Health_economics&amp;oldid=783361465"					
								Categories:  Hidden categories:</p><br><h1 lang="en">Public choice</h1><p> From Wikipedia, the free encyclopedia</p><p>Public choice or public choice theory refers to the use of economic tools to deal with traditional problems of political science.[1] Its content includes the study of political behavior. In political science, it is the subset of positive political theory that studies self-interested agents (voters, politicians, bureaucrats) and their interactions, which can be represented in a number of ways – using (for example) standard constrained utility maximization, game theory, or decision theory.[1] Public-choice analysis has roots in positive analysis (what is) but is often used for normative purposes (what ought to be) in order to identify a problem or to suggest improvements to constitutional rules (i.e., constitutional economics).[1][2][3]</p><p>The Journal of Economic Literature's classification code regards public choice as a subarea of microeconomics, under JEL: D7: Analysis of Collective Decision-Making (specifically, JEL: D72: Economic Models of Political Processes: Rent-Seeking, Elections, Legislatures, and Voting Behavior).[4] Public choice theory is also closely related to social-choice theory, a mathematical approach to aggregation of individual interests, welfares, or votes.[5] Much early work had aspects of both, and both fields use the tools of economics and game theory. Since voter behavior influences the behavior of public officials, public-choice theory often uses results from social-choice theory. General treatments of public choice may also be classified under public economics.[6]</p><h2>Contents</h2><h2>Background and development</h2><p>A precursor of modern public choice theory was the work of Knut Wicksell (1896),[7] which treated government as political exchange, a quid pro quo, in formulating a benefit principle linking taxes and expenditures.[8]</p><p>Some subsequent economic analysis has been described as treating government as though it attempted to maximize some kind sort of welfare function for society and as distinct from characterizations of economic agents, such as those in business.[1] In contrast, public choice theory modeled government as made up of officials who, besides pursuing the public interest, might act to benefit themselves, for example in the budget-maximizing model of bureaucracy, possibly at the cost of efficiency.[1][9]</p><p>Modern public-choice theory has been dated from the work of Duncan Black, sometimes called the founding father of public choice.[10] In a series of papers from 1948, which culminated in The Theory of Committees and Elections (1958),[11] and later, Black outlined a program of unification toward a more general Theory of Economic and Political Choices based on common formal methods,[12] developed underlying concepts of what would become median voter theory, and rediscovered earlier works on voting theory.[13][1][14]</p><p>Kenneth J. Arrow's Social Choice and Individual Values (1951) influenced formulation of the theory. Among other important works are Anthony Downs (1957) An Economic Theory of Democracy and Mancur Olson (1965) The Logic of Collective Action.[15]</p><p>James M. Buchanan and Gordon Tullock coauthored The Calculus of Consent: Logical Foundations of Constitutional Democracy (1962), considered one of the landmarks in public choice. In particular, the preface describes the book as about the political organization of a free society. But its methodology, conceptual apparatus, and analytics are derived, essentially, from the discipline that has as its subject the economic organization of such a society (1962, p. v). The book focuses on positive-economic analysis as to the development of constitutional democracy but in an ethical context of consent. The consent takes the form of a compensation principle like Pareto efficiency for making a policy change and unanimity or at least no opposition as a point of departure for social choice.</p><p>Somewhat later, the probabilistic voting theory started to displace the median voter theory in showing how to find Nash equilibria in multidimensional space. The theory was later formalized further by Peter Coughlin.[16]</p><h2>Decision-making processes and the state</h2><p>One way to organize the subject matter studied by public choice theorists is to begin with the foundations of the state itself. According to this procedure, the most fundamental subject is the origin of government. Although some work has been done on anarchy, autocracy, revolution, and even war, the bulk of the study in this area has concerned the fundamental problem of collectively choosing constitutional rules. This work assumes a group of individuals who aim to form a government, then it focuses on the problem of hiring the agents required to carry out government functions agreed upon by the members.[citation needed]</p><h2>Expressive interests and democratic irrationality</h2><p>Geoffrey Brennan and Loren Lomasky claim that democratic policy is biased to favor expressive interests and neglect practical and utilitarian considerations. Brennan and Lomasky differentiate between instrumental interests (any kind of practical benefit, both monetary and non-monetary) and expressive interests (forms of expression like applause). According to Brennan and Lomasky, the voting paradox can be resolved by differentiating between expressive and instrumental interests.</p><div class="gradientback"></div></div><div class="content"><p>This argument has led some public choice scholars to claim that politics is plagued by irrationality. In articles published in the Econ Journal Watch, economist Bryan Caplan contended that voter choices and government economic decisions are inherently irrational.[17][18] Caplan's ideas are more fully developed in his book The Myth of the Rational Voter (Princeton University Press 2007). Countering Donald Wittman's arguments in The Myth of Democratic Failure, Caplan claims that politics is biased in favor of irrational beliefs.</p><p>According to Caplan, democracy effectively subsidizes irrational beliefs. Anyone who derives utility from potentially irrational policies like protectionism can receive private benefits while imposing the costs of such beliefs on the general public. Were people to bear the full costs of their irrational beliefs, they would lobby for them optimally, taking into account both their instrumental consequences and their expressive appeal. Instead, democracy oversupplies policies based on irrational beliefs. Caplan defines rationality mainly in terms of mainstream price theory, pointing out that mainstream economists tend to oppose protectionism and government regulation more than the general population, and that more educated people are closer to economists on this score, even after controlling for confounding factors such as income, wealth or political affiliation. One criticism is that many economists do not share Caplan's views on the nature of public choice. However, Caplan does have data to support his position. Economists have, in fact, often been frustrated by public opposition to economic reasoning. As Sam Peltzman puts it:</p><p>Economists know what steps would improve the efficiency of HSE [health, safety, and environmental] regulation, and they have not been bashful advocates of them. These steps include substituting markets in property rights, such as emission rights, for command and control...The real problem lies deeper than any lack of reform proposals or failure to press them. It is our inability to understand their lack of political appeal.[19]</p><p>Public choice's application to government regulation was developed by George Stigler (1971) and Sam Peltzman (1976).</p><h2>Special interests</h2><p>Public choice theory is often used to explain how political decision-making results in outcomes that conflict with the preferences of the general public. For example, many advocacy group and pork barrel projects are not the desire of the overall democracy. However, it makes sense for politicians to support these projects. It may make them feel powerful and important. It can also benefit them financially by opening the door to future wealth as lobbyists. The project may be of interest to the politician's local constituency, increasing district votes or campaign contributions. The politician pays little or no cost to gain these benefits, as he is spending public money. Special-interest lobbyists are also behaving rationally. They can gain government favors worth millions or billions for relatively small investments. They face a risk of losing out to their competitors if they don't seek these favors. The taxpayer is also behaving rationally. The cost of defeating any one government give-away is very high, while the benefits to the individual taxpayer are very small. Each citizen pays only a few pennies or a few dollars for any given government favor, while the costs of ending that favor would be many times higher. Everyone involved has rational incentives to do exactly what they are doing, even though the desire of the general constituency is opposite. Costs are diffused, while benefits are concentrated. The voices of vocal minorities with much to gain are heard over those of indifferent majorities with little to individually lose.[20][21] However the notion that groups with concentrated interests will dominate politics is incomplete because it is only one half of political equilibrium. Something must incite those preyed upon to resist even the best organized concentrated interests. In his article on interest groups Gary Becker identified this countervailing force as being the deadweight loss from predation. His views capped what has come to be known as the Chicago school of political economy and it has come in sharp conflict with the so-called Virginia faction of public choice due to its assertion that politics will tend towards efficiency due to nonlinear deadweight losses and due to its claim that political efficiency renders policy advice irrelevant.[22]</p><p>While good government tends to be a pure public good for the mass of voters, there may be many advocacy groups that have strong incentives for lobbying the government to implement specific policies that would benefit them, potentially at the expense of the general public. For example, lobbying by the sugar manufacturers might result in an inefficient subsidy for the production of sugar, either direct or by protectionist measures. The costs of such inefficient policies are dispersed over all citizens, and therefore unnoticeable to each individual. On the other hand, the benefits are shared by a small special-interest group with a strong incentive to perpetuate the policy by further lobbying. Due to rational ignorance, the vast majority of voters will be unaware of the effort; in fact, although voters may be aware of special-interest lobbying efforts, this may merely select for policies which are even harder to evaluate by the general public, rather than improving their overall efficiency. Even if the public were able to evaluate policy proposals effectively, they would find it infeasible to engage in collective action in order to defend their diffuse interest. Therefore, theorists expect that numerous special interests will be able to successfully lobby for various inefficient policies. In public choice theory, such scenarios of inefficient government policies are referred to as government failure – a term akin to market failure from earlier theoretical welfare economics.[20]</p><h2>Rent-seeking</h2><p>A field that is closely related to public choice is rent-seeking. This field combines the study of a market economy with that of government. Thus, one might regard it as a new political economy. Its basic thesis is that when both a market economy and government are present, government agents provide numerous special market privileges. Both the government agents and self-interested market participants seek these privileges in order to partake in the resulting monopoly rent. Rentiers gain benefits above what the market would have offered, but in the process allocate resources in sub-optimal fashion from a societal point of view.</p><p>Rent-seeking is broader than public choice in that it applies to autocracies as well as democracies and, therefore, is not directly concerned with collective decision making. However, the obvious pressures it exerts on legislators, executives, bureaucrats, and even judges are factors that public choice theory must account for in its analysis of collective decision-making rules and institutions. Moreover, the members of a collective who are planning a government would be wise to take prospective rent-seeking into account.[21]</p><p>Another major claim is that much of political activity is a form of rent-seeking which wastes resources. Gordon Tullock, Jagdish Bhagwati, and Anne Osborn Krueger have argued that rent-seeking has caused considerable waste.[21] In a parallel line of research Fred McChesney claims that rent extraction causes considerable waste, especially in the developing world. As the term implies, rent extraction happens when officials use threats to extort payments from private parties.</p><h2>Bureaucracy</h2><p>Another major sub-field is the study of bureaucracy. The usual model depicts the top bureaucrats as being chosen by the chief executive and legislature, depending on whether the democratic system is presidential or parliamentary. The typical image of a bureau chief is a person on a fixed salary who is concerned with pleasing those who appointed him. The latter have the power to hire and fire him more or less at will. The bulk of the bureaucrats, however, are civil servants whose jobs and pay are protected by a civil service system against major changes by their appointed bureau chiefs. This image is often compared with that of a business owner whose profit varies with the success of production and sales, who aims to maximize profit, and who can in an ideal system hire and fire employees at will.[9] William Niskanen is generally considered the founder of public choice literature on the bureaucracy.[9]</p><h2>Political stance</h2><p>From such results it is sometimes asserted that public choice theory has an anti-state tilt. But there is ideological diversity among public choice theorists. Mancur Olson for example was an advocate of a strong state and instead opposed political interest group lobbying.[15] More generally, James Buchanan has suggested that public choice theory be interpreted as politics without romance, a critical approach to a pervasive earlier notion of idealized politics set against market failure.[23]</p><p>The British journalist, Alistair Cooke, commenting on the Nobel Prize awarded to James M. Buchanan in 1986, reportedly summarized the public choice view of politicians by saying, Public choice embodies the homely but important truth that politicians are, after all, no less selfish than the rest of us.[24]</p><div class="gradientback"></div></div><div class="content"><h2>Recognition</h2><p>Several notable public choice scholars have been awarded the Nobel Prize in Economics, including James M. Buchanan (1986), George Stigler (1982), Gary Becker (1992), Vernon Smith (2002) and Elinor Ostrom (2009). In addition, Vernon Smith and Elinor Ostrom were former presidents of the Public Choice Society.[25]</p><h2>Criticisms</h2><p>In their 1994 book Pathologies of Rational Choice Theory, political scientists Donald P. Green and Ian Shapiro argue that rational choice theory (of which public choice theory is a branch) has contributed less to the field than its popularity suggests.[26] They write:</p><p>Linda McQuaig writes in All You Can Eat:[citation needed]</p><p>Amartya Sen has acknowledged the contribution of Buchanan and Tullock's analysis of unanimity as a criterion for collective choice,[28] but argued for the logical inconsistency of the Pareto-principle version of unanimity with even minimal liberty in a social-choice framework.[29] More broadly he qualified its use when other information besides personal utility is given a weight in public judgments.[30]</p><p>Buchanan and Tullock themselves outline methodological qualifications of the approach developed in their work The Calculus of Consent (1962), p. 30:</p><p>The reach of public choice theory might be even wider than Buchanan and Tullock indicate. Some theory shows that relaxing the assumption of self-interest leaves many public choice problems in place (although sometimes in altered from). As long as political actors are rational maximizers who disagree about the objectives government should pursue, public choice problems persist even if the disagreement stems from adherence to competing ethical principles rather than from competing self-interested wants.[31]</p><h3>New Ideas and Policy Innovation rather than Self Interest</h3><p>Another criticism suggests that some of the great developments in politics and policy have not been a product of individual actor's vested self interests, but rather because of new ideas. New ideas, by virtue of being innovative, expand the policy choices on the menu outside of simple vested interests and allow for equilibriums which were previously not possible. Dani Rodrik of the Harvard Kennedy School provides several examples of this phenomenon, where both Elites and Non-Elites were made better off through policy innovation, or in the case of the democratization of South Africa, making commitments to avoid Hold-up problems.[32]</p><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Public_choice&amp;oldid=780790157"					
								Categories:  Hidden categories:</p><br><h1 lang="en">Institutional economics</h1><p> From Wikipedia, the free encyclopedia</p><p>Institutional economics focuses on understanding the role of the evolutionary process and the role of institutions in shaping economic behaviour. Its original focus lay in Thorstein Veblen's instinct-oriented dichotomy between technology on the one side and the ceremonial sphere of society on the other. Its name and core elements trace back to a 1919 American Economic Review article by Walton H. Hamilton.[1][2]</p><p>Institutional economics emphasizes a broader study of institutions and views markets as a result of the complex interaction of these various institutions (e.g. individuals, firms, states, social norms). The earlier tradition continues today as a leading heterodox approach to economics.[3]</p><p>A significant variant is the new institutional economics from the later 20th century, which integrates later developments of neoclassical economics into the analysis. Law and economics has been a major theme since the publication of the Legal Foundations of Capitalism by John R. Commons in 1924. Since then, there is heated debate on the role of law (formal institution) on economic growth.[4] Behavioral economics is another hallmark of institutional economics based on what is known about psychology and cognitive science, rather than simple assumptions of economic behavior.</p><p>Institutional economics focuses on learning, bounded rationality, and evolution (rather than assume stable preferences, rationality and equilibrium). It was a central part of American economics in the first part of the 20th century, including such famous but diverse economists as Thorstein Veblen, Wesley Mitchell, and John R. Commons.[5] Some institutionalists see Karl Marx as belonging to the institutionalist tradition, because he described capitalism as a historically-bounded social system; other institutionalist economists[who?] disagree with Marx's definition of capitalism, instead seeing defining features such as markets, money and the private ownership of production as indeed evolving over time, but as a result of the purposive actions of individuals.</p><p>Traditional institutionalism rejects the reduction of institutions to simply tastes, technology, and nature (see naturalistic fallacy).[6] Tastes, along with expectations of the future, habits, and motivations, not only determine the nature of institutions but are limited and shaped by them. If people live and work in institutions on a regular basis, it shapes their world-views. Fundamentally, this traditional institutionalism (and its modern counterpart institutionalist political economy) emphasizes the legal foundations of an economy (see John R. Commons) and the evolutionary, habituated, and volitional processes by which institutions are erected and then changed (see John Dewey, Thorstein Veblen, and Daniel Bromley.)</p><p>The vacillations of institutions are necessarily a result of the very incentives created by such institutions, and are thus endogenous. Emphatically, traditional institutionalism is in many ways a response to the current economic orthodoxy; its reintroduction in the form of institutionalist political economy is thus an explicit challenge to neoclassical economics, since it is based on the fundamental premise that neoclassicists oppose: that economics cannot be separated from the political and social system within which it is embedded.</p><p>Some of the authors associated with this school include Robert H. Frank, Warren Samuels, Mark Tool, Geoffrey Hodgson, Daniel Bromley, Jonathan Nitzan, Shimshon Bichler, Elinor Ostrom, Anne Mayhew, John Kenneth Galbraith and Gunnar Myrdal, but even the sociologist C. Wright Mills was highly influenced by the institutionalist approach in his major studies.</p><h2>Contents</h2><div class="gradientback"></div></div><div class="content"><h2>Thorstein Veblen</h2><p> Main articles: Thorstein Veblen and The Theory of the Leisure Class</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/e/e9/Veblen3a.jpg/220px-Veblen3a.jpg" width="220" height="288"><p>


				Thorstein Veblen came from a Norwegian immigrant family in rural Mid-western America.


				</p><p>
					Thorstein Veblen (1857–1929) wrote his first and most influential book while he was at the University of Chicago, on The Theory of the Leisure Class (1899).[7] In it he analyzed the motivation in capitalism to conspicuously consume their riches as a way of demonstrating success. Conspicuous leisure was another focus of Veblen's critique. The concept of conspicuous consumption was in direct contradiction to the neoclassical view that capitalism was efficient.</p><p>In The Theory of Business Enterprise (1904) Veblen distinguished the motivations of industrial production for people to use things from business motivations that used, or misused, industrial infrastructure for profit, arguing that the former is often hindered because businesses pursue the latter. Output and technological advance are restricted by business practices and the creation of monopolies. Businesses protect their existing capital investments and employ excessive credit, leading to depressions and increasing military expenditure and war through business control of political power. These two books, focusing on criticism first of consumerism, and second of profiteering, did not advocate change.</p><p>Through the 1920s and after the Wall Street Crash of 1929 Thorstein Veblen's warnings of the tendency for wasteful consumption and the necessity of creating sound financial institutions seemed to ring true. Veblen remains a leading critic, which cautions against the excesses of the American way.</p><p>Thorstein Veblen wrote in 1898 an article entitled Why is Economics Not an Evolutionary Science[8] and he became the precursor of current evolutionary economics.</p><h2>John R. Commons</h2><p> Main article: John R. Commons</p><p>John R. Commons (1862–1945) also came from mid-Western America. Underlying his ideas, consolidated in Institutional Economics (1934) was the concept that the economy is a web of relationships between people with diverging interests. There are monopolies, large corporations, labour disputes and fluctuating business cycles. They do however have an interest in resolving these disputes.</p><p>Commons thought that government should be the mediator between the conflicting groups. Commons himself devoted much of his time to advisory and mediation work on government boards and industrial commissions.</p><h2>Wesley Mitchell</h2><p> Main article: Wesley Mitchell</p><p>Wesley Clair Mitchell (August 5, 1874 – October 29, 1948) was an American economist known for his empirical work on business cycles and for guiding the National Bureau of Economic Research in its first decades. Mitchell’s teachers included economists Thorstein Veblen and J. L. Laughlin and philosopher John Dewey.</p><h2>Clarence Ayres</h2><p> Main article: Clarence Edwin Ayres</p><p>Clarence Ayres (May 6, 1891 – July 24, 1972) was the principal thinker of what some has called the Texas school of institutional economics. Ayres developed on the ideas of Thorstein Veblen with a dichotomy of technology and institutions to separate the inventive from the inherited aspects of economic structures. He claimed that technology was always one step ahead of the socio-cultural institutions.</p><p>It can be argued that Ayres was not an institutionalist in any normal sense of the term; since he identified institutions with sentiments and superstition and in consequence institutions only played a kind of residual role in this theory of development which core center was that of technology. Ayres was under strong influence of Hegel and institutions for Ayres had the same function as Schein (with the connotation of deception, and illusion) for Hegel. A more appropriate name for Ayres' position would be that of a techno-behaviorist rather than an institutionalist.</p><h2>Adolf Berle</h2><p> Main article: Adolf Berle</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/5/5f/Adolf_Augustus_Berle_NYWTS.jpg/220px-Adolf_Augustus_Berle_NYWTS.jpg" width="220" height="272"><p>


				Adolf Augustus Berle, Jr.


				</p><p>
					Adolf A. Berle (1895–1971) was one of the first authors to combine legal and economic analysis, and his work stands as a foundig pillar of thought in modern corporate governance. Like Keynes, Berle was at the Paris Peace Conference, 1919, but subsequently resigned from his diplomatic job dissatisfied with the Versailles Treaty terms. In his book with Gardiner C. Means, The Modern Corporation and Private Property (1932), he detailed the evolution in the contemporary economy of big business, and argued that those who controlled big firms should be better held to account.</p><p>Directors of companies are held to account to the shareholders of companies, or not, by the rules found in company law statutes. This might include rights to elect and fire the management, require for regular general meetings, accounting standards, and so on. In 1930s America, the typical company laws (e.g. in Delaware) did not clearly mandate such rights. Berle argued that the unaccountable directors of companies were therefore apt to funnel the fruits of enterprise profits into their own pockets, as well as manage in their own interests. The ability to do this was supported by the fact that the majority of shareholders in big public companies were single individuals, with scant means of communication, in short, divided and conquered.</p>
				<div class="gradientback"></div></div><div class="content">
				<p>


				An airline ticket showing the price in the ISO 4217 code "EUR" (bottom left) and not the currency sign €


				</p><p>
					ISO 4217 is a standard first published by International Organization for Standardization in 1978, which delineates currency designators, country codes (alpha and numeric), and references to minor units in three tables:</p><p>The tables, history and ongoing discussion are maintained by SIX Interbank Clearing on behalf of ISO and the Swiss Association for Standardization.[4]</p><p>The ISO 4217 code list is used in banking and business globally. In many countries the ISO codes for the more common currencies are so well known publicly that exchange rates published in newspapers or posted in banks use only these to delineate the different currencies, instead of translated currency names or ambiguous currency symbols. ISO 4217 codes are used on airline tickets and international train tickets to remove any ambiguity about the price.</p><h2>Contents</h2><h2>Code formation</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/d/db/South_East_Asia_Exchange_Rates_%286031878489%29.jpg/220px-South_East_Asia_Exchange_Rates_%286031878489%29.jpg" width="220" height="219"><p>


				A list of exchange rates for various base currencies given by a money changer in Thailand, with the Thailand Baht as the counter (or quote) currency.


				</p><p>
					The first two letters of the code are the two letters of the ISO 3166-1 alpha-2 country codes (which are also used as the basis for national top-level domains on the Internet) and the third is usually the initial of the currency itself. So Japan's currency code is JPY—JP for Japan and Y for yen. This eliminates the problem caused by the names dollar, franc, peso and pound being used in dozens of different countries, each having significantly differing values. Also, if a currency is revalued, the currency code's last letter is changed to distinguish it from the old currency. In some cases, the third letter is the initial for new in that country's language, to distinguish it from an older currency that was revalued; the code sometimes outlasts the usage of the term new itself (for example, the code for the Mexican peso is MXN). Other changes can be seen, however; the Russian ruble, for example, changed from RUR to RUB, where the B comes from the third letter in the word ruble.</p><h3>X currencies</h3><p>In addition to codes for most active national currencies ISO 4217 provides codes for supranational currencies, procedural purposes, and several things which are similar to currencies:</p><p>The use of an initial letter X for these purposes is facilitated by the ISO 3166 rule that no official country code beginning with X will ever be assigned. Because of this rule ISO 4217 can use X codes without risk of clashing with a future country code. ISO 3166 country codes beginning with X are used for private custom use (reserved), never for official codes. For instance, the ISO 3166-based NATO country codes (STANAG 1059, 9th edition) use X codes for imaginary exercise countries ranging from XXB for Brownland to XXR for Redland, as well as for major commands such as XXE for SHAPE or XXS for SACLANT. Consequently, ISO 4217 can use X codes for non-country-specific currencies without risk of clashing with future country codes.</p><p>The inclusion of EU (denoting the European Union) in the ISO 3166-1 reserved codes list, allows the euro to be coded as EUR rather than assigned a code beginning with X even though it is a supranational currency.</p><h3>Treatment of minor currency units (the exponent)</h3><p>The ISO 4217 standard includes a crude mechanism for expressing the relationship between a major currency unit and its corresponding minor currency unit. This mechanism is called the currency exponent and assumes a base of 10. For example, USD (the United States dollar) is equal to 100 of its minor currency unit the cent. So the USD has exponent 2 (10 to the power 2 is 100, which is the number of cents in a dollar). The code JPY (Japanese yen) is given the exponent 0, because its minor unit, the sen, although nominally valued at 1/100 of a yen, is of such negligible value that it is no longer used. Usually, as with the USD, the minor currency unit has a value that is 1/100 of the major unit, but in some cases (including most varieties of the dinar) 1/1000 is used, and sometimes ratios apply which are not integer powers of 10. Mauritania does not use a decimal division of units, setting 1 ouguiya (UM) equal to 5 khoums, and Madagascar has 1 ariary = 5 iraimbilanja. Some currencies do not have any minor currency unit at all and these are given an exponent of 0, as with currencies whose minor units are unused due to negligible value.</p><h3>Currency numbers</h3><p>There is also a three-digit code number assigned to each currency, in the same manner as there is also a three-digit code number assigned to each country as part of ISO 3166. This numeric code is usually the same as the ISO 3166-1 numeric code. For example, USD (United States dollar) has code 840 which is also the numeric code for the US (United States).</p><h2>Position of ISO 4217 code in amounts  </h2><p>The ISO standard does not regulate either the spacing, prefixing or suffixing in usage of currency codes. According however to the European Union's Publication Office,[5] in English, Irish, Latvian and Maltese texts, the ISO 4217 code is to be followed by a fixed space and the amount:</p><p>In Bulgarian, Croatian, Czech, Danish, Dutch, Estonian, Finnish, French, German, Greek, Hungarian, Italian, Lithuanian, Polish, Portuguese, Romanian, Slovak, Slovene, Spanish and Swedish the order is reversed; the amount is followed by a fixed space and the ISO 4217 code:</p><p>Note that, as illustrated, the order is determined not by the currency, but by the native language of the document context.</p><h2>History</h2><p>In 1973, the ISO Technical Committee 68 decided to develop codes for the representation of currencies and funds for use in any application of trade, commerce or banking. At the 17th session (February 1978), the related UN/ECE Group of Experts agreed that the three-letter alphabetic codes for International Standard ISO 4217, Codes for the representation of currencies and funds, would be suitable for use in international trade.</p><div class="gradientback"></div></div><div class="content"><p>Over time, new currencies are created and old currencies are discontinued. Frequently, these changes are due to the formation of new governments, treaties between countries standardizing on a shared currency, or revaluation of an existing currency due to excessive inflation. As a result, the list of codes must be updated from time to time. The ISO 4217 maintenance agency (MA), SIX Interbank Clearing, is responsible for maintaining the list of codes.</p><h2>Active codes</h2><p>The following is a list of active codes of official ISO 4217 currency names.</p><h3>USD/USS/USN, three currency codes belonging to the US</h3><p>The US dollar has two codes assigned: USD and USN (next day). The USS (same day) code is not in use any longer, and was removed from the list of active ISO 4217 codes in March 2014.</p><p>According to UN/CEFACT recommendation 9, paragraphs 8–9 ECE/TRADE/203, 1996, available online:</p><h2>Non ISO 4217 currencies</h2><h3>Currencies without ISO 4217 currency codes</h3><p>A number of currencies are not included in ISO 4217, because these currencies are: (a) minor currencies pegged 1:1 to a larger currency, even if independently regulated (b) a legal tender only issued as commemorative banknotes or coinage, or (c) a currency of an unrecognized or partially recognized state. These currencies include:</p><p>See Category:Fixed exchange rate for a list of all currently pegged currencies.</p><h3>Unofficial currency codes</h3><p>Despite having no official recognition in ISO 4217, the following non-ISO codes are sometimes used locally or commercially.</p><p>In addition, GBX is sometimes used (for example on the London Stock Exchange) to denote Penny sterling, a subdivision of pound sterling, the currency for the United Kingdom.</p><h3>Cryptocurrencies</h3><p>Recently, cryptocurrencies have unofficially used ISO codes used on various cryptocurrency exchanges, for instance LTC for Litecoin, NMC for Namecoin and XRP for Ripples. SIX Interbank Clearing (a Maintenance Agency of ISO) is currently studying the impact and role of cryptocurrencies and other independent currencies on ISO 4217.[16]</p><h2>Historical currency codes</h2><p>A number of currencies were official ISO 4217 currency codes and currency names until their replacement by the euro or other currencies. The table below shows the ISO currency codes of former currencies and their common names (which do not always match the ISO 4217 names). These codes were first introduced in 1989 after a request from the reinsurance sector in 1988 was accepted.</p><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=ISO_4217&amp;oldid=783976077"					
								Categories:  Hidden categories:</p><br><h1 lang="en">Human Development Index</h1><p> From Wikipedia, the free encyclopedia</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/0/0a/2016_UN_Human_Development_Report.svg/450px-2016_UN_Human_Development_Report.svg.png" width="450" height="197"><p>


				World map indicating the Human Development Index (based on 2015 and 2016 data, published on March 21, 2017).
				 




				<br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/9/93/2016_UN_Human_Development_Report_%28Quartiles%29.svg/450px-2016_UN_Human_Development_Report_%28Quartiles%29.svg.png" width="450" height="195"><br>


				World map indicating the categories of Human Development Index by country (based on 2015 and 2016 data, published on March 21, 2017).
				 



				</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/9/93/2016_UN_Human_Development_Report_%28Quartiles%29.svg/450px-2016_UN_Human_Development_Report_%28Quartiles%29.svg.png" width="450" height="195"><br><p>
					The Human Development Index (HDI) is a composite statistic of life expectancy, education, and per capita income indicators, which are used to rank countries into four tiers of human development. A country scores higher HDI when the lifespan is higher, the education level is higher, and the GDP per capita is higher. The HDI was developed by the Pakistani economist Mahbub ul Haq,[1] often framed in terms of whether people are able to be and do desirable things in their life, and was published by the United Nations Development Programme.</p><p>The 2010 Human Development Report introduced an Inequality-adjusted Human Development Index (IHDI). While the simple HDI remains useful, it stated that the IHDI is the actual level of human development (accounting for inequality), and the HDI can be viewed as an index of 'potential' human development (or the maximum IHDI that could be achieved if there were no inequality).</p><h2>Contents</h2><div class="gradientback"></div></div><div class="content"><h2>Origins</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/f/fc/Mahbub-ul-Haq.jpg/175px-Mahbub-ul-Haq.jpg" width="175" height="178"><p>


				Mahbub ul Haq



				<br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/e/e0/Amartya_Sen_NIH.jpg/175px-Amartya_Sen_NIH.jpg" width="175" height="280"><br>


				Amartya Sen


				</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/e/e0/Amartya_Sen_NIH.jpg/175px-Amartya_Sen_NIH.jpg" width="175" height="280"><br><p>
					The origins of the HDI are found in the annual Human Development Reports produced by the Human Development Reports Office of the United Nations Development Programme (UNDP). These were devised and launched by Pakistani economist Mahbub ul Haq in 1990, and had the explicit purpose to shift the focus of development economics from national income accounting to people-centered policies. To produce the Human Development Reports, Mahbub ul Haq formed a group of development economists including Paul Streeten, Frances Stewart, Gustav Ranis, Keith Griffin, Sudhir Anand, and Meghnad Desai. Nobel laureate Amartya Sen, utilized Haq's work in his own work on human capabilities.[2] Haq believed that a simple composite measure of human development was needed to convince the public, academics, and politicians that they can and should evaluate development not only by economic advances but also improvements in human well-being.</p><h2>Dimensions and calculation</h2><h3>New method (2010 Index onwards)</h3><p>Published on 4 November 2010 (and updated on 10 June 2011), the 2010 Human Development Index (HDI) combines three dimensions:[3][4]</p><p>In its 2010 Human Development Report, the UNDP began using a new method of calculating the HDI. The following three indices are used:</p><p>1. Life Expectancy Index (LEI) 
				  
					
					  
						=
						
						  
							
							  
								
								  LE
								
							  
							  -
							  20
							
							
							  85
							  -
							  20
							
						  
						
					  
					
					{\displaystyle ={\frac {{\textrm {LE}}-20}{85-20}}}
				  
				</p><p>2. Education Index (EI) 
				  
					
					  
						=
						
						  
							
							  
								
								  MYSI
								
							  
							  +
							  
								
								  EYSI
								
							  
							
							2
						  
						
					  
					
					{\displaystyle ={\frac {{\textrm {MYSI}}+{\textrm {EYSI}}}{2}}}
				  
				</p><br><img src="http:https://wikimedia.org/api/rest_v1/media/math/render/svg/55aabf77d89eb9e57d504c519802826d7a7da917" aria-hidden="true" style="vertical-align: -2.005ex; width:8.498ex; height:5.509ex;" alt="={\frac {\textrm {MYS}}{15}}"><br><img src="http:https://wikimedia.org/api/rest_v1/media/math/render/svg/d144416b4a2047923a6c231941cd3099f90fd5dd" aria-hidden="true" style="vertical-align: -2.005ex; width:7.95ex; height:5.509ex;" alt="={\frac {\textrm {EYS}}{18}}"><p>3. Income Index (II) 
				  
					
					  
						=
						
						  
							
							  ln
							  ?
							  (
							  
								
								  GNIpc
								
							  
							  )
							  -
							  ln
							  ?
							  (
							  100
							  )
							
							
							  ln
							  ?
							  (
							  75
							  ,
							  000
							  )
							  -
							  ln
							  ?
							  (
							  100
							  )
							
						  
						
					  
					
					{\displaystyle ={\frac {\ln({\textrm {GNIpc}})-\ln(100)}{\ln(75,000)-\ln(100)}}}
				  
				</p><p>Finally, the HDI is the geometric mean of the previous three normalized indices:

				  
					
					  
						
						  
							HDI
						  
						
						=
						
						  
							
							  
								
								  LEI
								
							  
							  ·
							  
								
								  EI
								
							  
							  ·
							  
								
								  II
								
							  
							
							
							  3
							
						  
						
						.
					  
					
					{\displaystyle {\textrm {HDI}}={\sqrt[{3}]{{\textrm {LEI}}\cdot {\textrm {EI}}\cdot {\textrm {II}}}}.}
				  
				</p><p>LE: Life expectancy at birth
				MYS: Mean years of schooling (i.e. years that a person aged 25 or older has spent in formal education)
				EYS: Expected years of schooling (i.e. total expected years of schooling for children under 18 years of age)
				GNIpc: Gross national income at purchasing power parity per capita</p><h3>Old method (before 2010 Index)</h3><p>The HDI combined three dimensions last used in its 2009 Report:</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/d/d7/Human_Development_Index_trends.svg/280px-Human_Development_Index_trends.svg.png" width="280" height="274"><p>


				HDI trends between 1975 and 2004
				 



				</p><p>
					This methodology was used by the UNDP until their 2011 report.</p><p>The formula defining the HDI is promulgated by the United Nations Development Programme (UNDP).[7] In general, to transform a raw variable, say 
				  
					
					  
						x
					  
					
					{\displaystyle x}
				  
				, into a unit-free index between 0 and 1 (which allows different indices to be added together), the following formula is used:</p><p>where 
				  
					
					  
						a
					  
					
					{\displaystyle a}
				  
				 and 
				  
					
					  
						b
					  
					
					{\displaystyle b}
				  
				 are the lowest and highest values the variable 
				  
					
					  
						x
					  
					
					{\displaystyle x}
				  
				 can attain, respectively.</p><div class="gradientback"></div></div><div class="content"><p>The Human Development Index (HDI) then represents the uniformly weighted sum with ? contributed by each of the following factor indices:</p><p>Other organizations/companies may include other factors, such as infant mortality, which produces a different HDI.</p><h2>2016 Human Development Index</h2><p> Main article: List of countries by Human Development Index</p><p>The 2016 Human Development Report by the United Nations Development Programme was released on March 21, 2017, and calculates HDI values based on estimates for 2015. Below is the list of the very high human development countries:[8]</p><h3>Inequality-adjusted HDI</h3><p> Main article: List of countries by inequality-adjusted HDI</p><p>The Inequality-adjusted Human Development Index (IHDI)[8] is a measure of the average level of human development of people in a society once inequality is taken into account.</p><p>The rankings are not relative to the HDI list above due to the exclusion of countries which are missing IHDI data (p.&nbsp;206).</p><li>&nbsp;Norway 0.898</li><li>&nbsp;Iceland 0.868</li><li>&nbsp;Netherlands 0.861</li><li>&nbsp;Australia 0.861</li><li>&nbsp;Germany 0.859</li><li>&nbsp;&nbsp;Switzerland 0.859</li><li>&nbsp;Denmark 0.858</li><li>&nbsp;Sweden 0.851</li><li>&nbsp;Ireland 0.850</li><li>&nbsp;Finland 0.843</li><li>&nbsp;Canada 0.839</li><li>&nbsp;Slovenia 0.838</li><li>&nbsp;United Kingdom 0.836</li><li>&nbsp;Czech Republic 0.830</li><li>&nbsp;Luxembourg 0.827</li><li>&nbsp;Belgium 0.821</li><li>&nbsp;Austria 0.815</li><li>&nbsp;France 0.813</li><li>&nbsp;United States 0.796</li><li>&nbsp;Slovakia 0.793</li><li>&nbsp;Japan 0.791</li><li>&nbsp;Spain 0.791</li><li>&nbsp;Estonia 0.788</li><li>&nbsp;Malta 0.786</li><li>&nbsp;Italy 0.784</li><li>&nbsp;Israel 0.778</li><li>&nbsp;Poland 0.774</li><li>&nbsp;Hungary 0.771</li><li>&nbsp;Cyprus 0.762</li><li>&nbsp;Lithuania 0.759</li><li>&nbsp;Greece 0.758</li><li>&nbsp;Portugal 0.755</li><li>&nbsp;South Korea 0.753</li><li>&nbsp;Croatia 0.752</li><li>&nbsp;Latvia 0.742</li><li>&nbsp;Montenegro 0.736</li><li>&nbsp;Russia 0.725</li><li>&nbsp;Romania 0.714</li><li>&nbsp;Argentina 0.698</li><li>&nbsp;Chile 0.692</li><p>Countries in the top quartile of HDI (very high human development group) with a missing IHDI: New Zealand, Singapore, Hong Kong, Liechtenstein, Brunei, Qatar, Saudi Arabia, Andorra, United Arab Emirates, Bahrain, and Kuwait.</p><h2>2015 Human Development Index</h2><p> Main article: List of countries by Human Development Index</p><p>The 2015 Human Development Report by the United Nations Development Programme was released on December 14, 2015, and calculates HDI values based on estimates for 2014. Below is the list of the very high human development countries:[10][11][12]</p><h3>Inequality-adjusted HDI</h3><p> Main article: List of countries by inequality-adjusted HDI</p><p>The Inequality-adjusted Human Development Index (IHDI)[10] is a measure of the average level of human development of people in a society once inequality is taken into account.</p><p>Note: The green arrows (), red arrows (), and blue dashes () represent changes in rank. The rankings are not relative to the HDI list above due to the exclusion of countries which are missing IHDI data (p.&nbsp;216).</p><li>&nbsp;Norway 0.893 ()</li><li>&nbsp;Netherlands 0.861 ( 1)</li><li>&nbsp;&nbsp;Switzerland 0.861 ( 1)</li><li>&nbsp;Australia 0.858 ( 2)</li><li>&nbsp;Denmark 0.856 ( 3)</li><li>&nbsp;Germany 0.853 ( 1)</li><li>&nbsp;Iceland 0.846 ( 1)</li><li>&nbsp;Sweden 0.846 ( 1)</li><li>&nbsp;Ireland 0.836 ( 1)</li><li>&nbsp;Finland 0.834 ( 1)</li><li>&nbsp;Canada 0.832 ( 2)</li><li>&nbsp;Slovenia 0.829 ()</li><li>&nbsp;United Kingdom 0.829 ( 3)</li><li>&nbsp;Czech Republic 0.823 ( 1)</li><li>&nbsp;Luxembourg 0.822 ( 1)</li><li>&nbsp;Belgium 0.820 ( 1)</li><li>&nbsp;Austria 0.816 ( 4)</li><li>&nbsp;France 0.811 ()</li><li>&nbsp;Slovakia 0.791 ( 2)</li><li>&nbsp;Estonia 0.782 ( 4)</li><li>&nbsp;Japan 0.780 ( 1)</li><div class="gradientback"></div></div><div class="content"><li>&nbsp;Israel 0.775 ( 3)</li><li>&nbsp;Spain 0.775 ( 1)</li><li>&nbsp;Italy 0.773 ( 1)</li><li>&nbsp;Hungary 0.769 ( 2)</li><li>&nbsp;Malta 0.767 ()</li><li>&nbsp;Poland 0.760 ( 2)</li><li>&nbsp;United States 0.760 ()</li><li>&nbsp;Cyprus 0.758 ( 1)</li><li>&nbsp;Greece 0.758 ( 5)</li><li>&nbsp;Lithuania 0.754 ()</li><li>&nbsp;South Korea 0.751 ( 1)</li><li>&nbsp;Portugal 0.744 ( 1)</li><li>&nbsp;Croatia 0.743 ( 1)</li><li>&nbsp;Belarus 0.741</li><li>&nbsp;Latvia 0.730</li><p>Countries in the top quartile of HDI (very high human development group) with a missing IHDI: New Zealand, Singapore, Hong Kong, Liechtenstein, Brunei, Qatar, Saudi Arabia, Andorra, United Arab Emirates, Bahrain, Cuba, and Kuwait.</p><h2>2014 Human Development Index</h2><p>The 2014 Human Development Report by the United Nations Development Programme was released on July 24, 2014, and calculates HDI values based on estimates for 2013. Below is the list of the very high human development countries:[16][11][12]</p><h3>Countries not included</h3><p>Some countries were not included for various reasons, primarily due to the lack of necessary data. The following United Nations Member States were not included in the 2014 report:[16] North Korea, Marshall Islands, Monaco, Nauru, San Marino, Somalia, South Sudan, Sudan, and Tuvalu.</p><h3>Inequality-adjusted HDI</h3><p> Main article: List of countries by inequality-adjusted HDI</p><p>The Inequality-adjusted Human Development Index (IHDI)[16] is a measure of the average level of human development of people in a society once inequality is taken into account.</p><p>Note: The green arrows (), red arrows (), and blue dashes () represent changes in rank. The rankings are not relative to the HDI list above due to the exclusion of countries which are missing IHDI data (p.&nbsp;168).</p><li>&nbsp;Norway 0.891 ()</li><li>&nbsp;Australia 0.860 ()</li><li>&nbsp;Netherlands 0.854 ( 1)</li><li>&nbsp;&nbsp;Switzerland 0.847 ( 3)</li><li>&nbsp;Germany 0.846 ()</li><li>&nbsp;Iceland 0.843 ( 2)</li><li>&nbsp;Sweden 0.840 ( 4)</li><li>&nbsp;Denmark 0.838 ( 1)</li><li>&nbsp;Canada 0.833 ( 4)</li><li>&nbsp;Ireland 0.832 ( 4)</li><li>&nbsp;Finland 0.830 ()</li><li>&nbsp;Slovenia 0.824 ( 2)</li><li>&nbsp;Austria 0.818 ( 1)</li><li>&nbsp;Luxembourg 0.814 ( 3)</li><li>&nbsp;Czech Republic 0.813 ( 1)</li><li>&nbsp;United Kingdom 0.812 ( 3)</li><li>&nbsp;Belgium 0.806 ( 2)</li><li>&nbsp;France 0.804 ()</li><li>&nbsp;Israel 0.793 ( 1)</li><li>&nbsp;Japan 0.779 (New)</li><li>&nbsp;Slovakia 0.778 ( 1)</li><li>&nbsp;Spain 0.775 ( 2)</li><li>&nbsp;Italy 0.768 ( 1)</li><li>&nbsp;Estonia 0.767 ( 1)</li><li>&nbsp;Greece 0.762 ( 2)</li><li>&nbsp;Malta 0.760 ( 3)</li><li>&nbsp;Hungary 0.757 ( 1)</li><li>&nbsp;United States 0.755 ( 12)</li><li>&nbsp;Poland 0.751 ( 1)</li><li>&nbsp;Cyprus 0.752 ( 1)</li><li>&nbsp;Lithuania 0.746 ( 2)</li><li>&nbsp;Portugal 0.739 ()</li><li>&nbsp;South Korea 0.736 ( 5)</li><li>&nbsp;Latvia 0.725 ( 1)</li><li>&nbsp;Croatia 0.721 ( 4)</li><li>&nbsp;Argentina 0.680 ( 7)</li><li>&nbsp;Chile 0.661 ( 4)</li><p>Countries in the top quartile of HDI (very high human development group) with a missing IHDI: New Zealand, Singapore, Hong Kong, Liechtenstein, Brunei, Qatar, Saudi Arabia, Andorra, United Arab Emirates, Bahrain, Cuba, and Kuwait.</p><h2>Past top countries</h2><p>The list below displays the top-ranked country from each year of the Human Development Index. Norway has been ranked the highest twelve times, Canada eight times, followed by Japan which has been ranked highest three times. Iceland has been ranked highest twice.</p><h3>In each original HDI</h3><p>The year represents when the report was published. In parentheses is the year for which the index was calculated.</p><h2>Geographical coverage</h2><p>The HDI has extended its geographical coverage: David Hastings, of the United Nations Economic and Social Commission for Asia and the Pacific, published a report geographically extending the HDI to 230+ economies, whereas the UNDP HDI for 2009 enumerates 182 economies and coverage for the 2010 HDI dropped to 169 countries.[18][19]</p><h2>Country/region specific HDI lists</h2><h2>Criticism</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/0/0f/Human_welfare_and_ecological_footprint.jpg/220px-Human_welfare_and_ecological_footprint.jpg" width="220" height="135"><div class="gradientback"></div></div><div class="content"><p>


				HDI vs. ecological footprint


				</p><p>
					The Human Development Index has been criticized on a number of grounds including alleged lack of consideration of technological development or contributions to the human civilization, focusing exclusively on national performance and ranking, lack of attention to development from a global perspective, measurement error of the underlying statistics, and on the UNDP's changes in formula which can lead to severe misclassification in the categorisation of 'low', 'medium', 'high' or 'very high' human development countries.[20]</p><p>Economists Hendrik Wolff, Howard Chong and Maximilian Auffhammer discuss the HDI from the perspective of data error in the underlying health, education and income statistics used to construct the HDI. They identified three sources of data error which are due to (i) data updating, (ii) formula revisions and (iii) thresholds to classify a country's development status and conclude that 11%, 21% and 34% of all countries can be interpreted as currently misclassified in the development bins due to the three sources of data error, respectively. The authors suggest that the United Nations should discontinue the practice of classifying countries into development bins because - they claim - the cut-off values seem arbitrary, can provide incentives for strategic behavior in reporting official statistics, and have the potential to misguide politicians, investors, charity donors and the public who use the HDI at large.[20]</p><p>In 2010, the UNDP reacted to the criticism and updated the thresholds to classify nations as low, medium, and high human development countries. In a comment to The Economist in early January 2011, the Human Development Report Office responded[21] to a January 6, 2011 article in the magazine[22] which discusses the Wolff et al. paper. The Human Development Report Office states that they undertook a systematic revision of the methods used for the calculation of the HDI and that the new methodology directly addresses the critique by Wolff et al. in that it generates a system for continuous updating of the human development categories whenever formula or data revisions take place.</p><h2>Notes and references</h2><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Human_Development_Index&amp;oldid=782574749"					
								Categories:  Hidden categories:</p><br><br><img alt="This is a good article. Click here for more information." src="http://upload.wikimedia.org/wikipedia/en/thumb/9/94/Symbol_support_vote.svg/19px-Symbol_support_vote.svg.png" width="19" height="20"><h1 lang="en">Euro</h1><p> From Wikipedia, the free encyclopedia</p><p> This article is about the currency. For other uses, see Euro (disambiguation).</p><p>The euro (sign: €; code: EUR) is the official currency of the eurozone, which consists of 19 of the 28 member states of the European Union: Austria, Belgium, Cyprus, Estonia, Finland, France, Germany, Greece, Ireland, Italy, Latvia, Lithuania, Luxembourg, Malta, the Netherlands, Portugal, Slovakia, Slovenia, and Spain.[3][4] The currency is also officially used by the institutions of the European Union and four other European countries, as well as unilaterally by two others, and is consequently used daily by some 337&nbsp;million Europeans as of 2015[update].[5] Outside of Europe, a number of overseas territories of EU members also use the euro as their currency.</p><p>Additionally, 210&nbsp;million people worldwide as of 2013[update] use currencies pegged to the euro. The euro is the second largest reserve currency as well as the second most traded currency in the world after the United States dollar.[6][7][8] As of January 2017[update], with more than €1,109,000,000,000 in circulation, the euro has one of the highest combined values of banknotes and coins in circulation in the world, having surpassed the U.S. dollar at one point.[9][note 17]</p><p>The name euro was officially adopted on 16 December 1995 in Madrid.[10] The euro was introduced to world financial markets as an accounting currency on 1 January 1999, replacing the former European Currency Unit (ECU) at a ratio of 1:1 (US$1.1743). Physical euro coins and banknotes entered into circulation on 1 January 2002, making it the day-to-day operating currency of its original members, and by May 2002 had completely replaced the former currencies.[11] While the euro dropped subsequently to US$0.8252 within two years (26 October 2000), it has traded above the U.S. dollar since the end of 2002, peaking at US$1.6038 on 18 July 2008.[12] Since late 2009, the euro has been immersed in the European sovereign-debt crisis which has led to the creation of the European Financial Stability Facility as well as other reforms aimed at stabilising the currency. In July 2012, the euro fell below US$1.21 for the first time in two years, following concerns raised over Greek debt and Spain's troubled banking sector.[13] As of June 2017, the euro–dollar exchange rate stands at ~ US$1.13.[14]</p><h2>Contents</h2><h2>Administration</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/5/51/European_Central_Bank_-_building_under_construction_-_Frankfurt_-_Germany_-_13.jpg/150px-European_Central_Bank_-_building_under_construction_-_Frankfurt_-_Germany_-_13.jpg" width="150" height="248"><p>


				The European Central Bank has its seat in Frankfurt (Germany) and is in charge of the monetary policy of the euro area.



				</p><p>
					 Main articles: European Central Bank, Maastricht Treaty, and Eurogroup</p><p>The euro is managed and administered by the Frankfurt-based European Central Bank (ECB) and the Eurosystem (composed of the central banks of the eurozone countries). As an independent central bank, the ECB has sole authority to set monetary policy. The Eurosystem participates in the printing, minting and distribution of notes and coins in all member states, and the operation of the eurozone payment systems.</p><p>The 1992 Maastricht Treaty obliges most EU member states to adopt the euro upon meeting certain monetary and budgetary convergence criteria, although not all states have done so. The United Kingdom and Denmark negotiated exemptions,[15] while Sweden (which joined the EU in 1995, after the Maastricht Treaty was signed) turned down the euro in a 2003 referendum, and has circumvented the obligation to adopt the euro by not meeting the monetary and budgetary requirements. All nations that have joined the EU since 1993 have pledged to adopt the euro in due course.</p><div class="gradientback"></div></div><div class="content"><h2>Issuing modalities for banknotes</h2><p>Since 5 January 2002, the national central banks (NCBs) and the ECB have issued euro banknotes on a joint basis.[16] Euro banknotes do not show which central bank issued them. Eurosystem NCBs are required to accept euro banknotes put into circulation by other Eurosystem members and these banknotes are not repatriated. The ECB issues 8% of the total value of banknotes issued by the Eurosystem.[16] In practice, the ECB's banknotes are put into circulation by the NCBs, thereby incurring matching liabilities vis-à-vis the ECB. These liabilities carry interest at the main refinancing rate of the ECB. The other 92% of the euro banknotes are issued by the NCBs in proportion to their respective shares in the capital key of the ECB,[16] calculated using national share of European Union population and national share of European Union GDP, equally weighted.[17]</p><h2>Characteristics</h2><h3>Coins and banknotes</h3><p> Main articles: Euro coins and Euro banknotes</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/6/65/Euro_coins_and_banknotes.jpg/220px-Euro_coins_and_banknotes.jpg" width="220" height="165"><p>


				Euro coins and banknotes of various denominations.


				</p><p>
					The euro is divided into 100 cents (sometimes referred to as euro cents, especially when distinguishing them from other currencies, and referred to as such on the common side of all cent coins). In Community legislative acts the plural forms of euro and cent are spelled without the s, notwithstanding normal English usage.[18][19] Otherwise, normal English plurals are sometimes used,[20] with many local variations such as centime in France.</p><p>All circulating coins have a common side showing the denomination or value, and a map in the background. Due to the linguistic plurality in the European Union, the Latin alphabet version of euro is used (as opposed to the less common Greek or Cyrillic) and Arabic numerals (other text is used on national sides in national languages, but other text on the common side is avoided). For the denominations except the 1-, 2- and 5-cent coins, the map only showed the 15 member states which were members when the euro was introduced. Beginning in 2007 or 2008 (depending on the country) the old map is being replaced by a map of Europe also showing countries outside the Union like Norway. The 1-, 2- and 5-cent coins, however, keep their old design, showing a geographical map of Europe with the 15 member states of 2002 raised somewhat above the rest of the map. All common sides were designed by Luc Luycx. The coins also have a national side showing an image specifically chosen by the country that issued the coin. Euro coins from any member state may be freely used in any nation that has adopted the euro.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/8/86/New_finnish_2013_5_euro.png/220px-New_finnish_2013_5_euro.png" width="220" height="223"><p>


				The new banknotes were introduced in the beginning of 2013. The top half of the image shows the front side of the banknote and the bottom half shows the back side.



				<br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/a/a8/EUR_10_obverse_%282014_issue%29.png/220px-EUR_10_obverse_%282014_issue%29.png" width="220" height="114"><br>


				10 euro note from the new Europa series written in Latin (EURO) and Greek (???O) alphabets, but also in the Cyrillic (????) alphabet, as a result of Bulgaria joining the European Union in 2007.


				</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/a/a8/EUR_10_obverse_%282014_issue%29.png/220px-EUR_10_obverse_%282014_issue%29.png" width="220" height="114"><br><p>
					The coins are issued in €2, €1, 50c, 20c, 10c, 5c, 2c, and 1c denominations. To avoid the use of the two smallest coins, some cash transactions are rounded to the nearest five cents in the Netherlands and Ireland[21][22] (by voluntary agreement) and in Finland (by law).[23] This practice is discouraged by the Commission, as is the practice of certain shops to refuse to accept high value euro notes.[24]</p><p>Commemorative coins with €2 face value have been issued with changes to the design of the national side of the coin. These include both commonly issued coins, such as the €2 commemorative coin for the fiftieth anniversary of the signing of the Treaty of Rome, and nationally issued coins, such as the coin to commemorate the 2004 Summer Olympics issued by Greece. These coins are legal tender throughout the eurozone. Collector coins with various other denominations have been issued as well, but these are not intended for general circulation, and they are legal tender only in the member state that issued them.[25]</p><p>The design for the euro banknotes has common designs on both sides. The design was created by the Austrian designer Robert Kalina.[26] Notes are issued in €500, €200, €100, €50, €20, €10, €5. Each banknote has its own colour and is dedicated to an artistic period of European architecture. The front of the note features windows or gateways while the back has bridges, symbolising links between countries and with the future. While the designs are supposed to be devoid of any identifiable characteristics, the initial designs by Robert Kalina were of specific bridges, including the Rialto and the Pont de Neuilly, and were subsequently rendered more generic; the final designs still bear very close similarities to their specific prototypes; thus they are not truly generic. The monuments looked similar enough to different national monuments to please everyone.[27]</p><h3>Payments clearing, electronic funds transfer</h3><p> Main article: Single Euro Payments Area</p><p>Capital within the EU may be transferred in any amount from one country to another. All intra-EU transfers in euro are treated as domestic transactions and bear the corresponding domestic transfer costs.[28] This includes all member states of the EU, even those outside the eurozone providing the transactions are carried out in euro.[29] Credit/debit card charging and ATM withdrawals within the eurozone are also treated as domestic transactions; however paper-based payment orders, like cheques, have not been standardised so these are still domestic-based. The ECB has also set up a clearing system, TARGET, for large euro transactions.[30]</p><h3>Currency sign</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/3/3b/Euro_logo_plus_character.png/220px-Euro_logo_plus_character.png" width="220" height="110"><div class="gradientback"></div></div><div class="content"><p>


				The euro sign; logotype and handwritten



				</p><p>
					 Main article: Euro sign</p><p>A special euro currency sign (€) was designed after a public survey had narrowed the original ten proposals down to two. The European Commission then chose the design created by the Belgian Alain Billiet.</p><p>Inspiration for the € symbol itself came from the Greek epsilon (?)[note 18]&nbsp;– a reference to the cradle of European civilisation&nbsp;– and the first letter of the word Europe, crossed by two parallel lines to 'certify' the stability of the euro.</p><p>The European Commission also specified a euro logo with exact proportions and foreground and background colour tones.[31] While the Commission intended the logo to be a prescribed glyph shape, font designers made it clear that they intended to design their own variants instead.[32] Typewriters lacking the euro sign can create it by typing a capital 'C', backspacing and overstriking it with the equal ('=') sign. Placement of the currency sign relative to the numeric amount varies from nation to nation, but for texts in English the symbol (or the ISO-standard EUR) should precede the amount.[33]</p><p>There is no official symbol for the cent.[citation needed]</p><h2>History</h2><p> Main article: History of the euro</p><h3>Introduction</h3><p>The euro was established by the provisions in the 1992 Maastricht Treaty. To participate in the currency, member states are meant to meet strict criteria, such as a budget deficit of less than three percent of their GDP, a debt ratio of less than sixty percent of GDP (both of which were ultimately widely flouted after introduction), low inflation, and interest rates close to the EU average. In the Maastricht Treaty, the United Kingdom and Denmark were granted exemptions per their request from moving to the stage of monetary union which would result in the introduction of the euro.</p><p>Economists who helped create or contributed to the euro include Fred Arditti, Neil Dowling, Wim Duisenberg, Robert Mundell, Tommaso Padoa-Schioppa and Robert Tollison.[citation needed] (For macroeconomic theory, see below.)</p><p>The name euro was officially adopted in Madrid on 16 December 1995.[10] Belgian Esperantist Germain Pirlot, a former teacher of French and history is credited with naming the new currency by sending a letter to then President of the European Commission, Jacques Santer, suggesting the name euro on 4 August 1995.[35]</p><p>Due to differences in national conventions for rounding and significant digits, all conversion between the national currencies had to be carried out using the process of triangulation via the euro. The definitive values of one euro in terms of the exchange rates at which the currency entered the euro are shown on the right.</p><p>The rates were determined by the Council of the European Union,[note 19] based on a recommendation from the European Commission based on the market rates on 31 December 1998. They were set so that one European Currency Unit (ECU) would equal one euro. The European Currency Unit was an accounting unit used by the EU, based on the currencies of the member states; it was not a currency in its own right. They could not be set earlier, because the ECU depended on the closing exchange rate of the non-euro currencies (principally the pound sterling) that day.</p><p>The procedure used to fix the conversion rate between the Greek drachma and the euro was different, since the euro by then was already two years old. While the conversion rates for the initial eleven currencies were determined only hours before the euro was introduced, the conversion rate for the Greek drachma was fixed several months beforehand.[note 20]</p><p>The currency was introduced in non-physical form (traveller's cheques, electronic transfers, banking, etc.) at midnight on 1 January 1999, when the national currencies of participating countries (the eurozone) ceased to exist independently. Their exchange rates were locked at fixed rates against each other. The euro thus became the successor to the European Currency Unit (ECU). The notes and coins for the old currencies, however, continued to be used as legal tender until new euro notes and coins were introduced on 1 January 2002.</p><p>The changeover period during which the former currencies' notes and coins were exchanged for those of the euro lasted about two months, until 28 February 2002. The official date on which the national currencies ceased to be legal tender varied from member state to member state. The earliest date was in Germany, where the mark officially ceased to be legal tender on 31 December 2001, though the exchange period lasted for two months more. Even after the old currencies ceased to be legal tender, they continued to be accepted by national central banks for periods ranging from several years to forever (the latter in Austria, Germany, Ireland, Estonia and Latvia for banknotes and coins; also, Belgium, Luxembourg, Slovenia and Slovakia will accept banknotes forever, but not coins). The earliest coins to become non-convertible were the Portuguese escudos, which ceased to have monetary value after 31 December 2002, although banknotes remain exchangeable until 2022.</p><h3>Eurozone crisis</h3><p> Main articles: Eurozone crisis and Greek government-debt crisis</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/0/0e/Government_surplus_or_deficit_%28EU-USA-UK%29.png/220px-Government_surplus_or_deficit_%28EU-USA-UK%29.png" width="220" height="188"><p>


				Budget deficit of the euro area compared to the United States and the UK.


				</p><p>
					Following the U.S. financial crisis in 2008, fears of a sovereign debt crisis developed in 2009 among fiscally conservative investors concerning some European states, with the situation becoming particularly tense in early 2010.[36][37] This included eurozone members Greece,[38] Ireland and Portugal and also some EU countries outside the area.[39] Iceland, the country which experienced the largest crisis in 2008 when its entire international banking system collapsed, has emerged less affected by the sovereign-debt crisis as the government was unable to bail the banks out. In the EU, especially in countries where sovereign debts have increased sharply due to bank bailouts, a crisis of confidence has emerged with the widening of bond yield spreads and risk insurance on credit default swaps between these countries and other EU members, most importantly Germany.[40][41] To be included in the eurozone, the countries had to fulfil certain convergence criteria, but the meaningfulness of such criteria was diminished by the fact it was not enforced with the same degree of strictness from country to country.[42]</p><div class="gradientback"></div></div><div class="content"><p>According to the Economist Intelligence Unit in 2011, [I]f the [euro area] is treated as a single entity, its [economic and fiscal] position looks no worse and in some respects, rather better than that of the US or the UK and the budget deficit for the euro area as a whole is much lower and the euro area's government debt/GDP ratio of 86% in 2010 was about the same level as that of the United States. Moreover, they write, private-sector indebtedness across the euro area as a whole is markedly lower than in the highly leveraged Anglo-Saxon economies. The authors conclude that the crisis is as much political as economic and the result of the fact that the euro area lacks the support of institutional paraphernalia (and mutual bonds of solidarity) of a state.[43]</p><p>The crisis continued with S&amp;P downgrading nine euro-area countries, including France, then downgrading the entire European Financial Stability Facility (EFSF) fund.[44]</p><p>In May 2012, socialist François Hollande was elected as president of France and a month later the French socialist legislative position was strengthened, while German leader Angela Merkel has appeared to be floundering and been badly let down by her advisers in recent months, one commentator said. As such, serious discord between French and German monetary decision-makers was [comparable to that of] ... 1992–93, at the height of the crisis over the European Monetary System, the forerunner to EMU (European Monetary Union). [H]itherto relatively dormant signs of euro skepticism in German public opinion and throughout industry have been multiplying in recent months, making Hollande's proposals increasingly unpalatable to a broad swathe of German opinion. Although considerable controversy will continue to swirl over Greece and Spain, the real battle lines over the future of the euro will be drawn up between Germany and France, the commentary concluded.[45] Another historical parallel&nbsp;– to 1931 when Germany was burdened with debt, unemployment and austerity while France and the United States were relatively strong creditors&nbsp;– gained attention in summer 2012[46] even as Germany received a debt-rating warning of its own.[47][48]</p><h2>Direct and indirect usage</h2><p> Further information: Eurozone, International status and usage of the euro, and Enlargement of the eurozone</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/f/f1/Eurozone_map.svg/400px-Eurozone_map.svg.png" width="400" height="396"><p>
				Andorra
				Bulgaria
				Croatia
				Czech Rep.
				Denmark
				Eurozone
				Hungary
				Kosovo
				Monaco
				Monte
				negro
				Poland
				Romania
				San Marino
				Sweden
				United
				Kingdom
				Vatican

				&nbsp;&nbsp;Eurozone


				&nbsp;&nbsp;ERM II


				&nbsp;&nbsp;Other EU members


				&nbsp;&nbsp;Monetary agreement


				&nbsp;&nbsp;Unilaterally adopted


				<br><img alt="Desc-i.svg" src="http://upload.wikimedia.org/wikipedia/commons/thumb/4/46/Desc-i.svg/10px-Desc-i.svg.png" width="10" height="10">

				</p><br><img alt="Desc-i.svg" src="http://upload.wikimedia.org/wikipedia/commons/thumb/4/46/Desc-i.svg/10px-Desc-i.svg.png" width="10" height="10"><h3>Direct usage</h3><p>
					The euro is the sole currency of 19 EU member states: Austria, Belgium, Cyprus, Estonia, Finland, France, Germany, Greece, Ireland, Italy, Latvia, Lithuania, Luxembourg, Malta, the Netherlands, Portugal, Slovakia, Slovenia, and Spain. These countries constitute the eurozone, some 332&nbsp;million people in total as of 2013[update].[49]</p><p>With all but two of the remaining EU members obliged to join, together with future members of the EU, the enlargement of the eurozone is set to continue. Outside the EU, the euro is also the sole currency of Montenegro and Kosovo and several European microstates (Andorra, Monaco, San Marino and the Vatican City) as well as in four overseas territories of EU members that are not themselves part of the EU (Saint Barthélemy, Saint Pierre and Miquelon, the French Southern and Antarctic Lands and Akrotiri and Dhekelia). Together this direct usage of the euro outside the EU affects nearly 3&nbsp;million people.</p><p>The euro has been used as a trading currency in Cuba since 1998,[50] and Syria since 2006.[51] There are also various currencies pegged to the euro (see below). In 2009, Zimbabwe abandoned its local currency and used major currencies instead, including the euro and the United States dollar.[52]</p><h3>Use as reserve currency</h3><p>Since its introduction, the euro has been the second most widely held international reserve currency after the U.S. dollar. The share of the euro as a reserve currency increased from 18% in 1999 to 27% in 2008. Over this period, the share held in U.S. dollar fell from 71% to 64% and that held in Yen fell from 6.4% to 3.3%. The euro inherited and built on the status of the Deutsche Mark as the second most important reserve currency. The euro remains underweight as a reserve currency in advanced economies while overweight in emerging and developing economies: according to the International Monetary Fund[53] the total of euro held as a reserve in the world at the end of 2008 was equal to $1.1&nbsp;trillion or €850 billion, with a share of 22% of all currency reserves in advanced economies, but a total of 31% of all currency reserves in emerging and developing economies.</p><p>The possibility of the euro becoming the first international reserve currency is now widely debated among economists.[54] Former US Federal Reserve Chairman Alan Greenspan gave his opinion in September 2007 that it was absolutely conceivable that the euro will replace the US dollar as reserve currency, or will be traded as an equally important reserve currency.[55] In contrast to Greenspan's 2007 assessment, the euro's increase in the share of the worldwide currency reserve basket has slowed considerably since 2007 and since the beginning of the worldwide credit crunch related recession and European sovereign-debt crisis.[53]</p><h3>Currencies pegged to the euro</h3><p> Main article: International status and usage of the euro</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/9/91/DOLLAR_AND_EURO_IN_THE_WORLD.svg/300px-DOLLAR_AND_EURO_IN_THE_WORLD.svg.png" width="300" height="154"><p>


				Worldwide use of the euro and the US dollar:
				&nbsp;&nbsp;Eurozone
				&nbsp;&nbsp;External adopters of the euro
				&nbsp;&nbsp;Currencies pegged to the euro
				&nbsp;&nbsp;Currencies pegged to the euro within narrow band
				&nbsp;&nbsp;United States
				&nbsp;&nbsp;External adopters of the US dollar
				&nbsp;&nbsp;Currencies pegged to the US dollar
				&nbsp;&nbsp;Currencies pegged to the US dollar within narrow band

				Note: The Belarusian ruble is pegged to the Euro, Russian ruble and US$ in a currency basket.


				</p><div class="gradientback"></div></div><div class="content"><p>
					Outside the eurozone, a total of 22 countries and territories that do not belong to the EU have currencies that are directly pegged to the euro including 13 countries in mainland Africa (CFA franc), two African island countries (Comorian franc and Cape Verdean escudo), three French Pacific territories (CFP franc) and three Balkan countries, Bosnia and Herzegovina (Bosnia and Herzegovina convertible mark), Bulgaria (Bulgarian lev) and Macedonia (Macedonian denar).[56] On 28 July 2009, São Tomé and Príncipe signed an agreement with Portugal which will eventually tie its currency to the euro.[57] Additionally, the Moroccan dirham is tied to a basket of currencies, including the Euro and the US dollar, with the Euro given the highest weighting.</p><p>With the exception of Bosnia, Bulgaria, Macedonia (which had pegged their currencies against the Deutsche Mark) and Cape Verde (formerly pegged to the Portuguese escudo), all of these non-EU countries had a currency peg to the French Franc before pegging their currencies to the euro. Pegging a country's currency to a major currency is regarded as a safety measure, especially for currencies of areas with weak economies, as the euro is seen as a stable currency, prevents runaway inflation and encourages foreign investment due to its stability.</p><p>Within the EU several currencies have a peg to the euro, in most instances as a precondition to joining the eurozone. The Bulgarian lev was formerly pegged to the Deutsche Mark; one other EU member state has a direct peg due to ERM II: the Danish krone.</p><p>In total, as of 2013[update], 182&nbsp;million people in Africa use a currency pegged to the euro, 27&nbsp;million people outside the eurozone in Europe, and another 545,000 people on Pacific islands.[49]</p><p>Since 2005, stamps issued by the Sovereign Military Order of Malta have been denominated in euros, although the Order's official currency remains the Maltese scudo.[58] The Maltese scudo itself is pegged to the euro and is only recognised as legal tender within the Order.[59]</p><h2>Economics</h2><h3>Optimal currency area</h3><p> Further information: Optimum currency area</p><p>In economics, an optimum currency area, or region (OCA or OCR), is a geographical region in which it would maximise economic efficiency to have the entire region share a single currency. There are two models, both proposed by Robert Mundell: the stationary expectations model and the international risk sharing model. Mundell himself advocates the international risk sharing model and thus concludes in favour of the euro.[60] However, even before the creation of the single currency, there were concerns over diverging economies. Before the late-2000s recession the chances of a state leaving the euro, or the chances that the whole zone would collapse, were considered extremely slim.[61] However the Greek government-debt crisis led to former British Foreign Secretary Jack Straw claiming the eurozone could not last in its current form.[62] Part of the problem seems to be the rules that were created when the euro was set up. John Lanchester, writing for The New Yorker, explains it thus:</p><p>The guiding principle of the currency, which opened for business in 1999, were supposed to be a set of rules to limit a country's annual deficit to three per cent of gross domestic product, and the total accumulated debt to sixty per cent of G.D.P. It was a nice idea, but by 2004 the two biggest economies in the euro zone, Germany and France, had broken the rules for three years in a row.[63]</p><h3>Transaction costs and risks</h3><p>The most obvious benefit of adopting a single currency is to remove the cost of exchanging currency, theoretically allowing businesses and individuals to consummate previously unprofitable trades. For consumers, banks in the eurozone must charge the same for intra-member cross-border transactions as purely domestic transactions for electronic payments (e.g., credit cards, debit cards and cash machine withdrawals).</p><p>The absence of distinct currencies also theoretically removes exchange rate risks, although the imposition of transfer restrictions in 2012–13 Cypriot financial crisis means that the situation is not quite so simple. The risk of unanticipated exchange rate movement has always added an additional risk or uncertainty for companies or individuals that invest or trade outside their own currency zones. Companies that hedge against this risk will no longer need to shoulder this additional cost. This is particularly important for countries whose currencies had traditionally fluctuated a great deal, particularly the Mediterranean nations[citation needed].</p><p>Financial markets on the continent are expected to be far more liquid and flexible than they were in the past. The reduction in cross-border transaction costs will allow larger banking firms to provide a wider array of banking services that can compete across and beyond the eurozone. However, although transaction costs were reduced, some studies have shown that risk aversion has increased during the last 40 years in the Eurozone.[65]</p><h3>Price parity</h3><p>Another effect of the common European currency is that differences in prices—in particular in price levels—should decrease because of the law of one price. Differences in prices can trigger arbitrage, i.e., speculative trade in a commodity across borders purely to exploit the price differential. Therefore, prices on commonly traded goods are likely to converge, causing inflation in some regions and deflation in others during the transition. Some evidence of this has been observed in specific eurozone markets.[66]</p><h3>Macroeconomic stability</h3><p>Low levels of inflation are the hallmark of stable and modern economies. Because a high level of inflation acts as a tax (seigniorage) and theoretically discourages investment, it is generally viewed as undesirable. In spite of the downside, many countries have been unable or unwilling to deal with serious inflationary pressures.[citation needed] Before the introduction of the euro, some countries had successfully contained inflation, which was then seen as a major economic problem, by establishing largely independent central banks. One such bank was the Bundesbank in Germany; the European Central Bank was modelled on the Bundesbank.[67] It is independent of the pressures of national governments and has a mandate to keep inflation low. Member countries that join the euro hope to enjoy the macroeconomic stability associated with low levels of inflation. The ECB (unlike the Federal Reserve in the United States of America) does not have a second objective to sustain growth and employment.[citation needed]</p><p>The Euro has come under criticism due to its imperialistic style regulation, lack of flexibility and [68] rigidity towards sharing member States on issues such as nominal interest rates Many national and corporate bonds denominated in euro are significantly more liquid and have lower interest rates than was historically the case when denominated in national currencies. While increased liquidity may lower the nominal interest rate on the bond, denominating the bond in a currency with low levels of inflation arguably plays a much larger role. A credible commitment to low levels of inflation and a stable debt reduces the risk that the value of the debt will be eroded by higher levels of inflation or default in the future, allowing debt to be issued at a lower nominal interest rate.</p><p>Unfortunately, there is also a cost in structurally keeping inflation lower than in the United States, UK, and China. The result is that seen from those countries, the euro has become expensive, making European products increasingly expensive for its largest importers. Hence export from the euro zone becomes more difficult. This is one of the main reasons why economic growth inside the euro zone now lags behind growth in other large economies.[citation needed] This effect is strongest in European countries with a weak economy.</p><p>In general, those in Europe who own large amounts of euros are served by high stability and low inflation. Those who now need to earn euros, including those countries who need to pay interest on large debts, are likely better served with a slightly less strong euro leading to more export. Because with a lower euro, investors would see better chances for (companies in) southern European countries to grow themselves out of the crisis. As a result, investing there would become less risky, and that would push interest rates for southern countries more in line with the European average.[citation needed]</p><div class="gradientback"></div></div><div class="content"><p>The contradiction here is that high macroeconomic stability in the form of ongoing historically low inflation over time leads to economic problems, creating higher interest rates and political and economic instability for the weaker partners.[citation needed]</p><p>A 2009 consensus from the studies of the introduction of the euro concluded that it has increased trade within the eurozone by 5% to 10%,[69] although one study suggested an increase of only 3%[70] while another estimated 9 to 14%.[71] However, a meta-analysis of all available studies suggests that the prevalence of positive estimates is caused by publication bias and that the underlying effect may be negligible.[72] Furthermore, studies accounting for time trend reflecting general cohesion policies in Europe that started before, and continue after implementing the common currency find no effect on trade.[73][74] These results suggest that other policies aimed at European integration might be the source of observed increase in trade.</p><p>Physical investment seems to have increased by 5% in the eurozone due to the introduction.[75] Regarding foreign direct investment, a study found that the intra-eurozone FDI stocks have increased by about 20% during the first four years of the EMU.[76] Concerning the effect on corporate investment, there is evidence that the introduction of the euro has resulted in an increase in investment rates and that it has made it easier for firms to access financing in Europe. The euro has most specifically stimulated investment in companies that come from countries that previously had weak currencies. A study found that the introduction of the euro accounts for 22% of the investment rate after 1998 in countries that previously had a weak currency.[77]</p><p>The introduction of the euro has led to extensive discussion about its possible effect on inflation. In the short term, there was a widespread impression in the population of the eurozone that the introduction of the euro had led to an increase in prices, but this impression was not confirmed by general indices of inflation and other studies.[78][79] A study of this paradox found that this was due to an asymmetric effect of the introduction of the euro on prices: while it had no effect on most goods, it had an effect on cheap goods which have seen their price round up after the introduction of the euro. The study found that consumers based their beliefs on inflation of those cheap goods which are frequently purchased.[80] It has also been suggested that the jump in small prices may be because prior to the introduction, retailers made fewer upward adjustments and waited for the introduction of the euro to do so.[81]</p><p>One of the advantages of the adoption of a common currency is the reduction of the risk associated with changes in currency exchange rates. It has been found that the introduction of the euro created significant reductions in market risk exposures for nonfinancial firms both in and outside of Europe.[82] These reductions in market risk were concentrated in firms domiciled in the eurozone and in non-Euro firms with a high fraction of foreign sales or assets in Europe.</p><p>The introduction of the euro seems to have had a strong effect on European financial integration. According to a study on this question, it has significantly reshaped the European financial system, especially with respect to the securities markets [...] However, the real and policy barriers to integration in the retail and corporate banking sectors remain significant, even if the wholesale end of banking has been largely integrated.[83] Specifically, the euro has significantly decreased the cost of trade in bonds, equity, and banking assets within the eurozone.[84] On a global level, there is evidence that the introduction of the euro has led to an integration in terms of investment in bond portfolios, with eurozone countries lending and borrowing more between each other than with other countries.[85]</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/e/ea/Long-term_interest_rates_of_eurozone_countries_since_1993.png/300px-Long-term_interest_rates_of_eurozone_countries_since_1993.png" width="300" height="143"><p>


				Long-term interest rates of Euro countries, 1993–2016


				</p><p>
					As of January 2014, and since the introduction of the euro, interest rates of most members countries (particularly those with a weak currency), have decreased. The countries whose interest rates fell most as a result of the adoption of the euro are Greece, Ireland, Portugal, Spain, and Italy. These very countries have had the most serious sovereign financing problems.</p><p>The effect of declining interest rates, combined with excess liquidity continually provided by the ECB, made it easier for banks within the countries in which interest rates fell the most, and their linked sovereigns, to borrow significant amounts (above the 3% of GDP budget deficit imposed on the eurozone initially) and significantly inflate their public and private debt levels.[86] Following the financial crisis of 2007–2008, governments in these countries found it necessary to bail out or nationalise their privately held banks to prevent systemic failure of the banking system when underlying hard or financial asset values were found to be grossly inflated and sometimes so near worthless there was no liquid market for them.[87] This further increased the already high levels of public debt to a level the markets began to consider unsustainable, via increasing government bond interest rates, producing the ongoing European sovereign-debt crisis.</p><p>The evidence on the convergence of prices in the eurozone with the introduction of the euro is mixed. Several studies failed to find any evidence of convergence following the introduction of the euro after a phase of convergence in the early 1990s.[88][89] Other studies have found evidence of price convergence,[90][91] in particular for cars.[92] A possible reason for the divergence between the different studies is that the processes of convergence may not have been linear, slowing down substantially between 2000 and 2003, and resurfacing after 2003 as suggested by a recent study (2009).[93]</p><p>A study suggests that the introduction of the euro has had a positive effect on the amount of tourist travel within the EMU, with an increase of 6.5%.[94]</p><h2>Exchange rates</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/c/c5/EUR-USD.PNG/300px-EUR-USD.PNG" width="300" height="200"><p>


				Euro-US Dollar exchange rate, starting from 2002. More recent information is available here.


				</p><div class="gradientback"></div></div><div class="content"><h3>Flexible exchange rates</h3><p>
					The ECB targets interest rates rather than exchange rates and in general does not intervene on the foreign exchange rate markets. This is because of the implications of the Mundell–Fleming model, which implies a central bank cannot (without capital controls) maintain interest rate and exchange rate targets simultaneously, because increasing the money supply results in a depreciation of the currency. In the years following the Single European Act, the EU has liberalised its capital markets, and as the ECB has chosen monetary autonomy, the exchange-rate regime of the euro is flexible, or floating. The result of the ECB maintaining historically low interest rates and restricting money supply has been that over the last decade the euro has become expensive relative to the currency of Europe's main trading partners. However, in 2010, the euro started on a sharp decline. Starting at U.S$1.60 in 2008, and dropping to US$1.04 in 2015. The Canadian dollar, despite seeing a decline in value against the USD, has seen an increase in value relative to the euro.</p><h3>Against other major currencies</h3><p>The euro is the second-most widely held reserve currency after the U.S. dollar. After its introduction on 4 January 1999 its exchange rate against the other major currencies fell reaching its lowest exchange rates in 2000 (25 October vs the U.S. dollar, 26 October vs Japanese Yen, 3 May vs Pound Sterling). Afterwards it regained and its exchange rate reached its historical highest point in 2008 (15 July vs U.S. dollar, 23 July vs Japanese Yen, 29 December vs Pound Sterling). With the advent of the global financial crisis the euro initially fell, only to regain later. Despite pressure due to the European sovereign-debt crisis the euro remained stable.[95] In November 2011 the euro's exchange rate index&nbsp;– measured against currencies of the bloc's major trading partners&nbsp;– was trading almost two percent higher on the year, approximately at the same level as it was before the crisis kicked off in 2007.[96]</p><h2>Linguistic issues</h2><p> Main article: Linguistic issues concerning the euro</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/f/f5/EUR_5_obverse_%282013_issue%29.png/220px-EUR_5_obverse_%282013_issue%29.png" width="220" height="113"><p>


				5 euro note from the new Europa series written in Latin (EURO) and Greek (???O) alphabets, but also in the Cyrillic (????) alphabet, as a result of Bulgaria joining the European Union in 2007.


				</p><p>
					The formal titles of the currency are euro for the major unit and cent for the minor (one hundredth) unit and for official use in most eurozone languages; according to the ECB, all languages should use the same spelling for the nominative singular.[100] This may contradict normal rules for word formation in some languages, e.g., those where there is no eu diphthong. Bulgaria has negotiated an exception; euro in the Bulgarian Cyrillic alphabet is spelled as e??? (evro) and not e??? (euro) in all official documents.[101] In the Greek script the term e??? (evró) is used; the Greek cent coins are denominated in ?ept?/? (leptó/á). Official practice for English-language EU legislation is to use the words euro and cent as both singular and plural,[102] although the European Commission's Directorate-General for Translation states that the plural forms euros and cents should be used in English.[103]</p><h2>Criticism</h2><h3>Unemployment</h3><p>Nobel memorial prize-winning economist James Meade thought that a central bank should not make price stability the objective of aggregate demand management. When prices are likely to be pushed up by increase of indirect taxes or adverse terms-of-trade shocks, the surge in prices must be cancelled out by decline in domestic money wage costs, as long as such a price stability policy is adopted.[104] There would be unemployment in the all industrial sectors under a price stabilisation policy, suggesting that in the short run the elasticity of demand for labour is low.</p><p>Under the ECB's price stabilisation policy, many people in the eurozone have difficulty finding a job. The unemployment rate of Spain is around 25 percent in 2014, and an economic forecast says that the figure will not decrease below 20 percent until 2017.[105]</p><p>ELSTAT, the statistics agency of Greece, shows that Greece's unemployment rate was 27 percent in June 2014.[106] OECD forecasts that Greece's unemployment rate will remain around 27 percent until 2016. Due to long-term unemployment, skills of jobless persons have been depreciated and their motivation of finding jobs has been lost, which causes the country's level of unemployment to remain high.[107]</p><p>Spain's youth unemployment rate is 53.8 percent in July 2014, and this is the highest figure in the eurozone.[109] This figure is comparable to 53.1 percent of the Greek youth unemployment in May 2014.</p><p>In July 2014, the averaged unemployment rate of the eurozone is 11.7 percent, slight decrease from 11.9 percent in 2013.[108][109]</p><p>Likewise, Paul Krugman argued that the existence of a single shared currency across the entire eurozone, in combination with tight money policies of the ECB (motivated by insistence of Germany on low inflation), placed much of Southern Europe in a state of permanent high unemployment. According to Krugman, during the period between the creation of the euro and the 2008 financial crisis, countries of Southern Europe experienced abnormally high rates of wage growth due to high influx of investor money. Between 2000 and 2008, unit labor costs actually declined slightly in Germany, but rose by 30% in Spain and Greece.[110] This created an imbalance that put these countries at competitive disadvantage relative to Northern Europe. Returning to full employment at this point requires that the labor costs gap is somehow cancelled out. If Spain and Greece had their own currencies, this would have easily happened through exchange rate adjustment. Since they don't, it can either happen through a decrease in nominal wages in Spain and Greece, also known as internal devaluation, (an extremely difficult and slow process, since nominal wages, in general, exhibit downward rigidity), or through an equal increase in nominal wages (i.e. inflation) in Northern Europe, which does not happen because of active resistance from Germany.[111][112]</p><h2>Notes</h2><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Euro&amp;oldid=783608999"					
								Categories:  Hidden categories:</p><br><h1 lang="en">Outline of economics</h1><p> From Wikipedia, the free encyclopedia</p><p>The following hierarchical outline is provided as an overview of and topical guide to economics:</p><p>Economics – analyzes the production, distribution, and consumption of goods and services. It aims to explain how economies work and how economic agents interact.</p><h2>Contents</h2><div class="gradientback"></div></div><div class="content"><h2>Description of Economics</h2><p>Economics can be described as all of the following:</p><h2>Branches of economics</h2><h3>Subdisciplines of economics</h3><h3>Methodologies or approaches</h3><h3>Multidisciplinary fields involving economics</h3><h2>Types of economies</h2><p> Main articles: Economy and Economic system</p><p>Economy – system of human activities related to the production, distribution, exchange, and consumption of goods and services of a country or other area.</p><h3>Economies, by political &amp; social ideological structure</h3><h3>Economies, by scope</h3><h3>Economies, by regulation</h3><h2>Economic elements</h2><h3>Economic activities</h3><h3>Economic forces</h3><h3>Economic measures</h3><h3>Economic participants</h3><h3>Economic politics</h3><p>Economic policy</p><h3>Infrastructure</h3><p>Infrastructure</p><h3>Markets</h3><p>Market</p><p>Market form</p><h3>Money</h3><p>Money</p><h3>Resources</h3><p>Resource management</p><p>Factors of production</p><p>Land</p><p>Capital</p><h2>Economic theory</h2><h3>Economic ideologies</h3><h2>History of economics</h2><h3>History of economic thought</h3><p>History of economic thought</p><h3>Economic history</h3><p>Economic history</p><h2>General economic concepts</h2><h2>Economics organizations</h2><h2>Economics publications</h2><h2>Persons influential in the field of economics</h2><h3>Nobel Memorial Prize–winning economic historians</h3><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Outline_of_economics&amp;oldid=779322882"					
								Categories:  Hidden categories:</p><br><h1 lang="en">Economics (disambiguation)</h1><p> From Wikipedia, the free encyclopedia</p><div class="gradientback"></div></div><div class="content"><p>Economics is the social science that studies the production, distribution, and consumption of goods and services.</p><p>Economics may also refer to:</p><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Economics_(disambiguation)&amp;oldid=642984251"					
								Categories:  Hidden categories:</p><br><h1 lang="en">Schools of economic thought</h1><p> From Wikipedia, the free encyclopedia</p><p>In the history of economic thought, a school of economic thought is a group of economic thinkers who share or shared a common perspective on the way economies work. While economists do not always fit into particular schools, particularly in modern times, classifying economists into schools of thought is common. Economic thought may be roughly divided into three phases: premodern (Greco-Roman, Indian, Persian, Islamic, and Imperial Chinese), early modern (mercantilist, physiocrats) and modern (beginning with Adam Smith and classical economics in the late 18th century). Systematic economic theory has been developed mainly since the beginning of what is termed the modern era.</p><p>Currently, the great majority of economists follow an approach referred to as mainstream economics (sometimes called 'orthodox economics'). Within the mainstream in the United States, distinctions can be made between the Saltwater school (associated with Berkeley, Harvard, MIT, Pennsylvania, Princeton, and Yale), and the more laissez-faire ideas of the Freshwater school (represented by the Chicago school of economics, Carnegie Mellon University, the University of Rochester and the University of Minnesota). Both of these schools of thought are associated with the neoclassical synthesis.</p><p>Some influential approaches of the past, such as the historical school of economics and institutional economics, have become defunct or have declined in influence, and are now considered heterodox approaches. Other longstanding heterodox schools of economic thought include Austrian economics and Marxian economics. Some more recent developments in economic thought such as feminist economics and ecological economics adapt and critique mainstream approaches with an emphasis on particular issues rather than developing as independent schools.</p><h2>Contents</h2><h2>Ancient economic thought</h2><p> Main article: Ancient economic thought</p><h2>Islamic economics</h2><p> Main articles: Islamic economic jurisprudence and Islamic economics in the world</p><p>Islamic economics is the practice of economics in accordance with Islamic law. The origins can be traced back to the Caliphate,[1] where an early market economy and some of the earliest forms of merchant capitalism took root between the 8th–12th centuries, which some refer to as Islamic capitalism.[2]</p><p>Islamic economics seeks to enforce Islamic regulations not only on personal issues, but to implement broader economic goals and policies of an Islamic society, based on uplifting the deprived masses. It was founded on free and unhindered circulation of wealth so as to handsomely reach even the lowest echelons of society. One distinguishing feature is the tax on wealth (in the form of both Zakat and Jizya), and bans levying taxes on all kinds of trade and transactions (Income/Sales/Excise/Import/Export duties etc.). Another distinguishing feature is prohibition of interest in the form of excess charged while trading in money. Its pronouncement on use of paper currency also stands out. Though promissory notes are recognized, they must be fully backed by reserves. Fractional-reserve banking is disallowed as a form of breach of trust.</p><p>It saw innovations such as trading companies, big businesses, contracts, bills of exchange, long-distance international trade, the first forms of partnership (mufawada) such as limited partnerships (mudaraba), and the earliest forms of credit, debt, profit, loss, capital (al-mal), capital accumulation (nama al-mal),[3] circulating capital, capital expenditure, revenue, cheques, promissory notes,[4] trusts (see Waqf), startup companies,[5] savings accounts, transactional accounts, pawning, loaning, exchange rates, bankers, money changers, ledgers, deposits, assignments, the double-entry bookkeeping system,[6] lawsuits,[7] and agency institution.[8][9]</p><p>This school has seen a revived interest in development and understanding since the later part of the 20th century.</p><h2>Scholasticism</h2><p> Main article: Scholasticism</p><h2>Mercantilism</h2><p> Main article: Mercantilism</p><p>Economic policy in Europe during the late Middle Ages and early Renaissance treated economic activity as a good which was to be taxed to raise revenues for the nobility and the church. Economic exchanges were regulated by feudal rights, such as the right to collect a toll or hold a faire, as well as guild restrictions and religious restrictions on lending. Economic policy, such as it was, was designed to encourage trade through a particular area. Because of the importance of social class, sumptuary laws were enacted, regulating dress and housing, including allowable styles, materials and frequency of purchase for different classes. Niccolò Machiavelli in his book The Prince was one of the first authors to theorize economic policy in the form of advice. He did so by stating that princes and republics should limit their expenditures and prevent either the wealthy or the populace from despoiling the other. In this way a state would be seen as generous because it was not a heavy burden on its citizens.</p><h2>Physiocrats</h2><p> Main article: Physiocrats</p><p>The Physiocrats were 18th century French economists who emphasized the importance of productive work, and particularly agriculture, to an economy's wealth. Their early support of free trade and deregulation influenced Adam Smith and the classical economists.</p><h2>Classical political economy</h2><p> Main article: Classical economics</p><p>Classical economics, also called classical political economy, was the original form of mainstream economics of the 18th and 19th centuries. Classical economics focuses on the tendency of markets to move to equilibrium and on objective theories of value. Neo-classical economics differs from classical economics primarily in being utilitarian in its value theory and using marginal theory as the basis of its models and equations. Marxian economics also descends from classical theory. Anders Chydenius (1729–1803) was the leading classical liberal of Nordic history. Chydenius, who was a Finnish priest and member of parliament, published a book called The National Gain in 1765, in which he proposes ideas of freedom of trade and industry and explores the relationship between economy and society and lays out the principles of liberalism, all of this eleven years before Adam Smith published a similar and more comprehensive book, The Wealth of Nations. According to Chydenius, democracy, equality and a respect for human rights were the only way towards progress and happiness for the whole of society.</p><h2>American (National) School</h2><div class="gradientback"></div></div><div class="content"><p> Main article: American School (economics)</p><p>The American School owes its origin to the writings and economic policies of Alexander Hamilton, the first Treasury Secretary of the United States. It emphasized high tariffs on imports to help develop the fledgling American manufacturing base and to finance infrastructure projects, as well as National Banking, Public Credit, and government investment into advanced scientific and technological research and development. Friedrich List, one of the most famous proponents of the economic system, named it the National System, and was the main impetus behind the development of the German Zollverein and the economic policies of Germany under Chancellor Otto Von Bismarck beginning in 1879.</p><h2>French liberal school</h2><p> Main article: French Liberal School</p><p>The French Liberal School (also called the Optimist School or Orthodox School) is a 19th-century school of economic thought that was centered on the Collège de France and the Institut de France. The Journal des Économistes was instrumental in promulgating the ideas of the School. The School voraciously defended free trade and laissez-faire capitalism. They were primary opponents of collectivist, interventionist and protectionist ideas. This made the French School a forerunner of the modern Austrian School.</p><h2>German historical school</h2><p> Main article: Historical school of economics</p><p>The Historical school of economics was an approach to academic economics and to public administration that emerged in the 19th century in Germany, and held sway there until well into the 20th century. The Historical school held that history was the key source of knowledge about human actions and economic matters, since economics was culture-specific, and hence not generalizable over space and time. The School rejected the universal validity of economic theorems. They saw economics as resulting from careful empirical and historical analysis instead of from logic and mathematics. The School preferred historical, political, and social studies to self-referential mathematical modelling. Most members of the school were also Kathedersozialisten, i.e. concerned with social reform and improved conditions for the common man during a period of heavy industrialization. The Historical School can be divided into three tendencies: the Older, led by Wilhelm Roscher, Karl Knies, and Bruno Hildebrand; the Younger, led by Gustav von Schmoller, and also including Étienne Laspeyres, Karl Bücher, Adolph Wagner, and to some extent Lujo Brentano; the Youngest, led by Werner Sombart and including, to a very large extent, Max Weber.</p><p>Predecessors included Friedrich List. The Historical school largely controlled appointments to Chairs of Economics in German universities, as many of the advisors of Friedrich Althoff, head of the university department in the Prussian Ministry of Education 1882-1907, had studied under members of the School. Moreover, Prussia was the intellectual powerhouse of Germany and so dominated academia, not only in central Europe, but also in the United States until about 1900, because the American economics profession was led by holders of German Ph.Ds. The Historical school was involved in the Methodenstreit (strife over method) with the Austrian School, whose orientation was more theoretical and a prioristic. In English speaking countries, the Historical school is perhaps the least known and least understood approach to the study of economics, because it differs radically from the now-dominant Anglo-American analytical point of view. Yet the Historical school forms the basis—both in theory and in practice—of the social market economy, for many decades the dominant economic paradigm in most countries of continental Europe. The Historical school is also a source of Joseph Schumpeter's dynamic, change-oriented, and innovation-based economics. Although his writings could be critical of the School, Schumpeter's work on the role of innovation and entrepreneurship can be seen as a continuation of ideas originated by the Historical School, especially the work of von Schmoller and Sombart.</p><h2>English historical school</h2><p> Main article: English historical school of economics</p><p>Although not nearly as famous as its German counterpart, there was also an English Historical School, whose figures included William Whewell, Richard Jones, Thomas Edward Cliffe Leslie, Walter Bagehot, Thorold Rogers, Arnold Toynbee, William Cunningham, and William Ashley. It was this school that heavily critiqued the deductive approach of the classical economists, especially the writings of David Ricardo. This school revered the inductive process and called for the merging of historical fact with those of the present period.</p><h2>French historical school</h2><h2>Utopian economics</h2><h2>Georgist economics</h2><p> Main article: Georgism</p><p>Georgism or geoism is an economic philosophy proposing that both individual and national economic outcomes would be improved by the utilization of economic rent resulting from control over land and natural resources through levies such as a land value tax.</p><h2>Marxian economics</h2><p> Main article: Marxian economics</p><p>Marxian economics descended from the work of Karl Marx and Friedrich Engels. This school focuses on the labor theory of value and what Marx considered to be the exploitation of labour by capital. Thus, in Marxian economics, the labour theory of value is a method for measuring the exploitation of labour in a capitalist society rather than simply a theory of price.[10][11]</p><h2>Neo-Marxian economics</h2><p> Main article: Neo-Marxian economics</p><h2>State socialism</h2><p> Main article: Socialist economics</p><h2>Ricardian socialism</h2><p> Main article: Ricardian socialism</p><p>Ricardian socialism is a branch of early 19th century classical economic thought based on the theory that labor is the source of all wealth and exchange value, and rent, profit and interest represent distortions to a free market. The pre-Marxian theories of capitalist exploitation they developed are widely regarded as having been heavily influenced by the works of David Ricardo, and favoured collective ownership of the means of production.</p><h2>Anarchist economics</h2><p> Main article: Anarchist economics</p><p>Anarchist economics comprises a set of theories which seek to outline modes of production and exchange not governed by coercive social institutions:</p><p>Thinkers associated with anarchist economics include:</p><h2>Distributism</h2><div class="gradientback"></div></div><div class="content"><p> Main article: Distributism</p><p>Distributism is an economic philosophy that was originally formulated in the late 19th century and early 20th century by Catholic thinkers to reflect the teachings of Pope Leo XIII's encyclical Rerum Novarum, and Pope Pius's XI encyclical Quadragesimo Anno. It seeks to pursue a third way between capitalism and socialism, desiring to order society according to Christian principles of justice while still preserving private property.</p><h2>Institutional economics</h2><p> Main article: Institutional economics</p><p>Institutional economics focuses on understanding the role of the evolutionary process and the role of institutions in shaping economic behaviour. Its original focus lay in Thorstein Veblen's instinct-oriented dichotomy between technology on the one side and the ceremonial sphere of society on the other. Its name and core elements trace back to a 1919 American Economic Review article by Walton H. Hamilton.[12][13]</p><h2>New institutional economics</h2><p> Main article: New institutional economics</p><p>New institutional economics is a perspective that attempts to extend economics by focusing on the social and legal norms and rules (which are institutions) that underlie economic activity and with analysis beyond earlier institutional economics and neoclassical economics.[14] It can be seen as a broadening step to include aspects excluded in neoclassical economics. It rediscovers aspects of classical political economy.</p><h2>Neoclassical economics</h2><p> Main article: Neoclassical economics</p><p>Neoclassical economics is the dominant form of economics used today and has the highest amount of adherents among economists.[dubious – discuss] It is often referred to by its critics as Orthodox Economics. The more specific definition this approach implies was captured by Lionel Robbins in a 1932 essay: the science which studies human behavior as a relation between scarce means having alternative uses. The definition of scarcity is that available resources are insufficient to satisfy all wants and needs; if there is no scarcity and no alternative uses of available resources, then there is no economic problem.</p><h2>Lausanne school</h2><p> Main article: Lausanne School</p><h2>Austrian school</h2><p> Main article: Austrian School</p><p>Austrian economists advocate methodological individualism in interpreting economic developments, the subjective theory of value, that money is non-neutral, and emphasize the organizing power of the price mechanism (see economic calculation debate) and a laissez faire approach to the economy.[15]</p><h2>Stockholm school</h2><p> Main article: Stockholm School</p><h2>Keynesian economics</h2><p> Main articles: Keynesian economics, Post-Keynesian economics, Neo-Keynesian economics, and New Keynesian economics</p><p>Keynesian economics has developed from the work of John Maynard Keynes and focused on macroeconomics in the short-run, particularly the rigidities caused when prices are fixed. It has two successors. Post-Keynesian economics is an alternative school—one of the successors to the Keynesian tradition with a focus on macroeconomics. They concentrate on macroeconomic rigidities and adjustment processes, and research micro foundations for their models based on real-life practices rather than simple optimizing models. Generally associated with Cambridge, England and the work of Joan Robinson (see Post-Keynesian economics). New-Keynesian economics is the other school associated with developments in the Keynesian fashion. These researchers tend to share with other Neoclassical economists the emphasis on models based on micro foundations and optimizing behavior, but focus more narrowly on standard Keynesian themes such as price and wage rigidity. These are usually made to be endogenous features of these models, rather than simply assumed as in older style Keynesian ones (see New-Keynesian economics).</p><h2>Chicago school</h2><p> Main article: Chicago school of economics</p><p>The Chicago School is a neoclassical school of economic thought associated with the work of the faculty at the University of Chicago, notable particularly in macroeconomics for developing monetarism as an alternative to Keynesianism and its influence on the use of rational expectations in macroeconomic modelling.</p><h2>Carnegie school</h2><p> Main article: Carnegie School</p><h2>Neo-Ricardianism</h2><p> Main article: Neo-Ricardianism</p><h2>Modern schools (late 19th and 20th century)</h2><p>Mainstream economics is a term used to distinguish economics in general from heterodox approaches and schools within economics. It begins with the premise that resources are scarce and that it is necessary to choose between competing alternatives. That is, economics deals with tradeoffs. With scarcity, choosing one alternative implies forgoing another alternative—the opportunity cost. The opportunity cost expresses an implicit relationship between competing alternatives. Such costs, considered as prices in a market economy, are used for analysis of economic efficiency or for predicting responses to disturbances in a market. In a planned economy comparable shadow price relations must be satisfied for the efficient use of resources, as first demonstrated by the Italian economist Enrico Barone. Economists represent incentives and costs as playing a pervasive role in shaping decision making. An immediate example of this is the consumer theory of individual demand, which isolates how prices (as costs) and income affect quantity demanded. Modern mainstream economics builds primarily on neoclassical economics, which began to develop in the late 19th century. Mainstream economics also acknowledges the existence of market failure and insights from Keynesian economics. It uses models of economic growth for analyzing long-run variables affecting national income. It employs game theory for modeling market or non-market behavior. Some important insights on collective behavior (for example, emergence of organizations) have been incorporated through the new institutional economics. A definition that captures much of modern economics is that of Lionel Robbins in a 1932 essay: the science which studies human behaviour as a relationship between ends and scarce means which have alternative uses. Scarcity means that available resources are insufficient to satisfy all wants and needs. Absent scarcity and alternative uses of available resources, there is no economic problem. The subject thus defined involves the study of choice, as affected by incentives and resources. Economics generally is the study of how people allocate scarce resources among alternative uses.</p><p>Heterodox economics: Some schools of thought are at variance with the microeconomic formalism of neoclassical economics. Heterodox economists instead emphasize the influence of history, natural systems, uncertainty, and power. Among these, we have institutional economics, Marxian economics, feminist economics, socialist economics, binary economics, ecological economics, bioeconomics and thermoeconomics.</p><div class="gradientback"></div></div><div class="content"><h2>Heterodox schools (20th and 21st century)</h2><p>In the late 19th century, a number of heterodox schools contended with the neoclassical school that arose following the marginal revolution. Most survive to the present day as self-consciously dissident schools, but with greatly diminished size and influence relative to mainstream economics. The most significant are Institutional economics, Marxian economics and the Austrian School.</p><p>The development of Keynesian economics was a substantial challenge to the dominant neoclassical school of economics. Keynesian views eventually entered the mainstream as a result of the Keynesian-neoclassical synthesis developed by John Hicks. The rise of Keynesianism, and its incorporation into mainstream economics, reduced the appeal of heterodox schools. However, advocates of a more fundamental critique of orthodox economics formed a school of Post-Keynesian economics.</p><p>More recent heterodox developments include evolutionary economics (though this term is also used to describe institutional economics), feminist, Green economics, Post-autistic economics, and Thermoeconomics</p><p>Heterodox approaches often embody criticisms of the mainstream approaches. For instance:</p><p>Most heterodox views are critical of capitalism. The most notable exception is Austrian economics.</p><p>Georgescu-Roegen reintroduced into economics, the concept of entropy from thermodynamics (as distinguished from what, in his view, is the mechanistic foundation of neoclassical economics drawn from Newtonian physics) and did foundational work which later developed into evolutionary economics. His work contributed significantly to thermoeconomics and to ecological economics.[16][17][18][19][20]</p><h2>20th century schools</h2><p>Notable schools or trends of thought in economics in the 20th century were as follows. These were advocated by well-defined groups of academics that became widely known:</p><p>In the late 20th century, areas of study that produced change in economic thinking were: risk-based (rather than price-based models), imperfect economic actors, and treating economics as a biological science (based on evolutionary norms rather than abstract exchange).</p><p>The study of risk was influential, in viewing variations in price over time as more important than actual price. This applied particularly to financial economics, where risk/return tradeoffs were the crucial decisions to be made.</p><p>An important area of growth was the study of information and decision. Examples of this school included the work of Joseph Stiglitz. Problems of asymmetric information and moral hazard, both based around information economics, profoundly affected modern economic dilemmas like executive stock options, insurance markets, and Third-World debt relief.</p><p>Finally, there were a series of economic ideas rooted in the conception of economics as a branch of biology, including the idea that energy relationships, rather than price relationships, determine economic structure. The use of fractal geometry to create economic models (see Energy Economics). In its infancy the application of non-linear dynamics to economic theory, as well as the application of evolutionary psychology explored the processes of valuation and the persistence of non-equilibrium conditions. The most visible work was in the area of applying fractals to market analysis, particularly arbitrage (see Complexity economics). Another infant branch of economics was neuroeconomics. The latter combines neuroscience, economics, and psychology to study how we make choices.</p><h2>Economic viewpoints</h2><h3>Within mainstream</h3><p>Mainstream economics encompasses a wide (but not unbounded) range of views. Politically, most mainstream economists hold views ranging from laissez-faire to modern liberalism. There are also divergent views on particular issues within economics, such as the effectiveness and desirability of Keynesian macroeconomic policy. Although, historically, few mainstream economists have regarded themselves as members of a school, many would identify with one or more of neoclassical economics, monetarism, Keynesian economics, new classical economics, or behavioral economics.</p><p>Controversies within mainstream economics tend to be stated in terms of:</p><p>An example of a mainstream economic approach is the Triple Bottom Line accounting methods for cities developed by ICLEI and advocated by the C40 organization of the world's 40 largest cities. As this example suggests, a mainstream approach is defined by the degree to which it is adopted and advocated, not necessarily its technical rigor.</p><h3>Outside the mainstream</h3><p>Other viewpoints on economic issues from outside mainstrain economics include dependency theory and world systems theory in the study of international relations</p><p>Proposed radical reforms of the economic system originating outside mainstream economics include the participatory economics movement and binary economics.</p><h2>Notes</h2><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Schools_of_economic_thought&amp;oldid=783673823"					
								Categories:  Hidden categories:</p><br><h1 lang="en">Demand</h1><p> From Wikipedia, the free encyclopedia</p><p>In economics, demand is the quantity of a commodity or a service that people are willing or able to buy at a certain price.[1]</p><p>The relationship between price and quantity demanded is also known as demand curve. Preferences and choices, which underly demand, can be represented as functions of cost, benefit, odds and other variables.</p><h2>Contents</h2><h2>Determinants of (Factors affecting) demand</h2><p>Innumerable factors and circumstances could affect a buyer's willingness or ability to buy a good. Some of the more common factors are:</p><h2>Demand function and equation</h2><div class="gradientback"></div></div><div class="content"><p>The demand equation is the mathematical expression of the relationship between the quantity of a good demanded and those factors that affect the willingness and ability of a consumer to buy the good. For example, Qd = f(P; Prg, Y) is a demand equation where Qd is the quantity of a good demanded, P is the price of the good, Prg is the price of a related good, and Y is income; the function on the right side of the equation is called the demand function. The semi-colon in the list of arguments in the demand function means that the variables to the right are being held constant as one plots the demand curve in (quantity, price) space. A simple example of a demand equation is Qd = 325 - P - 30Prg + 1.4Y. Here 325 is the repository of all relevant non-specified factors that affect demand for the product. P is the price of the good. The coefficient is negative in accordance with the law of demand. The related good may be either a complement or a substitute. If a complement, the coefficient of its price would be negative as in this example. If a substitute, the coefficient of its price would be positive. Income, Y, has a positive coefficient indicating that the good is a normal good. If the coefficient was negative the good in question would be an inferior good meaning that the demand for the good would fall as the consumer's income increased. Specifying values for the non price determinants, Prg = 4.00 and Y = 50, results in the demand equation Q = 325 - P - 30(4) +1.4(50) or Q = 275 - P. If income were to increase to 55 the new demand equation would be Q = 282 - P. Graphically this change in a non price determinant of demand would be reflected in an outward shift of the demand function caused by a change in the x intercept.</p><h2>Demand curve</h2><p> Main article: Demand curve</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/3/36/Marshall_PED.png" width="175" height="180"><p>In economics, the demand curve is the graph depicting the relationship between the price of a certain commodity and the amount of it that consumers are willing and able to purchase at that given price.</p><h2>Price elasticity of demand (PED)</h2><p> Main article: Price elasticity of demand</p><p>PED is a measure of the sensitivity of the quantity variable, Q, to changes in the price variable, P. Elasticity answers the question of the percent by which the quantity demanded will change relative to (divided by) a given percentage change in the price. For infinitesimal changes the formula for calculating PED is the absolute value of (?Q/?P)×(P/Q).</p><h3>Determinants of PED</h3><p>The overriding factor in determining PED is the willingness and ability of consumers after a price changes to postpone immediate consumption decisions concerning the good and to search for substitutes (wait and look).</p><h3>Elasticity along linear demand curve</h3><p>The slope of a linear demand curve is constant. The elasticity of demand changes continuously as one moves down the demand curve because the ratio of price to quantity continuously falls. At the point the demand curve intersects the y-axis PED is infinitely elastic, because the variable Q appearing in the denominator of the elasticity formula is zero there. At the point the demand curve intersects the x-axis PED is zero, because the variable P appearing in the numerator of the elasticity formula is zero there.[2] At one point on the demand curve PED is unitary elastic: PED equals one. Above the point of unitary elasticity is the elastic range of the demand curve (meaning that the elasticity is greater than one). Below is the inelastic range, in which the elasticity is less than one. The decline in elasticity as one moves down the curve is due to the falling P/Q ratio.</p><h3>Constant price elasticity demand</h3><p>
				  
					
					  
						Q
						=
						a
						
						  P
						  
							c
						  
						
					  
					
					{\displaystyle Q=aP^{c}}
				  
				 where a and c are parameters, and the constant price elasticity is c and 
				  
					
					  
						c
						=
						0
					  
					
					{\displaystyle c\leq 0}
				  
				.</p><h2>Market structure and the demand curve</h2><p>In perfectly competitive markets the demand curve, the average revenue curve, and the marginal revenue curve all coincide and are horizontal at the market-given price.[3] The demand curve is perfectly elastic and coincides with the average and marginal revenue curves. Economic actors are price-takers. Perfectly competitive firms have zero market power; that is, they have no ability to affect the terms and conditions of exchange. A perfectly competitive firm's decisions are limited to whether to produce and if so, how much. In less than perfectly competitive markets the demand curve is negatively sloped and there is a separate marginal revenue curve. A firm in a less than perfectly competitive market is a price-setter. The firm can decide how much to produce or what price to charge. In deciding one variable the firm is necessarily determining the other variable</p><h2>Inverse demand function</h2><p> Main article: Inverse demand function</p><p>In its standard form a linear demand equation is Q = a - bP. That is, quantity demanded is a function of price. The inverse demand equation, or price equation, treats price as a function g of quantity demanded: P = f(Q). To compute the inverse demand equation, simply solve for P from the demand equation.[4] For example, if the demand equation is Q = 240 - 2P then the inverse demand equation would be P = 120 - .5Q, the right side of which is the inverse demand function.[5]</p><p>The inverse demand function is useful in deriving the total and marginal revenue functions. Total revenue equals price, P, times quantity, Q, or TR = P×Q. Multiply the inverse demand function by Q to derive the total revenue function: TR = (120 - .5Q) × Q = 120Q - 0.5Q². The marginal revenue function is the first derivative of the total revenue function; here MR = 120 - Q. Note that the MR function has the same y-intercept as the inverse demand function in this linear example; the x-intercept of the MR function is one-half the value of that of the demand function, and the slope of the MR function is twice that of the inverse demand function. This relationship holds true for all linear demand equations. The importance of being able to quickly calculate MR is that the profit-maximizing condition for firms regardless of market structure is to produce where marginal revenue equals marginal cost (MC). To derive MC the first derivative of the total cost function is taken. For example, assume cost, C, equals 420 + 60Q + Q2. Then MC = 60 + 2Q. Equating MR to MC and solving for Q gives Q = 20. So 20 is the profit maximizing quantity: to find the profit-maximizing price simply plug the value of Q into the inverse demand equation and solve for P.</p><div class="gradientback"></div></div><div class="content"><h2>Residual demand curve</h2><p>The demand curve facing a particular firm is called the residual demand curve. The residual demand curve is the market demand that is not met by other firms in the industry at a given price. The residual demand curve is the market demand curve D(p), minus the supply of other organizations, So(p): Dr(p) = D(p) - So(p )[6]</p><h2>Is the demand curve for PC firm really flat?</h2><p>Practically every introductory microeconomics text describes the demand curve facing a perfectly competitive firm as being flat or horizontal. A horizontal demand curve is perfectly elastic. If there are n identical firms in the market then the elasticity of demand PED facing any one firm is</p><p>where PEDm is the market elasticity of demand, PES is the elasticity of supply of each of the other firms, and (n -1) is the number of other firms. This formula suggests two things. The demand curve is not perfectly elastic and if there are a large number of firms in the industry the elasticity of demand for any individual firm will be extremely high and the demand curve facing the firm will be nearly flat.[6]</p><p>For example assume that there are 80 firms in the industry and that the demand elasticity for industry is -1.0 and the price elasticity of supply is 3. Then</p><p>That is the firm PED is 317 times as elastic as the market PED. If a firm raised its price by one tenth of one percent demand would drop by nearly one third.[6] if the firm raised its price by three tenths of one percent the quantity demanded would drop by nearly 100%. Three tenths of one percent marks the effective range of pricing power the firm has because any attempt to raise prices by a higher percentage will effectively reduce quantity demanded to zero.</p><h2>Demand management in economics</h2><p>Demand management in economics is the art or science of controlling economic or aggregate demand to avoid a recession. Such management is inspired by Keynesian macroeconomics, and Keynesian economics is sometimes referred to as demand-side economics.</p><h2>Different types of goods demand</h2><p>Negative demand: If the market response to a product is negative, it shows that people are not aware of the features of the service and the benefits offered. Under such circumstances, the marketing unit of a service firm has to understand the psyche of the potential buyers and find out the prime reason for the rejection of the service. For example: if passengers refuse a bus conductor's call to board the bus. The service firm has to come up with an appropriate strategy to remove the misunderstandings of the potential buyers. A strategy needs to be designed to transform the negative demand into a positive demand.</p><p>No demand: If people are unaware, have insufficient information about a service or due to the consumer's indifference this type of a demand situation could occur. The marketing unit of the firm should focus on promotional campaigns and communicating reasons for potential customers to use the firm's services. Service differentiation is one of the popular strategies used to compete in a no demand situation in the market.</p><p>Latent demand: At any given time it is impossible to have a set of services that offer total satisfaction to all the needs and wants of society. In the market there exists a gap between desirables and the availables. There is always a search on for better and newer offers to fill the gap between desirability and availability. Latent demand is a phenomenon of any economy at any given time, it should be looked upon as a business opportunity by service firms and they should orient themselves to identify and exploit such opportunities at the right time. For example, a passenger traveling in an ordinary bus dreams of traveling in a luxury bus. Therefore, latent demand is nothing but the gap between desirability and availability.</p><p>Seasonal demand:Some services do not have an all year round demand, they might be required only at a certain period of time. Seasons all over the world are very diverse. Seasonal demands create many problems to service organizations, such as:- idling the capacity, fixed cost and excess expenditure on marketing and promotions. Strategies used by firms to overcome this hurdle are like - to nurture the service consumption habit of customers so as to make the demand unseasonal, or other than that firms recognize markets elsewhere in the world during the off-season period. Hence, this presents and opportunity to target different markets with the appropriate season in different parts of the world. For example, the need for Christmas cards comes around once a year. Or the, seasonal fruits in a country.</p><p>Demand patterns need to be studied in different segments of the market. Service organizations need to constantly study changing demands related to there service offerings over various time periods. They have to develop a system to chart these demand fluctuations, which helps them in predicting the demand cycles. Demands do fluctuate randomly, therefore, they should be followed on a daily, weekly or a monthly basis.</p><h2>Criticism</h2><p>E. F. Schumacher challenges the prevailing economic assumption that fulfilling demand is the purpose of economic activity, offering a framework of what he calls Buddhist economics in which wise demands, fulfilling genuine human needs, are distinguished from unwise demands, arising from the five intellectual impairments recognized by Buddhism:[7]</p><p>The cultivation and expansion of needs is the antithesis of wisdom. It is also the antithesis of freedom and peace. Every increase of needs tends to increase one’s dependence on outside forces over which one cannot have control, and therefore increases existential fear. Only by a reduction of needs can one promote a genuine reduction in those tensions which are the ultimate causes of strife and war.[8]</p><h2>Demand reduction</h2><h3>In psychopharmacology</h3><p> Main article: Demand reduction</p><p>Demand reduction refers to efforts aimed at reducing the public desire for illegal and illicit drugs. The drug policy is in contrast to the reduction of drug supply, but the two policies are often implemented together.</p><h3>In energy conservation</h3><p> Main article: Energy demand management</p><p>Energy demand management, also known as demand-side management (DSM) or demand-side response (DSR), is the modification of consumer demand for energy through various methods such as financial incentives and behavioral change through education.</p><h2>Notes</h2><div class="gradientback"></div></div><div class="content"><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Demand&amp;oldid=778789425"					
								Categories:  				
											
						<br>
							

											 
										

							</p><br><h1 lang="en">Macroeconomics</h1><p> From Wikipedia, the free encyclopedia</p><p>Macroeconomics (from the Greek prefix makro- meaning large and economics) is a branch of economics dealing with the performance, structure, behavior, and decision-making of an economy as a whole. This includes national, regional, and global economies.[1] Macroeconomics and microeconomics, a pair of terms coined by Ragnar Frisch, are the two most general fields in economics.[2] In contrast to macroeconomics, microeconomics is the branch of economics that studies the behavior of individuals and firms in making decisions and the interactions among these individuals and firms in narrowly-defined markets.</p><p>Macroeconomists study aggregated indicators such as GDP, unemployment rates, national income, price indices, and the interrelations among the different sectors of the economy to better understand how the whole economy functions. Macroeconomists develop models that explain the relationship between such factors as national income, output, consumption, unemployment, inflation, savings, investment, international trade and international finance.</p><p>While macroeconomics is a broad field of study, there are two areas of research that are emblematic of the discipline: the attempt to understand the causes and consequences of short-run fluctuations in national income (the business cycle), and the attempt to understand the determinants of long-run economic growth (increases in national income). Macroeconomic models and their forecasts are used by governments to assist in the development and evaluation of economic policy.</p><h2>Contents</h2><h2>Basic macroeconomic concepts</h2><p>Macroeconomics encompasses a variety of concepts and variables, but there are three central topics for macroeconomic research.[3] Macroeconomic theories usually relate the phenomena of output, unemployment, and inflation. Outside of macroeconomic theory, these topics are also important to all economic agents including workers, consumers, and producers.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/7/7e/Circulation_in_macroeconomics.svg/220px-Circulation_in_macroeconomics.svg.png" width="220" height="196"><p>


				Circulation in macroeconomics.


				</p><h3>Output and income</h3><p>
					National output is the total amount of everything a country produces in a given period of time. Everything that is produced and sold generates an equal amount of income. Therefore, output and income are usually considered equivalent and the two terms are often used interchangeably. Output can be measured as total income, or it can be viewed from the production side and measured as the total value of final goods and services or the sum of all value added in the economy.[4]</p><p>Macroeconomic output is usually measured by gross domestic product (GDP) or one of the other national accounts. Economists are interested in long-run increases in output study economic growth. Advances in technology, accumulation of machinery and other capital, and better education and human capital all these factors lead to increased economic output over time. However, output does not always increase consistently. Business cycles can cause short-term drops in output called recessions. Economists look for macroeconomic policies that prevent economies from slipping into recessions and that lead to faster long-term growth.</p><h3>Unemployment</h3><p> Main article: Unemployment</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/d/db/Okuns_law_differences_1948_to_mid_2011.png/220px-Okuns_law_differences_1948_to_mid_2011.png" width="220" height="160"><p>


				A chart using US data showing the relationship between economic growth and unemployment expressed by Okun's law. The relationship demonstrates cyclical unemployment. Economic growth leads to a lower unemployment rate.


				</p><p>
					The amount of unemployment in an economy is measured by the unemployment rate, i.e. the percentage of workers without jobs in the labor force. The unemployment rate in the labor force only includes workers actively looking for jobs. People who are retired, pursuing education, or discouraged from seeking work by a lack of job prospects are excluded.</p><p>Unemployment can be generally broken down into several types that are related to different causes.</p><h3>Inflation and deflation</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/8/80/M2andInflation.png/220px-M2andInflation.png" width="220" height="160"><p>


				The ten-year moving averages of changes in price level and growth in money supply (using the measure of M2, the supply of hard currency and money held in most types of bank accounts) in the US from 1875 to 2011. Over the long run, the two series show a close relationship.


				</p><p>
					A general price increase across the entire economy is called inflation. When prices decrease, there is deflation. Economists measure these changes in prices with price indexes. Inflation can occur when an economy becomes overheated and grows too quickly. Similarly, a declining economy can lead to deflation.</p><div class="gradientback"></div></div><div class="content"><p>Central bankers, who manage a country's money supply, try to avoid changes in price level by using monetary policy. Raising interest rates or reducing the supply of money in an economy will reduce inflation. Inflation can lead to increased uncertainty and other negative consequences. Deflation can lower economic output. Central bankers try to stabilize prices to protect economies from the negative consequences of price changes.</p><p>Changes in price level may be the result of several factors. The quantity theory of money holds that changes in price level are directly related to changes in the money supply. Most economists believe that this relationship explains long-run changes in the price level.[10] Short-run fluctuations may also be related to monetary factors, but changes in aggregate demand and aggregate supply can also influence price level. For example, a decrease in demand due to a recession can lead to lower price levels and deflation. A negative supply shock, such as an oil crisis, lowers aggregate supply and can cause inflation.</p><h2>Macroeconomic models</h2><h3>Aggregate demand–aggregate supply</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/2/25/AS_%2B_AD_graph.svg/220px-AS_%2B_AD_graph.svg.png" width="220" height="172"><p>


				A traditional AS–AD diagram showing a shift in AD and the AS curve becoming inelastic beyond potential output.


				</p><p>
					The AD-AS model has become the standard textbook model for explaining the macroeconomy.[11] This model shows the price level and level of real output given the equilibrium in aggregate demand and aggregate supply. The aggregate demand curve's downward slope means that more output is demanded at lower price levels.[12] The downward slope is the result of three effects: the Pigou or real balance effect, which states that as real prices fall, real wealth increases, resulting in higher consumer demand of goods; the Keynes or interest rate effect, which states that as prices fall, the demand for money decreases, causing interest rates to decline and borrowing for investment and consumption to increase; and the net export effect, which states that as prices rise, domestic goods become comparatively more expensive to foreign consumers, leading to a decline in exports.[12]</p><p>In the conventional Keynesian use of the AS-AD model, the aggregate supply curve is horizontal at low levels of output and becomes inelastic near the point of potential output, which corresponds with full employment.[11] Since the economy cannot produce beyond the potential output, any AD expansion will lead to higher price levels instead of higher output.</p><p>The AD–AS diagram can model a variety of macroeconomic phenomena, including inflation. Changes in the non-price level factors or determinants cause changes in aggregate demand and shifts of the entire aggregate demand (AD) curve. When demand for goods exceeds supply there is an inflationary gap where demand-pull inflation occurs and the AD curve shifts upward to a higher price level. When the economy faces higher costs, cost-push inflation occurs and the AS curve shifts upward to higher price levels.[13] The AS–AD diagram is also widely used as a pedagogical tool to model the effects of various macroeconomic policies.[14]</p><h3>IS–LM</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/b/b9/Islm.svg/220px-Islm.svg.png" width="220" height="220"><p>


				In this example of an IS/LM chart, the IS curve moves to the right, causing higher interest rates (i) and expansion in the "real" economy (real GDP, or Y).


				</p><p>
					The IS–LM model represents all the combinations of interest rates and output that ensure the equilibrium in the goods and money markets.[15] The goods market is represented by the equilibrium in investment and saving (IS), and the money market is represented by the equilibrium between the money supply and liquidity preference.[16] The IS curve consists of the points where investment, given the interest rate, is equal to savings, given output.[17]</p><p>The IS curve is downward sloping because output and interest rate have an inverse relationship in the goods market: as output increases, more money is saved, which means interest rates must be lower to spur enough investment to match savings.[17] The LM curve is upward sloping because interest rate and output have a positive relationship in the money market: as output increases, the demand for money increases, resulting in a rise in interest rate.[18]</p><p>The IS/LM model is often used to demonstrate the effects of monetary and fiscal policy.[15] Textbooks frequently use the IS/LM model, but it does not feature the complexities of most modern macroeconomic models.[15] Nevertheless, these models still feature similar relationships to those in IS/LM.[15]</p><h3>Growth models</h3><p>The neoclassical growth model of Robert Solow has become a common textbook model for explaining economic growth in the long-run.[citation needed] The model begins with a production function where national output is the product of two inputs: capital and labor. The Solow model assumes that labor and capital are used at constant rates without the fluctuations in unemployment and capital utilization commonly seen in business cycles.[19]</p><p>An increase in output, or economic growth, can only occur because of an increase in the capital stock, a larger population, or technological advancements that lead to higher productivity (total factor productivity). An increase in the savings rate leads to a temporary increase as the economy creates more capital, which adds to output. However, eventually the depreciation rate will limit the expansion of capital: savings will be used up replacing depreciated capital, and no savings will remain to pay for an additional expansion in capital. Solow's model suggests that economic growth in terms of output per capita depends solely on technological advances that enhance productivity.[20]</p><p>In the 1980s and 1990s endogenous growth theory arose to challenge neoclassical growth theory. This group of models explains economic growth through other factors, such as increasing returns to scale for capital and learning-by-doing, that are endogenously determined instead of the exogenous technological improvement used to explain growth in Solow's model.[21]</p><h2>Macroeconomic policy</h2><p>Macroeconomic policy is usually implemented through two sets of tools: fiscal and monetary policy. Both forms of policy are used to stabilize the economy, which can mean boosting the economy to the level of GDP consistent with full employment.[22] Macroeconomic policy focuses on limiting the effects of the business cycle to achieve the economic goals of price stability, full employment, and growth. [23]</p><div class="gradientback"></div></div><div class="content"><h3>Monetary policy</h3><p> Further information: Monetary policy</p><p>Central banks implement monetary policy by controlling the money supply through several mechanisms. Typically, central banks take action by issuing money to buy bonds (or other assets), which boosts the supply of money and lowers interest rates, or, in the case of contractionary monetary policy, banks sell bonds and take money out of circulation. Usually policy is not implemented by directly targeting the supply of money.</p><p>Central banks continuously shift the money supply to maintain a targeted fixed interest rate. Some of them allow the interest rate to fluctuate and focus on targeting inflation rates instead. Central banks generally try to achieve high output without letting loose monetary policy that create large amounts of inflation.</p><p>Conventional monetary policy can be ineffective in situations such as a liquidity trap. When interest rates and inflation are near zero, the central bank cannot loosen monetary policy through conventional means.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/a/a7/Economic_Policy_-_Intervention_Strategy_Matrix.png/350px-Economic_Policy_-_Intervention_Strategy_Matrix.png" width="350" height="263"><p>


				An example of intervention strategy under different conditions


				</p><p>
					Central banks can use unconventional monetary policy such as quantitative easing to help increase output. Instead of buying government bonds, central banks can implement quantitative easing by buying not only government bonds, but also other assets such as corporate bonds, stocks, and other securities. This allows lower interest rates for a broader class of assets beyond government bonds. In another example of unconventional monetary policy, the United States Federal Reserve recently made an attempt at such a policy with Operation Twist. Unable to lower current interest rates, the Federal Reserve lowered long-term interest rates by buying long-term bonds and selling short-term bonds to create a flat yield curve.</p><h3>Fiscal policy</h3><p> Further information: Fiscal policy</p><p>Fiscal policy is the use of government's revenue and expenditure as instruments to influence the economy. Examples of such tools are expenditure, taxes, debt.</p><p>For example, if the economy is producing less than potential output, government spending can be used to employ idle resources and boost output. Government spending does not have to make up for the entire output gap. There is a multiplier effect that boosts the impact of government spending. For instance, when the government pays for a bridge, the project not only adds the value of the bridge to output, but also allows the bridge workers to increase their consumption and investment, which helps to close the output gap.</p><p>The effects of fiscal policy can be limited by crowding out. When the government takes on spending projects, it limits the amount of resources available for the private sector to use. Crowding out occurs when government spending simply replaces private sector output instead of adding additional output to the economy. Crowding out also occurs when government spending raises interest rates, which limits investment. Defenders of fiscal stimulus argue that crowding out is not a concern when the economy is depressed, plenty of resources are left idle, and interest rates are low.[citation needed]</p><p>Fiscal policy can be implemented through automatic stabilizers. Automatic stabilizers do not suffer from the policy lags of discretionary fiscal policy. Automatic stabilizers use conventional fiscal mechanisms but take effect as soon as the economy takes a downturn: spending on unemployment benefits automatically increases when unemployment rises and, in a progressive income tax system, the effective tax rate automatically falls when incomes decline.</p><h3>Comparison</h3><p>Economists usually favor monetary over fiscal policy because it has two major advantages. First, monetary policy is generally implemented by independent central banks instead of the political institutions that control fiscal policy. Independent central banks are less likely to make decisions based on political motives.[22] Second, monetary policy suffers shorter inside lags and outside lags than fiscal policy. Central banks can quickly make and implement decisions while discretionary fiscal policy may take time to pass and even longer to carry out.[22]</p><h2>Development</h2><p> Main article: History of macroeconomic thought</p><h3>Origins</h3><p>Macroeconomics descended from the once divided fields of business cycle theory and monetary theory.[24] The quantity theory of money was particularly influential prior to World War II. It took many forms, including the version based on the work of Irving Fisher:</p><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Macroeconomics&amp;oldid=784150718"					
								Categories:  Hidden categories:</p><br><h1 lang="en">Heterodox economics</h1><p> From Wikipedia, the free encyclopedia</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/8/8a/Heterodox3.png/220px-Heterodox3.png" width="220" height="164"><p>


				Heterodox economics family tree.


				</p><p>
					Heterodox economics refers to schools of economic thought or methodologies that are outside mainstream economics, often represented by expositors as contrasting with or going beyond neoclassical economics.[1][2] Heterodox economics is an umbrella term used to cover various approaches, schools, or traditions. These include anarchist, socialist, Marxian, institutional, evolutionary, Georgist, Austrian, feminist,[3] social, post-Keynesian (not to be confused with New Keynesian),[2] and ecological economics among others.[4] In the JEL classification codes developed by the Journal of Economic Literature, heterodox economics is in the second of the 19 primary categories at:</p><div class="gradientback"></div></div><div class="content"><p>Mainstream economics may be called orthodox or conventional economics by its critics.[5] Alternatively, mainstream economics deals with the rationality–individualism–equilibrium nexus and heterodox economics is more radical in dealing with the institutions–history–social structure nexus.[6] Many mainstream economists dismiss heterodox economics as fringe and irrelevant,[7] with little or no influence on the vast majority of academic economists in the English-speaking world.</p><p>A recent review documents several prominent groups of heterodox economists since at least the 1990s as working together with a resulting increase in coherence across different constituents.[2] Along these lines, the International Confederation of Associations for Pluralism in Economics (ICAPE) does not define heterodox economics and has avoided defining its scope. ICAPE defines its mission as promoting pluralism in economics.</p><p>In defining a common ground in the critical commentary, one writer described fellow heterodox economists as trying to do three things: (1) identify shared ideas that generate a pattern of heterodox critique across topics and chapters of introductory macro texts; (2) give special attention to ideas that link methodological differences to policy differences; and (3) characterize the common ground in ways that permit distinct paradigms to develop common differences with textbook economics in different ways.[8]</p><p>One study suggests four key factors as important to the study of economics by self-identified heterodox economists: history, natural systems, uncertainty, and power.[9]</p><h2>Contents</h2><h2>History</h2><p>A number of heterodox schools of economic thought challenged the dominance of neoclassical economics after the neoclassical revolution of the 1870s. In addition to socialist critics of capitalism, heterodox schools in this period included advocates of various forms of mercantilism, such as the American School dissenters from neoclassical methodology such as the historical school, and advocates of unorthodox monetary theories such as Social credit. Other heterodox schools active before and during the Great Depression included Technocracy and Georgism.</p><p>Physical scientists and biologists were the first individuals to use energy flows to explain social and economic development. Joseph Henry, an American physicist and first secretary of the Smithsonian Institution, remarked that the fundamental principle of political economy is that the physical labor of man can only be ameliorated by… the transformation of matter from a crude state to a artificial condition...by expending what is called power or energy.[10][11]</p><p>The rise, and absorption into the mainstream of Keynesian economics, which appeared to provide a more coherent policy response to unemployment than unorthodox monetary or trade policies contributed to the decline of interest in these schools.</p><p>After 1945, the neoclassical synthesis of Keynesian and neoclassical economics resulted in a clearly defined mainstream position based on a division of the field into microeconomics (generally neoclassical but with a newly developed theory of market failure) and macroeconomics (divided between Keynesian and monetarist views on such issues as the role of monetary policy). Austrians and post-Keynesians who dissented from this synthesis emerged as clearly defined heterodox schools. In addition, the Marxist and institutionalist schools remained active.</p><p>Up to 1980 the most notable themes of heterodox economics in its various forms included:</p><li>rejection of the atomistic individual conception in favor of a socially embedded individual conception;</li><li>emphasis on time as an irreversible historical process;</li><li>reasoning in terms of mutual influences between individuals and social structures.</li><p>From approximately 1980 mainstream economics has been significantly influenced by a number of new research programs, including behavioral economics, complexity economics, evolutionary economics, experimental economics, and neuroeconomics. As a consequence, some heterodox economists, such as John B. Davis, proposed that the definition of heterodox economics has to be adapted to this new, more complex reality:[12]</p><h2>Rejection of neoclassical economics</h2><p>There is no single heterodox economic theory; there are many different heterodox theories in existence. What they all share, however, is a rejection of the neoclassical orthodoxy as representing the appropriate tool for understanding the workings of economic and social life.[13] The reasons for this rejection may vary. Some of the elements commonly found in heterodox critiques are listed below.</p><h3>Criticism of the neoclassical model of individual behavior</h3><p>One of the most broadly accepted principles of neoclassical economics is the assumption of the rationality of economic agents. Indeed, for a number of economists, the notion of rational maximizing behavior is taken to be synonymous with economic behavior (Becker 1976, Hirshleifer 1984). When some economists' studies do not embrace the rationality assumption, they are seen as placing the analyses outside the boundaries of the Neoclassical economics discipline (Landsberg 1989, 596). Neoclassical economics begins with the a priori assumptions that agents are rational and that they seek to maximize their individual utility (or profits) subject to environmental constraints. These assumptions provide the backbone for rational choice theory.</p><p>Many heterodox schools are critical of the homo economicus model of human behavior used in standard neoclassical model. A typical version of the critique is that of Satya Gabriel:[14]</p><p>Neoclassical economic theory is grounded in a particular conception of human psychology, agency or decision-making. It is assumed that all human beings make economic decisions so as to maximize pleasure or utility. Some heterodox theories reject this basic assumption of neoclassical theory, arguing for alternative understandings of how economic decisions are made and/or how human psychology works. It is possible to accept the notion that humans are pleasure seeking machines, yet reject the idea that economic decisions are governed by such pleasure seeking. Human beings may, for example, be unable to make choices consistent with pleasure maximization due to social constraints and/or coercion. Humans may also be unable to correctly assess the choice points that are most likely to lead to maximum pleasure, even if they are unconstrained (except in budgetary terms) in making such choices. And it is also possible that the notion of pleasure seeking is itself a meaningless assumption because it is either impossible to test or too general to refute. Economic theories that reject the basic assumption of economic decisions as the outcome of pleasure maximization are heterodox.</p><p>Shiozawa emphasizes that economic agents act in a complex world and therefore impossible for them to attain maximal utility point. They instead behave as if there are a repertories of many ready made rules, one of which they chose according to relevant situation.[15]</p><h3>Criticism of the neoclassical model of market equilibrium</h3><div class="gradientback"></div></div><div class="content"><p>In microeconomic theory, cost-minimization by consumers and by firms implies the existence of supply and demand correspondences for which market clearing equilibrium prices exist, if there are large numbers of consumers and producers. Under convexity assumptions or under some marginal-cost pricing rules, each equilibrium will be Pareto efficient: In large economies, non-convexity also leads to quasi-equilibria that are nearly efficient.</p><p>However, the concept of market equilibrium has been criticized by Austrians, post-Keynesians and others, who object to applications of microeconomic theory to real-world markets, when such markets are not usefully approximated by microeconomic models. Heterodox economists assert that micro-economic models rarely capture reality.</p><p>Mainstream microeconomics may be defined in terms of optimization and equilibrium, following the approaches of Paul Samuelson and Hal Varian. On the other hand, heterodox economics may be labeled as falling into the nexus of institutions, history, and social structure.[4][16]</p><h2>Most recent developments</h2><p>Over the past two decades, the intellectual agendas of heterodox economists have taken a decidedly pluralist turn. Leading heterodox thinkers have moved beyond the established paradigms of Austrian, Feminist, Institutional-Evolutionary, Marxian, Post Keynesian, Radical, Social, and Sraffian economics—opening up new lines of analysis, criticism, and dialogue among dissenting schools of thought. This cross-fertilization of ideas is creating a new generation of scholarship in which novel combinations of heterodox ideas are being brought to bear on important contemporary and historical problems, such as socially grounded reconstructions of the individual in economic theory; the goals and tools of economic measurement and professional ethics; the complexities of policymaking in today's global political economy; and innovative connections among formerly separate theoretical traditions (Marxian, Austrian, feminist, ecological, Sraffian, institutionalist, and post-Keynesian) (for a review of post-Keynesian economics, see Lavoie (1992); Rochon (1999)).</p><p>David Colander, an advocate of complexity economics, argues that the ideas of heterodox economists are now being discussed in the mainstream without mention of the heterodox economists, because the tools to analyze institutions, uncertainty, and other factors have now been developed by the mainstream. He suggests that heterodox economists should embrace rigorous mathematics and attempt to work from within the mainstream, rather than treating it as an enemy.[17]</p><p>Some schools of heterodox economic thought have also taken a transdisciplinary approach. Thermoeconomics is based on the claim that human economic processes are governed by the second law of thermodynamics. The posited relationship between economic theory, energy and entropy, has been extended further by systems scientists to explain the role of energy in biological evolution in terms of such economic criteria as productivity, efficiency, and especially the costs and benefits of the various mechanisms for capturing and utilizing available energy to build biomass and do work.[18][19]</p><h2>Fields of heterodox economic thought</h2><p># Listed in Journal of Economic Literature codes scrolled to at JEL: B5 - Current Heterodox Approaches.</p><p>§ Listed in The New Palgrave Dictionary of Economics, 2nd Edition, v. 8, Appendix IV, p.&nbsp;856, searchable by clicking (the JEL classification codes JEL:) radio button B5, B52, or B59, then the Search button (or Update Search Results button) at http://www.dictionaryofeconomics.com/search_results?edition=all&amp;field=content&amp;q=&amp;topicid=B5.</p><p>Some schools in the social sciences aim to promote certain perspectives: classical and modern political economy; economic sociology and anthropology; gender and racial issues in economics; and so on.</p><h3>Notable heterodox economists</h3><h3>Articles</h3><h3>Books</h3><h3>Articles, conferences, papers</h3><h3>Journals</h3><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Heterodox_economics&amp;oldid=784013342"					
								Categories:  Hidden categories:</p><br><h1 lang="en">Econometrics</h1><p> From Wikipedia, the free encyclopedia</p><p>Econometrics is the application of statistical methods to economic data and is described as the branch of economics that aims to give empirical content to economic relations.[1] More precisely, it is the quantitative analysis of actual economic phenomena based on the concurrent development of theory and observation, related by appropriate methods of inference.[2] An introductory economics textbook describes econometrics as allowing economists to sift through mountains of data to extract simple relationships.[3] The first known use of the term econometrics (in cognate form) was by Polish economist Pawel Ciompa in 1910.[4] Ragnar Frisch is credited with coining the term in the sense in which it is used today.[5]</p><p>The basic tool for econometrics is the multiple linear regression model.[6] Econometric theory uses statistical theory and mathematical statistics to evaluate and develop econometric methods.[7][8] Econometricians try to find estimators that have desirable statistical properties including unbiasedness, efficiency, and consistency. Applied econometrics uses theoretical econometrics and real-world data for assessing economic theories, developing econometric models, analyzing economic history, and forecasting.</p><h2>Contents</h2><h2>Basic models: linear regression</h2><p>The basic tool for econometrics is the multiple linear regression model.[6] In modern econometrics, other statistical tools are frequently used, but linear regression is still the most frequently used starting point for an analysis.[6] Estimating a linear regression on two variables can be visualized as fitting a line through data points representing paired values of the independent and dependent variables.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/d/db/Okuns_law_differences_1948_to_mid_2011.png/220px-Okuns_law_differences_1948_to_mid_2011.png" width="220" height="160"><p>


				Okun's law representing the relationship between GDP growth and the unemployment rate. The fitted line is found using regression analysis.


				</p><p>
					For example, consider Okun's law, which relates GDP growth to the unemployment rate. This relationship is represented in a linear regression where the change in unemployment rate (
				  
					
					  
						?
						&nbsp;
						
						  Unemployment
						
					  
					
					{\displaystyle \Delta \ {\text{Unemployment}}}
				  
				) is a function of an intercept (
				  
					
					  
						
						  ß
						  
							0
						  
						
					  
					
					{\displaystyle \beta _{0}}
				  
				), a given value of GDP growth multiplied by a slope coefficient 
				  
					
					  
						
						  ß
						  
							1
						  
						
					  
					
					{\displaystyle \beta _{1}}
				  
				 and an error term, 
				  
					
					  
						e
					  
					
					{\displaystyle \varepsilon }
				  
				:</p><div class="gradientback"></div></div><div class="content"><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Econometrics&amp;oldid=783675655"					
								Categories:  Hidden categories:</p><br><h1 lang="en">Economic system</h1><p> From Wikipedia, the free encyclopedia</p><br><p>


				Circulation model of economic flows for a closed market economy


				</p><p>
					An economic system is a system of production, resource allocation, and distribution of goods and services within a society or a given geographic area. It includes the combination of the various institutions, agencies, entities, decision-making processes, and patterns of consumption that comprise the economic structure of a given community. As such, an economic system is a type of social system. The mode of production is a related concept.[1] All economic systems have three basic questions to ask: what to produce, how to produce and in what quantities, and who receives the output of production.</p><p>The study of economic systems includes how these various agencies and institutions are linked to one another, how information flows between them, and the social relations within the system (including property rights and the structure of management).</p><p>The analysis of economic systems traditionally focused on the dichotomies and comparisons between market economies and planned economies, and on the distinctions between capitalism and socialism.[2] Subsequently, the categorization of economic systems expanded to include other topics and models that do not conform to the traditional dichotomy. Today the dominant form of economic organization at the world level is based on market-oriented mixed economies.[3]</p><p>Economic systems is the category in the Journal of Economic Literature classification codes that includes the study of such systems. One field that cuts across them is comparative economic systems, which include the following subcategories of different systems:</p><h2>Contents</h2><h2>Components</h2><p>There are multiple components to economic systems. Decision-making structures of an economy determine the use of economic inputs (the factors of production), distribution of output, the level of centralization in decision-making, and who makes these decisions. Decisions might be carried out by industrial councils, by a government agency, or by private owners.</p><p>In one view, every economic system represents an attempt to solve three fundamental and interdependent problems:</p><p>Thus every economy is a system that allocates resources for exchange, production, distribution and consumption. The system is stabilized through a combination of threat and trust, which are the outcome of institutional arrangements.[6] An economic system possesses the following institutions:</p><h2>Typology</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/8/80/Common_Economic_Systems_Typology_%28v2%29.png/350px-Common_Economic_Systems_Typology_%28v2%29.png" width="350" height="220"><p>


				Common typology for economic systems categorized by resource ownership and resource allocation mechanism



				<br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/5/55/Communism.PNG/350px-Communism.PNG" width="350" height="162"><br>


				Marxist-Leninist Communist states (red) and former Communist states (orange) of the world


				</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/5/55/Communism.PNG/350px-Communism.PNG" width="350" height="162"><br><p>
					There are several basic questions that must be answered in order for an economy to run satisfactorily. The scarcity problem, for example, requires answers to basic questions, such as: what to produce, how to produce it, and who gets what is produced. An economic system is a way of answering these basic questions, and different economic systems answer them differently. Many different objectives may be seen as desirable for an economy, like efficiency, growth, liberty, and equality.[9]</p><div class="gradientback"></div></div><div class="content"><p>Economic systems are commonly segmented by their property rights regime for the means of production and by their dominant resource allocation mechanism. Economies that combine private ownership with market allocation are called market capitalism, and economies that combine private ownership with economic planning are labelled command capitalism or dirigisme. Likewise, systems that mix public or cooperative ownership of the means of production with economic planning are called socialist planned economies, and systems that combine public or cooperative ownership with markets are called market socialism.[10] Some perspectives build upon this basic nomenclature to take other variables into account, such as class processes within an economy. This leads some economists to categorize, for example, the Soviet Union's economy as state capitalism based on the analysis that the working class was exploited by the party leadership. Instead of looking at nominal ownership, this perspective takes into account the organizational form within economic enterprises.[11]</p><p>In a capitalist economic system, production is carried out for private profit, and decisions regarding investment and allocation of factor inputs are determined by business owners in factor markets. The means of production are primarily owned by private enterprises, and decisions regarding production and investment are determined by private owners in capital markets. Capitalist systems range from laissez-faire, with minimal government regulation and state enterprise, to regulated and social market systems, with the aims of ameliorating market failures (see economic intervention) or supplementing the private marketplace with social policies to promote equal opportunities (see welfare state), respectively.</p><p>In socialist economic systems (socialism), production for use is carried out; decisions regarding the use of the means of production are adjusted to satisfy economic demand; and investment is determined through economic planning procedures. There is a wide range of proposed planning procedures and ownership structures for socialist systems, with the common feature among them being the social ownership of the means of production. This might take the form of public ownership by all of society, or ownership cooperatively by their employees. A socialist economic system that features social ownership but is based on the process of capital accumulation and utilization of capital markets for the allocation of capital goods between socially-owned enterprises falls under the subcategory of market socialism.[12]</p><h3>Allocation mechanism</h3><p>The basic and general economic systems segmented by allocation are:</p><h3>Types</h3><p>Capitalism generally features the private ownership of the means of production (capital), and a market economy for coordination. Corporate capitalism refers to a capitalist marketplace characterized by the dominance of hierarchical, bureaucratic corporations.</p><p>Mercantilism was the dominant model in Western Europe from the 16th to 18th century. This encouraged imperialism and colonialism until economic and political changes resulted in global decolonization. Modern capitalism has favored free trade to take advantages of increased efficiency due to national comparative advantage and economies of scale in a larger, more universal market. Some critics[who?] have applied the term neo-colonialism to the power imbalance between multi-national corporations operating in a free market vs. seemingly impoverished people in developing countries.</p><p>There is no precise definition of a mixed economy. Theoretically, it may refer to an economic system that combines one of three characteristics: public and private ownership of industry, market-based allocation with economic planning, or free-markets with state interventionism.</p><p>In practice, mixed economy generally refers to market economies with substantial state interventionism and/or sizable public sector alongside a dominant private sector. Actual mixed economies gravitate more heavily to one end of the spectrum. Notable economic models and theories that have been described as a mixed economy include:</p><p>Socialist economic systems (all of which feature social ownership of the means of production) can be subdivided by their coordinating mechanism (planning and markets) into planned socialist and market socialist systems. Additionally, socialism can be divided based on their property structures between those that are based on public ownership, worker or consumer cooperatives and common ownership (i.e., non-ownership). Communism is a hypothetical stage of Socialist development articulated by Marx as second stage Socialism in Critique of the Gotha Program, whereby economic output is distributed based on need and not simply on the basis of labor contribution.</p><p>The original conception of socialism involved the substitution of money as a unit of calculation and monetary prices as a whole with calculation in kind (or valuation based on natural units), with business and financial decisions replaced by engineering and technical criteria for managing the economy. Fundamentally, this meant that socialism would operate under different economic dynamics than those of capitalism and the price system.[13] Later models of socialism developed by neoclassical economists (most notably Oskar Lange and Abba Lerner) were based on the use of notional prices derived from a trial-and-error approach to achieve market clearing prices on the part of a planning agency. These models of socialism were called market socialism because they included a role for markets, money and prices.</p><p>The primary emphasis of socialist planned economies is to coordinate production to produce economic output to directly satisfy economic demand as opposed to the indirect mechanism of the profit system where satisfying needs is subordinate to the pursuit of profit; and to advance the productive forces of the economy in a more efficient manner while being immune to the perceived systemic inefficiencies (cyclical processes) and crisis of overproduction so that production would be subject to the needs of society as opposed to being ordered around capital accumulation.[14][15]</p><p>In a pure socialist planned economy that involves different processes of resource allocation, production and means of quantifying value, the use of money would be replaced with a different measure of value and accounting tool that would embody more accurate information about an object or resource.</p><p>In practice, the economic system of the former Soviet Union and Eastern bloc operated as a command economy, featuring a combination of state owned enterprises and central planning using the material balances method. The extent to which these economic systems achieved socialism or represented a viable alternative to capitalism is subject to debate.[16]</p><p>In orthodox Marxism, the mode of production is tantamount to the subject of this article, determining with a superstructure of relations the entirety of a given culture or stage of human development.</p><h3>Other aspects</h3><p>Corporatism refers to economic tripartite involving negotiations between business, labor, and state interest groups to establish economic policy, or more generally to assigning people to political groups based on their occupational affiliation.</p><p>Certain subsets of an economy, or the particular goods, services, techniques of production, or moral rules can also be described as an economy. For example, some terms emphasize specific sectors or externalizes:</p><p>Others emphasize a particular religion:</p><div class="gradientback"></div></div><div class="content"><h2>Evolutionary economics</h2><p>Karl Marx's theory of economic development was based on the premise of evolving economic systems; specifically, in his view, over the course of history superior economic systems would replace inferior ones. Inferior systems were beset by internal contradictions and inefficiencies that make them impossible to survive over the long term. In Marx's scheme, feudalism was replaced by capitalism, which would eventually be superseded by socialism.[17] Joseph Schumpeter had an evolutionary conception of economic development, but unlike Marx, he de-emphasized the role of class struggle in contributing to qualitative change in the economic mode of production. In subsequent world history, Communist states run according to Marxist-Leninist ideologies have either collapsed or gradually reformed their centrally-planned economies toward market-based economies, for example with perestroika and the dissolution of the Soviet Union, Chinese economic reform, and Ð?i M?i in Vietnam.</p><p>Mainstream evolutionary economics continues to study economic change in modern times. There has also been renewed interest in understanding economic systems as evolutionary systems in the emerging field of Complexity economics.</p><h2>Context in society</h2><p>An economic system can be considered a part of the social system and hierarchically equal to the law system, political system, cultural, etc. There is often a strong correlation between certain ideologies, political systems and certain economic systems (for example, consider the meanings of the term communism). Many economic systems overlap each other in various areas (for example, the term mixed economy can be argued to include elements from various systems). There are also various mutually exclusive hierarchical categorizations.</p><h2>Political ideologies</h2><h3>Anarchist and libertarianism</h3><p>Various strains of anarchism advocate different economic systems, all of which have very small or no government involvement. These include:</p><p>Libertarianism also advocates a minimal role for government, including economic systems like:</p><h2>List of economic systems</h2><p>(merge in progress)</p><p>Unsorted:</p><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Economic_system&amp;oldid=784081125"					
								Categories:  Hidden categories:</p><br><h1 lang="en">Post-scarcity economy</h1><p> From Wikipedia, the free encyclopedia</p><p>Post-scarcity is a hypothetical economy in which most goods can be produced in great abundance with minimal human labor needed, so that they become available to all very cheaply or even freely.[1][2] Post-scarcity is not generally taken to mean that scarcity has been eliminated for all consumer goods and services; instead, it is often taken to mean that all people can easily have their basic survival needs met along with some significant proportion of their desires for goods and services,[3] with writers on the topic often emphasizing that certain commodities are likely to remain scarce in a post-scarcity society.[4][5][6][7]</p><p>In the paper “The Post-Scarcity World of 2050-2075”[8], authors defend that we are currently living an age of scarcity resulted from neglect behavior with the future from the 19th and 20th centuries. The period between 1975 and 2005 was characterized by relative abundance of resources (oil, water, energy, food, credit, among others) which boosted industrialization and development in the western economies. An increased demand of resources combined with a rising population led to resource exhaustion.[8]</p><p>One of the main traces of the scarcity periods is the increase and fluctuation of prices. To deal with that situation, technology advancements come into play, driving an efficient use of resources to a certain extent that costs will be considerably reduced (almost everything will be free). Consequently, authors forecast that the period between 2050 and 2075 will be a post-scarcity age in which scarcity will no longer exist.[8]</p><h2>Contents</h2><h2>The post-scarcity model</h2><h3>Speculative technology</h3><p>Today, futurists who speak of post-scarcity suggest economies based on advances in automated manufacturing technologies,[4] often including the idea of self-replicating machines, the adoption of division of labour[9] which in theory could produce nearly all goods in abundance, given adequate raw materials and energy. More speculative forms of nanotechnology (such as molecular assemblers or nanofactories, which do not currently exist) raise the possibility of devices that can automatically manufacture any specified goods given the correct instructions and the necessary raw materials and energy,[10] and so many nanotechnology enthusiasts have suggested it will usher in a post-scarcity world.[11][12] In the more near-term future, the increasing automation of physical labor using robots is often discussed as means of creating a post-scarcity economy.[13][14] Increasingly versatile forms of rapid prototyping machines, and a hypothetical self-replicating version of such a machine known as a RepRap, have also been predicted to help create the abundance of goods needed for a post-scarcity economy.[15] Advocates of self-replicating machines such as Adrian Bowyer, the creator of the RepRap project, argue that once a self-replicating machine is designed, then since anyone who owns one can make more copies to sell (and would also be free to ask for a lower price than other sellers), market competition will naturally drive the cost of such machines down to the bare minimum needed to make a profit,[16][17] in this case just above the cost of the physical materials and energy that must be fed into the machine as input, and the same should go for any other goods that the machine can build.</p><p>Even with fully automated production, limitations on the number of goods produced would arise from the availability of raw materials and energy, as well as ecological damage associated with manufacturing technologies.[4] Advocates of technological abundance often argue for more extensive use of renewable energy and greater recycling in order to prevent future drops in availability of energy and raw materials, and reduce ecological damage.[4] Solar energy in particular is often emphasized, as the cost of solar panels continues to drop[4] (and could drop far more with automated production by self-replicating machines), and advocates point out the total solar power striking the Earth's surface annually exceeds our civilization's current annual power usage by a factor of thousands.[18][19] Advocates also sometimes argue that the energy and raw materials available could be greatly expanded if we looked to resources beyond the Earth. For example, asteroid mining is sometimes discussed as a way of greatly reducing scarcity for many useful metals such as nickel.[20] While early asteroid mining might involve manned missions, advocates hope that eventually humanity could have automated mining done by self-replicating machines.[20][21] If this were done, then the only capital expenditure would be a single self-replicating unit (whether robotic or nanotechnological), after which the number of units could replicate at no further cost, limited only by the available raw materials needed to build more.[21]</p><h3>Digital abundance</h3><p>Richard Stallman, the founder of the GNU project, has cited the eventual creation of a post-scarcity society as one of his motivations:[22]</p><div class="gradientback"></div></div><div class="content"><p>In the long run, making programs free is a step toward the post-scarcity world, where nobody will have to work very hard just to make a living. People will be free to devote themselves to activities that are fun, such as programming, after spending the necessary ten hours a week on required tasks such as legislation, family counseling, robot repair and asteroid prospecting. There will be no need to be able to make a living from programming.</p><h3>Marxism</h3><p>Karl Marx, in a section of his Grundrisse that came to be known as the Fragment on Machines,[23][24] argued that the transition to a post-capitalist society combined with advances in automation would allow for significant reductions in labor needed to produce necessary goods, eventually reaching a point where all people would have significant amounts of leisure time to pursue science, the arts, and creative activities; a state some commentators later labeled as post-scarcity.[25] Marx argued that capitalism—the dynamic of economic growth based on capital accumulation—depends on exploiting the surplus labor of workers, but a post-capitalist society would allow for:</p><p>The free development of individualities, and hence not the reduction of necessary labour time so as to posit surplus labour, but rather the general reduction of the necessary labour of society to a minimum, which then corresponds to the artistic, scientific etc. development of the individuals in the time set free, and with the means created, for all of them.[26]</p><p>Marx's concept of a post-capitalist communist society involves the free distribution of goods made possible by the abundance provided by automation.[27] The fully developed communist economic system is postulated to develop from a preceding socialist system. Marx held the view that socialism—a system based on social ownership of the means of production—would enable progress toward the development of fully developed communism by further advancing productive technology. Under socialism, with its increasing levels of automation, an increasing proportion of goods would be distributed freely.[28]</p><p>Marx did not believe in the elimination of most physical labor through technological advancements alone in a capitalist society, because he believed capitalism contained within it certain tendencies which countered increasing automation and prevented it from developing beyond a limited point, so that manual industrial labor could not be eliminated until the overthrow of capitalism.[29] Some commentators on Marx have argued that at the time he wrote the Grundrisse, he thought that the collapse of capitalism due to advancing automation was inevitable despite these counter-tendencies, but that by the time of his major work Capital: Critique of Political Economy he had abandoned this view, and came to believe that capitalism could continually renew itself unless overthrown.[30][31][32]</p><h2>Fiction</h2><h3>Science fiction</h3><h3>Books</h3><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Post-scarcity_economy&amp;oldid=780541834"					
								Categories:  Hidden categories:</p><br><h1 lang="en">National accounts</h1><p> From Wikipedia, the free encyclopedia</p><p>National accounts or national account systems (NAS) are the implementation of complete and consistent accounting techniques for measuring the economic activity of a nation. These include detailed underlying measures that rely on double-entry accounting. By design, such accounting makes the totals on both sides of an account equal even though they each measure different characteristics, for example production and the income from it. As a method, the subject is termed national accounting or, more generally, social accounting.[1] Stated otherwise, national accounts as systems may be distinguished from the economic data associated with those systems.[2] While sharing many common principles with business accounting, national accounts are based on economic concepts.[3] One conceptual construct for representing flows of all economic transactions that take place in an economy is a social accounting matrix with accounts in each respective row-column entry.[4]</p><p>National accounting has developed in tandem with macroeconomics from the 1930s with its relation of aggregate demand to total output through interaction of such broad expenditure categories as consumption and investment.[5] Economic data from national accounts are also used for empirical analysis of economic growth and development.[1][6]</p><h2>Contents</h2><h2>Scope</h2><p>National accounts broadly present output, expenditure, and income activities of the economic actors (households, corporations, government) in an economy, including their relations with other countries' economies, and their wealth (net worth). They present both flows (measured over a period) and stocks (measured at the end of a period), ensuring that the flows are reconciled with the stocks. As to flows, the national income and product accounts (in U.S. terminology) provide estimates for the money value of income and output per year or quarter, including GDP. As to stocks, the 'capital accounts' are a balance-sheet approach that has assets on one side (including values of land, the capital stock, and financial assets) and liabilities and net worth on the other, measured as of the end of the accounting period. National accounts also include measures of the changes in assets, liabilities, and net worth per accounting period. These may refer to flow of funds accounts or, again, capital accounts.[1]</p><p>There are a number of aggregate measures in the national accounts, notably including gross domestic product or GDP, perhaps the most widely cited measure of aggregate economic activity. Ways of breaking down GDP include as types of income (wages, profits, etc.) or expenditure (consumption, investment/saving, etc.). Measures of these are examples of macro-economic data.[7][8][9][10] Such aggregate measures and their change over time are generally of strongest interest to economic policymakers, although the detailed national accounts contain a source of information for economic analysis, for example in the input-output tables which show how industries interact with each other in the production process.</p><p>National accounts can be presented in nominal or real amounts, with real amounts adjusted to remove the effects of price changes over time.[11] A corresponding price index can also be derived from national output. Rates of change of the price level and output may also be of interest. An inflation rate (growth rate of the price level) may be calculated for national output or its expenditure components. Economic growth rates (most commonly the growth rate of GDP) are generally measured in real (constant-price) terms. One use of economic-growth data from the national accounts is in growth accounting across longer periods of time for a country or across to estimate different sources of growth, whether from growth of factor inputs or technological change.[12]</p><p>The accounts are derived from a wide variety of statistical source data including surveys, administrative and census data, and regulatory data, which are integrated and harmonized in the conceptual framework. They are usually compiled by national statistical offices and/or central banks in each country, though this is not always the case, and may be released on both an annual and (less detailed) quarterly frequency. Practical issues include inaccuracies from differences between economic and accounting methodologies, lack of controlled experiments on quality of data from diverse sources, and measurement of intangibles and services of the banking and financial sectors.[13]</p><p>Two developments relevant to the national accounts since the 1980s include the following. Generational accounting is a method for measuring redistribution of lifetime tax burdens across generations from social insurance, including social security and social health insurance. It has been proposed as a better guide to the sustainability of a fiscal policy than budget deficits, which reflect only taxes minus spending in the current year.[14] Environmental or green national accounting is the method of valuing environmental assets, which are usually not counted in measuring national wealth, in part due to the difficulty of valuing them. The method has been proposed as an alternative to an implied zero valuation of environmental assets and as a way of measuring the sustainability of welfare levels in the presence of environmental degradation.[15]</p><div class="gradientback"></div></div><div class="content"><p>Macroeconomic data not derived from the national accounts are also of wide interest, for example some cost-of-living indexes, the unemployment rate, and the labor force participation rate.[16] In some cases, a national-accounts counterpart of these may be estimated, such as a price index computed from the personal consumption expenditures and the GDP gap (the difference between observed GDP and potential GDP).[17]</p><h2>Main components</h2><p>The presentation of national accounts data may vary by country (commonly, aggregate measures are given greatest prominence), however the main national accounts include the following accounts for the economy as a whole and its main economic actors.</p><p>The accounts may be measured as gross or net of consumption of fixed capital (a concept in national accounts similar to depreciation in business accounts).</p><p>Notably absent from these components, however, is unpaid work, because its value is not included in any of the aforementioned categories of accounts, just as it is not included in calculating gross domestic product (GDP). An Australian study has shown the value of this uncounted work to be approximately 50% of GDP, making its exclusion rather significant.[18] As GDP is tied closely to the national accounts system,[19] this may lead to a distorted view of national accounts. Because national accounts are widely used by governmental policy-makers in implementing controllable economic agendas,[20] some analysts have advocated for either a change in the makeup of national accounts or adjustments in the formulation of public policy.[21]</p><h2>History</h2><p>The original motivation for the development of national accounts and the systematic measurement of employment was the need for accurate measures of aggregate economic activity. This was made more pressing by the Great Depression and as a basis for Keynesian macroeconomic stabilisation policy and wartime economic planning. The first efforts to develop such measures were undertaken in the late 1920s and 1930s, notably by Colin Clark and Simon Kuznets. Richard Stone of the U.K. led later contributions during World War II and thereafter. The first formal national accounts were published by the United States in 1947. Many European countries followed shortly thereafter, and the United Nations published A System of National Accounts and Supporting Tables in 1952.[1][22] International standards for national accounting are defined by the United Nations System of National Accounts, with the most recent version released for 2008.[23]</p><p>Even before that in early 1920s there were national economic accounts tables. One of such systems was called Balance of national economy and was used in USSR and other socialistic countries to measure the efficiency of socialistic production.Economic theory.[24]</p><p>In Europe, the worldwide System of National Accounts has been adapted in the European System of Accounts (ESA), which is applied by members of the European Union and many other European countries. Research on the subject continues from its beginnings through today.[25]</p><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=National_accounts&amp;oldid=768273936"					
								Categories:  Hidden categories:</p><br><h1 lang="en">Behavioral economics</h1><p> From Wikipedia, the free encyclopedia</p><p>Behavioral economics, along with the related sub-field behavioral finance, studies the effects of psychological, social, cognitive, and emotional factors on the economic decisions of individuals and institutions and the consequences for market prices, returns, and resource allocation, although not always that narrowly, but also more generally, of the impact of different kinds of behavior, in different environments of varying experimental values.[1]</p><p>Risk tolerance is a crucial factor in personal financial decision making. Risk tolerance is defined as individuals willingness to engage in a financial activity whose outcome is uncertain.[2]</p><p>Behavioral economics is primarily concerned with the bounds of rationality of economic agents. Behavioral models typically integrate insights from psychology, neuroscience and microeconomic theory; in so doing, these behavioral models cover a range of concepts, methods, and fields.[3][4]</p><p>The study of behavioral economics includes how market decisions are made and the mechanisms that drive public choice. The use of the term behavioral economics in U.S. scholarly papers has increased in the past few years, as shown by a recent study.[5]</p><p>There are three prevalent themes in behavioral finances:[6]</p><h2>Contents</h2><h2>History</h2><p>During the classical period of economics, microeconomics was closely linked to psychology. For example, Adam Smith wrote The Theory of Moral Sentiments, which proposed psychological explanations of individual behavior, including concerns about fairness and justice,[7] and Jeremy Bentham wrote extensively on the psychological underpinnings of utility. However, during the development of neo-classical economics economists sought to reshape the discipline as a natural science, deducing economic behavior from assumptions about the nature of economic agents. They developed the concept of homo economicus, whose psychology was fundamentally rational.</p><p>However, many important neo-classical economists employed more sophisticated psychological explanations, including Francis Edgeworth, Vilfredo Pareto, and Irving Fisher. Economic psychology emerged in the 20th century in the works of Gabriel Tarde,[8] George Katona,[9] and Laszlo Garai.[10] Expected utility and discounted utility models began to gain acceptance, generating testable hypotheses about decision-making given uncertainty and intertemporal consumption, respectively. Observed and repeatable anomalies eventually challenged those hypotheses, and further steps were taken by the Nobel Prize-winner Maurice Allais, for example, in setting out the Allais paradox, a decision problem he first presented in 1953 that contradicts the expected utility hypothesis.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/c/c8/Daniel_KAHNEMAN.jpg" width="150" height="179"><p>In the 1960s cognitive psychology began to shed more light on the brain as an information processing device (in contrast to behaviorist models). Psychologists in this field, such as Ward Edwards,[11] Amos Tversky, and Daniel Kahneman began to compare their cognitive models of decision-making under risk and uncertainty to economic models of rational behavior. In mathematical psychology, there is a longstanding interest in the transitivity of preference and what kind of measurement scale utility constitutes.[12]</p><div class="gradientback"></div></div><div class="content"><h3>Prospect theory</h3><p>In 1979, Kahneman and Tversky wrote Prospect Theory: An Analysis of Decision Under Risk, an important paper that used cognitive psychology to explain various divergences of economic decision making from neo-classical theory.[13] Prospect theory has two stages: an editing stage and an evaluation stage.</p><p>In the editing stage, risky situations are simplified using various heuristics of choice. In the evaluation phase, risky alternatives are evaluated using various psychological principles that include the following:</p><p>Prospect theory is able to explain everything that the two main existing decision theories—expected utility theory and rank dependent utility theory—can explain. However, the converse is false. Prospect theory has been used to explain a range of phenomena that existing decision theories have great difficulty in explaining. These include backward bending labor supply curves, asymmetric price elasticities, tax evasion, co-movement of stock prices and consumption, etc.</p><p>In 1992, in the Journal of Risk and Uncertainty, Kahneman and Tversky gave their revised account of prospect theory that they called cumulative prospect theory.[verification needed] The new theory eliminated the editing phase in prospect theory and focused just on the evaluation phase. Its main feature was that it allowed for non-linear probability weighting in a cumulative manner, which was originally suggested in John Quiggin's rank dependent utility theory.</p><p>Psychological traits such as overconfidence, projection bias, and the effects of limited attention are now part of the theory. Other developments include a conference at the University of Chicago,[14] a special behavioral economics edition of the Quarterly Journal of Economics (In Memory of Amos Tversky), and Kahneman's 2002 Nobel Prize for having integrated insights from psychological research into economic science, especially concerning human judgment and decision-making under uncertainty.[15]</p><h3>Intertemporal choice</h3><p>Behavioral economics has also been applied to intertemporal choice. Intertemporal choice is defined as making a decision and having the effects of such decision happening in a different time. Intertemporal choice behavior is largely inconsistent, as exemplified by George Ainslie's hyperbolic discounting—one of the prominently studied observations—and further developed by David Laibson, Ted O'Donoghue, and Matthew Rabin. Hyperbolic discounting describes the tendency to discount outcomes in the near future more than for outcomes in the far future. This pattern of discounting is dynamically inconsistent (or time-inconsistent), and therefore inconsistent with basic models of rational choice, since the rate of discount between time t and t+1 will be low at time t-1 when t is the near future, but high at time t when t is the present and time t+1 is the near future.</p><p>The pattern can also be explained through models of sub-additive discounting that distinguish the delay and interval of discounting: people are less patient (per-time-unit) over shorter intervals regardless of when they occur.</p><h3>Other areas of research</h3><p>Other branches of behavioral economics enrich the model of the utility function without implying inconsistency in preferences. Ernst Fehr, Armin Falk, and Matthew Rabin studied fairness, inequity aversion, and reciprocal altruism, weakening the neoclassical assumption of perfect selfishness. This work is particularly applicable to wage setting. The work on intrinsic motivation by Gneezy and Rustichini and identity by Akerlof and Kranton assumes that agents derive utility from adopting personal and social norms in addition to conditional expected utility. According to Aggarwal, in addition to behavioral deviations from rational equilibrium, markets are also likely to suffer from lagged responses, search costs, externalities of the commons, and other frictions making it difficult to disentangle behavioral effects in market behavior.[16]</p><p>Conditional expected utility is a form of reasoning where the individual has an illusion of control, and calculates the probabilities of external events and hence their utility as a function of their own action, even when they have no causal ability to affect those external events.[17][18]</p><p>Behavioral economics caught on among the general public with the success of books such as Dan Ariely's Predictably Irrational. Practitioners of the discipline have studied quasi-public policy topics such as broadband mapping.[19][20]</p><p>Taxation from a behavioral economics viewpoint is illustrated in the book The Darwin Economy by Robert H. Frank where he invokes the concept of 'positional consumption' vs 'non-positional consumption'. Positional consumption is the consumption we do that is relative to other people, while non-positional consumption is absolute. Good houses and good schools are essentially positional, and savings for retirement are essentially non-positional. Frank argues that since most of our consumption is positional, tax policies must reflect it, and that it's not possible to form coherent societies without some form of progressive taxation.[21]</p><h2>Criticism</h2><p>Critics of behavioral economics typically stress the rationality of economic agents.[22] They contend that experimentally observed behavior has limited application to market situations, as learning opportunities and competition ensure at least a close approximation of rational behavior.</p><p>Others note that cognitive theories, such as prospect theory, are models of decision making, not generalized economic behavior, and are only applicable to the sort of once-off decision problems presented to experiment participants or survey respondents.[citation needed]</p><p>A notable concern is that despite a great deal of rhetoric, there is no real consistent behavioral theory yet. Behavioral economics scholars also have no unified theory. Until that happens, it is a collection of loosely related or unrelated observations. What is missing is a foundational behavioral theory that can be tested in many domains as a competitor to neoclassical theory.[citation needed]</p><p>Traditional economists are also skeptical of the experimental and survey-based techniques which behavioral economics uses extensively. Economists typically stress revealed preferences over stated preferences (from surveys) in the determination of economic value. Experiments and surveys are at risk of systemic biases, strategic behavior and lack of incentive compatibility.[citation needed]</p><h3>Responses</h3><p>Rabin[23] dismisses these criticisms, claiming that consistent results are typically obtained in multiple situations and geographies and can produce good theoretical insight. Behavioral economists have also responded to these criticisms by focusing on field studies rather than lab experiments. Some economists see a fundamental schism between experimental economics and behavioral economics, but prominent behavioral and experimental economists tend to share techniques and approaches in answering common questions. For example, behavioral economists are investigating neuroeconomics, which is entirely experimental and cannot yet be verified in the field.[citation needed]</p><p>Other proponents of behavioral economics note that neoclassical models often fail to predict outcomes in real world contexts. Behavioral insights can influence neoclassical models. Behavioral economists note that these revised models not only reach the same correct predictions as the traditional models, but also correctly predict some outcomes where the traditional models failed.[citation needed]</p><div class="gradientback"></div></div><div class="content"><p>According to some researchers,[24] when studying the mechanisms that form the basis of decision-making, especially financial decision-making, it is necessary to recognize that most decisions are made under stress[25] because, Stress is the nonspecific body response to any demands presented to it.[26]</p><p>From a biological point of view, human behaviors are essentially the same during crises accompanied by stock market crashes and during bubble growth when share prices exceed historic highs. During those periods, most market participants see something new for themselves, and this inevitably induces a stress response in them with accompanying changes in their endocrine profiles and motivations. The result is quantitative and qualitative changes in behavior. However, this is only one example of where behavior affecting economics and finance can be observed and variably-contrasted using behavioral economics, and it is a mistake to think of its usefulness as only applying within such environments tested-in or -of conditions similar to stock exchanges specifically. Also, often selfish-reasoning, 'adult behaviors', and similar, can be identified within criminal-concealment(s), and legal-deficiencies and neglect of different types can be observed and discovered. Awareness of indirect consequence (or lack of), at least in potential with different experimental models and methods, can be used as well—behavioral economics' potential uses are broad, but its reliability need scrutiny. An underestimation of the role of novelty as a stressor is the primary shortcoming of current approaches for market research. So, it is necessary to account for the biologically determined diphasisms of human behavior in everyday low-stress conditions and in response to stressors.[24]</p><h2>Applied issues</h2><h3>Behavioral finance</h3><p>The central issue in behavioral finance is explaining why market participants make irrational systematic errors contrary to assumption of rational market participants.[1] Such errors affect prices and returns, creating market inefficiencies. The study of behavioral finance also investigates how other participants take advantage (arbitrage) of such errors and market inefficiencies.</p><p>Behavioral finance highlights inefficiencies, such as under- or over-reactions to information, as causes of market trends and, in extreme cases, of bubbles and crashes. Such reactions have been attributed to limited investor attention, overconfidence, overoptimism, mimicry (herding instinct) and noise trading. Technical analysts consider behavioral finance to be behavioral economics' academic cousin and the theoretical basis for technical analysis.[27]</p><p>Other key observations include the asymmetry between decisions to acquire or keep resources, known as the bird in the bush paradox, and loss aversion, the unwillingness to let go of a valued possession. Loss aversion appears to manifest itself in investor behavior as a reluctance to sell shares or other equity if doing so would result in a nominal loss.[28] It may also help explain why housing prices rarely/slowly decline to market clearing levels during periods of low demand.</p><p>Benartzi and Thaler, applying a version of prospect theory, claim to have solved the equity premium puzzle, something conventional finance models so far have been unable to do.[29] Experimental finance applies the experimental method, e.g., creating an artificial market through some kind of simulation software to study people's decision-making process and behavior in financial markets.</p><p>Quantitative behavioral finance uses mathematical and statistical methodology to understand behavioral biases. In marketing research, a study shows little evidence that escalating biases impact marketing decisions.[30] Leading contributors include Gunduz Caginalp (Editor of the Journal of Behavioral Finance from 2001–04), and collaborators include 2002 Nobel Laureate Vernon Smith, David Porter, Don Balenovich,[31] Vladimira Ilieva and Ahmet Duran,[32] and Ray Sturm.[33]</p><h3>Financial models</h3><p>Some financial models used in money management and asset valuation incorporate behavioral finance parameters. Examples:</p><p>Critics such as Eugene Fama typically support the efficient-market hypothesis. They contend that behavioral finance is more a collection of anomalies than a true branch of finance and that these anomalies are either quickly priced out of the market or explained by appealing to market microstructure arguments. However, individual cognitive biases are distinct from social biases; the former can be averaged out by the market, while the other can create positive feedback loops that drive the market further and further from a fair price equilibrium. Similarly, for an anomaly to violate market efficiency, an investor must be able to trade against it and earn abnormal profits; this is not the case for many anomalies.[35]</p><p>A specific example of this criticism appears in some explanations of the equity premium puzzle. It is argued that the cause is entry barriers (both practical and psychological) and that returns between stocks and bonds should equalize as electronic resources open up the stock market to more traders.[36] In response, others contend that most personal investment funds are managed through superannuation funds, minimizing the effect of these putative entry barriers.[citation needed] In addition, professional investors and fund managers seem to hold more bonds than one would expect given return differentials.[citation needed]</p><h3>Game theory</h3><p> Main article: Behavioral game theory</p><p>Behavioral game theory, Invented by Colin Camerer, analyzes interactive strategic decisions and behavior using the methods of game theory,[37] experimental economics, and experimental psychology. Experiments include testing deviations from typical simplifications of economic theory such as the independence axiom[38] and neglect of altruism,[39] fairness,[40] and framing effects.[41] On the positive side, the method has been applied to interactive learning[42] and social preferences.[43] As a research program, the subject is a development of the last three decades.[44]</p><h3>Economic reasoning in non-human animals</h3><p>A handful of comparative psychologists have attempted to demonstrate quasi-economic reasoning in non-human animals. Early attempts along these lines focus on the behavior of rats and pigeons. These studies draw on the tenets of comparative psychology, where the main goal is to discover analogs to human behavior in experimentally-tractable non-human animals. They are also methodologically similar to the work of Ferster and Skinner.[45] Methodological similarities aside, early researchers in non-human economics deviate from behaviorism in their terminology. Although such studies are set up primarily in an operant conditioning chamber using food rewards for pecking/bar-pressing behavior, the researchers describe pecking and bar-pressing not in terms of reinforcement and stimulus-response relationships but instead in terms of work, demand, budget, and labor. Recent studies have adopted a slightly different approach, taking a more evolutionary perspective, comparing economic behavior of humans to a species of non-human primate, the capuchin monkey.[46]</p><p>Many early studies of non-human economic reasoning were performed on rats and pigeons in an operant conditioning chamber. These studies looked at things like peck rate (in the case of the pigeon) and bar-pressing rate (in the case of the rat) given certain conditions of reward. Early researchers claim, for example, that response pattern (pecking/bar-pressing rate) is an appropriate analogy to human labor supply.[47] Researchers in this field advocate for the appropriateness of using animal economic behavior to understand the elementary components of human economic behavior.[48] In a paper by Battalio, Green, and Kagel,[47] they write,</p><div class="gradientback"></div></div><div class="content"><p>The typical laboratory environment to study labor supply in pigeons is set up as follows. Pigeons are first deprived of food. Since the animals become hungry, food becomes highly desired. The pigeons are then placed in an operant conditioning chamber and through orienting and exploring the environment of the chamber they discover that by pecking a small disk located on one side of the chamber, food is delivered to them. In effect, pecking behavior becomes reinforced, as it is associated with food. Before long, the pigeon pecks at the disk (or stimulus) regularly.</p><p>In this circumstance, the pigeon is said to work for the food by pecking. The food, then, is thought of as the currency. The value of the currency can be adjusted in several ways, including the amount of food delivered, the rate of food delivery and the type of food delivered (some foods are more desirable than others).</p><p>Economic behavior similar to that observed in humans is discovered when the hungry pigeons stop working/work less when the reward is reduced. Researchers argue that this is similar to labor supply behavior in humans. That is, like humans (who, even in need, will only work so much for a given wage), the pigeons demonstrate decreases in pecking (work) when the reward (value) is reduced.[47]</p><p>In human economics, a typical demand curve has negative slope. This means that as the price of a certain good increases, the amount that consumers are willing and able to purchase decreases. Researchers studying the demand curves of non-human animals, such as rats, also find downward slopes.</p><p>Researchers have studied demand in rats in a manner distinct from studying labor supply in pigeons. Specifically, in an operant conditioning chamber containing rats as experimental subjects, we require them to press a bar, instead of pecking a small disk, to receive a reward. The reward can be food (reward pellets), water, or a commodity drink such as cherry cola. Unlike in previous pigeon studies, where the work analog was pecking and the monetary analog was reward, the work analog in this experiment is bar-pressing. Under these circumstances, the researchers claim that changing the number of bar presses required to obtain a commodity item is analogous to changing the price of a commodity item in human economics.[49]</p><p>In effect, results of demand studies in non-human animals show that, as the bar-pressing requirement (cost) increases, the number of times an animal presses the bar equal to or greater than the bar-pressing requirement (payment) decreases.</p><h3>Evolutionary psychology</h3><p>An evolutionary psychology perspective states that many of the perceived limitations in rational choice can be explained as being rational in the context of maximizing biological fitness in the ancestral environment, but not necessarily in the current one. Thus, when living at subsistence level where a reduction of resources may result in death, it may have been rational to place a greater value on preventing losses than on obtaining gains. It may also explain behavioral differences between groups, such as males being less risk-averse than females since males have more variable reproductive success than females. While unsuccessful risk-seeking may limit reproductive success for both sexes, males may potentially increase their reproductive success from successful risk-seeking much more than females can.[50]</p><h2>Notable theorists</h2><h3>Economics</h3><h3>Psychology</h3><h3>Finance</h3><h2>Citations</h2><p>Description and preview.</p><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Behavioral_economics&amp;oldid=779832385"					
								Categories:  Hidden categories:</p><br><h1 lang="en">Demographic economics</h1><p> From Wikipedia, the free encyclopedia</p><p>Demographic economics or population economics is the application of economic analysis to demography, the study of human populations, including size, growth, density, distribution, and vital statistics.[1][2]</p><p>Aspects of the subject include</p><p>Other subfields include measuring value of life[53][54] and the economics of the elderly[55][56][57] and the handicapped[58][59][60] and of gender,[61][62][63] race, minorities, and non-labor discrimination.[64][65] In coverage and subfields, it complements labor economics[66][67] and implicates a variety of other economics subjects.[68][69][70]</p><h2>Subareas</h2><p>The Journal of Economic Literature classification codes are a way of categorizing subjects in economics. There, Demographic Economics is paired with Labor Economics as one of 19 primary classifications at JEL: J.[71] It has 8 subareas, which are listed below with JEL-code links to corresponding available article-preview links of The New Palgrave Dictionary of Economics (2008) Online:</p><p>Related:</p><h2>Notes</h2><h2>Journals</h2><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Demographic_economics&amp;oldid=783362262"					
								Categories:  Hidden categories:</p><br><div class="gradientback"></div></div><div class="content"><h1 lang="en">Economics of digitization</h1><p> From Wikipedia, the free encyclopedia</p><p>The economics of digitization is the field of economics that studies how digitization affects markets and how digital data can be used to study economics. Digitization is the process by which technology lowers the costs of storing, sharing, and analyzing data. This process has changed how consumers behave, how industrial activity is organized, and how governments operate. The economics of digitization exists as a distinct field of economics for two reasons. First, new economic models are needed because many traditional assumptions about information no longer holds in a digitized world. Second, the new types of data generated by digitization require new methods to analyze.</p><p>Research in the economics of digitization touches on several fields of economics including industrial organization, labor economics, and intellectual property. Consequently, many of the contributions to the economics of digitization have also found an intellectual home in these fields. An underlying theme in much of the work in the field is that existing government regulation of copyright, security, and antitrust is inappropriate in the modern world. For example, information goods, such as news articles and movies, now have zero marginal costs of production and sharing. This has made the redistribution without permission common and has increased competition between providers of information goods. Research in the economics of digitization studies how policy should adapt in response to these changes.</p><h2>Contents</h2><h2>Information technology and access to networks</h2><h3>Technological standards</h3><p>The Internet is a multi-layered network which is operated by a variety of participants. The Internet has come to mean a combination of standards, networks, and web applications (such as streaming and file-sharing) that have accumulated around networking technology. The emergence of the Internet coincided with the growth of a new type of organizational structure, the standards committee.[1][2] Standards committees are responsible for designing critical standards for the Internet such as TCP/IP, HTML, and CSS. These committees are composed of representatives from firms, academia, and non-profit organizations. Their goal is to make decisions that advance technology while retaining interoperability between Internet components. Economists are interested in how these organizational structures make decisions and whether those decisions are optimal.</p><h3>The supply of Internet access</h3><p>The commercial supply of Internet access began when the National Science Foundation removed restrictions for using the Internet for commercial purposes. During the 90's internet access was provided by numerous regional and national Internet service providers (ISPs). However, by 2014, the provision of high-speed broadband access was consolidated. About 80% of Americans can only buy 25Mbit/s from one provider and a majority only have a choice of two providers for 10Mbit/s service. Economists are particularly interested by competition and network effects within this industry.[3] Furthermore, the availability of broadband may affect other economic outcomes such as the relative wages of skilled and unskilled workers.[4]</p><h3>Demand for the Internet</h3><p>A key issue in the economics of digitization is the economic value of Internet-based services. The motivation for this question is two-fold. First, economists are interested in understanding digitization related policies such as network infrastructure investment and subsidies for Internet access. Second, economists want to measure the gains to consumers from the Internet. The revenues of Internet Service Providers provided one direct measure of the growth in the Internet economy.[5][6] This is an important topic because many economists believe that traditional measures of economic growth, such as GDP, understate the true benefits of improving technology. The modern digital economy also tends to lead to rely on inputs with zero price.[7]</p><h2>The effects of digitization on industrial organization</h2><h3>Platforms and online marketplaces</h3><p>Digitization has coincided with the increased prominence of platforms and marketplaces that connect diverse agents in social and economic activity. A platform is defined by Bresnahan and Greenstein (1999)[8] as a reconfigurable base of compatible components on which users build applications. Platforms are most readily identified with their technical standards, i.e., engineering specifications for hardware and standards for software. The pricing and product strategies that platforms use differ from those of traditional firms because of the presence of network effects. Network effects arise within platforms because participation by one group affects the utility of another group. Many online platforms replicate identical process or algorithms at virtually no cost, allowing them to scale the network effect without encountering diminishing returns. Large scale network effects make the analysis of competition between platforms more complex than the analysis of competition between traditional firms. Much work in the economics of digitization studies the question of how these firms should operate and how they compete with each other.[9][10] A particularly important issue is whether markets for online platforms have a tendency towards winner-takes-all competitive outcomes, and should be subject to antitrust actions.</p><p>Online platforms often drastically reduce transactions costs, especially in markets where the quality of a good or trading partner is uncertain.[11] For example, eBay drastically increased the market for used consumer goods by offering a search engine, reputation system, and other services that make trade less risky. Other online marketplaces of this type include Airbnb for accommodations, Prosper for lending, and Odesk for labor. Economists are interested in quantifying the gains from these marketplaces and studying how they should be designed. For example, eBay, Odesk, and other marketplaces have adapted the use of auctions as a selling mechanisms. This has prompted a large literature on the comparative advantages of selling goods via auction versus using a fixed price.[12][13][14][15]</p><h3>User-generated content and open source production</h3><p>Digitization has coincided with the production of software and content by users who are not directly compensated for their work. Furthermore, those goods are typically distributed for free on the Internet. Prominent examples of open-source software include the Apache HTTP Server, Mozilla Firefox, and the Linux operating system. Economists are interested in the incentives of users to produce this software and how this software either substitutes or complements existing production processes.[16] Another area of study is estimating the degree to which GDP and other measures of economic activity are mis-measured due to open source software. For example, Greenstein and Nagle (2014)[17] estimate that Apache alone accounts for a mis-measurement between $2 billion and $12 billion.</p><p>In addition, open source production can be used for hardware, known as open hardware, normally by sharing digital designs such as CAD files.[18] Sharing of open hardware designs can generate significant value because of the ability to digitally replicate products for approximately the cost of materials using technologies such as 3D printers.[19][20]</p><p>Another active area of research studies the incentives to produce user-generated content such as Wikipedia articles, digital videos, blogs, podcasts, etc. For example, Zhang and Zhu (2011)[21] show that Wikipedia contributors are motivated by the social interaction with other contributors. Greenstein and Zhu (2012)[22] show that while many Wikipedia articles exhibit slant, the overall level of slant across articles on Wikipedia has diminished over time.</p><h3>Advertising</h3><p>Advertising is an important source of revenue for information goods, both online and offline. Given the prevalence of advertising-supported information goods online, it is important to understand how online advertising works. Economists have spent much effort in trying to quantify the returns to online advertising. One especially interesting aspect of online advertising is its ability to target customers using fine demographic and behavioral data.[23] This ability potentially affects the ability of new and small firms to gain exposure to customers and to grow. However, targeted advertising is also controversial because it sometimes uses private data about individuals obtained through third-party sources. Quantifying the costs and benefits of using this type of data is an active research area in the field.</p><div class="gradientback"></div></div><div class="content"><h2>The effects of digitization on consumer choice</h2><h3>Search, search engines and recommendation systems</h3><p>Perhaps the oldest and largest stream of research on the Internet and market frictions emphasizes reduced search costs. This literature builds on an older theory literature in economics[24][25][26] that examines how search costs affect prices. Digitization of retail and marketing meant that consumers could easily compare prices across stores, so the empirical work on Internet pricing examined the impact on prices and price dispersion. Initially hypothesized by Bakos (1997),[27] the first wave of this research empirically documented lower prices, but still substantial dispersion.[28][29][30]</p><p>The newest wave of this research collects data about online searches to examine the actual search process that consumers undertake when looking for a product online.[31][32] This question also emphasizes that the final stage of purchase is often controlled by a more familiar retail environment, and it raises questions about the growing importance of standards and platforms in the distribution of creative content.</p><p>As noted earlier, near-zero marginal costs of distribution for information goods might change where and how information goods get consumed. Geographic boundaries might be less important if information can travel long distances for free.[33][34][35] One open question concerns the incidence of the impact of low distribution costs. The benefits might vary by location, with locations with fewer offline options generating a larger benefit from digitization.[36][37]</p><p>Furthermore, online retailers of digital goods can carry many more products and never worry about running out of inventory. Even if a song only sells a handful of times, it is still profitable to be offered for sale on the Internet. At the same time, the zero marginal costs of distribution mean that top-selling (superstar) items never go out of stock and therefore can achieve even higher sales (Anderson, 2006). Several papers in the literature attempt to quantify the economic impact of increased product variety made available through electronic markets.[38][39] Bar-Isaac et al. (2012)[40] derive a theory of when lower search costs will result in 'superstar' and 'long-tail' effects.</p><h3>Reputation systems</h3><p>One particularly important aspect of digitization for consumers is the increased use of reputation systems on retail websites and online marketplaces. Sixty-eight percent of respondents in a 2013 Nielsen survey said that they trusted online reviews. Numerous papers have shown that these review systems affect consumer demand for restaurants[41] books,[42] and hotels. A key area of research in digitization studies whether online reputations accurately reveal both the vertical and horizontal quality of a good. For example, Forman et al. (2008)[43] show that local reviews have more effect than reviews from distant reviewers, suggesting that reviews provide information about both vertical and horizontal differentiation. On the other hand, several show that online review are biased because not everyone leaves reviews,[44] because reviewers are afraid of retaliation,[45] and because sellers may promote their own products using the review system.[46] Newer research proposes designs for reputation systems that more efficiently aggregate information about the experiences of users.[47]</p><h2>The effects of digitization on labor markets</h2><p>Digitization has partially or fully replaced many tasks that were previously done by human laborers. At the same time, computers have made some workers much more productive. Economists are interested in understanding how these two forces interact in determining labor market outcomes. For example, a large literature studies the magnitude and causes of skill-biased technical change, the process by which technology improves wages for educated workers. Alternatively, Author (2014)[48] describes a framework for classifying jobs into those more or less prone to replacement by computers. Furthermore, the use of information technology only increases productivity when it's complemented by organization changes. For example, Garicano and Heation (2010)[49] show that IT increases the productivity of police departments only when those police departments increased training and expanded support personnel.</p><p>Another consequence of digitization is that it has drastically reduced the costs of communication between workers across different organizations and locations. This has led to a change in the geographic and contractual organization of production. Economists are interested in the magnitude of this change and its effect on local labor markets. A recent study found that the potential of manufacturing sector jobs to be offshored did not reduce wages in the US. However, survey evidence suggests that 25% of American jobs are potentially offshorable in the future.[50]</p><p>Online labor market platforms like Odesk and Amazon Mechanical Turk represent a particularly interesting form of labor production arising out of digitization. Economists who study these platforms are interested in how they compete with or complement more traditional firms. Another active area of research is how to incentivize workers on these platforms to produce more efficiently.[51] While workers engaged in routine, lower-skill tasks such as data entry are particularly susceptible to competition from online labor markets, creative professions are also exposed, as many online platforms now provide opportunities to crowdsource creative work.</p><h2>Government policy and digitization</h2><h3>Intellectual property and digitization</h3><p>One main area of policy interest related to digitization concerns intellectual property. The justification for giving copyright and patent right relies on the theory that the potential to gain these rights encourages the production and sharing of intellectual property. However, digitization and ease of copying has made it difficult to defend intellectual property rights, especially in the case of copyright. Varian (2005)[52] supplies a theoretical framework for thinking about this change from an economics perspective. Usually, the economic effect on copyright-holders in the context of free copying is considered to be negative. However, Varian suggests an important counter-argument. If the value a consumer puts on the right to copy is greater than the reduction in sales, a seller can increase profits by allowing that right. Varian also provides a detailed description of several business models which potentially address the greater difficulty of enforcing copyrights as digitization increases. Alternative business models for intellectual property holders include selling complementary goods, subscriptions, personalization, and advertising.</p><p>Empirical research in this area studies the effects of Internet file-sharing on the supply and demand for paid content. For example, Danaher et al. 2010[53] show that the removal of NBC content from iTunes increased the illicit copying of NBC shows by 11.4%. This result shows that licensed and unlicensed content are substitutes. Giorcelli and Moser (2014)[54] show that the spread of copyright in Italy between 1770 and 1900 increased the production of new and better operas. Sill, there is little work on how these empirical results should inform copyright rules and security practices.</p><h3>Net neutrality</h3><p> Main article: Net neutrality</p><h3>Privacy, security, and digitization</h3><p>Privacy and data security is an area where digitization has substantially changed the costs and benefits to various economic actors. Traditional policies regarding privacy circumscribed the ability of government agencies to access individual data. However, the large-scale ability of firms to collect, parse, and analyze detailed micro-level data about consumers has shifted the policy focus. Now, the concern is whether firms' access consumer data should be regulation and restricted. In the past decade, theoretical work on commercial privacy has tended to focus on behavioral price discrimination as being a potential application of a context where researchers can model privacy concerns from an economics perspective.[55][56]</p><p>Goldfarb and Tucker (2011a)[57] wrote the first paper to empirically study the economic effects of privacy regulation for the advertising-supported Internet. The implementation of privacy regulation in Europe has made it more difficult for firms to collect and use consumer browsing data to target their ads more accurately; the field test data shows these policies are associated with a 65 percent reduction in the influence banner ads have on purchase intent. As well as this main effect, their research also suggests that privacy regulation might change the web landscape in unanticipated ways, with advertising becoming even more intrusive. It also might lead marketers to shift their media buys away from newspapers because of difficulties in finding relevant advertising to show.</p><div class="gradientback"></div></div><div class="content"><p>Another related concern is what precautions should firms take to prevent data breaches such as those at Target and Staples. Arora et al. (2010)[58] models the firm's effort in securing data from an economics perspective. They find that direct competition reduces the time that a firm takes to patch a vulnerability to its software. Other attempts at measuring the consequences of information security policy from an economics perspective are Miller and Tucker (2011),[59] who look at policies mandating encryption, and Romanosky et al. (2011),[60] who look at mandatory breach notification laws.</p><h3>Other issues</h3><p>There are many other policies related to digitization that are of interest to economists. For example, digitization may affect government effectiveness and accountability.[61] Digitization also makes it easier for firms in one jurisdiction to supply consumers in another. This creates challenges for tax enforcement.[62] Another issue is that companies with new, Internet based business models, such as Airbnb and Uber, pose challenges for regulation aimed at traditional service providers. Many safety and quality enforcement regulations may no longer be necessary with the advent of online reputation systems. Lastly, digitization is of great importance to health care policy. For example, electronic medical records have the potential to make healthcare more effective but pose challenges to privacy policy.[63][64]</p><h2>Books</h2><p>In May 2015 the National Bureau of Economic Research published a book with University of Chicago Press entitled Economic Analysis of the Digital Economy. The editors for the book are Avi Goldfarb, Shane Greenstein, and Catherine Tucker. The volume brings together leading scholars to explore this emerging area of research.[65] This follows on a book that collected twenty-five important articles in the area, published by Edward Elgar Publishing, titled Economics of Digitization.[66]</p><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Economics_of_digitization&amp;oldid=779577722"					
								Categories:  Hidden categories:</p><br><h1 lang="en">Computational economics</h1><p> From Wikipedia, the free encyclopedia</p><p>Computational economics is a research discipline at the interface of computer science, economics, and management science.[1] This subject encompasses computational modeling of economic systems, whether agent-based,[2] general-equilibrium,[3] macroeconomic,[4] or rational-expectations,[5] computational econometrics and statistics,[6] computational finance, computational tools for the design of automated internet markets, programming tools specifically designed for computational economics, and pedagogical tools for the teaching of computational economics. Some of these areas are unique to computational economics, while others extend traditional areas of economics by solving problems that are difficult to study without the use of computers and associated numerical methods.[7]</p><p>Computational economics uses computer-based economic modeling for the solution of analytically and statistically formulated economic problems. A research program, to that end, is agent-based computational economics (ACE), the computational study of economic processes, including whole economies, as dynamic systems of interacting agents.[8] As such, it is an economic adaptation of the complex adaptive systems paradigm.[9] Here the agent refers to computational objects modeled as interacting according to rules, not real people.[2] Agents can represent social, biological, and/or physical entities. The theoretical assumption of mathematical optimization by agents in equilibrium is replaced by the less restrictive postulate of agents with bounded rationality adapting to market forces,[10] including game-theoretical contexts.[11] Starting from initial conditions determined by the modeler, an ACE model develops forward through time driven solely by agent interactions. The ultimate scientific objective of the method is to ... test theoretical ?ndings against real-world data in ways that permit empirically supported theories to cumulate over time, with each researcher’s work building appropriately on the work that has gone before.[12]</p><p>Computational solution tools include for example software for carrying out various matrix operations (e.g. matrix inversion) and for solving systems of linear and nonlinear equations. For a repository of public-domain computational solution tools, visit here.</p><p>The following journals specialize in computational economics: ACM Transactions on Economics and Computation, [13] Computational Economics,[1] Journal of Applied Econometrics,[14] Journal of Economic Dynamics and Control,[15] and the Journal of Economic Interaction and Coordination.[16]</p><li>^ a b Computational Economics. About This Journal and Aims and Scope.</li><li>^ a b Scott E. Page, 2008. agent-based models, The New Palgrave Dictionary of Economics, 2nd Edition. Abstract.</li><li>^ The New Palgrave Dictionary of Economics, 2008. 2nd Edition:
				&nbsp; • computation of general equilibria by Herbert E. Scarf. Abstract.
				&nbsp; • computation of general equilibria (new developments) by Felix Kubler. Abstract.</li><li>^ • Hans M. Amman, David A. Kendrick, and John Rust, ed., 1996. Handbook of Computational Economics, v. 1, ch. 1-6, preview links.</li><li>^ Ray C. Fair Computational Methods for Macroeconometric Models, Hans M. Amman, David A. Kendrick, and John Rust, ed., 1996. Handbook of Computational Economics, v. 1, ch. , pp. 143-169. Outline.</li><li>^ • Vassilis A. Hajivassiliou, 2008. computational methods in econometrics, The New Palgrave Dictionary of Economics, 2nd Edition. Abstract.
				&nbsp;&nbsp; • Keisuke Hirano, 2008. decision theory in econometrics, The New Palgrave Dictionary of Economics, 2nd Edition. Abstract.
				&nbsp;&nbsp; • James O. Berger, 2008. statistical decision theory, The New Palgrave Dictionary of Economics, 2nd Edition. Abstract.</li><li>^ • Hans M. Amman, David A. Kendrick, and John Rust, ed., 1996. Handbook of Computational Economics, v. 1, Elsevier. Description &amp; chapter-preview links.
				&nbsp;&nbsp; • Kenneth L. Judd, 1998. Numerical Methods in Economics, MIT Press. Links to description and chapter previews.</li><li>^ • Scott E. Page, 2008. agent-based models, The New Palgrave Dictionary of Economics, 2nd Edition. Abstract.
				&nbsp;&nbsp; • Leigh Tesfatsion, 2006. Agent-Based Computational Economics: A Constructive Approach to Economic Theory, ch. 16, Handbook of Computational Economics, v. 2, [pp. 831-880]. Abstract and pre-pub PDF.
				&nbsp;&nbsp; • Kenneth L. Judd, 2006. Computationally Intensive Analyses in Economics, Handbook of Computational Economics, v. 2, ch. 17, pp. 881- 893. Pre-pub PDF.
				&nbsp;&nbsp; • L. Tesfatsion and K. Judd, ed., 2006. Handbook of Computational Economics, v. 2, Agent-Based Computational Economics, Elsevier. Description &amp; and chapter-preview links.
				&nbsp;&nbsp; • Thomas J. Sargent, 1994. Bounded Rationality in Macroeconomics, Oxford. Description and chapter-preview 1st-page links.</li><li>^ • W. Brian Arthur, 1994. Inductive Reasoning and Bounded Rationality, American Economic Review, 84(2), pp. 406-411.
				&nbsp;&nbsp; • Leigh Tesfatsion, 2003. Agent-based Computational Economics: Modeling Economies as Complex Adaptive Systems, Information Sciences, 149(4), pp. 262-268 Archived April 26, 2012, at the Wayback Machine..
				&nbsp;&nbsp; • _____, 2002. Agent-Based Computational Economics: Growing Economies from the Bottom Up, Artificial Life, 8(1), pp.55-82. Abstract and pre-pub PDF.</li><li>^ • W. Brian Arthur, 1994. Inductive Reasoning and Bounded Rationality, American Economic Review, 84(2), pp. 406-411.
				&nbsp;&nbsp; • John H. Holland and John H. Miller (1991). Artificial Adaptive Agents in Economic Theory, American Economic Review, 81(2), pp. 365-370.
				&nbsp;&nbsp; • Thomas C. Schelling, 1978 [2006]. Micromotives and Macrobehavior, Norton. Description, preview.
				&nbsp;&nbsp; • Thomas J. Sargent, 1994. Bounded Rationality in Macroeconomics, Oxford. Description and chapter-preview 1st-page links.</li><li>^ • Joseph Y. Halpern, 2008. computer science and game theory, The New Palgrave Dictionary of Economics, 2nd Edition. Abstract.
				&nbsp;&nbsp; • Yoav Shoham, 2008. Computer Science and Game Theory, Communications of the ACM, 51(8), pp. 75-79.
				&nbsp;&nbsp; • Alvin E. Roth, 2002. The Economist as Engineer: Game Theory, Experimentation, and Computation as Tools for Design Economics, Econometrica, 70(4), pp. 1341–1378.</li><div class="gradientback"></div></div><div class="content"><li>^ Leigh Tesfatsion, 2006. Agent-Based Computational Economics: A Constructive Approach to Economic Theory, ch. 16, Handbook of Computational Economics, v. 2, sect. 5, p. 865 [pp. 831-880]. Abstract and pre-pub PDF.</li><li>^ http://teac.acm.org</li><li>^ Journal of Applied Econometrics - Wiley Online Library. onlinelibrary.wiley.com. 2011. Retrieved October 31, 2011.&nbsp;</li><li>^ Journal of Economic Dynamics and Control, including Aims &amp; scope link.
				&nbsp;For a much-cited overview and issue, see:
				&nbsp; • Leigh Tesfatsion, 2001. Introduction to the Special Issue on Agent-based Computational Economics, Journal of Economic Dynamics &amp; Control, pp. 281-293.
				&nbsp; • [Special issue], 2001. Journal of Economic Dynamics and Control, Agent-based Computational Economics (ACE). 25(3-4), pp. 281-654. Abstract/outline links.</li><li>^ Journal of Economic Interaction and Coordination. springer.com. 2011. Retrieved October 31, 2011.&nbsp;</li><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Computational_economics&amp;oldid=783358046"					
								Categories:  Hidden categories:</p><br><h1 lang="en">Education economics</h1><p> From Wikipedia, the free encyclopedia</p><p>Education economics or the economics of education is the study of economic issues relating to education, including the demand for education, the financing and provision of education, and the comparative efficiency of various educational programs and policies. From early works on the relationship between schooling and labor market outcomes for individuals, the field of the economics of education has grown rapidly to cover virtually all areas with linkages to education.</p><h2>Contents</h2><h2>Education as an investment</h2><p>Economics distinguishes in addition to physical capital another form of capital that is no less critical as a means of production – human capital. With investments in human capital, such as education, three major economic effects can be expected:[1]</p><h3>Investment costs</h3><p>Investments in human capital entail an investment cost, just as any investment does. Typically in European countries most education expenditure takes the form of government consumption, although some costs are also borne by individuals. These investments can be rather costly. EU governments spent between 3% and 8% of GDP on education in 2005, the average being 5%.[2] However, measuring the spending this way alone greatly underestimates the costs because a more subtle form of costs is completely overlooked: the opportunity cost of forgone wages as students cannot work while they study. It has been estimated that the total costs, including opportunity costs, of education are as much as double the direct costs.[3] Including opportunity costs investments in education can be estimated to have been around 10% of GDP in the EU countries in 2005. In comparison investments in physical capital were 20% of GDP.[4] Thus the two are of similar magnitude.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/0/0e/Average_years_of_schooling_versus_GDP_per_capita.jpg/270px-Average_years_of_schooling_versus_GDP_per_capita.jpg" width="270" height="160"><p>


				Average years of schooling versus GDP per capita (USD 2005).


				</p><h3>Returns on investment</h3><p>
					Human capital in the form of education shares many characteristics with physical capital. Both require an investment to create and, once created, both have economic value. Physical capital earns a return because people are willing to pay to use a piece of physical capital in work as it allows them to produce more output. To measure the productive value of physical capital, we can simply measure how much of a return it commands in the market. In the case of human capital calculating returns is more complicated – after all, we cannot separate education from the person to see how much it rents for. To get around this problem, the returns to human capital are generally inferred from differences in wages among people with different levels of education. Hall and Jones have calculated from international data that on average that the returns on education are 13.4% per year for first four years of schooling (grades 1–4), 10.1% per year for the next four years (grades 5–8) and 6.8% for each year beyond eight years.[5] Thus someone with 12 years of schooling can be expected to earn, on average, 1.1344 × 1.1014 × 1.0684 = 3.161 times as much as someone with no schooling at all.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/6/62/Predicted_versus_actual_GDP_per_worker.jpg/270px-Predicted_versus_actual_GDP_per_worker.jpg" width="270" height="186"><p>


				Predicted versus actual GDP per worker. The figure shows how much one would expect each country’s GDP to be higher based on the data on average years of schooling


				</p><h3>Effects on productivity</h3><p>
					Economy-wide, the effect of human capital on incomes has been estimated to be rather significant: 65% of wages paid in developed countries is payments to human capital and only 35% to raw labor.[1] The higher productivity of well-educated workers is one of the factors that explain higher GDPs and, therefore, higher incomes in developed countries. A strong correlation between GDP and education is clearly visible among the countries of the world, as is shown by the upper left figure. It is less clear, however, how much of a high GDP is explained by education. After all, it is also possible that rich countries can simply afford more education.</p><p>To distinguish the part of GDP explained with education from other causes, Weil[1] has calculated how much one would expect each country’s GDP to be higher based on the data on average schooling. This was based on the above-mentioned calculations of Hall and Jones on the returns on education. GDPs predicted by Weil’s calculations can be plotted against actual GDPs, as is done in the figure on the left, demonstrating that the variation in education explains some, but not all, of the variation in GDP.</p><p>Finally, the matter of externalities should be considered. Usually when speaking of externalities one thinks of the negative effects of economic activities that are not included in market prices, such as pollution. These are negative externalities. However, there are also positive externalities – that is, positive effects of which someone can benefit without having to pay for it. Education bears with it major positive externalities: giving one person more education raises not only his or her output but also the output of those around him or her. Educated workers can bring new technologies, methods and information to the consideration of others. They can teach things to others and act as an example. The positive externalities of education include the effects of personal networks and the roles educated workers play in them.[6]</p><div class="gradientback"></div></div><div class="content"><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/6/6a/DiagFuncMacroSyst.pdf/page1-360px-DiagFuncMacroSyst.pdf.jpg" width="360" height="509"><p>Positive externalities from human capital are one explanation for why governments are involved in education. If people were left on their own, they would not take into account the full social benefit of education – in other words the rise in the output and wages of others – so the amount they would choose to obtain would be lower than the social optimum.[1]</p><h2>Demand for education</h2><h3>Liberal approaches</h3><p>The dominant model of the demand for education is based on human capital theory. The central idea is that undertaking education is investment in the acquisition of skills and knowledge which will increase earnings, or provide long-term benefits such as an appreciation of literature (sometimes referred to as cultural capital).[7] An increase in human capital can follow technological progress as knowledgeable employees are in demand due to the need for their skills, whether it be in understanding the production process or in operating machines. Studies from 1958 attempted to calculate the returns from additional schooling (the percent increase in income acquired through an additional year of schooling). Later results attempted to allow for different returns across persons or by level of education.[8]</p><p>Statistics have shown that countries with high enrollment/graduation rates have grown faster than countries without. The United States has been the world leader in educational advances, beginning with the high school movement (1910–1950). There also seems to be a correlation between gender differences in education with the level of growth; more development is observed in countries which have an equal distribution of the percentage of women versus men who graduated from high school. When looking at correlations in the data, education seems to generate economic growth; however, it could be that we have this causality relationship backwards. For example, if education is seen as a luxury good, it may be that richer households are seeking out educational attainment as a symbol of status, rather than the relationship of education leading to wealth.</p><p>Educational advance is not the only variable for economic growth, though, as it only explains about 14% of the average annual increase in labor productivity over the period 1915-2005. From lack of a more significant correlation between formal educational achievement and productivity growth, some economists see reason to believe that in today’s world many skills and capabilities come by way of learning outside of traditional education, or outside of schooling altogether.[9]</p><p>An alternative model of the demand for education, commonly referred to as screening, is based on the economic theory of signalling. The central idea is that the successful completion of education is a signal of ability.[10]</p><h3>Marxist critique</h3><p>Although Marx and Engels did not write widely about the social functions of education, their concepts and methods are theorized and criticized by the influence of Marx as education being used in reproduction of capitalist societies. Marx and Engels approached scholarship as revolutionary scholarship where education should serve as a propaganda for the struggle of the working class.[11] The classical Marxian paradigm sees education as serving the interest of capital and is seeking alternative modes of education that would prepare students and citizens for more progressive socialist mode of social organizations. Marx and Engels understood education and free time as essential to developing free individuals and creating many-sided human beings, thus for them education should become a more essential part of the life of people unlike capitalist society which is organized mainly around work and the production of commodities.[11]</p><h2>Financing and provision</h2><p>In most countries school education is predominantly financed and provided by governments. Public funding and provision also plays a major role in higher education. Although there is wide agreement on the principle that education, at least at school level, should be financed mainly by governments, there is considerable debate over the desirable extent of public provision of education. Supporters of public education argue that universal public provision promotes equality of opportunity and social cohesion. Opponents of public provision advocate alternatives such as vouchers.[12][13][14]</p><h3>Pre-primary education financing</h3><p>Compared to other areas of basic education, globally comparable data on pre-primary education financing remain scarce. While much of existing non-formal and private programmes may not be fully accounted for, it can be deduced from the level of provision that pre-primary financing remains inadequate, especially when considered against expected benefits. Globally, pre-primary education accounts for the lowest proportion of the total public expenditure on education, in spite of the much-documented positive impact of quality early childhood care and education on later learning and other social outcomes.[15]</p><h2>Education production function</h2><p>An education production function is an application of the economic concept of a production function to the field of education. It relates various inputs affecting a student’s learning (schools, families, peers, neighborhoods, etc.) to measured outputs including subsequent labor market success, college attendance, graduation rates, and, most frequently, standardized test scores. The original study that eventually prompted interest in the idea of education production functions was by a sociologist, James S. Coleman. The Coleman Report, published in 1966, concluded that the marginal effect of various school inputs on student achievement was small compared to the impact of families and friends.[16] Later work, by Eric A. Hanushek, Richard Murnane, and other economists introduced the structure of production to the consideration of student learning outcomes. Hanushek at al. (2008) reported a very high correlation between adjusted growth rate and adjusted test scores.[17]</p><p>A large number of successive studies, increasingly involving economists, produced inconsistent results about the impact of school resources on student performance, leading to considerable controversy in policy discussions.[18][19] The interpretation of the various studies has been very controversial, in part because the findings have directly influenced policy debates. Two separate lines of study have been particularly widely debated. The overall question of whether added funds to schools are likely to produce higher achievement (the “money doesn’t matter” debate) has entered into legislative debates and court consideration of school finance systems.[20][21][22] Additionally, policy discussions about class size reduction heightened academic study of the relationship of class size and achievement.[23][24][25]</p><h2>Sources</h2><h2>Notes</h2><p>Selected entries on education from The New Palgrave Dictionary of Economics, 2008), 2nd Edition:</p><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Education_economics&amp;oldid=783361491"					
								Categories:  Hidden categories:</p><br><h1 lang="en">Evolutionary economics</h1><p> From Wikipedia, the free encyclopedia</p><p>Evolutionary economics is part of mainstream economics[1] as well as a heterodox school of economic thought that is inspired by evolutionary biology. Much like mainstream economics, it stresses complex interdependencies, competition, growth, structural change, and resource constraints but differs in the approaches which are used to analyze these phenomena.[2]</p><div class="gradientback"></div></div><div class="content"> <p>Evolutionary economics deals with the study of processes that transform economy for firms, institutions, industries, employment, production, trade and growth within, through the actions of diverse agents from experience and interactions, using evolutionary methodology. Evolutionary economics analyses the unleashing of a process of technological and institutional innovation by generating and testing a diversity of ideas which discover and accumulate more survival value for the costs incurred than competing alternatives. The evidence suggests that it could be adaptive efficiency that defines economic efficiency. Mainstream economic reasoning begins with the postulates of scarcity and rational agents (that is, agents modeled as maximizing their individual welfare), with the rational choice for any agent being a straightforward exercise in mathematical optimization. There has been renewed interest in treating economic systems as evolutionary systems in the developing field of Complexity economics.[citation needed]</p><p>Evolutionary economics does not take the characteristics of either the objects of choice or of the decision-maker as fixed. Rather its focus is on the non-equilibrium processes that transform the economy from within and their implications. The processes in turn emerge from actions of diverse agents with bounded rationality who may learn from experience and interactions and whose differences contribute to the change. The subject draws more recently on evolutionary game theory[3] and on the evolutionary methodology of Charles Darwin and the non-equilibrium economics principle of circular and cumulative causation. It is naturalistic in purging earlier notions of economic change as teleological or necessarily improving the human condition.[4]</p><p>A different approach is to apply evolutionary psychology principles to economics which is argued to explain problems such as inconsistencies and biases in rational choice theory. Basic economic concepts such as utility may be better viewed as due to preferences that maximized evolutionary fitness in the ancestral environment but not necessarily in the current one.[5]</p><h2>Contents</h2><h2>Predecessors</h2><p>In the mid-19th century, Karl Marx presented a schema of stages of historical development, by introducing the notion that human nature was not constant and was not determinative of the nature of the social system; on the contrary, he made it a principle that human behavior was a function of the social and economic system in which it occurred.</p><p>Marx based his theory of economic development on the premise of developing economic systems; specifically, over the course of history superior economic systems would replace inferior ones. Inferior systems were beset by internal contradictions and inefficiencies that make them impossible to survive over the long term. In Marx's scheme, feudalism was replaced by capitalism, which would eventually be superseded by socialism.[6]</p><p>At approximately the same time, Charles Darwin developed a general framework for comprehending any process whereby small, random variations could accumulate and predominate over time into large-scale changes that resulted in the emergence of wholly novel forms (speciation).</p><p>This was followed shortly after by the work of the American pragmatic philosophers (Peirce, James, Dewey) and the founding of two new disciplines, psychology and anthropology, both of which were oriented toward cataloging and developing explanatory frameworks for the variety of behavior patterns (both individual and collective) that were becoming increasingly obvious to all systematic observers. The state of the world converged with the state of the evidence to make almost inevitable the development of a more modern framework for the analysis of substantive economic issues.</p><h3>Veblen (1898)</h3><p>Thorstein Veblen (1898) coined the term evolutionary economics in English. He began his career in the midst of this period of intellectual ferment, and as a young scholar came into direct contact with some of the leading figures of the various movements that were to shape the style and substance of social sciences into the next century and beyond. Veblen saw the need for taking account of cultural variation in his approach; no universal human nature could possibly be invoked to explain the variety of norms and behaviors that the new science of anthropology showed to be the rule, rather than the exception. He emphasised the conflict between industrial and pecuniary or ceremonial values and this Veblenian dichotomy was interpreted in the hands of later writers as the ceremonial / instrumental dichotomy (Hodgson 2004);</p><p>Veblen saw that every culture is materially based and dependent on tools and skills to support the life process, while at the same time, every culture appeared to have a stratified structure of status (invidious distinctions) that ran entirely contrary to the imperatives of the instrumental (read: technological) aspects of group life. The ceremonial was related to the past, and conformed to and supported the tribal legends; instrumental was oriented toward the technological imperative to judge value by the ability to control future consequences. The Veblenian dichotomy was a specialized variant of the instrumental theory of value due to John Dewey, with whom Veblen was to make contact briefly at the University of Chicago.</p><p>Arguably the most important works by Veblen include, but are not restricted to, his most famous works (The Theory of the Leisure Class; The Theory of Business Enterprise), but his monograph Imperial Germany and the Industrial Revolution and the 1898 essay entitled Why is Economics not an Evolutionary Science have both been influential in shaping the research agenda for following generations of social scientists. TOLC and TOBE together constitute an alternative construction on the neoclassical marginalist theories of consumption and production, respectively.</p><p>Both are founded on his dichotomy, which is at its core a valuational principle. The ceremonial patterns of activity are not bound to any past, but to one that generated a specific set of advantages and prejudices that underlie the current institutions. Instrumental judgments create benefits according to a new criterion, and therefore are inherently subversive. This line of analysis was more fully and explicitly developed by Clarence E. Ayres of the University of Texas at Austin from the 1920s.</p><p>A seminal article by Armen Alchian (1950) argued for adaptive success of firms faced with uncertainty and incomplete information replacing profit maximization as an appropriate modeling assumption.[7] Kenneth Boulding was one of the advocates of the evolutionary methods in social science, as is evident from Kenneth Boulding's Evolutionary Perspective. Kenneth Arrow, Ronald Coase and Douglass North are some of the Bank of Sweden Prize in Economic Sciences in Memory of Alfred Nobel winners who are known for their sympathy to the field.</p><p>More narrowly the works Jack Downie[8] and Edith Penrose[9] offer many insights for those thinking about evolution at the level of the firm in an industry.</p><p>Joseph Schumpeter, who lived in the first half of 20th century, was the author of the book The Theory of Economic Development (1911, transl. 1934). It is important to note that for the word development he used in his native language, the German word Entwicklung, which can be translated as development or evolution. The translators of the day used the word development from the French développement, as opposed to evolution as this was used by Darwin. (Schumpeter, in his later writings in English as a professor at Harvard, used the word evolution.) The current term in common use is economic development.</p><p>In Schumpeter's book he proposed an idea radical for its time: the evolutionary perspective. He based his theory on the assumption of usual macroeconomic equilibrium, which is something like the normal mode of economic affairs. This equilibrium is being perpetually destroyed by entrepreneurs who try to introduce innovations. A successful introduction of an innovation (i.e. a disruptive technology) disturbs the normal flow of economic life, because it forces some of the already existing technologies and means of production to lose their positions within the economy.[citation needed]</p><h2>Present state of discussion</h2><div class="gradientback"></div></div><div class="content"><p>One of the major contributions to the emerging field of evolutionary economics has been the publication of An Evolutionary Theory of Economic Change by Richard Nelson and Sidney G. Winter. These authors have focused mostly on the issue of changes in technology and routines, suggesting a framework for their analysis. If the change occurs constantly in the economy, then some kind of evolutionary process must be in action, and there has been a proposal that this process is Darwinian in nature.</p><p>Then, mechanisms that provide selection, generate variation and establish self-replication, must be identified. The authors introduced the term 'steady change' to highlight the evolutionary aspect of economic processes and contrast it with the concept of 'steady state' popular in classical economics.[10] Their approach can be compared and contrasted with the population ecology or organizational ecology approach in sociology: see Douma &amp; Schreuder (2013, chapter 11).</p><p>Milton Friedman proposed that markets act as major selection vehicles. As firms compete, unsuccessful rivals fail to capture an appropriate market share, go bankrupt and have to exit.[11] The variety of competing firms is both in their products and practices, that are matched against markets. Both products and practices are determined by routines that firms use: standardized patterns of actions implemented constantly. By imitating these routines, firms propagate them and thus establish inheritance of successful practices.[12][13] A general theory of this process has been proposed by Kurt Dopfer, John Foster and Jason Potts as the micro meso macro framework.[14]</p><p>Economic processes, as part of life processes, are intrinsically evolutionary. From the evolutionary equation that describe life processes, an analytical formula on the main factors of economic processes, such as fixed cost and variable cost, can be derived. The economic return, or competitiveness, of economic entities of different characteristics under different kinds of environment can be calculated.[15] The change of environment causes the change of competitiveness of different economic entities and systems. This is the process of evolution of economic systems.</p><p>In recent years, evolutionary models have been used to assist decision making in applied settings and find solutions to problems such as optimal product design and service portfolio diversification.[16]</p><h2>Evolutionary psychology</h2><p>A different approach is to apply evolutionary psychology principles to economics which is argued to explain problems such as inconsistencies and biases in rational choice theory. A basic economic concept such as utility may be better viewed as due to preferences that maximized evolutionary fitness in the ancestral environment but not necessarily in the current one. Loss aversion may be explained as being rational when living at subsistence level where a reduction of resources may have meant death and it thus may have been rational to place a greater value on losses than on gains.[5]</p><p>People are sometimes more cooperative and altruistic than predicted by economic theory which may be explained by mechanisms such as reciprocal altruism and group selection for cooperative behavior. An evolutionary approach may also explain differences between groups such as males being less risk-averse than females since males have more variable reproductive success than females. While unsuccessful risk-seeking may limit reproductive success for both sexes, males may potentially increase their reproductive success much more than females from successful risk-seeking. Frequency-dependent selection may explain why people differ in characteristics such as cooperative behavior with cheating becoming an increasingly less successful strategy as the numbers of cheaters increase.[5]</p><p>Another argument is that humans have a poor intuitive grasp of the economics of the current environment which is very different from the ancestral environment. The ancestral environment likely had relatively little trade, division of labor, and capital goods. Technological change was very slow, wealth differences were much smaller, and possession of many available resources were likely zero-sum games where large inequalities were caused by various forms of exploitation. Humans therefore may have poor intuitive understanding the benefits of free trade (causing calls for protectionism), the value of capital goods (making the labor theory of value appealing), and may intuitively undervalue the benefits of technological development.[5]</p><p>There may be a tendency to see the number of available jobs as a zero-sum game with the total number of jobs being fixed which causes people to not realize that minimum wage laws reduce the number of jobs or to believe that an increased number of jobs in other nations necessarily decreases the number of jobs in their own nation. Large income inequality may easily be viewed as due to exploitation rather than as due to individual differences in productivity. This may easily cause poor economic policies, especially since individual voters have few incentives to make the effort of studying societal economics instead of relying on their intuitions since an individual's vote counts for so little and since politicians may be reluctant to take a stand against intuitive views that are incorrect but widely held.[5]</p><h3>Journals</h3><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Evolutionary_economics&amp;oldid=783350140"					
								Categories:  Hidden categories:</p><br><h1 lang="en">Economic geography</h1><p> From Wikipedia, the free encyclopedia</p><p>Economic geography is the study of the location, distribution and spatial organization of economic activities across the world. It represents a traditional subfield of the discipline of geography. However, many economists have also approached the field in ways more typical of the discipline of economics.[1]</p><p>Economic geography has taken a variety of approaches to many different subject matters, including the location of industries, economies of agglomeration (also known as linkages), transportation, international trade, development, real estate, gentrification, ethnic economies, gendered economies, core-periphery theory, the economics of urban form, the relationship between the environment and the economy (tying into a long history of geographers studying culture-environment interaction), and globalization.</p><h2>Contents</h2><h2>Theoretical background and influences</h2><p>The subject matter investigated is strongly influenced by the researcher's methodological approach. Neoclassical location theorists, following in the tradition of Alfred Weber, tend to focus on industrial location and use quantitative methods. Since the 1970s, two broad reactions against neoclassical approaches have significantly changed the discipline: Marxist political economy, growing out of the work of David Harvey; and the new economic geography which takes into account social, cultural, and institutional factors in the spatial economy.</p><p>Economists such as Paul Krugman and Jeffrey Sachs have also analyzed many traits related to economic geography. Krugman called his application of spatial thinking to international trade theory the new economic geography, which directly competes with an approach within the discipline of geography that is also called new economic geography.[2] The name geographical economics has been suggested as an alternative.[3]</p><h2>History</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/1/1e/ElSalvadorfairtradecoffee.jpg/220px-ElSalvadorfairtradecoffee.jpg" width="220" height="138"><div class="gradientback"></div></div><div class="content"><p>


				The coffee trade is a worldwide industry


				</p><p>
					Some of the first traces of the study of spatial aspects of economic activities can be found in seven Chinese maps of the State of Qin dating to the 4th century BC. Ancient writings can be attributed to the Greek geographer Strabo's Geographika compiled almost 2000 years ago. As the science of cartography developed, geographers illuminated many aspects used today in the field; maps created by different European powers described the resources likely to be found in American, African, and Asian territories. The earliest travel journals included descriptions of the native peoples, the climate, the landscape, and the productivity of various locations. These early accounts encouraged the development of transcontinental trade patterns and ushered in the era of mercantilism.</p><p>World War II contributed to the popularization of geographical knowledge generally, and post-war economic recovery and development contributed to the growth of economic geography as a discipline. During environmental determinism's time of popularity, Ellsworth Huntington and his theory of climatic determinism, while later greatly criticized, notably influenced the field. Valuable contributions also came from location theorists such as Johann Heinrich von Thünen or Alfred Weber. Other influential theories include Walter Christaller's Central place theory, the theory of core and periphery.[citation needed]</p><p>Fred K. Schaefer's article Exceptionalism in geography: A Methodological Examination, published in the American journal Annals of the Association of American Geographers, and his critique of regionalism, made a large impact on the field: the article became a rallying point for the younger generation of economic geographers who were intent on reinventing the discipline as a science, and quantitative methods began to prevail in research. Well-known economic geographers of this period include William Garrison, Brian Berry, Waldo Tobler, Peter Haggett and William Bunge.</p><p>Contemporary economic geographers tend to specialize in areas such as location theory and spatial analysis (with the help of geographic information systems), market research, geography of transportation, real estate price evaluation, regional and global development, planning, Internet geography, innovation, social networks.[4]</p><h2>Approaches to study</h2><p>As economic geography is a very broad discipline, with economic geographers using many different methodologies in the study of economic phenomena in the world some distinct approaches to study have evolved over time:</p><p>Economic geography is sometimes approached as a branch of anthropogeography that focuses on regional systems of human economic activity. An alternative description of different approaches to the study of human economic activity can be organized around spatiotemporal analysis, analysis of production/consumption of economic items, and analysis of economic flow. Spatiotemporal systems of analysis include economic activities of region, mixed social spaces, and development.</p><p>Alternatively, analysis may focus on production, exchange, distribution and consumption of items of economic activity. Allowing parameters of space-time and item to vary, a geographer may also examine material flow, commodity flow, population flow and information flow from different parts of the economic activity system. Through analysis of flow and production, industrial areas, rural and urban residential areas, transportation site, commercial service facilities and finance and other economic centers are linked together in an economic activity system.</p><h3>Branches</h3><p>Thematically, economic geography can be divided into these subdisciplines:</p><p>It is traditionally considered the branch of economic geography that investigates those parts of the Earth's surface that are transformed by humans through primary sector activities. It thus focuses on structures of agricultural landscapes and asks for the processes that lead to these spatial patterns. While most research in this area concentrates rather on production than on consumption,[1] a distinction can be made between nomothetic (e.g. distribution of spatial agricultural patterns and processes) and idiographic research (e.g. human-environment interaction and the shaping of agricultural landscapes). The latter approach of agricultural geography is often applied within regional geography.</p><p>These areas of study may overlap with other geographical sciences.</p><h3>Economists and economic geographers</h3><p>Generally, spatially interested economists study the effects of space on the economy. Geographers, on the other hand, are interested in the economic processes' impact on spatial structures.</p><p>Moreover, economists and economic geographers differ in their methods in approaching spatial-economic problems in several ways. An economic geographer will often take a more holistic approach in the analysis of economic phenomena, which is to conceptualize a problem in terms of space, place and scale as well as the overt economic problem that is being examined. The economist approach, according to some economic geographers, has the main drawback of homogenizing the economic world in ways economic geographers try to avoid.[7]</p><h2>New economic geography</h2><p>With the rise of the New Economy, economic inequalities are increasing spatially. The New Economy, generally characterized by globalization, increasing use of information and communications technology, growth of knowledge goods, and feminization, has enabled economic geographers to study social and spatial divisions caused by the arising New Economy, including the emerging digital divide.</p><p>The new economic geographies consist of primarily service-based sectors of the economy that use innovative technology, such as industries where people rely on computers and the internet. Within these is a switch from manufacturing-based economies to the digital economy. In these sectors, competition makes technological changes robust. These high technology sectors rely heavily on interpersonal relationships and trust, as developing things like software is very different from other kinds of industrial manufacturing—it requires intense levels of cooperation between many different people, as well as the use of tacit knowledge. As a result of cooperation becoming a necessity, there is a clustering in the high-tech new economy of many firms.</p><h3>Social and spatial divisions</h3><p>As characterized through the work of Diane Perrons,[8] in Anglo-American literature, the New Economy consists of two distinct types. New Economic Geography 1 (NEG1) is characterized by sophisticated spatial modelling. It seeks to explain uneven development and the emergence of industrial clusters. It does so through the exploration of linkages between centripetal and centrifugal forces, especially those of economies of scale.</p><p>New Economic Geography 2 (NEG2) also seeks to explain the apparently paradoxical emergence of industrial clusters in a contemporary context, however, it emphasizes relational, social, and contextual aspects of economic behaviour, particularly the importance of tacit knowledge. The main difference between these two types is NEG2's emphasis on aspects of economic behaviour that NEG1 considers intangible.</p><p>Both New Economic Geographies acknowledge transport costs, the importance of knowledge in a new economy, possible effects of externalities, and endogenous processes that generate increases in productivity. The two also share a focus on the firm as the most important unit and on growth rather than development of regions. As a result, the actual impact of clusters on a region is given far less attention, relative to the focus on clustering of related activities in a region.</p><div class="gradientback"></div></div><div class="content"><p>However, the focus on the firm as the main entity of significance hinders the discussion of New Economic Geography. It limits the discussion in a national and global context and confines it to a smaller scale context. It also places limits on the nature of activities carried out in the firm and their position within the global value chain. Further work done by Bjorn Asheim (2001) and Gernot Grabher (2002) challenges the idea of the firm through action-research approaches and mapping organizational forms and their linkages. In short, the focus on the firm in new economic geographies is undertheorized in NEG1 and undercontextualized in NEG2, which limits the discussion of its impact on spatial economic development.</p><p>Spatial divisions within these arising New Economic geographies are apparent in the form of the digital divide, as a result of regions attracting talented workers instead of developing skills at a local level (see Creative Class for further reading). Despite increasing inter-connectivity through developing information communication technologies, the contemporary world is still defined through its widening social and spatial divisions, most of which are increasingly gendered. Danny Quah explains these spatial divisions through the characteristics of knowledge goods in the New Economy: goods defined by their infinite expansibility, weightlessness, and nonrivalry. Social divisions are expressed through new spatial segregation that illustrates spatial sorting by income, ethnicity, abilities, needs, and lifestyle preferences. Employment segregation can be seen through the overrepresentation of women and ethnic minorities in lower-paid service sector jobs. These divisions in the new economy are much more difficult to overcome as a result of few clear pathways of progression to higher-skilled work.</p><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Economic_geography&amp;oldid=780980532"					
								Categories:  Hidden categories:</p><br><br><img alt="This is a good article. Click here for more information." src="http://upload.wikimedia.org/wikipedia/en/thumb/9/94/Symbol_support_vote.svg/19px-Symbol_support_vote.svg.png" width="19" height="20"><h1 lang="en">Mathematical economics</h1><p> From Wikipedia, the free encyclopedia</p><p>Mathematical economics is the application of mathematical methods to represent theories and analyze problems in economics. By convention, the applied methods refer to those beyond simple geometry, such as differential and integral calculus, difference and differential equations, matrix algebra, mathematical programming, and other computational methods.[1][2] An advantage claimed for the approach is its allowing formulation of theoretical relationships with rigor, generality, and simplicity.[3]</p><p>Mathematics allows economists to form meaningful, testable propositions about wide-ranging and complex subjects which could less easily be expressed informally. Further, the language of mathematics allows economists to make specific, positive claims about controversial or contentious subjects that would be impossible without mathematics.[4] Much of economic theory is currently presented in terms of mathematical economic models, a set of stylized and simplified mathematical relationships asserted to clarify assumptions and implications.[5]</p><p>Broad applications include:</p><p>Formal economic modeling began in the 19th century with the use of differential calculus to represent and explain economic behavior, such as utility maximization, an early economic application of mathematical optimization. Economics became more mathematical as a discipline throughout the first half of the 20th century, but introduction of new and generalized techniques in the period around the Second World War, as in game theory, would greatly broaden the use of mathematical formulations in economics.[8][7]</p><p>This rapid systematizing of economics alarmed critics of the discipline as well as some noted economists. John Maynard Keynes, Robert Heilbroner, Friedrich Hayek and others have criticized the broad use of mathematical models for human behavior, arguing that some human choices are irreducible to mathematics.</p><h2>Contents</h2><h2>History</h2><p> Main article: History of economic thought</p><p>The use of mathematics in the service of social and economic analysis dates back to the 17th century. Then, mainly in German universities, a style of instruction emerged which dealt specifically with detailed presentation of data as it related to public administration. Gottfried Achenwall lectured in this fashion, coining the term statistics. At the same time, a small group of professors in England established a method of reasoning by figures upon things relating to government and referred to this practice as Political Arithmetick.[9] Sir William Petty wrote at length on issues that would later concern economists, such as taxation, Velocity of money and national income, but while his analysis was numerical, he rejected abstract mathematical methodology. Petty's use of detailed numerical data (along with John Graunt) would influence statisticians and economists for some time, even though Petty's works were largely ignored by English scholars.[10]</p><p>The mathematization of economics began in earnest in the 19th century. Most of the economic analysis of the time was what would later be called classical economics. Subjects were discussed and dispensed with through algebraic means, but calculus was not used. More importantly, until Johann Heinrich von Thünen's The Isolated State in 1826, economists did not develop explicit and abstract models for behavior in order to apply the tools of mathematics. Thünen's model of farmland use represents the first example of marginal analysis.[11] Thünen's work was largely theoretical, but he also mined empirical data in order to attempt to support his generalizations. In comparison to his contemporaries, Thünen built economic models and tools, rather than applying previous tools to new problems.[12]</p><p>Meanwhile, a new cohort of scholars trained in the mathematical methods of the physical sciences gravitated to economics, advocating and applying those methods to their subject,[13] and described today as moving from geometry to mechanics.[14] These included W.S. Jevons who presented paper on a general mathematical theory of political economy in 1862, providing an outline for use of the theory of marginal utility in political economy.[15] In 1871, he published The Principles of Political Economy, declaring that the subject as science must be mathematical simply because it deals with quantities. Jevons expected the only collection of statistics for price and quantities would permit the subject as presented to become an exact science.[16] Others preceded and followed in expanding mathematical representations of economic problems.</p><h3>Marginalists and the roots of neoclassical economics</h3><p> Main article: Marginalism</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/e/eb/Economics_cournot_diag4_svg.svg/275px-Economics_cournot_diag4_svg.svg.png" width="275" height="275"><div class="gradientback"></div></div><div class="content"><p>


				Equilibrium quantities as a solution to two reaction functions in Cournot duopoly. Each reaction function is expressed as a linear equation dependent upon quantity demanded.


				</p><p>
					Augustin Cournot and Léon Walras built the tools of the discipline axiomatically around utility, arguing that individuals sought to maximize their utility across choices in a way that could be described mathematically.[17] At the time, it was thought that utility was quantifiable, in units known as utils.[18] Cournot, Walras and Francis Ysidro Edgeworth are considered the precursors to modern mathematical economics.[19]</p><p>Cournot, a professor of mathematics, developed a mathematical treatment in 1838 for duopoly—a market condition defined by competition between two sellers.[19] This treatment of competition, first published in Researches into the Mathematical Principles of Wealth,[20] is referred to as Cournot duopoly. It is assumed that both sellers had equal access to the market and could produce their goods without cost. Further, it assumed that both goods were homogeneous. Each seller would vary her output based on the output of the other and the market price would be determined by the total quantity supplied. The profit for each firm would be determined by multiplying their output and the per unit Market price. Differentiating the profit function with respect to quantity supplied for each firm left a system of linear equations, the simultaneous solution of which gave the equilibrium quantity, price and profits.[21] Cournot's contributions to the mathematization of economics would be neglected for decades, but eventually influenced many of the marginalists.[21][22] Cournot's models of duopoly and Oligopoly also represent one of the first formulations of non-cooperative games. Today the solution can be given as a Nash equilibrium but Cournot's work preceded modern game theory by over 100 years.[23]</p><p>While Cournot provided a solution for what would later be called partial equilibrium, Léon Walras attempted to formalize discussion of the economy as a whole through a theory of general competitive equilibrium. The behavior of every economic actor would be considered on both the production and consumption side. Walras originally presented four separate models of exchange, each recursively included in the next. The solution of the resulting system of equations (both linear and non-linear) is the general equilibrium.[24] At the time, no general solution could be expressed for a system of arbitrarily many equations, but Walras's attempts produced two famous results in economics. The first is Walras' law and the second is the principle of tâtonnement. Walras' method was considered highly mathematical for the time and Edgeworth commented at length about this fact in his review of Éléments d'économie politique pure (Elements of Pure Economics).[25]</p><p>Walras' law was introduced as a theoretical answer to the problem of determining the solutions in general equilibrium. His notation is different from modern notation but can be constructed using more modern summation notation. Walras assumed that in equilibrium, all money would be spent on all goods: every good would be sold at the market price for that good and every buyer would expend their last dollar on a basket of goods. Starting from this assumption, Walras could then show that if there were n markets and n-1 markets cleared (reached equilibrium conditions) that the nth market would clear as well. This is easiest to visualize with two markets (considered in most texts as a market for goods and a market for money). If one of two markets has reached an equilibrium state, no additional goods (or conversely, money) can enter or exit the second market, so it must be in a state of equilibrium as well. Walras used this statement to move toward a proof of existence of solutions to general equilibrium but it is commonly used today to illustrate market clearing in money markets at the undergraduate level.[26]</p><p>Tâtonnement (roughly, French for groping toward) was meant to serve as the practical expression of Walrasian general equilibrium. Walras abstracted the marketplace as an auction of goods where the auctioneer would call out prices and market participants would wait until they could each satisfy their personal reservation prices for the quantity desired (remembering here that this is an auction on all goods, so everyone has a reservation price for their desired basket of goods).[27]</p><p>Only when all buyers are satisfied with the given market price would transactions occur. The market would clear at that price—no surplus or shortage would exist. The word tâtonnement is used to describe the directions the market takes in groping toward equilibrium, settling high or low prices on different goods until a price is agreed upon for all goods. While the process appears dynamic, Walras only presented a static model, as no transactions would occur until all markets were in equilibrium. In practice very few markets operate in this manner.[28]</p><p>Edgeworth introduced mathematical elements to Economics explicitly in Mathematical Psychics: An Essay on the Application of Mathematics to the Moral Sciences, published in 1881.[29] He adopted Jeremy Bentham's felicific calculus to economic behavior, allowing the outcome of each decision to be converted into a change in utility.[30] Using this assumption, Edgeworth built a model of exchange on three assumptions: individuals are self-interested, individuals act to maximize utility, and individuals are free to recontract with another independently of...any third party.[31]</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/en/thumb/b/b9/Contract-curve-on-edgeworth-box.svg/350px-Contract-curve-on-edgeworth-box.svg.png" width="350" height="263"><p>


				An Edgeworth box displaying the contract curve on an economy with two participants. Referred to as the "core" of the economy in modern parlance, there are infinitely many solutions along the curve for economies with two participants[32]


				</p><p>
					Given two individuals, the set of solutions where the both individuals can maximize utility is described by the contract curve on what is now known as an Edgeworth Box. Technically, the construction of the two-person solution to Edgeworth's problem was not developed graphically until 1924 by Arthur Lyon Bowley.[33] The contract curve of the Edgeworth box (or more generally on any set of solutions to Edgeworth's problem for more actors) is referred to as the core of an economy.[34]</p><p>Edgeworth devoted considerable effort to insisting that mathematical proofs were appropriate for all schools of thought in economics. While at the helm of The Economic Journal, he published several articles criticizing the mathematical rigor of rival researchers, including Edwin Robert Anderson Seligman, a noted skeptic of mathematical economics.[35] The articles focused on a back and forth over tax incidence and responses by producers. Edgeworth noticed that a monopoly producing a good that had jointness of supply but not jointness of demand (such as first class and economy on an airplane, if the plane flies, both sets of seats fly with it) might actually lower the price seen by the consumer for one of the two commodities if a tax were applied. Common sense and more traditional, numerical analysis seemed to indicate that this was preposterous. Seligman insisted that the results Edgeworth achieved were a quirk of his mathematical formulation. He suggested that the assumption of a continuous demand function and an infinitesimal change in the tax resulted in the paradoxical predictions. Harold Hotelling later showed that Edgeworth was correct and that the same result (a diminution of price as a result of the tax) could occur with a discontinuous demand function and large changes in the tax rate.[36]</p><div class="gradientback"></div></div><div class="content"><h2>Modern mathematical economics</h2><p>From the later-1930s, an array of new mathematical tools from the differential calculus and differential equations, convex sets, and graph theory were deployed to advance economic theory in a way similar to new mathematical methods earlier applied to physics.[8][37] The process was later described as moving from mechanics to axiomatics.[38]</p><h3>Differential calculus</h3><p> Main articles: Foundations of Economic Analysis and Differential calculus</p><p>Vilfredo Pareto analyzed microeconomics by treating decisions by economic actors as attempts to change a given allotment of goods to another, more preferred allotment. Sets of allocations could then be treated as Pareto efficient (Pareto optimal is an equivalent term) when no exchanges could occur between actors that could make at least one individual better off without making any other individual worse off.[39] Pareto's proof is commonly conflated with Walrassian equilibrium or informally ascribed to Adam Smith's Invisible hand hypothesis.[40] Rather, Pareto's statement was the first formal assertion of what would be known as the first fundamental theorem of welfare economics.[41] These models lacked the inequalities of the next generation of mathematical economics.</p><p>In the landmark treatise Foundations of Economic Analysis (1947), Paul Samuelson identified a common paradigm and mathematical structure across multiple fields in the subject, building on previous work by Alfred Marshall. Foundations took mathematical concepts from physics and applied them to economic problems. This broad view (for example, comparing Le Chatelier's principle to tâtonnement) drives the fundamental premise of mathematical economics: systems of economic actors may be modeled and their behavior described much like any other system. This extension followed on the work of the marginalists in the previous century and extended it significantly. Samuelson approached the problems of applying individual utility maximization over aggregate groups with comparative statics, which compares two different equilibrium states after an exogenous change in a variable. This and other methods in the book provided the foundation for mathematical economics in the 20th century.[7][42]</p><h3>Linear models</h3><p>Restricted models of general equilibrium were formulated by John von Neumann in 1937.[43] Unlike earlier versions, the models of von Neumann had inequality constraints. For his model of an expanding economy, von Neumann proved the existence and uniqueness of an equilibrium using his generalization of Brouwer's fixed point theorem. Von Neumann's model of an expanding economy considered the matrix pencil&nbsp; A - ? B with nonnegative matrices&nbsp;A and B; von Neumann sought probability vectors&nbsp;p and&nbsp;q and a positive number&nbsp;? that would solve the complementarity equation</p><p>along with two inequality systems expressing economic efficiency. In this model, the (transposed) probability vector p represents the prices of the goods while the probability vector q represents the intensity at which the production process would run. The unique solution ? represents the rate of growth of the economy, which equals the interest rate. Proving the existence of a positive growth rate and proving that the growth rate equals the interest rate were remarkable achievements, even for von Neumann.[44][45][46] Von Neumann's results have been viewed as a special case of linear programming, where von Neumann's model uses only nonnegative matrices.[47] The study of von Neumann's model of an expanding economy continues to interest mathematical economists with interests in computational economics.[48][49][50]</p><p> Main article: Input-output model</p><p>In 1936, the Russian–born economist Wassily Leontief built his model of input-output analysis from the 'material balance' tables constructed by Soviet economists, which themselves followed earlier work by the physiocrats. With his model, which described a system of production and demand processes, Leontief described how changes in demand in one economic sector would influence production in another.[51] In practice, Leontief estimated the coefficients of his simple models, to address economically interesting questions. In production economics, Leontief technologies produce outputs using constant proportions of inputs, regardless of the price of inputs, reducing the value of Leontief models for understanding economies but allowing their parameters to be estimated relatively easily. In contrast, the von Neumann model of an expanding economy allows for choice of techniques, but the coefficients must be estimated for each technology.[52][53]</p><h3>Mathematical optimization</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/6/62/MaximumParaboloid.png/220px-MaximumParaboloid.png" width="220" height="165"><p>


				Red dot in z direction as maximum for paraboloid function of (x, y) inputs



				</p><p>
					 Main articles: Mathematical optimization and Dual problem</p><p>In mathematics, mathematical optimization (or optimization or mathematical programming) refers to the selection of a best element from some set of available alternatives.[54] In the simplest case, an optimization problem involves maximizing or minimizing a real function by selecting input values of the function and computing the corresponding values of the function. The solution process includes satisfying general necessary and sufficient conditions for optimality. For optimization problems, specialized notation may be used as to the function and its input(s). More generally, optimization includes finding the best available element of some function given a defined domain and may use a variety of different computational optimization techniques.[55]</p><p>Economics is closely enough linked to optimization by agents in an economy that an influential definition relatedly describes economics qua science as the study of human behavior as a relationship between ends and scarce means with alternative uses.[56] Optimization problems run through modern economics, many with explicit economic or technical constraints. In microeconomics, the utility maximization problem and its dual problem, the expenditure minimization problem for a given level of utility, are economic optimization problems.[57] Theory posits that consumers maximize their utility, subject to their budget constraints and that firms maximize their profits, subject to their production functions, input costs, and market demand.[58]</p><p>Economic equilibrium is studied in optimization theory as a key ingredient of economic theorems that in principle could be tested against empirical data.[7][59] Newer developments have occurred in dynamic programming and modeling optimization with risk and uncertainty, including applications to portfolio theory, the economics of information, and search theory.[58]</p><div class="gradientback"></div></div><div class="content"><p>Optimality properties for an entire market system may be stated in mathematical terms, as in formulation of the two fundamental theorems of welfare economics[60] and in the Arrow–Debreu model of general equilibrium (also discussed below).[61] More concretely, many problems are amenable to analytical (formulaic) solution. Many others may be sufficiently complex to require numerical methods of solution, aided by software.[55] Still others are complex but tractable enough to allow computable methods of solution, in particular computable general equilibrium models for the entire economy.[62]</p><p>Linear and nonlinear programming have profoundly affected microeconomics, which had earlier considered only equality constraints.[63] Many of the mathematical economists who received Nobel Prizes in Economics had conducted notable research using linear programming: Leonid Kantorovich, Leonid Hurwicz, Tjalling Koopmans, Kenneth J. Arrow, and Robert Dorfman, Paul Samuelson, and Robert Solow.[64] Both Kantorovich and Koopmans acknowledged that George B. Dantzig deserved to share their Nobel Prize for linear programming. Economists who conducted research in nonlinear programming also have won the Nobel prize, notably Ragnar Frisch in addition to Kantorovich, Hurwicz, Koopmans, Arrow, and Samuelson.</p><p> Main articles: Linear programming and Simplex algorithm</p><p>Linear programming was developed to aid the allocation of resources in firms and in industries during the 1930s in Russia and during the 1940s in the United States. During the Berlin airlift (1948), linear programming was used to plan the shipment of supplies to prevent Berlin from starving after the Soviet blockade.[65][66]</p><p>Extensions to nonlinear optimization with inequality constraints were achieved in 1951 by Albert W. Tucker and Harold Kuhn, who considered the nonlinear optimization problem:</p><br><img src="http:https://wikimedia.org/api/rest_v1/media/math/render/svg/132e57acb643253e7810ee9702d9581f159a1c61" aria-hidden="true" style="vertical-align: -0.671ex; width:1.289ex; height:2.509ex;" alt="f"><br><img src="http:https://wikimedia.org/api/rest_v1/media/math/render/svg/87f9e315fd7e2ba406057a97300593c4802b53e4" aria-hidden="true" style="vertical-align: -0.338ex; width:1.34ex; height:1.676ex;" alt="x"><br><img src="http:https://wikimedia.org/api/rest_v1/media/math/render/svg/d3556280e66fe2c0d0140df20935a6f057381d77" aria-hidden="true" style="vertical-align: -0.671ex; width:1.126ex; height:2.009ex;" alt="g"><br><img src="http:https://wikimedia.org/api/rest_v1/media/math/render/svg/87f9e315fd7e2ba406057a97300593c4802b53e4" aria-hidden="true" style="vertical-align: -0.338ex; width:1.34ex; height:1.676ex;" alt="x"><br><img src="http:https://wikimedia.org/api/rest_v1/media/math/render/svg/b26be3e694314bc90c3215047e4a2010c6ee184a" aria-hidden="true" style="vertical-align: -0.338ex; width:1.349ex; height:2.176ex;" alt="h"><br><img src="http:https://wikimedia.org/api/rest_v1/media/math/render/svg/87f9e315fd7e2ba406057a97300593c4802b53e4" aria-hidden="true" style="vertical-align: -0.338ex; width:1.34ex; height:1.676ex;" alt="x"><br><img src="http:https://wikimedia.org/api/rest_v1/media/math/render/svg/132e57acb643253e7810ee9702d9581f159a1c61" aria-hidden="true" style="vertical-align: -0.671ex; width:1.289ex; height:2.509ex;" alt="f"><br><img src="http:https://wikimedia.org/api/rest_v1/media/math/render/svg/d3556280e66fe2c0d0140df20935a6f057381d77" aria-hidden="true" style="vertical-align: -0.671ex; width:1.126ex; height:2.009ex;" alt="g"><br><img src="http:https://wikimedia.org/api/rest_v1/media/math/render/svg/2f461e54f5c093e92a55547b9764291390f0b5d0" aria-hidden="true" style="vertical-align: -0.671ex; margin-left: -0.016ex; width:0.985ex; height:2.509ex;" alt="j"><br><img src="http:https://wikimedia.org/api/rest_v1/media/math/render/svg/0a07d98bb302f3856cbabc47b2b9016692e3f7bc" aria-hidden="true" style="vertical-align: -0.338ex; width:2.051ex; height:1.676ex;" alt="m"><br><img src="http:https://wikimedia.org/api/rest_v1/media/math/render/svg/0a07d98bb302f3856cbabc47b2b9016692e3f7bc" aria-hidden="true" style="vertical-align: -0.338ex; width:2.051ex; height:1.676ex;" alt="m"><br><img src="http:https://wikimedia.org/api/rest_v1/media/math/render/svg/b26be3e694314bc90c3215047e4a2010c6ee184a" aria-hidden="true" style="vertical-align: -0.338ex; width:1.349ex; height:2.176ex;" alt="h"><br><img src="http:https://wikimedia.org/api/rest_v1/media/math/render/svg/2f461e54f5c093e92a55547b9764291390f0b5d0" aria-hidden="true" style="vertical-align: -0.671ex; margin-left: -0.016ex; width:0.985ex; height:2.509ex;" alt="j"><br><img src="http:https://wikimedia.org/api/rest_v1/media/math/render/svg/829091f745070b9eb97a80244129025440a1cfac" aria-hidden="true" style="vertical-align: -0.338ex; width:0.704ex; height:2.176ex;" alt="l"><br><img src="http:https://wikimedia.org/api/rest_v1/media/math/render/svg/829091f745070b9eb97a80244129025440a1cfac" aria-hidden="true" style="vertical-align: -0.338ex; width:0.704ex; height:2.176ex;" alt="l"><p>In allowing inequality constraints, the Kuhn–Tucker approach generalized the classic method of Lagrange multipliers, which (until then) had allowed only equality constraints.[67] The Kuhn–Tucker approach inspired further research on Lagrangian duality, including the treatment of inequality constraints.[68][69] The duality theory of nonlinear programming is particularly satisfactory when applied to convex minimization problems, which enjoy the convex-analytic duality theory of Fenchel and Rockafellar; this convex duality is particularly strong for polyhedral convex functions, such as those arising in linear programming. Lagrangian duality and convex analysis are used daily in operations research, in the scheduling of power plants, the planning of production schedules for factories, and the routing of airlines (routes, flights, planes, crews).[69]</p><p>Economic dynamics allows for changes in economic variables over time, including in dynamic systems. The problem of finding optimal functions for such changes is studied in variational calculus and in optimal control theory. Before the Second World War, Frank Ramsey and Harold Hotelling used the calculus of variations to that end.</p><p>Following Richard Bellman's work on dynamic programming and the 1962 English translation of L. Pontryagin et al.'s earlier work,[70] optimal control theory was used more extensively in economics in addressing dynamic problems, especially as to economic growth equilibrium and stability of economic systems,[71] of which a textbook example is optimal consumption and saving.[72] A crucial distinction is between deterministic and stochastic control models.[73] Other applications of optimal control theory include those in finance, inventories, and production for example.[74]</p><p>It was in the course of proving of the existence of an optimal equilibrium in his 1937 model of economic growth that John von Neumann introduced functional analytic methods to include topology in economic theory, in particular, fixed-point theory through his generalization of Brouwer's fixed-point theorem.[8][43][75] Following von Neumann's program, Kenneth Arrow and Gérard Debreu formulated abstract models of economic equilibria using convex sets and fixed–point theory. In introducing the Arrow–Debreu model in 1954, they proved the existence (but not the uniqueness) of an equilibrium and also proved that every Walras equilibrium is Pareto efficient; in general, equilibria need not be unique.[76] In their models, the (primal) vector space represented quantitites while the dual vector space represented prices.[77]</p><div class="gradientback"></div></div><div class="content"><p>In Russia, the mathematician Leonid Kantorovich developed economic models in partially ordered vector spaces, that emphasized the duality between quantities and prices.[78] Kantorovich renamed prices as objectively determined valuations which were abbreviated in Russian as o.&nbsp;o.&nbsp;o., alluding to the difficulty of discussing prices in the Soviet Union.[77][79][80]</p><p>Even in finite dimensions, the concepts of functional analysis have illuminated economic theory, particularly in clarifying the role of prices as normal vectors to a hyperplane supporting a convex set, representing production or consumption possibilities. However, problems of describing optimization over time or under uncertainty require the use of infinite–dimensional function spaces, because agents are choosing among functions or stochastic processes.[77][81][82][83]</p><h3>Differential decline and rise</h3><p>John von Neumann's work on functional analysis and topology in broke new ground in mathematics and economic theory.[43][84] It also left advanced mathematical economics with fewer applications of differential calculus. In particular, general equilibrium theorists used general topology, convex geometry, and optimization theory more than differential calculus, because the approach of differential calculus had failed to establish the existence of an equilibrium.</p><p>However, the decline of differential calculus should not be exaggerated, because differential calculus has always been used in graduate training and in applications. Moreover, differential calculus has returned to the highest levels of mathematical economics, general equilibrium theory (GET), as practiced by the GET-set (the humorous designation due to Jacques H. Drèze). In the 1960s and 1970s, however, Gérard Debreu and Stephen Smale led a revival of the use of differential calculus in mathematical economics. In particular, they were able to prove the existence of a general equilibrium, where earlier writers had failed, because of their novel mathematics: Baire category from general topology and Sard's lemma from differential topology. Other economists associated with the use of differential analysis include Egbert Dierker, Andreu Mas-Colell, and Yves Balasko.[85][86] These advances have changed the traditional narrative of the history of mathematical economics, following von Neumann, which celebrated the abandonment of differential calculus.</p><h3>Game theory</h3><p> Main article: Game Theory</p><p>John von Neumann, working with Oskar Morgenstern on the theory of games, broke new mathematical ground in 1944 by extending functional analytic methods related to convex sets and topological fixed-point theory to economic analysis.[8][84] Their work thereby avoided the traditional differential calculus, for which the maximum–operator did not apply to non-differentiable functions. Continuing von Neumann's work in cooperative game theory, game theorists Lloyd S. Shapley, Martin Shubik, Hervé Moulin, Nimrod Megiddo, Bezalel Peleg influenced economic research in politics and economics. For example, research on the fair prices in cooperative games and fair values for voting games led to changed rules for voting in legislatures and for accounting for the costs in public–works projects. For example, cooperative game theory was used in designing the water distribution system of Southern Sweden and for setting rates for dedicated telephone lines in the USA.</p><p>Earlier neoclassical theory had bounded only the range of bargaining outcomes and in special cases, for example bilateral monopoly or along the contract curve of the Edgeworth box.[87] Von Neumann and Morgenstern's results were similarly weak. Following von Neumann's program, however, John Nash used fixed–point theory to prove conditions under which the bargaining problem and noncooperative games can generate a unique equilibrium solution.[88] Noncooperative game theory has been adopted as a fundamental aspect of experimental economics,[89] behavioral economics,[90] information economics,[91] industrial organization,[92] and political economy.[93] It has also given rise to the subject of mechanism design (sometimes called reverse game theory), which has private and public-policy applications as to ways of improving economic efficiency through incentives for information sharing.[94]</p><p>In 1994, Nash, John Harsanyi, and Reinhard Selten received the Nobel Memorial Prize in Economic Sciences their work on non–cooperative games. Harsanyi and Selten were awarded for their work on repeated games. Later work extended their results to computational methods of modeling.[95]</p><h3>Agent-based computational economics</h3><p> Main article: Agent-based computational economics</p><p>Agent-based computational economics (ACE) as a named field is relatively recent, dating from about the 1990s as to published work. It studies economic processes, including whole economies, as dynamic systems of interacting agents over time. As such, it falls in the paradigm of complex adaptive systems.[96] In corresponding agent-based models, agents are not real people but computational objects modeled as interacting according to rules ... whose micro-level interactions create emergent patterns in space and time.[97] The rules are formulated to predict behavior and social interactions based on incentives and information. The theoretical assumption of mathematical optimization by agents markets is replaced by the less restrictive postulate of agents with bounded rationality adapting to market forces.[98]</p><p>ACE models apply numerical methods of analysis to computer-based simulations of complex dynamic problems for which more conventional methods, such as theorem formulation, may not find ready use.[99] Starting from specified initial conditions, the computational economic system is modeled as evolving over time as its constituent agents repeatedly interact with each other. In these respects, ACE has been characterized as a bottom-up culture-dish approach to the study of the economy.[100] In contrast to other standard modeling methods, ACE events are driven solely by initial conditions, whether or not equilibria exist or are computationally tractable. ACE modeling, however, includes agent adaptation, autonomy, and learning.[101] It has a similarity to, and overlap with, game theory as an agent-based method for modeling social interactions.[95] Other dimensions of the approach include such standard economic subjects as competition and collaboration,[102] market structure and industrial organization,[103] transaction costs,[104] welfare economics[105] and mechanism design,[94] information and uncertainty,[106] and macroeconomics.[107][108]</p><p>The method is said to benefit from continuing improvements in modeling techniques of computer science and increased computer capabilities. Issues include those common to experimental economics in general[109] and by comparison[110] and to development of a common framework for empirical validation and resolving open questions in agent-based modeling.[111] The ultimate scientific objective of the method has been described as test[ing] theoretical findings against real-world data in ways that permit empirically supported theories to cumulate over time, with each researcher's work building appropriately on the work that has gone before.[112]</p><h2>Mathematicization of economics</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/b/b1/Ivsrf.gif/275px-Ivsrf.gif" width="275" height="251"><div class="gradientback"></div></div><div class="content"><p>


				The surface of the Volatility smile is a 3-D surface whereby the current market implied volatility (Z-axis) for all options on the underlier is plotted against strike price and time to maturity (X &amp; Y-axes).[113]


				</p><p>
					Over the course of the 20th century, articles in core journals[114] in economics have been almost exclusively written by economists in academia. As a result, much of the material transmitted in those journals relates to economic theory, and economic theory itself has been continuously more abstract and mathematical.[115] A subjective assessment of mathematical techniques[116] employed in these core journals showed a decrease in articles that use neither geometric representations nor mathematical notation from 95% in 1892 to 5.3% in 1990.[117] A 2007 survey of ten of the top economic journals finds that only&nbsp;5.8% of the articles published in 2003 and 2004 both lacked statistical analysis of data and lacked displayed mathematical expressions that were indexed with numbers at the margin of the page.[118]</p><h2>Econometrics</h2><p> Main article: Econometrics</p><p>Between the world wars, advances in mathematical statistics and a cadre of mathematically trained economists led to econometrics, which was the name proposed for the discipline of advancing economics by using mathematics and statistics. Within economics, econometrics has often been used for statistical methods in economics, rather than mathematical economics. Statistical econometrics features the application of linear regression and time series analysis to economic data.</p><p>Ragnar Frisch coined the word econometrics and helped to found both the Econometric Society in 1930 and the journal Econometrica in 1933.[119][120] A student of Frisch's, Trygve Haavelmo published The Probability Approach in Econometrics in 1944, where he asserted that precise statistical analysis could be used as a tool to validate mathematical theories about economic actors with data from complex sources.[121] This linking of statistical analysis of systems to economic theory was also promulgated by the Cowles Commission (now the Cowles Foundation) throughout the 1930s and 1940s.[122]</p><p>The roots of modern econometrics can be traced to the American economist Henry L. Moore. Moore studied agricultural productivity and attempted to fit changing values of productivity for plots of corn and other crops to a curve using different values of elasticity. Moore made several errors in his work, some from his choice of models and some from limitations in his use of mathematics. The accuracy of Moore's models also was limited by the poor data for national accounts in the United States at the time. While his first models of production were static, in 1925 he published a dynamic moving equilibrium model designed to explain business cycles—this periodic variation from overcorrection in supply and demand curves is now known as the cobweb model. A more formal derivation of this model was made later by Nicholas Kaldor, who is largely credited for its exposition.[123]</p><h2>Application</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/b/b9/Islm.svg/300px-Islm.svg.png" width="300" height="300"><p>


				The IS/LM model is a Keynesian macroeconomic model designed to make predictions about the intersection of "real" economic activity (e.g. spending, income, savings rates) and decisions made in the financial markets (Money supply and Liquidity preference). The model is no longer widely taught at the graduate level but is common in undergraduate macroeconomics courses.[124]


				</p><p>
					Much of classical economics can be presented in simple geometric terms or elementary mathematical notation. Mathematical economics, however, conventionally makes use of calculus and matrix algebra in economic analysis in order to make powerful claims that would be more difficult without such mathematical tools. These tools are prerequisites for formal study, not only in mathematical economics but in contemporary economic theory in general. Economic problems often involve so many variables that mathematics is the only practical way of attacking and solving them. Alfred Marshall argued that every economic problem which can be quantified, analytically expressed and solved, should be treated by means of mathematical work.[125]</p><p>Economics has become increasingly dependent upon mathematical methods and the mathematical tools it employs have become more sophisticated. As a result, mathematics has become considerably more important to professionals in economics and finance. Graduate programs in both economics and finance require strong undergraduate preparation in mathematics for admission and, for this reason, attract an increasingly high number of mathematicians. Applied mathematicians apply mathematical principles to practical problems, such as economic analysis and other economics-related issues, and many economic problems are often defined as integrated into the scope of applied mathematics.[17]</p><p>This integration results from the formulation of economic problems as stylized models with clear assumptions and falsifiable predictions. This modeling may be informal or prosaic, as it was in Adam Smith's The Wealth of Nations, or it may be formal, rigorous and mathematical.</p><p>Broadly speaking, formal economic models may be classified as stochastic or deterministic and as discrete or continuous. At a practical level, quantitative modeling is applied to many areas of economics and several methodologies have evolved more or less independently of each other.[126]</p><h2>Classification</h2><p>According to the Mathematics Subject Classification (MSC), mathematical economics falls into the Applied mathematics/other classification of category 91:</p><p>with MSC2010 classifications for 'Game theory' at codes 91Axx and for 'Mathematical economics' at codes 91Bxx.</p><p>The Handbook of Mathematical Economics series (Elsevier), currently 4 volumes, distinguishes between mathematical methods in economics, v. 1, Part I, and areas of economics in other volumes where mathematics is employed.[127]</p><p>Another source with a similar distinction is The New Palgrave: A Dictionary of Economics (1987, 4 vols., 1,300 subject entries). In it, a Subject Index includes mathematical entries under 2 headings (vol. IV, pp.&nbsp;982–3):</p><p>A widely used system in economics that includes mathematical methods on the subject is the JEL classification codes. It originated in the Journal of Economic Literature for classifying new books and articles. The relevant categories are listed below (simplified below to omit Miscellaneous and Other JEL codes), as reproduced from JEL classification codes#Mathematical and quantitative methods JEL: C Subcategories. The New Palgrave Dictionary of Economics (2008, 2nd ed.) also uses the JEL codes to classify its entries. The corresponding footnotes below have links to abstracts of The New Palgrave Online for each JEL category (10 or fewer per page, similar to Google searches).</p><div class="gradientback"></div></div><div class="content"><h2>Criticisms and defences</h2><h3>Adequacy of mathematics for qualitative and complicated economics</h3><p>Friedrich Hayek contended that the use of formal techniques projects a scientific exactness that does not appropriately account for informational limitations faced by real economic agents. [139]</p><p>In an interview, the economic historian Robert Heilbroner stated:[140]</p><p>I guess the scientific approach began to penetrate and soon dominate the profession in the past twenty to thirty years. This came about in part because of the invention of mathematical analysis of various kinds and, indeed, considerable improvements in it. This is the age in which we have not only more data but more sophisticated use of data. So there is a strong feeling that this is a data-laden science and a data-laden undertaking, which, by virtue of the sheer numerics, the sheer equations, and the sheer look of a journal page, bears a certain resemblance to science . . . That one central activity looks scientific. I understand that. I think that is genuine. It approaches being a universal law. But resembling a science is different from being a science.</p><p>Heilbroner stated that some/much of economics is not naturally quantitative and therefore does not lend itself to mathematical exposition.[141]</p><h3>Testing predictions of mathematical economics</h3><p>Philosopher Karl Popper discussed the scientific standing of economics in the 1940s and 1950s. He argued that mathematical economics suffered from being tautological. In other words, insofar that economics became a mathematical theory, mathematical economics ceased to rely on empirical refutation but rather relied on mathematical proofs and disproof.[142] According to Popper, falsifiable assumptions can be tested by experiment and observation while unfalsifiable assumptions can be explored mathematically for their consequences and for their consistency with other assumptions.[143]</p><p>Sharing Popper's concerns about assumptions in economics generally, and not just mathematical economics, Milton Friedman declared that all assumptions are unrealistic. Friedman proposed judging economic models by their predictive performance rather than by the match between their assumptions and reality.[144]</p><h3>Mathematical economics as a form of pure mathematics</h3><p>Considering mathematical economics, J.M. Keynes wrote in The General Theory:[145]</p><p>It is a great fault of symbolic pseudo-mathematical methods of formalising a system of economic analysis ... that they expressly assume strict independence between the factors involved and lose their cogency and authority if this hypothesis is disallowed; whereas, in ordinary discourse, where we are not blindly manipulating and know all the time what we are doing and what the words mean, we can keep ‘at the back of our heads’ the necessary reserves and qualifications and the adjustments which we shall have to make later on, in a way in which we cannot keep complicated partial differentials ‘at the back’ of several pages of algebra which assume they all vanish. Too large a proportion of recent ‘mathematical’ economics are merely concoctions, as imprecise as the initial assumptions they rest on, which allow the author to lose sight of the complexities and interdependencies of the real world in a maze of pretentious and unhelpful symbols.</p><h3>Defense of mathematical economics</h3><p>In response to these criticisms, Paul Samuelson argued that mathematics is a language, repeating a thesis of Josiah Willard Gibbs. In economics, the language of mathematics is sometimes necessary for representing substantive problems. Moreover, mathematical economics has led to conceptual advances in economics.[146] In particular, Samuelson gave the example of microeconomics, writing that few people are ingenious enough to grasp [its] more complex parts... without resorting to the language of mathematics, while most ordinary individuals can do so fairly easily with the aid of mathematics.[147]</p><p>Some economists state that mathematical economics deserves support just like other forms of mathematics, particularly its neighbors in mathematical optimization and mathematical statistics and increasingly in theoretical computer science. Mathematical economics and other mathematical sciences have a history in which theoretical advances have regularly contributed to the reform of the more applied branches of economics. In particular, following the program of John von Neumann, game theory now provides the foundations for describing much of applied economics, from statistical decision theory (as games against nature) and econometrics to general equilibrium theory and industrial organization. In the last decade, with the rise of the internet, mathematical economicists and optimization experts and computer scientists have worked on problems of pricing for on-line services --- their contributions using mathematics from cooperative game theory, nondifferentiable optimization, and combinatorial games.</p><p>Robert M. Solow concluded that mathematical economics was the core infrastructure of contemporary economics:</p><p>Economics is no longer a fit conversation piece for ladies and gentlemen. It has become a technical subject. Like any technical subject it attracts some people who are more interested in the technique than the subject. That is too bad, but it may be inevitable. In any case, do not kid yourself: the technical core of economics is indispensable infrastructure for the political economy. That is why, if you consult [a reference in contemporary economics] looking for enlightenment about the world today, you will be led to technical economics, or history, or nothing at all.[148]</p><h2>Mathematical economists</h2><p>Prominent mathematical economists include, but are not limited to, the following (by century of birth).</p><h3>19th century</h3><h3>20th century</h3><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Mathematical_economics&amp;oldid=783711517"					
								Categories:  Hidden categories:</p><br><div class="gradientback"></div></div><div class="content"><h1 lang="en">History of economic thought</h1><p> From Wikipedia, the free encyclopedia</p><p>The history of economic thought deals with different thinkers and theories in the subject that became political economy and economics, from the ancient world to the present day. It encompasses many disparate schools of economic thought. Ancient Greek writers such as the philosopher Aristotle examined ideas about the art of wealth acquisition, and questioned whether property is best left in private or public hands. In the Middle Ages, scholasticists such as Thomas Aquinas argued that it was a moral obligation of businesses to sell goods at a just price.</p><p>In the Western world, economics was not a separate discipline, but part of philosophy until the 18th–19th century Industrial Revolution and the 19th century Great Divergence, which accelerated economic growth.[1] Long before that, from the Renaissance at least, economics as an intellectual discipline or science was dominated by Western thinkers and their academic institutions, schooling economists from outside the West, although there are isolated instances in other societies.</p><h2>Contents</h2><h2>Ancient economic thought (before 500 AD)</h2><p> Main articles: Ancient economic thought, Arthashastra, Republic (dialogue), Credit theory of money, Politics (Aristotle), Nicomachean Ethics, Metallism, and Oeconomicus</p><h3>China</h3><p>Fan Li (also known as Tao Zhu Gong) (born 517 BC),[2] an adviser to King Goujian of Yue, wrote on economic issues and developed a set of golden business rules.[3]</p><h3>India</h3><p>Chanakya (born 350 BC) wrote the Arthashastra, a treatise on statecraft, economic policy and military strategy.[citation needed]</p><h3>Greco-Roman World</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/9/98/Sanzio_01_Plato_Aristotle.jpg/100px-Sanzio_01_Plato_Aristotle.jpg" width="100" height="131"><p>


				Plato and his pupil Aristotle had an enduring effect on Western philosophy.


				</p><p>
					Ancient Athens, a slave-based society, developed an embryonic model of democracy.[4]</p><p>Xenophon's (c. 430–354 BC) Oeconomicus (c. 360 BC) is a dialogue principally about household management and agriculture.</p><p>Plato's dialogue The Republic (c. 380–360 BC) describing an ideal city-state run by philosopher-kings contained references to specialization of labor and to production. Plato was the first to advocate the credit theory of money, that is, money as a unit of account for debt.[citation needed]</p><p>Aristotle's Politics (c. 350 BC) analyzed different forms of the state (monarchy, aristocracy, constitutional government, tyranny, oligarchy, and democracy) as a critique of Plato's model of a philosopher-kings. Of particular interest for economists, Plato provided a blueprint of a society based on common ownership of resources. Aristotle viewed this model as an oligarchical anathema. Though Aristotle did certainly advocate holding many things in common, he argued that not everything could be, simply because of the wickedness of human nature.[5]</p><p>It is clearly better that property should be private, wrote Aristotle, but the use of it common; and the special business of the legislator is to create in men this benevolent disposition. In Politics Book I, Aristotle discusses the general nature of households and market exchanges. For him there is a certain art of acquisition or wealth-getting, but because it[clarification needed] is the same many people are obsessed with its accumulation, and wealth-getting for one's household is necessary and honorable, while exchange on the retail trade for simple accumulation is justly censured, for it is dishonorable.[6] Writing of the people, Aristotle stated that they as a whole thought acquisition of wealth (chrematistike) as being either the same as, or a principle of oikonomia (household management – oikonomos),[7][8] with oikos meaning house and with nomos meaning custom or as law.[9] Aristotle himself highly disapproved of usury and cast scorn on making money through a monopoly.[10]</p><p>Aristotle discarded Plato's credit theory of money for metallism, the theory that money derives its value from the purchasing power of the commodity upon which it is based, and is only an instrument, its sole purpose being a medium of exchange, which means on its own it is worthless... not useful as a means to any of the necessities of life.[11]</p><h2>Economic thought in the Middle Ages (500–1500 AD)</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/c/cd/Gentile_da_Fabriano_052.jpg/100px-Gentile_da_Fabriano_052.jpg" width="100" height="137"><p>


				Thomas Aquinas (1225–1274) taught that high prices in response to high demand is theft.



				</p><p>
					 Main articles: Thomas Aquinas, Scholasticism, Duns Scotus, Ibn Khaldun, Muqaddimah, and Islamic economic jurisprudence</p><h3>Thomas Aquinas</h3><p>Thomas Aquinas (1225–1274) was an Italian theologian and economic writer. He taught in both Cologne and Paris, and was part of a group of Catholic scholars known as the Schoolmen, who moved their enquiries beyond theology to philosophical and scientific debates. In the treatise Summa Theologica Aquinas dealt with the concept of a just price, which he considered necessary for the reproduction of the social order. Similar in many ways to the modern concept of long run equilibrium, a just price was just sufficient to cover the costs of production, including the maintenance of a worker and his family. Aquinas argued it was immoral for sellers to raise their prices simply because buyers had a pressing need for a product.</p><p>Aquinas discusses a number of topics in the format of questions and replies, substantial tracts dealing with Aristotle's theory. Questions 77 and 78 concern economic issues, primarily what a just price might be, and the fairness of a seller dispensing faulty goods. Aquinas argued against any form of cheating and recommended always paying compensation in lieu of good service[clarification needed]. Whilst human laws might not impose sanctions for unfair dealing, divine law did, in his opinion.</p><div class="gradientback"></div></div><div class="content"><h3>Duns Scotus</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/7/73/John_Duns_Scotus_-_geograph.org.uk_-_1178460.jpg/100px-John_Duns_Scotus_-_geograph.org.uk_-_1178460.jpg" width="100" height="133"><p>


				Duns Scotus (1265–1308)


				</p><p>
					One of Aquinas' main critics[12] was Duns Scotus (1265–1308), originally from Duns Scotland, who taught in Oxford, Cologne, and Paris. In his work Sententiae (1295), he thought it possible to be more precise than Aquinas in calculating a just price, emphasizing the costs of labor and expenses, although he recognized that the latter might be inflated by exaggeration because buyer and seller usually have different ideas of a just price. If people did not benefit from a transaction, in Scotus' view, they would not trade. Scotus said merchants perform a necessary and useful social role by transporting goods and making them available to the public.[12]</p><h3>Jean Buridan</h3><p>Jean Buridan (French:&nbsp;[by?id?~]; Latin Johannes Buridanus; c. 1300 – after 1358) was a French priest. Buridanus looked at money from two angles: its metal value and its purchasing power, which he acknowledged can vary. He argued that aggregated, not individual, demand and supply determine market prices. Hence, for him a just price was what the society collectively and not just one individual is willing to pay.</p><h3>Ibn Khaldun</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/b/b2/Ibn_Khaldoun-Kassus.jpg/100px-Ibn_Khaldoun-Kassus.jpg" width="100" height="164"><p>


				Ibn Khaldun (1332–1406)


				 
				</p><p>
					Until Joseph J. Spengler's 1964 work Economic Thought of Islam: Ibn Khaldun,[14] Adam Smith (1723–1790) was considered the Father of Economics. Now there is a second candidate, Arab Muslim scholar Ibn Khaldun (1332–1406) of Tunisia, although what influence Khaldun had in the West is unclear. Arnold Toynbee called Ibn Khaldun a genius who appears to have been inspired by no predecessors and to have found no kindred souls among his contemporaries...and yet, in the Prolegomena (Muqaddimat) to his Universal History he has conceived and formulated a philosophy of history which is undoubtedly the greatest work of its kind that has ever yet been created by any mind in any time or place.[15] Ibn Khaldoun expressed a theory of the lifecycle of civilizations, the specialization of labor, and the value of money as a means of exchange rather than as a store of inherent value. His ideas on taxes bore a striking resemblance to supply-side economics' Laffer curve, which posits that beyond a certain point higher taxes discourage production and actually cause revenues to fall.[16]</p><h3>Nicole Oresme</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/3/35/Oresme.jpg/100px-Oresme.jpg" width="100" height="97"><p>


				Nicolas d'Oresme (1320–82)


				</p><p>
					French philosopher and priest Nicolas d'Oresme (1320–1382) wrote De origine, natura, jure et mutationibus monetarum, about the origin, nature, law, and alterations of money. It is one of the earliest manuscripts on the concept of money.</p><h3>Antonin of Florence</h3><p>Saint Antoninus of Florence (1389–1459), O.P., was an Italian Dominican friar, who became Archbishop of Florence. Antoninus' writings address social and economic development, and argued that the state has a duty to intervene in mercantile affairs for the common good, and an obligation to help the poor and needy. In his primary work, summa theologica he was mainly concerned about price, justice and capital theory. Like Duns Scotus, he distinguishes between the natural value of a good and its practical value. The latter is determined by its suitability to satisfy needs (virtuositas), its rarity (raritas) and its subjective value (complacibilitas). Due to this subjective component there can not only be one just price, but a bandwidth of more or less just prices.</p><h2>Mercantilism and international trade (16th to 18th century)</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/8/81/Mirabeau_p%C3%A8re.jpg/100px-Mirabeau_p%C3%A8re.jpg" width="100" height="128"><p>


				Marquis de Mirabeau (1715–1789)



				</p><p>
					 Main article: Mercantilism</p><p>Mercantilism dominated Europe from the 16th to the 18th century.[17] Despite the localism of the Middle Ages, the waning of feudalism saw new national economic frameworks begin to strengthen. After the 15th century voyages of Christopher Columbus and other explorers opened up new opportunities for trade with the New World and Asia, newly-powerful monarchies wanted a more powerful military state to boost their status. Mercantilism was a political movement and an economic theory that advocated the use of the state's military power to ensure that local markets and supply sources were protected, spawning protectionism.</p><div class="gradientback"></div></div><div class="content"><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/2/29/Lorrain.seaport.jpg/200px-Lorrain.seaport.jpg" width="200" height="150"><p>


				French seaport during the heyday of mercantilism


				</p><p>
					Mercantile theorists held that international trade could not benefit all countries at the same time. Money and precious metals were the only source of riches in their view, and limited resources must be allocated between countries, therefore tariffs should be used to encourage exports, which bring money into the country, and discourage imports which send it abroad. In other words, a positive balance of trade ought to be maintained through a surplus of exports, often backed by military might. Despite the prevalence of the model, the term mercantilism was not coined until 1763, by Victor de Riqueti, marquis de Mirabeau (1715–1789), and popularized by Adam Smith in 1776, who vigorously opposed it.</p><h3>School of Salamanca</h3><p> Main article: School of Salamanca</p><p>In the 16th century the Jesuit School of Salamanca in Spain developed economic theory to a high level, only to have their contributions[clarification needed] forgotten until the 20th century.</p><h3>Sir Thomas More</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/d/d2/Hans_Holbein%2C_the_Younger_-_Sir_Thomas_More_-_Google_Art_Project.jpg/100px-Hans_Holbein%2C_the_Younger_-_Sir_Thomas_More_-_Google_Art_Project.jpg" width="100" height="124"><p>


				Sir Thomas More (1478–1535)



				</p><p>
					 Main article: Sir Thomas More</p><p>In 1516 English humanist Sir Thomas More (1478–1535) published Utopia, which describes an ideal society where land is owned in common and there is universal education and religious tolerance, inspiring the English Poor Laws (1587) and the communism-socialism movement[citation needed].</p><h3>Nicolaus Copernicus</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/7/77/Nicolaus_Copernicus.jpg/100px-Nicolaus_Copernicus.jpg" width="100" height="131"><p>


				Nicolaus Copernicus (1473–1543)



				</p><p>
					 Main articles: Nicolaus Copernicus and Quantity theory of money</p><p>In 1517 Polish astronomer Nicolaus Copernicus (1473–1543) published the first known argument for the quantity theory of money. In 1519 he also published the first known form of Gresham's Law: Bad money drives out good.</p><h3>Jean Bodin</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/e/e5/Jean_Bodin.jpg/100px-Jean_Bodin.jpg" width="100" height="126"><p>


				Jean Bodin (1530–1596)



				</p><p>
					 Main article: Jean Bodin</p><p>In 1568 Jean Bodin (1530–1596) of France published Reply to Malestroit, containing the first known analysis of inflation, which he claimed was caused by importation of gold and silver from South America, backing the quantity theory of money.</p><h3>Barthélemy de Laffemas</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/c/ca/Barth%C3%A9lemy_de_Laffemas.jpg/100px-Barth%C3%A9lemy_de_Laffemas.jpg" width="100" height="114"><p>


				Barthélemy de Laffemas (1545–1612)


				</p><p>
					In 1598 French mercantilist economist Barthélemy de Laffemas (1545–1612) published Les Trésors et richesses pour mettre l'Estat en splendeur, which blasted those who frowned on French silks because the industry created employment for the poor, the first known mention of underconsumption theory, which was later refined by John Maynard Keynes.</p><h3>Leonardus Lessius</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/1/1b/Leonardus_Lessius_%281554-1623%29.jpg/100px-Leonardus_Lessius_%281554-1623%29.jpg" width="100" height="156">
				<div class="gradientback"></div></div><div class="content">
				<p>The political philosophy of the classical republics have in any case had an influence on republican thought throughout the subsequent centuries. Philosophers and politicians advocating for republics, such as Machiavelli, Montesquieu, Adams, and Madison, relied heavily on classical Greek and Roman sources which described various types of regimes.</p><p>Aristotle's Politics discusses various forms of government. One form Aristotle named politeia, which consisted of a mixture of the other forms. He argued that this was one of the ideal forms of government. Polybius expanded on many of these ideas, again focusing on the idea of mixed government. The most important Roman work in this tradition is Cicero's De re publica.</p><p>Over time, the classical republics were either conquered by empires or became ones themselves. Most of the Greek republics were annexed to the Macedonian Empire of Alexander. The Roman Republic expanded dramatically conquering the other states of the Mediterranean that could be considered republics, such as Carthage. The Roman Republic itself then became the Roman Empire.</p><h3>Other ancient republics</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/f/fe/Ashoka_pillar_at_Vaishali%2C_Bihar%2C_India.jpg/220px-Ashoka_pillar_at_Vaishali%2C_Bihar%2C_India.jpg" width="220" height="165"><p>


				Vaishali was the capital of the Vajjian Confederacy, an early republic from ancient India.


				</p><p>
					The term republic is not commonly used to refer to pre-classical city states, especially if outside Europe and the area which was under Graeco-Roman influence.[12] However some early states outside Europe had governments that are sometimes today considered similar to republics.</p><p>In the ancient Near East, a number of cities of the Eastern Mediterranean achieved collective rule. Arwad has been cited as one of the earliest known examples of a republic, in which the people, rather than a monarch, are described as sovereign.[20] The Israelite confederation of the era before the United Monarchy has also been considered a type of republic.[12][21] In Africa the Axum Empire was organized as a confederation ruled similarly to a royal republic.[22] Similarly the Igbo nation of what is now Nigeria.[23]</p><h3>Indian subcontinent</h3><p>The ancient Indian subcontinent had a number of early republics known as Mahajanapadas.[24] Mahajanapadas consisted of sixteen oligarchic republics that existed during the sixth centuries BCE to fourth centuries BCE.[25][26] Some Indian scholars, such as K.P. Jayaswal, have argued that a number of states in ancient India had republican forms of government.[27][28][29] While there are no surviving constitutions or works of political philosophy from this period in Indian history, but surviving religious texts do refer to a number of states having sabhas or ga?a sangha, a type of republic or council-based, as opposed to monarchical, government. Ancient Greek writers mention Alexander the Great encountering city states and regions where a council of elders ruled with paramount authority.[30]</p><h3>Icelandic Commonwealth</h3><p>The Icelandic Commonwealth was established in 930 AD by refugees from Norway who had fled the unification of that country under King Harald Fairhair. The Commonwealth consisted of a number of clans run by chieftains, and the Althing was a combination of parliament and supreme court where disputes appealed from lower courts were settled, laws were decided, and decisions of national importance were taken. One such example was the Christianisation of Iceland in 1000, where the Althing decreed, in order to prevent an invasion, that all Icelanders must be baptized, and forbade celebration of pagan rituals. Contrary to most states, the Icelandic Commonwealth had no official leader.</p><p>In the early 13th century, the Age of the Sturlungs, the Commonwealth began to suffer from long conflicts between warring clans. This, combined with pressure from the Norwegian king Haakon IV for the Icelanders to re-join the Norwegian family, led the Icelandic chieftains to accept Haakon IV as king by the signing of the Gamli sáttmáli (Old Covenant) in 1262. This effectively brought the Commonwealth to an end. The Althing, however, is still Iceland's parliament, almost 800 years later.[31]</p><h3>Mercantile republics</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/6/64/Giovanni_Battista_Tiepolo_080.jpg/220px-Giovanni_Battista_Tiepolo_080.jpg" width="220" height="98"><p>


				Giovanni Battista Tiepolo, Neptune offers the wealth of the sea to Venice, 1748–50. This painting is an allegory of the power of the Republic of Venice.


				</p><p>
					In Europe new republics appeared in the late Middle Ages when a number of small states embraced republican systems of government. These were generally small, but wealthy, trading states, like the Italian city-states and the Hanseatic League, in which the merchant class had risen to prominence. Knud Haakonssen has noted that, by the Renaissance, Europe was divided with those states controlled by a landed elite being monarchies and those controlled by a commercial elite being republics.[14]</p><p>Across Europe a wealthy merchant class developed in the important trading cities. Despite their wealth they had little power in the feudal system dominated by the rural land owners, and across Europe began to advocate for their own privileges and powers. The more centralized states, such as France and England, granted limited city charters.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/e/e9/Commencement_r%C3%A9publique_messine_Auguste_Migette_1862.jpg/220px-Commencement_r%C3%A9publique_messine_Auguste_Migette_1862.jpg" width="220" height="125"><p>


				Beginning of the Republic of Metz. Election of the first Head-Alderman in 1289, by Auguste Migette. Metz was then a free imperial city of the Holy Roman Emperor.


				</p><p>
					In the more loosely governed Holy Roman Empire, 51 of the largest towns became free imperial cities. While still under the dominion of the Holy Roman Emperor most power was held locally and many adopted republican forms of government.[32] The same rights to imperial immediacy were secured by the major trading cities of Switzerland. The towns and villages of alpine Switzerland had, courtesy of geography, also been largely excluded from central control. Unlike Italy and Germany, much of the rural area was thus not controlled by feudal barons, but by independent farmers who also used communal forms of government. When the Habsburgs tried to reassert control over the region both rural farmers and town merchants joined the rebellion. The Swiss were victorious, and the Swiss Confederacy was proclaimed, and Switzerland has retained a republican form of government to the present.[21]</p><div class="gradientback"></div></div><div class="content"><p>Italy was the most densely populated area of Europe, and also one with the weakest central government. Many of the towns thus gained considerable independence and adopted commune forms of government. Completely free of feudal control, the Italian city-states expanded, gaining control of the rural hinterland.[32] The two most powerful were the Republic of Venice and its rival the Republic of Genoa. Each were large trading ports, and further expanded by using naval power to control large parts of the Mediterranean. It was in Italy that an ideology advocating for republics first developed. Writers such as Bartholomew of Lucca, Brunetto Latini, Marsilius of Padua, and Leonardo Bruni saw the medieval city-states as heirs to the legacy of Greece and Rome.</p><p>Two Russian cities with powerful merchant class—Novgorod and Pskov—also adopted republican forms of government in 12th and 13th centuries, respectively, which ended when the republics were conquered by Muscovy/Russia at the end 15th – beginning of 16th century.[33]</p><p>The dominant form of government for these early republics was control by a limited council of elite patricians. In those areas that held elections, property qualifications or guild membership limited both who could vote and who could run. In many states no direct elections were held and council members were hereditary or appointed by the existing council. This left the great majority of the population without political power, and riots and revolts by the lower classes were common. The late Middle Ages saw more than 200 such risings in the towns of the Holy Roman Empire.[34] Similar revolts occurred in Italy, notably the Ciompi Revolt in Florence.</p><p>Following the collapse of the Seljuk Sultanate of Rum and establishment of the Turkish Anatolian Beyliks, the Ahiler merchant fraternities established a state centered on Ankara that is sometimes compared to the Italian mercantile republics.</p><h3>Calvinist republics</h3><p>While the classical writers had been the primary ideological source for the republics of Italy, in Northern Europe, the Protestant Reformation would be used as justification for establishing new republics.[35] Most important was Calvinist theology, which developed in the Swiss Confederacy, one of the largest and most powerful of the medieval republics. John Calvin did not call for the abolition of monarchy, but he advanced the doctrine that the faithful had the duty to overthrow irreligious monarchs.[36] Advocacy for republics appeared in the writings of the Huguenots during the French Wars of Religion.[37]</p><p>Calvinism played an important role in the republican revolts in England and the Netherlands. Like the city-states of Italy and the Hanseatic League, both were important trading centres, with a large merchant class prospering from the trade with the New World. Large parts of the population of both areas also embraced Calvinism. During the Dutch Revolt (beginning in 1566), the Dutch Republic emerged from rejection of Spanish Habsburg rule. However, the country did not adopt the republican form of government immediately: in the formal declaration of independence (Act of Abjuration, 1581), the throne of king Philip was only declared vacant, and the Dutch magistrates asked the Duke of Anjou, queen Elizabeth of England and prince William of Orange, one after another, to replace Philip. It took until 1588 before the Estates (the Staten, the representative assembly at the time) decided to vest the sovereignty of the country in themselves.</p><p>In 1641 the English Civil War began. Spearheaded by the Puritans and funded by the merchants of London, the revolt was a success, and King Charles I was executed. In England James Harrington, Algernon Sidney, and John Milton became some of the first writers to argue for rejecting monarchy and embracing a republican form of government. The English Commonwealth was short lived, and the monarchy soon restored. The Dutch Republic continued in name until 1795, but by the mid-18th century the stadtholder had become a de facto monarch. Calvinists were also some of the earliest settlers of the British and Dutch colonies of North America.</p><h3>Liberal republics</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/9/99/Place_de_la_R%C3%A9publique_-_Marianne.jpg/200px-Place_de_la_R%C3%A9publique_-_Marianne.jpg" width="200" height="133"><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/6/68/Emblem_of_Septinsular_republic.svg/200px-Emblem_of_Septinsular_republic.svg.png" width="200" height="150"><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/1/19/Upprop_f%C3%B6r_republik_1848.jpg/200px-Upprop_f%C3%B6r_republik_1848.jpg" width="200" height="128"><p>Along with these initial republican revolts, early modern Europe also saw a great increase in monarchial power. The era of absolute monarchy replaced the limited and decentralized monarchies that had existed in most of the Middle Ages. It also saw a reaction against the total control of the monarch as a series of writers created the ideology known as liberalism.</p><p>Most of these Enlightenment thinkers were far more interested in ideas of constitutional monarchy than in republics. The Cromwell regime had discredited republicanism, and most thinkers felt that republics ended in either anarchy or tyranny.[38] Thus philosophers like Voltaire opposed absolutism while at the same time being strongly pro-monarchy.</p><p>Jean-Jacques Rousseau and Montesquieu praised republics, and looked on the city-states of Greece as a model. However, both also felt that a nation-state like France, with 20 million people, would be impossible to govern as a republic. Rousseau admired the republican experiment in Corsica (1755–1769) and described his ideal political structure of small self-governing communes. Montesquieu felt that a city-state should ideally be a republic, but maintained that a limited monarchy was better suited to a large nation.</p><p>The American Revolution began as a rejection only of the authority of the British Parliament over the colonies, not of the monarchy. The failure of the British monarch to protect the colonies from what they considered the infringement of their rights to representative government, the monarch's branding of those requesting redress as traitors, and his support for sending combat troops to demonstrate authority resulted in widespread perception of the British monarchy as tyrannical. With the United States Declaration of Independence the leaders of the revolt firmly rejected the monarchy and embraced republicanism. The leaders of the revolution were well versed in the writings of the French liberal thinkers, and also in history of the classical republics. John Adams had notably written a book on republics throughout history. In addition, the widely distributed and popularly read-aloud tract Common Sense, by Thomas Paine, succinctly and eloquently laid out the case for republican ideals and independence to the larger public. The Constitution of the United States, ratified in 1789, created a relatively strong federal republic to replace the relatively weak confederation under the first attempt at a national government with the Articles of Confederation and Perpetual Union ratified in 1783. The first ten amendments to the Constitution, called the United States Bill of Rights, guaranteed certain natural rights fundamental to republican ideals that justified the Revolution.</p><div class="gradientback"></div></div><div class="content"><p>The French Revolution was also not republican at its outset. Only after the Flight to Varennes removed most of the remaining sympathy for the king was a republic declared and Louis XVI sent to the guillotine. The stunning success of France in the French Revolutionary Wars saw republics spread by force of arms across much of Europe as a series of client republics were set up across the continent. The rise of Napoleon saw the end of the French First Republic and her Sister Republics, each replaced by 'popular monarchies'. Throughout the Napoleonic period, the victors extinguished many of the oldest republics on the continent, including the Republic of Venice, the Republic of Genoa, and the Dutch Republic. They were eventually transformed into monarchies or absorbed into neighbouring monarchies.</p><p>Outside Europe another group of republics was created as the Napoleonic Wars allowed the states of Latin America to gain their independence. Liberal ideology had only a limited impact on these new republics. The main impetus was the local European descended Creole population in conflict with the Peninsulares—governors sent from overseas. The majority of the population in most of Latin America was of either African or Amerindian descent, and the Creole elite had little interest in giving these groups power and broad-based popular sovereignty. Simón Bolívar, both the main instigator of the revolts and one of its most important theorists, was sympathetic to liberal ideals but felt that Latin America lacked the social cohesion for such a system to function and advocated autocracy as necessary.</p><p>In Mexico this autocracy briefly took the form of a monarchy in the First Mexican Empire. Due to the Peninsular War, the Portuguese court was relocated to Brazil in 1808. Brazil gained independence as a monarchy on September 7, 1822, and the Empire of Brazil lasted until 1889. In the other states various forms of autocratic republic existed until most were liberalized at the end of the 20th century.[39]</p><p>The French Second Republic was created in 1848, but abolished by Napoleon III who proclaimed himself Emperor in 1852. The French Third Republic was established in 1870, when a civil revolutionary committee refused to accept Napoleon III's surrender during the Franco-Prussian War. Spain briefly became the First Spanish Republic in 1873–74, but the monarchy was soon restored. By the start of the 20th century France, Switzerland and San Marino remained the only republics in Europe. This changed when, after the 1908 Lisbon Regicide, the 5 October 1910 revolution established the Portuguese Republic.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/4/4c/Chinese_republic_forever.jpg/200px-Chinese_republic_forever.jpg" width="200" height="129"><p>


				A 1920s poster that commemorates the permanent President of the Republic of China Yuan Shikai and the provisional President of the Republic Sun Yat-sen


				</p><p>
					In East Asia, China had seen considerable anti-Qing sentiment during the 19th century, and a number of protest movements developed calling for constitutional monarchy. The most important leader of these efforts was Sun Yat-sen, whose Three Principles of the People combined American, European, and Chinese ideas. Under his leadership the Republic of China was proclaimed on January 1, 1912.</p><p>Republicanism expanded significantly in the aftermath of World War I, when several of the largest European empires collapsed: the Russian Empire (1917), German Empire (1918), Austro-Hungarian Empire (1918), and Ottoman Empire (1922) were all replaced by republics. New states gained independence during this turmoil, and many of these, such as Ireland, Poland, Finland and Czechoslovakia, chose republican forms of government. Following Greece's defeat in the Greco-Turkish War (1919–22), the monarchy was briefly replaced by the Second Hellenic Republic (1924–35). In 1931, the proclamation of the Second Spanish Republic (1931–39) resulted in the Spanish Civil War that would be the prelude of World War II.</p><p>Republican ideas were spreading, especially in Asia. The United States began to have considerable influence in East Asia in the later part of the 19th century, with Protestant missionaries playing a central role. The liberal and republican writers of the west also exerted influence. These combined with native Confucian inspired political philosophy that had long argued that the populace had the right to reject unjust government that had lost the Mandate of Heaven.</p><p>Two short-lived republics were proclaimed in East Asia, the Republic of Formosa and the First Philippine Republic.</p><h3>Decolonization</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/1/1a/Commonwealth_republics.svg/200px-Commonwealth_republics.svg.png" width="200" height="103"><p>


				A map of the Commonwealth republics


				</p><p>
					In the years following World War II, most of the remaining European colonies gained their independence, and most became republics. The two largest colonial powers were France and the United Kingdom. Republican France encouraged the establishment of republics in its former colonies. the United Kingdom attempted to follow the model it had for its earlier settler colonies of creating independent Commonwealth realms still linked under the same monarchy. While most of the settler colonies and the smaller states of the Caribbean retained this system, it was rejected by the newly independent countries in Africa and Asia, which revised their constitutions and became republics.</p><p>Britain followed a different model in the Middle East; it installed local monarchies in several colonies and mandates including Iraq, Jordan, Kuwait, Bahrain, Oman, Yemen and Libya. In subsequent decades revolutions and coups overthrew a number of monarchs and installed republics. Several monarchies remain, and the Middle East is the only part of the world where several large states are ruled by monarchs with almost complete political control.[45]</p><h3>Socialist republics</h3><p>In the wake of the First World War, the Russian monarchy fell during the Russian Revolution. The Russian Provisional Government was established in its place on the lines of a liberal republic, but this was overthrown by the Bolsheviks who went on to establish the Union of Soviet Socialist Republics. This was the first republic established under Marxist-Leninist ideology. Communism was wholly opposed to monarchy, and became an important element of many republican movements during the 20th century. The Russian Revolution spread into Mongolia, and overthrew its theocratic monarchy in 1924. In the aftermath of the Second World War the communists gradually gained control of Romania, Bulgaria, Yugoslavia, Hungary and Albania, ensuring that the states were reestablished as socialist republics rather than monarchies.</p><div class="gradientback"></div></div><div class="content"><p>Communism also intermingled with other ideologies. It was embraced by many national liberation movements during decolonization. In Vietnam, communist republicans pushed aside the Nguy?n Dynasty, and monarchies in neighbouring Laos and Cambodia were overthrown by communist movements in the 1970s. Arab socialism contributed to a series of revolts and coups that saw the monarchies of Egypt, Iraq, Libya, and Yemen ousted. In Africa Marxist-Leninism and African socialism led to the end of monarchy and the proclamation of republics in states such as Burundi and Ethiopia.</p><h3>Islamic republics</h3><p> Main article: Islamic republic</p><p>Islamic political philosophy has a long history of opposition to absolute monarchy, notably in the work of Al-Farabi. Sharia law took precedence over the will of the ruler, and electing rulers by means of the Shura was an important doctrine. While the early caliphate maintained the principles of an elected ruler, later states became hereditary or military dictatorships though many maintained some pretense of a consultative shura.</p><p>None of these states are typically referred to as republics. The current usage of republic in Muslim countries is borrowed from the western meaning, adopted into the language in the late 19th century.[46] The 20th century saw republicanism become an important idea in much of the Middle East, as monarchies were removed in many states of the region. Iraq became a secular state. Some nations, such as Indonesia and Azerbaijan, began as secular. In Iran, the 1979 revolution overthrew the monarchy and created an Islamic republic based on the ideas of Islamic democracy.</p><h2>Head of state</h2><h3>Structure</h3><p>With no monarch, most modern republics use the title president for the head of state. Originally used to refer to the presiding officer of a committee or governing body in Great Britain the usage was also applied to political leaders, including the leaders of some of the Thirteen Colonies (originally Virginia in 1608); in full, the President of the Council.[47] The first republic to adopt the title was the United States of America. Keeping its usage as the head of a committee the President of the Continental Congress was the leader of the original congress. When the new constitution was written the title of President of the United States was conferred on the head of the new executive branch.</p><p>If the head of state of a republic is also the head of government, this is called a presidential system. There are a number of forms of presidential government. A full-presidential system has a president with substantial authority and a central political role.</p><p>In other states the legislature is dominant and the presidential role is almost purely ceremonial and apolitical, such as in Germany and India. These states are parliamentary republics and operate similarly to constitutional monarchies with parliamentary systems where the power of the monarch is also greatly circumscribed. In parliamentary systems the head of government, most often titled prime minister, exercises the most real political power. Semi-presidential systems have a president as an active head of state, but also have a head of government with important powers.</p><p>The rules for appointing the president and the leader of the government, in some republics permit the appointment of a president and a prime minister who have opposing political convictions: in France, when the members of the ruling cabinet and the president come from opposing political factions, this situation is called cohabitation.</p><p>In some countries, like Switzerland, Bosnia and Herzegovina and San Marino, the head of state is not a single person but a committee (council) of several persons holding that office. The Roman Republic had two consuls, elected for a one year-term by the comitia centuriata, consisting of all adult, freeborn males who could prove citizenship.</p><h3>Elections</h3><p>In liberal democracies presidents are elected, either directly by the people or indirectly by a parliament or council. Typically in presidential and semi-presidential systems the president is directly elected by the people, or is indirectly elected as done in the United States. In that country the president is officially elected by an electoral college, chosen by the States, all of which do so by direct election of the electors. The indirect election of the president through the electoral college conforms to the concept of republic as one with a system of indirect election. In the opinion of some, direct election confers legitimacy upon the president and gives the office much of its political power.[48] However, this concept of legitimacy differs from that expressed in the United States Constitution which established the legitimacy of the United States president as resulting from the signing of the Constitution by nine states.[49] The idea that direct election is required for legitimacy also contradicts the spirit of the Great Compromise, whose actual result was manifest in the clause[50] that provides voters in smaller states with slightly more representation in presidential selection than those in large states.</p><p>In states with a parliamentary system the president is usually elected by the parliament. This indirect election subordinates the president to the parliament, and also gives the president limited legitimacy and turns most presidential powers into reserve powers that can only be exercised under rare circumstance. There are exceptions where elected presidents have only ceremonial powers, such as in Ireland.</p><h3>Ambiguities</h3><p>The distinction between a republic and a monarchy is not always clear. The constitutional monarchies of the former British Empire and Western Europe today have almost all real political power vested in the elected representatives, with the monarchs only holding either theoretical powers, no powers or rarely used reserve powers. Real legitimacy for political decisions comes from the elected representatives and is derived from the will of the people. While hereditary monarchies remain in place, political power is derived from the people as in a republic. These states are thus sometimes referred to as crowned republics.[51]</p><p>Terms such as liberal republic are also used to describe all of the modern liberal democracies.[52]</p><p>There are also self-proclaimed republics that act similarly to monarchies with absolute power vested in the leader and passed down from father to son. North Korea and Syria are two notable examples where a son has inherited political control. Neither of these states are officially monarchies. There is no constitutional requirement that power be passed down within one family, but it has occurred in practice.</p><p>There are also elective monarchies where ultimate power is vested in a monarch, but the monarch is chosen by some manner of election. A current example of such a state is Malaysia where the Yang di-Pertuan Agong is elected every five years by the Conference of Rulers composed of the nine hereditary rulers of the Malay states, and the Vatican City-State, where the pope is selected by cardinal-electors, currently all cardinals under a specific age. While rare today, elective monarchs were common in the past. The Holy Roman Empire is an important example, where each new emperor was chosen by a group of electors. Islamic states also rarely employed primogeniture, instead relying on various forms of election to choose a monarch's successor.</p><p>The Polish–Lithuanian Commonwealth had an elective monarchy, with a wide suffrage of some 500,000 nobles. The system, known as the Golden Liberty, had developed as a method for powerful landowners to control the crown. The proponents of this system looked to classical examples, and the writings of the Italian Renaissance, and called their elective monarchy a rzeczpospolita, based on res publica.</p><h3>Sub-national republics</h3><p>In general being a republic also implies sovereignty as for the state to be ruled by the people it cannot be controlled by a foreign power. There are important exceptions to this, for example, republics in the Soviet Union were member states which had to meet three criteria to be named republics:</p><div class="gradientback"></div></div><div class="content"><li>be on the periphery of the Soviet Union so as to be able to take advantage of their theoretical right to secede;</li><li>be economically strong enough to be self-sufficient upon secession; and</li><li>be named after at least one million people of the ethnic group which should make up the majority population of said republic.</li><p>It is sometimes argued that the former Soviet Union was also a supra-national republic, based on the claim that the member states were different nations.</p><p>Socialist Federative Republic of Yugoslavia (and earlier names) was a federal entity composed of six republics (Socialist Republic of Bosnia and Herzegovina, Croatia, Macedonia, Montenegro, Serbia, and Slovenia). Each republic had its parliament, government, institute of citizenship, constitution, etc... but certain functions were delegated to the federation (army, monetary matters). Each republic also had a right of self-determination according to the conclusions of the second session of the AVNOJ and according to the federal constitution.</p><p>States of the United States are required, like the federal government, to be republican in form, with final authority resting with the people. This was required because the states were intended to create and enforce most domestic laws, with the exception of areas delegated to the federal government and prohibited to the states. The founding fathers of the country intended most domestic laws to be handled by the states. Requiring the states to be a republic in form was seen as protecting the citizens' rights and preventing a state from becoming a dictatorship or monarchy, and reflected unwillingness on the part of the original 13 states (all independent republics) to unite with other states that were not republics. Additionally, this requirement ensured that only other republics could join the union.</p><p>In the example of the United States, the original 13 British colonies became independent states after the American Revolution, each having a republican form of government. These independent states initially formed a loose confederation called the United States and then later formed the current United States by ratifying the current U.S. Constitution, creating a union of sovereign states with the union or federal government also being a republic. Any state joining the union later was also required to be a republic.</p><h2>Other meanings</h2><h3>Political philosophy</h3><p> Main article: Republicanism</p><p>The term republic originated from the writers of the Renaissance as a descriptive term for states that were not monarchies. These writers, such as Machiavelli, also wrote important prescriptive works describing how such governments should function. These ideas of how a government and society should be structured is the basis for an ideology known as classical republicanism or civic humanism. This ideology is based on the Roman Republic and the city states of Ancient Greece and focuses on ideals such as civic virtue, rule of law, and mixed government.[53]</p><p>This understanding of a republic as a distinct form of government from a liberal democracy is one of the main theses of the Cambridge School of historical analysis.[54] This grew out of the work of J. G. A. Pocock who in 1975 argued that a series of scholars had expressed a consistent set of republican ideals. These writers included Machiavelli, Milton, Montesquieu, and the founders of the United States of America.</p><p>Pocock argued that this was an ideology with a history and principles distinct from liberalism.[55] These ideas were embraced by a number of different writers, including Quentin Skinner, Philip Pettit[56] and Cass Sunstein. These subsequent writers have further explored the history of the idea, and also outlined how a modern republic should function.</p><h3>United States</h3><p> Main article: Republicanism in the United States</p><p>A distinct set of definitions for the word republic evolved in the United States. In common parlance, a republic is a state that does not practice direct democracy but rather has a government indirectly controlled by the people. This understanding of the term was originally developed by James Madison, and notably employed in Federalist Paper No. 10. This meaning was widely adopted early in the history of the United States, including in Noah Webster's dictionary of 1828. It was a novel meaning to the term; representative democracy was not an idea mentioned by Machiavelli and did not exist in the classical republics.[57] Also, there is evidence that contemporaries of Madison considered the meaning of the word to reflect the definition found elsewhere, as is the case with a quotation of Benjamin Franklin taken from the notes of James McHenry where the question is put forth, a Republic or a Monarchy?[58]</p><p>The term republic does not appear in the Declaration of Independence, but does appear in Article IV of the Constitution which guarantee[s] to every State in this Union a Republican form of Government. What exactly the writers of the constitution felt this should mean is uncertain. The Supreme Court, in Luther v. Borden (1849), declared that the definition of republic was a political question in which it would not intervene. In two later cases, it did establish a basic definition. In United States v. Cruikshank (1875), the court ruled that the equal rights of citizens were inherent to the idea of a republic.</p><p>However, the term republic is not synonymous with the republican form. The republican form is defined as one in which the powers of sovereignty are vested in the people and are exercised by the people, either directly, or through representatives chosen by the people, to whom those powers are specially delegated. In re Duncan, 139 U.S. 449, 11 S.Ct. 573, 35 L.Ed. 219; Minor v. Happersett, 88 U.S. (21 Wall.) 162, 22 L.Ed. 627. [59]</p><p>Beyond these basic definitions the word republic has a number of other connotations. W. Paul Adams observes that republic is most often used in the United States as a synonym for state or government, but with more positive connotations than either of those terms.[60] Republicanism is often referred to as the founding ideology of the United States. Traditionally scholars believed this American republicanism was a derivation of the classical liberal ideologies of John Locke and others developed in Europe.</p><p>A political philosophy of republicanism that formed during the Renaissance period, and initiated by Machiavelli, was thought to have had little impact on the founders of the United States. In the 1960s and 1970s a revisionist school[citation needed] led by the likes of Bernard Bailyn began to argue that republicanism was just as or even more important than liberalism in the creation of the United States.[61] This issue is still much disputed and scholars like Isaac Kramnick completely reject this view.[62]</p><p>• Thomas Corwin, Senate Speech Against the Mexican War-Congressional Globe 1847</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/7/79/Thomas_Corwin%2C_Senate_Speech_Against_the_Mexican_War-Congressional_Globe-ed._WRE-Apr11.pdf/page1-220px-Thomas_Corwin%2C_Senate_Speech_Against_the_Mexican_War-Congressional_Globe-ed._WRE-Apr11.pdf.jpg" width="220" height="285"><p>


				Speech of U.S. Senator against the Mexican–American War characterizing it as imperialist and presidential



				 
				 
				 
				 
				 

				 



									
										</p><div class="gradientback"></div></div><div class="content"><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Republic&amp;oldid=782043588"					
								Categories:  Hidden categories:</p><br><h1 lang="en">Prokopis Pavlopoulos</h1><p>
					 From Wikipedia, the free encyclopedia</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/8/85/Prokopis_Pavlopoulos_with_Reuven_Rivlin_%283%29.jpg/250px-Prokopis_Pavlopoulos_with_Reuven_Rivlin_%283%29.jpg" width="250" height="172"><p>


				Prokopis Pavlopoulos with the President of Israel, Reuven Rivlin, 30 March 2016


				</p><p>
					Prokopios Pavlopoulos (Greek: ?????p??? ?a???p?????, pronounced&nbsp;[pro'kopios pav'lopulos], born 10 July 1950), commonly shortened to Prokopis (?????p??), is the seventh President of Greece, in office since 2015. A lawyer, university professor and politician, he was Minister for the Interior from 2004 to 2009.</p><p>On 18 February 2015, Pavlopoulos was elected by the Hellenic Parliament as President of Greece, with 233 votes in favour.</p><h2>Contents</h2><h2>Academic career</h2><p>Prokopis Pavlopoulos was born in Kalamata[1] to high school principal and classics teacher Vasilios Pavlopoulos and grew up in the same city.[2] After finishing school in his home town, he entered the Law School of the University of Athens in 1968.[2]</p><p>In 1975, on a government scholarship, he received his DEA from the Paris Panthéon-Assas University, followed by his PhD in 1977 on Public Law.[2] He then returned to Greece to serve his military service in the Hellenic Army (1978–79).[2] He was elected Lecturer at the University of Athens in 1980, and he was promoted to Reader in 1981. In 1983 he became Assistant Professor and he was promoted to Associate Professor in 1986. In 1989, he was elected (Full) Professor of Administrative Law.[1] In 1986, Pavlopoulos was an adjunct faculty member at the Panthéon-Assas University.[3]</p><h2>Political career</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/c/c5/Vladimir_Putin_and_Prokopis_Pavlopoulos_%282016-01-15%29_01.jpg/300px-Vladimir_Putin_and_Prokopis_Pavlopoulos_%282016-01-15%29_01.jpg" width="300" height="185"><p>


				Pavlopoulos met Vladimir Putin on 15 January 2016


				</p><p>
					Pavlopoulos was secretary to the first President of the metapolitefsi, Michail Stasinopoulos, in 1974.[1][4] From November 1989 to April 1990, he served as alternate Minister for the Presidency and government spokesman in the ecumenical government headed by Xenophon Zolotas.[2][4] He served as head of the legal office to President Konstantinos Karamanlis from 1990 to 1995, and political advisor to Miltiadis Evert, then chairman of New Democracy, from September 1995.[1][4] He was elected as a State MP for the New Democracy party in the 1996 parliamentary election, and in the 2000 parliamentary election he was elected as an MP for the Athens A constituency. He was appointed as New Democracy's Press and Information Spokesman by Evert on 20 April 1996; he subsequently became its Parliamentary Spokesman on 14 April 2000.[1][4] Pavlopoulos was successively re-elected for Athens A in the 2000, 2004, 2007, 2009 and 2012 elections.[2]</p><p>Following the March 2004 legislative election, which was won by New Democracy, Pavlopoulos became Minister for the Interior, Public Administration and Decentralisation in the new government of the Prime Minister Kostas Karamanlis on 10 March 2004.[4][5] In the government appointed following New Democracy's victory in the September 2007 parliamentary election, the Interior Ministry was merged with the Ministry of Public Order, and Pavlopoulous became Minister of the Interior and Public Order.[6]</p><p>He is a member of the Central Committee of New Democracy, and on 29 July 2004 he was designated as a member of the party's Political Council as one of seven MP candidates; no vote was necessary because there were only seven MP seats available on the Council.[7]</p><p>On 17 February, Prime Minister Alexis Tsipras nominated Pavlopoulos as the ruling SYRIZA–ANEL coalition's candidate for the post of President of Greece in the presidential election that had begun in December 2014.[8] On 18 February 2015, backed by SYRIZA, ANEL and his own New Democracy party, Pavlopoulos was elected by the Greek Parliament as the new President of Greece with 233 votes in favour. He succeeded Karolos Papoulias after the end of the latter's term on 13 March 2015.[9]</p><h2>Personal life</h2><p>Pavlopoulos is married to Vlassia Pavlopoulou-Peltsemi and together they have two daughters, Maria and Zoe, and one son, Vasilis.[2][10]</p><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Prokopis_Pavlopoulos&amp;oldid=782144020"					
								Categories:  Hidden categories:</p><br><h1 lang="en">Nikos Voutsis</h1><p> From Wikipedia, the free encyclopedia</p><p>Nikos Voutsis (Greek: ????? ???ts??; born 4 March 1951) is a Greek politician who served as the Minister of the Interior and Administrative Reconstruction from January 2015 to August 2015 in the First Cabinet of Alexis Tsipras.[1] Since 4 October 2015 he is the Speaker of the Hellenic Parliament.[2]</p><h2>Contents</h2><h2>Early life and education</h2><p>Voutsis was born in Athens. He graduated from the University of Athens and the National Technical University of Athens with a degree in civil engineering.</p><div class="gradientback"></div></div><div class="content"><h2>Political career</h2><p>Voutsis served as a regional councillor in Attica with the group Attiki Cooperation –No to the Memorandum from 2010 to 2012.</p><p>Voutsis was first elected as a Member of the Hellenic Parliament representing Athens A in the May 2012 legislative election, and was reelected in June 2012 and January 2015.</p><p>Re-elected in the September 2015 elections, on 4 October 2015 he was elected as the new Speaker of the Hellenic Parliament with 181 votes.[2]</p><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Nikos_Voutsis&amp;oldid=783374900"					
								Categories:  Hidden categories:</p><br><h1 lang="en">History of modern Greece</h1><p> From Wikipedia, the free encyclopedia</p><p>The history of modern Greece covers the history of Greece from the recognition of its autonomy from the Ottoman Empire by the Great Powers (Great Britain, France, and Russia) in 1828, after the Greek War of Independence, to the present day.</p><h2>Contents</h2><h2>Background</h2><p> Main articles: Frankokratia, Ottoman Greece, Modern Greek Enlightenment, and Greek War of Independence</p><p>The Byzantine Empire had ruled most of the Greek-speaking world since late Antiquity, but experienced a decline as a result of Muslim Arab and Seljuk Turkish invasions but was fatally weakened by the sacking of Constantinople by the Latin Crusaders in 1204. The establishment of Catholic Latin states on Greek soil, and the struggles of the Orthodox Byzantine Greeks against them, led to the emergence of a distinct Greek national identity. The Byzantine Empire was restored by the Palaiologos dynasty in 1261, but it was a shadow of its former self, and constant civil wars and foreign attacks in the 14th century brought about its terminal decline. As a result, most of Greece gradually became part of the Ottoman Empire in the late 14th and early 15th century, culminating in the Fall of Constantinople in 1453, the conquest of the Duchy of Athens in 1458, and of the Despotate of the Morea in 1460.</p><p>Ottoman control was largely absent in the mountainous interior of Greece, and many fled there, often becoming brigands.[1] Otherwise, only the islands of the Aegean and a few coastal fortresses on the mainland, under Venetian and Genoese rule, remained free from Ottoman rule, but by the mid-16th century, the Ottomans had conquered most of them as well. Rhodes fell in 1522, Cyprus in 1571, and the Venetians retained Crete until 1670. The Ionian Islands were only briefly ruled by the Ottomans (Kefalonia from 1479 to 1481 and from 1485 to 1500), and remained primarily under the rule of Venice.</p><p>The first large-scale insurrection against Ottoman rule was the Orlov Revolt of the early 1770s, but it was brutally repressed. The same time, however, also marks the start of the Modern Greek Enlightenment, as Greeks who studied in Western Europe brought knowledge and ideas back to their homeland, and as Greek merchants and shipowners increased their wealth. As a result, especially in the aftermath of the French Revolution, liberal and nationalist ideas began to spread across the Greek lands.</p><p>In 1821, the Greeks rose up against the Ottoman Empire. Initial successes were followed by infighting, which almost caused the Greek struggle to collapse; nevertheless, the prolongation of the fight forced the Great Powers (Britain, Russia and France) to recognize the claims of the Greek rebels to separate statehood (Treaty of London) and intervene against the Ottomans at the Battle of Navarino. Greece was initially to be an autonomous state under Ottoman suzerainty, but by 1832, in the Treaty of Constantinople, it was recognized as a fully independent kingdom. In the meantime, the 3rd National Assembly of the Greek insurgents called upon Ioannis Kapodistrias, a former foreign minister of Russia, to take over the governance of the fledgling state in 1827.</p><h2>Administration of Ioannis Kapodistrias</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/2/2b/Kapodistrias3.jpg/180px-Kapodistrias3.jpg" width="180" height="238"><p>


				Ioannis Kapodistrias.


				</p><p>
					On his arrival, Kapodistrias launched a major reform and modernisation programme that covered all areas. He re-established military unity by bringing an end to the second phase of the civil war; re-organised the military, which was then able to reconquer territory lost to the Ottoman military during the civil wars; and introduced the first modern quarantine system in Greece, which brought diseases such typhoid fever, cholera and dysentery under control for the first time since the start of the War of Independence.</p><p>Kapodistrias also negotiated with the Great Powers and the Ottoman Empire to establish the borders and degree of independence of the Greek state; signed the peace treaty that ended the War of Independence with the Ottomans; introduced the phoenix, the first modern Greek currency; organised local administration; and, in an effort to raise the living standards of the population, introduced the cultivation of the potato into Greece.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/3/3e/Phoenix_Greek_coin_1828-1833.jpg/220px-Phoenix_Greek_coin_1828-1833.jpg" width="220" height="107"><p>


				Face and Obverse of a Phoenix coin.


				</p><p>
					Furthermore, he tried to undermine the authority of the traditional clans (or dynasties) that he considered the useless legacy of a bygone and obsolete era.[2] However, he underestimated the political and military strength of the capetanei (?apeta?a??? – commanders) who had led the revolt against Ottoman Empire in 1821, and who had expected a leadership role in the post-revolution Government. When a dispute between the capetanei of Laconia and the appointed governor of the province escalated into an armed conflict, he called in Russian troops to restore order, because much of the army was controlled by capetanei who had been part of the rebellion.</p><p>George Finlay's 1861 History of Greek Revolution records that by 1831 Kapodistrias's government had become hated, chiefly by the independent Maniots, but also by the Roumeliotes and the rich and influential merchant families of Hydra, Spetses and Psara. The customs dues of the inhabitants of Hydra were the chief source of revenue for these municipalities, and they refused to hand these over to Kapodistrias. It appears that Kapodistrias had refused to convene the National Assembly and was ruling as a despot, possibly influenced by his Russian experiences. The municipality of Hydra instructed Admiral Miaoulis and Alexandros Mavrokordatos to go to Poros and seize the Hellenic Navy's fleet there. This Miaoulis did so with the intention of preventing a blockade of the islands, so for a time it seemed as if the National Assembly would be called.</p><div class="gradientback"></div></div><div class="content"><p>Kapodistrias called on the British and French residents to support him in putting down the rebellion, but this they refused to do. Nonetheless, an Admiral Rikord (or Ricord) took his ships north to Poros. Colonel (later General) Kallergis took a half-trained force of Greek Army regulars and a force of irregulars in support. With less than 200 men, Miaoulis was unable to make much of a fight; Fort Heidek on Bourtzi Island was overrun by the regulars and the brig Spetses (once Laskarina Bouboulina's Agamemnon) sank by Ricord's force. Encircled by the Russians in the harbor and Kallergis' force on land, Poros surrendered. Miaoulis was forced to set charges in the flagship Hellas and the corvette Hydra to blow them up when he and his handful of followers returned to Hydra. Kallergis' men were enraged by the loss of the ships and sacked Poros, carrying off plunder to Nauplion.</p><p>The loss of the best ships in the fleet crippled the Hellenic Navy for many years, but it also weakened Kapodistrias' position. He did finally call the National Assembly, but his other actions triggered more opposition and that led to his downfall.</p><h2>Assassination of Kapodistrias and the creation of the Kingdom of Greece</h2><p> Further information: Kingdom of Greece</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/0/0d/Kapodistrias_death.jpg/250px-Kapodistrias_death.jpg" width="250" height="165"><p>


				Assassination of Ioannis Kapodistrias by Dionysios Tsokos.



				<br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/3/35/Peter_von_Hess_-_The_Entry_of_King_Othon_of_Greece_in_Athens_-_WGA11387.jpg/250px-Peter_von_Hess_-_The_Entry_of_King_Othon_of_Greece_in_Athens_-_WGA11387.jpg" width="250" height="150"><br>


				The Entry of King Otto in Athens by Peter von Hess.


				</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/3/35/Peter_von_Hess_-_The_Entry_of_King_Othon_of_Greece_in_Athens_-_WGA11387.jpg/250px-Peter_von_Hess_-_The_Entry_of_King_Othon_of_Greece_in_Athens_-_WGA11387.jpg" width="250" height="150"><br><p>
					In 1831, Kapodistrias ordered the imprisonment of Petrobey Mavromichalis, the Bey of the Mani Peninsula, one of the wildest and most rebellious parts of Greece. This was a mortal offence to the Mavromichalis family, and on 9 October 1831 (27 September in the Julian Calendar) Kapodistrias was assassinated by Petros' brother Konstantis and son Georgios on the steps of the church of Saint Spyridon in Nafplio.</p><p>Ioannis Kapodistrias was succeeded as Governor by his younger brother, Augustinos Kapodistrias. Augustinos ruled only for six months, during which the country was very much plunged into chaos. Under the protocol signed at the London Conference of 1832 on 7 May 1832 between Bavaria and the protecting Powers, Greece was defined as an independent kingdom, free of Ottoman control, with the Arta-Volos line as its northern frontier. The protocol also dealt with the way in which a Regency was to be managed until Otto of Bavaria reached his majority to assume the throne of Greece. The Ottoman Empire was indemnified in the sum of 40,000,000 piastres for the loss of territory in the new kingdom.</p><h2>Reign of King Otto, 1833–1863</h2><p> Main article: Otto of Greece</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/5/5d/Prinz_Otto_von_Bayern_Koenig_von_Griechenland_1833.jpg/180px-Prinz_Otto_von_Bayern_Koenig_von_Griechenland_1833.jpg" width="180" height="223"><p>


				Otto, the first King of modern Greece.


				</p><p>
					Otto's reign would prove troubled, but he managed to hang on for 30 years before he and his wife, Queen Amalia, left the same way they came, aboard a British warship. During the early years of his reign, a group of Bavarian Regents ruled in his name, and they made themselves very unpopular by trying to impose German ideas of rigid hierarchical government on the Greeks, while keeping most significant state offices away from them. Nevertheless, they laid the foundations of a Greek administration, army, justice system and education system. Otto was sincere in his desire to give Greece good government, but he suffered from two great handicaps: his Roman Catholic faith and his childless marriage to Queen Amalia. This meant he could neither be crowned as King of Greece under the Orthodox rite nor establish a dynasty.</p><p>The Bavarian Regents ruled until 1837, when they were recalled at the insistence of Britain and France. Otto thereafter appointed Greek ministers, although Bavarian officials still ran most of the administration and the army. At this time, Greece still had no legislature and no constitution. Discontent grew until the 3 September 1843 Revolution broke out in Athens. Otto agreed to grant a constitution and convened a National Assembly that met in November of the same year. The Greek Constitution of 1844 then created a bicameral parliament consisting of an Assembly (Vouli) and a Senate (Gerousia). Power then passed into the hands of a group of Greek politicians, most of whom who had been commanders in the War of Independence against the Ottomans.</p><p>Greek politics in the 19th century was dominated by the national question. The majority of Greeks continued to live under Ottoman rule, and Greeks dreamed of liberating them all and reconstituting a state embracing all the Greek lands, with Constantinople as its capital. This was called the Great Idea (Megali Idea), and it was sustained by almost continuous rebellions against Ottoman rule in Greek-speaking territories, particularly Crete, Thessaly and Macedonia.</p><p>When the Crimean War broke out in 1854, Greece saw an opportunity to gain Ottoman-controlled territory that had large Greek populations. Greece, an Orthodox nation, had considerable support in Russia, but the Russian government decided it was too dangerous to help Greece expand its holdings.[3] When the Russians attacked the Ottoman forces, Greece invaded Thessaly and Epirus. To block further Greek moves, the British and French occupied the main Greek port at Piraeus from April 1854 to February 1857.[4] The Greeks, gambling on a Russian victory, incited the large-scale Epirus Revolt of 1854 as well as uprisings in Crete. The revolts failed and Greece made no gains during the Crimean War, which Russia lost.[5]</p><div class="gradientback"></div></div><div class="content"><p>A new generation of Greek politicians was growing increasingly intolerant of King Otto's continuing interference in government. In 1862, the King dismissed his Prime Minister, the former admiral Constantine Kanaris, the most prominent politician of the period. This provoked a military rebellion, forcing Otto to accept the inevitable and leave the country.</p><p>The Greeks then asked Britain to send Queen Victoria's son Prince Alfred as their new king, but this was vetoed by the other Powers. Instead, a young Danish Prince became King George I. George was a very popular choice as a constitutional monarch, and he agreed that his sons would be raised in the Greek Orthodox faith. As a reward to the Greeks for adopting a pro-British King, Britain ceded the Ionian Islands to Greece.</p><h2>Reign of King George I, 1864–1913</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/1/18/King_George_of_Hellenes.jpg/180px-King_George_of_Hellenes.jpg" width="180" height="244"><p>


				King George I of the Hellenes in Hellenic Navy uniform.


				</p><p>
					At the urging of Britain and King George, Greece adopted the much more democratic Greek Constitution of 1864. The powers of the King were reduced, the Senate was abolished, and the franchise was extended to all adult males. Approval voting was used in elections, with one urn for each candidate divided into yes and no portions into which voters dropped lead beads. Nevertheless, Greek politics remained heavily dynastic, as it has always been. Family names such as Zaimis, Rallis and Trikoupis occurred repeatedly as Prime Ministers.</p><p>Although parties were centered around the individual leaders, often bearing their names, two broad political tendencies existed: the liberals, led first by Charilaos Trikoupis and later by Eleftherios Venizelos, and the conservatives, led initially by Theodoros Deligiannis and later by Thrasivoulos Zaimis. Trikoupis and Deligiannis dominated Greek politics in the later 19th century, alternating in office. Trikoupis favoured co-operation with Great Britain in foreign affairs, the creation of infrastructure and an indigenous industry, raising protective tariffs and progressive social legislation, while the more populist Deligiannis depended on the promotion of Greek nationalism and the Megali Idea.</p><p>Greece remained a very poor country throughout the 19th century. The country lacked raw materials, infrastructure and capital. Agriculture was mostly at the subsistence level, and the only important export commodities were currants, raisins and tobacco. Some Greeks grew rich as merchants and shipowners, and Piraeus became a major port, but little of this wealth found its way to the Greek peasantry. Greece remained hopelessly in debt to London finance houses.</p><p>By the 1890s Greece was virtually bankrupt. Poverty was rife in the rural areas and the islands, and was eased only by large-scale emigration to the United States. There was little education in the rural areas. Nevertheless, there was progress in building communications and infrastructure, and fine public buildings were erected in Athens. Despite the bad financial situation, Athens staged the revival of the Olympic Games in 1896, which proved a great success.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/a/a0/The_Hellenic_Parliament_%284551856563%29.jpg/250px-The_Hellenic_Parliament_%284551856563%29.jpg" width="250" height="140"><p>


				The Hellenic Parliament in the 1880s, with PM Charilaos Trikoupis standing at the podium.


				</p><p>
					The parliamentary process developed greatly in Greece during the reign of George I. Initially, the royal prerogative in choosing his prime minister remained and contributed to governmental instability, until the introduction of the dedilomeni principle of parliamentary confidence in 1875 by the reformist Charilaos Trikoupis. Clientelism and frequent electoral upheavals however remained the norm in Greek politics, and frustrated the country's development.</p><p>Corruption and Trikoupis' increased spending (to create necessary infrastructure such as the Corinth Canal) overtaxed the weak Greek economy, forcing the declaration of public insolvency in 1893 and to accept the imposition of an International Financial Control authority to pay off the country's creditors.</p><p>Another political issue in 19th-century Greece was the Greek language question. The Greek people spoke a form of Greek called Demotic. Many of the educated elite saw this as a peasant dialect and were determined to restore the glories of Ancient Greek. Government documents and newspapers were consequently published in Katharevousa (purified) Greek, a form that few ordinary Greeks could read. Liberals favoured recognising Demotic as the national language, but conservatives and the Orthodox Church resisted all such efforts, to the extent that when the New Testament was translated into Demotic in 1901, riots erupted in Athens and the government fell (the Evangeliaka). This issue would continue to plague Greek politics until the 1970s.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/en/thumb/c/c9/Map_of_Greece_1903.png/200px-Map_of_Greece_1903.png" width="200" height="159"><p>


				Map of the Kingdom of Greece, the Cretan State and the Principality of Samos in 1903, before the Balkan Wars.


				</p><p>
					All Greeks were united, however, in their determination to liberate the Greek-speaking provinces of the Ottoman Empire. Especially in Crete, the Cretan Revolt (1866–1869) raised nationalist fervour. When war broke out between Russian and the Ottomans in the Russo-Turkish War (1877–1878), Greek popular sentiment rallied to Russia's side, but Greece was too poor and too concerned about British intervention to enter the war officially. Nevertheless, in 1881, Thessaly and small parts of Epirus were ceded to Greece as part of the Treaty of Berlin.</p><p>Greeks in Crete continued to stage regular revolts, and in 1897, the Greek government under Theodoros Deligiannis, bowing to popular pressure, declared war on the Ottomans. In the ensuing Greco-Turkish War of 1897, the badly trained and equipped Greek army was defeated by the Ottomans. Through the intervention of the Great Powers however, Greece lost only a little territory along the border to Turkey, while Crete was established as an autonomous state under Prince George of Greece as the Cretan State.</p><div class="gradientback"></div></div><div class="content"><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/7/7b/Goudi_coup_poster.jpg/250px-Goudi_coup_poster.jpg" width="250" height="194"><p>


				Popular lithograph celebrating the success of the Goudi pronunciamiento of 1909 as a national rebirth.


				</p><p>
					Nationalist sentiment among Greeks in the Ottoman Empire continued to grow, and by the 1890s there were constant disturbances in Macedonia. Here, the Greeks were in competition not only with the Ottomans, but also with the Bulgarians, in an armed propaganda struggle for the hearts and minds of the ethnically mixed local population, the so-called Macedonian Struggle.</p><p>In July 1908, the Young Turk Revolution broke out in the Ottoman Empire. Taking advantage of the Ottoman internal turmoil, Austria-Hungary annexed Bosnia and Herzegovina and Bulgaria declared its independence from the Ottoman Empire. On Crete, the local population, led by a young politician named Eleftherios Venizelos, declared Enosis, Union with Greece, provoking another crisis. The fact that the Greek government, led by Dimitrios Rallis, proved unable to likewise take advantage of the situation and bring Crete into the fold, rankled many Greeks, especially young military officers. These formed a secret society, the Military League, with the purpose of emulating their Ottoman colleagues to seek governmental reforms.</p><p>The resulting Goudi coup on 15 August 1909 marked a watershed in modern Greek history: as the military conspirators were inexperienced in politics, they asked Venizelos, who had impeccable liberal credentials, to come to Greece as their political adviser. Venizelos quickly established himself as a powerful political figure, and his allies won the August 1910 elections. Venizelos became Prime Minister in October 1910, ushering a period of 25 years where his personality would dominate Greek politics.</p><p>Venizelos initiated a major reform program, including a new and more liberal constitution and reforms in the spheres of public administration, education and economy. French and British military missions were invited for the army and navy respectively, and arms purchases were made. In the meantime, the Ottoman Empire's weaknesses were revealed by the ongoing Italo-Turkish War in Libya.</p><h3>Balkan Wars</h3><p> Main article: Balkan Wars</p><p>Through the spring of 1912, a series of bilateral agreements between the Christian Balkan states (Greece, Bulgaria, Montenegro and Serbia) formed the Balkan League, which in October 1912 declared war on the Ottoman Empire. In the First Balkan War, the Ottomans were defeated on all fronts, and the four allies rushed to grab as much territory as they could. The Greeks occupied Thessaloniki just ahead of the Bulgarians, and also took much of Epirus with Ioannina, as well as Crete and the Aegean Islands.</p><p>The Treaty of London (1913) ended the war, but no one was left satisfied, and soon, the four allies fell out over the partition of Macedonia. In June 1913, Bulgaria attacked Greece and Serbia, beginning the Second Balkan War, but was beaten back. The Treaty of Bucharest (1913), which concluded the Second Balkan War, left Greece with southern Epirus, the southern half of Macedonia (known as Greek Macedonia), Crete and the Aegean islands, except for the Dodecanese, which had been occupied by Italy since 1911. These gains nearly doubled Greece's area and population.</p><p>In March 1913, an anarchist, Alexandros Schinas, assassinated King George in Thessaloniki, and his son came to the throne as Constantine I. Constantine was the first Greek king born in Greece and the first to be Greek Orthodox by birth. His very name had been chosen in the spirit of romantic Greek nationalism (the Megali Idea), evoking the Byzantine emperors of that name. In addition, as the Commander-in-chief of the Greek Army during the Balkan Wars, his popularity was enormous, rivalled only by that of Venizelos, his Prime Minister.</p><h2>World War I and subsequent crises, 1914-1922</h2><p> Main articles: Greece during World War I, National Schism, Greek genocide, and Asia Minor Campaign</p><p>When World War I broke out in 1914, the King and his Prime Minister Venizelos both preferred to maintain a neutral stance, in spite of Greece's treaty of alliance with Serbia, which had been attacked by Austria-Hungary as the first belligerent action of the conflict. But when the Allies asked for Greek help in the Dardanelles campaign of 1915, offering Cyprus in exchange, their diverging views became apparent: Constantine had been educated in Germany, was married to Sophia of Prussia, sister of Kaiser Wilhelm, and was convinced of the Central Powers' victory. Venizelos, on the other hand, was an ardent anglophile, and believed in an Allied victory.</p><p>Since Greece, a maritime country, could not oppose the mighty British navy, and citing the need for a respite after two wars, King Constantine favored continued neutrality, while Venizelos actively sought Greek entry in the war on the Allied side. Venizelos resigned, but won the Greek elections of 1915 and again formed the government. When Bulgaria entered the war as a German ally in October 1915, Venizelos invited Allied forces into Greece (the Salonika Front), for which he was again dismissed by Constantine.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/c/cd/Venizelos_WWI_1918.jpg/250px-Venizelos_WWI_1918.jpg" width="250" height="163"><p>


				Venizelos reviews a section of the Greek army on the Macedonian front during the First World War, 1917. He is accompanied by Admiral Pavlos Koundouriotis (left) and General Maurice Sarrail (right).


				</p><p>
					In August 1916, after several incidents in which both sides in the war had encroached upon the still theoretically neutral Greek territory, Venizelist officers rose up in Allied-controlled Thessaloniki and Venizelos established a separate government there known as the result of a so-called Movement of National Defence. Constantine was now ruling only in what was Greece before the Balkan Wars (Old Greece), and his government was subject to repeated humiliations from the Allies. In November 1916 the French occupied Piraeus, bombarded Athens and forced the Greek fleet to surrender. The royalist troops fired at them, leading to a battle between French and Greek royalist troops. There were also riots against supporters of Venizelos in Athens (the Noemvriana).</p><p>Following the February Revolution in Russia in 1917, the Tsar's support for his cousin Constantine was eliminated, and he was forced to leave the country, without actually abdicating, in June 1917. His second son Alexander became King, while the remaining royal family and the most prominent royalists followed him into exile. Venizelos now led a superficially united Greece into the war on the Allied side, but underneath the surface, the division of Greek society into Venizelists and anti-Venizelists, the so-called National Schism, became more entrenched.</p><div class="gradientback"></div></div><div class="content"><h3>Greco-Turkish War (1919–1922)</h3><p> Main article: Greco-Turkish War (1919–1922)</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/d/d6/Hellenism_in_the_Near_East_1918.jpg/200px-Hellenism_in_the_Near_East_1918.jpg" width="200" height="245"><p>


				The Greek Kingdom and the Greek diaspora in the Balkans and western Asia Minor, according to a 1919 map submitted to the Paris Peace Conference.


				</p><p>
					With the end of the war in November 1918, the moribund Ottoman Empire was ready to be carved up among the victors, and Greece now expected the Allies to deliver on their promises. In no small measure through the diplomatic efforts of Venizelos, Greece secured Western Thrace in the Treaty of Neuilly in November 1919 and Eastern Thrace and a zone around Smyrna in western Anatolia (already under Greek administration as the Occupation of Izmir since May 1919) in the Treaty of Sèvres of August 1920. The future of Constantinople was left to be determined. But at the same time, a Turkish National Movement rose in Turkey led by Mustafa Kemal (later Kemal Atatürk), who set up a rival government in Ankara and was engaged in fighting the Greek army.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/f/f3/Greco_Turkish_War_1919-1922.svg/220px-Greco_Turkish_War_1919-1922.svg.png" width="220" height="156"><p>


				Map of the military developments during the Greco-Turkish War (1919–1922).


				</p><p>
					At this point, the fulfillment of the Megali Idea seemed near. Yet so deep was the rift in Greek society that on his return to Greece, an assassination attempt was made on Venizelos by two royalist former officers. Even more surprisingly, Venizelos' Liberal Party lost the Greek elections of November 1920, and in the Greek plebescite of 1920, the Greek people voted for the return of King Constantine from exile after the sudden death of King Alexander.</p><p>The United Opposition, which had campaigned on the slogan of an end to the Asia Minor Campaign in Anatolia, instead intensified it. But the royalist restoration had dire consequences: many veteran Venizelist officers were dismissed or left the army, while Italy and France found the return of the hated Constantine a useful pretext for switching their support to Kemal. Finally, in August 1922, the Turkish army shattered the Greek front, and took Smyrna in an operation that led to the disastrous Great Fire of Smyrna.</p><p>The Greek army evacuated not only Anatolia, but also Eastern Thrace and the islands of Imbros and Tenedos in accordance with the terms of the (Treaty of Lausanne). A population exchange between Greece and Turkey was agreed between the two countries, with over 1.5 million Christians and almost half a million Muslims being uprooted. This catastrophe marked the end of the Megali Idea, and left Greece financially exhausted, demoralized, and having to house and feed a proportionately huge number of Greek refugees.</p><h2>Republic and Monarchy (1922–1940)</h2><p> Main articles: 11 September 1922 Revolution, Second Hellenic Republic, and 4th of August Regime</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/a/ae/Demonstration_for_the_declaration_of_the_Greek_Republic_-_1924.jpg/220px-Demonstration_for_the_declaration_of_the_Greek_Republic_-_1924.jpg" width="220" height="169"><p>


				Crowds celebrating in Athens the proclamation of the Republic, 1924, with placards of republican leaders Papanastasiou, Hatzikyriakos and Kondylis.


				</p><p>
					The catastrophe deepened the political crisis, with the returning army rising up under Venizelist officers and forcing King Constantine to abdicate again, in September 1922, in favour of his firstborn son, George II. The Revolutionary Committee headed by Colonels Stylianos Gonatas (soon to become Prime Minister) and Nikolaos Plastiras engaged in a witch-hunt against the royalists, culminating in the Trial of the Six.</p><p>The Greek election of 1923 was held to form a National Assembly with powers to draft a new constitution. Following a failed royalist Leonardopoulos-Gargalidis coup attempt, the monarchist parties abstained, leading to a landslide for the Liberals and their allies. King George II was asked to leave the country, and on 25 March 1924, Alexandros Papanastasiou proclaimed the Second Hellenic Republic, ratified by the Greek plebiscite of 1924 a month later.</p><p>However, the new Republic was built on unstable foundations. The National Schism lived on, as the monarchists, with the exception of Ioannis Metaxas, did not acknowledge the Venizelist-sponsored Republican regime. The army, which had power and provided many of the leading proponents of both sides, became a factor to be reckoned with, prone to intervene in politics.</p><p>Greece was diplomatically isolated and vulnerable, as the Corfu incident of 1923 showed, and the economic foundations of the state were in ruins after a decade of war and the sudden increase of the country's population by a quarter. The refugees, however, also brought a new air into Greece. They were impoverished now, but before 1922 many had been entrepreneurs and well-educated. Staunch supporters of Venizelos and the Republic, many would radicalize and play a leading role in the nascent Communist Party of Greece.</p><p>In June 1925, General Theodoros Pangalos launched a coup and ruled as a dictator for a year until a counter-coup by another General, Georgios Kondylis, unseated him and restored the Republic. In the meantime, Pangalos managed to embroil Greece in a short-lived war with Bulgaria precipitated by the Incident at Petrich and make unacceptable concessions in Thessaloniki and its hinterland to Yugoslavia in an effort to gain its support for his revanchist policies against Turkey.</p><p>In 1928, Venizelos returned from exile. After a landslide victory in the Greek election of 1928, he formed a government. This was the only cabinet of the Second Republic to run its full four-year term, and the work it left behind was considerable. Alongside domestic reforms, Venizelos restored Greece's frayed international relations, even initiating a Greco-Turkish reconciliation with a visit to Ankara and the signing of a Friendship Agreement in 1930.</p><div class="gradientback"></div></div><div class="content"><p>The Great Depression hit Greece, an already poor country dependent on agricultural exports, particularly hard. Matters were made worse by the closing off of emigration to the United States, the traditional safety valve of rural poverty. High unemployment and consequent social unrest resulted, and the Communist Party of Greece made rapid advances. Venizelos was forced to default on Greece's national debt in 1932, and he fell from office after the Greek elections of 1932. He was succeeded by a monarchist coalition government led by Panagis Tsaldaris of the People's Party.</p><p>Two failed Venizelist military coups followed in 1933 and 1935 in an effort to preserve the Republic, but they had the opposite effect. On 10 October 1935, a few months after he suppressed the 1935 Greek coup d'état attempt, Georgios Kondylis, the former Venizelist stalwart, abolished the Republic in another coup, and declared the monarchy restored. The rigged Greek plebiscite of 1935 confirmed the regime change (with an unsurprising 97.88% of votes), and King George II returned.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/1/12/Metaxas-regime-greek-fascism.png/220px-Metaxas-regime-greek-fascism.png" width="220" height="139"><p>


				The conservative regime of Ioannis Metaxas (4th of August Regime) adopted many of the ideas and symbolism of Italian Fascism. Here members of the National Organisation of Youth give the Roman salute to Metaxas.


				</p><p>
					King George II immediately dismissed Kondylis and appointed Professor Konstantinos Demertzis as interim Prime Minister. Venizelos meanwhile, in exile, urged an end to the conflict over the monarchy in view of the threat to Greece from the rise of Fascist Italy. His successors as Liberal leader, Themistoklis Sophoulis and Georgios Papandreou, agreed, and the restoration of the monarchy was accepted. The Greek elections of 1936 resulted in a hung parliament, with the Communists holding the balance. As no government could be formed, Demertzis continued on. At the same time, a series of deaths left the Greek political scene in disarray: Kondylis died in February, Venizelos in March, Demertzis in April and Tsaldaris in May. The road was now clear for Ioannis Metaxas, who had succeeded Demertzis as interim Prime Minister.</p><p>Metaxas, a retired royalist general, believed that an authoritarian government was necessary to prevent social conflict and quell the rising power of the Communists. On 4 August 1936, with the King's support, he suspended parliament and established the 4th of August Regime. The Communists were suppressed and the Liberal leaders went into internal exile. Patterning itself after Benito Mussolini's Fascist Italy,[citation needed] Metaxas' regime promoted various concepts such as the Third Hellenic Civilization, the Roman salute, a National Organisation of Youth, and introduced measures to gain popular support, such as the Greek Social Insurance Institute (IKA), still the biggest social security institution in Greece.</p><p>Despite these efforts, the regime lacked a broad popular base or a mass movement supporting it. The Greek people were generally apathetic, without actively opposing Metaxas. Metaxas also improved the country's defenses in preparation for the forthcoming European war, constructing, among other defensive measures, the Metaxas Line. Despite his aping of Fascism, and the strong economic ties with resurgent Nazi Germany, Metaxas followed a policy of neutrality, given Greece's traditionally strong ties to Britain, reinforced by King George II's personal anglophilia. In April 1939, the Italian threat suddenly loomed closer when Italy annexed Albania, whereupon Britain publicly guaranteed Greece's borders. Thus, when World War II broke out in September 1939, Greece remained neutral.</p><h2>World War II</h2><p> Main articles: Military history of Greece during World War II, Axis Occupation of Greece, and Greek Resistance</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/3/3b/Bundesarchiv_Bild_101I-164-0389-23A%2C_Athen%2C_Hissen_der_Hakenkreuzflagge.jpg/200px-Bundesarchiv_Bild_101I-164-0389-23A%2C_Athen%2C_Hissen_der_Hakenkreuzflagge.jpg" width="200" height="284"><p>


				The symbolic start of the Occupation: German soldiers raising the German War Flag over the Acropolis. It would be taken down in one of the first acts of the Greek Resistance.



				<br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/a/a0/Triple_Occupation_of_Greece.png/200px-Triple_Occupation_of_Greece.png" width="200" height="204"><br>


				The three occupation zones. Blue indicates the Italian, red the German and green the territory annexed by Bulgaria. The Italian zone was taken over by the Germans in September 1943.



				<br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/5/51/%CE%91%CE%BD%CF%84%CE%AC%CF%81%CF%84%CE%B5%CF%82_%CF%84%CE%BF%CF%85_%CE%95%CE%91%CE%9C-%CE%95%CE%9B%CE%91%CE%A3.jpg/200px-%CE%91%CE%BD%CF%84%CE%AC%CF%81%CF%84%CE%B5%CF%82_%CF%84%CE%BF%CF%85_%CE%95%CE%91%CE%9C-%CE%95%CE%9B%CE%91%CE%A3.jpg" width="200" height="153"><br>


				Guerillas of ELAS


				</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/a/a0/Triple_Occupation_of_Greece.png/200px-Triple_Occupation_of_Greece.png" width="200" height="204"><br><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/5/51/%CE%91%CE%BD%CF%84%CE%AC%CF%81%CF%84%CE%B5%CF%82_%CF%84%CE%BF%CF%85_%CE%95%CE%91%CE%9C-%CE%95%CE%9B%CE%91%CE%A3.jpg/200px-%CE%91%CE%BD%CF%84%CE%AC%CF%81%CF%84%CE%B5%CF%82_%CF%84%CE%BF%CF%85_%CE%95%CE%91%CE%9C-%CE%95%CE%9B%CE%91%CE%A3.jpg" width="200" height="153"><br><p>
					Despite this declared neutrality, Greece became a target for Mussolini's expansionist policies. Provocations against Greece included the sinking of the Greek cruiser Elli on 15 August 1940. Italian troops crossed the border on 28 October 1940, beginning the Greco-Italian War, but were stopped by a determined Greek defence that ultimately drove them back into Albania.</p><p>Metaxas died suddenly in January 1941. His death raised hopes for a liberalization of his regime and the restoration of parliamentary rule, but King George quashed these hopes when he retained the regime's machinery in place. In the meantime, Adolf Hitler was reluctantly forced to divert German troops to rescue Mussolini from defeat, and attacked Greece through Yugoslavia and Bulgaria on 6 April 1941. Despite British assistance, the Germans overran most of the country by the end of May. The King and the government escaped to Crete, where they stayed until the end of the Battle of Crete. They then transferred to Egypt, where a Greek government in exile was established.</p><div class="gradientback"></div></div><div class="content"><p>The occupied country of Greece was divided in three zones (German, Italian and Bulgarian) and in Athens, a puppet regime was established. The members were either conservatives or nationalists with fascist leanings. The three quisling prime ministers were Georgios Tsolakoglou, the general who had signed the armistice with the Wehrmacht, Konstantinos Logothetopoulos, and Ioannis Rallis, who took office when the German defeat was inevitable and aimed primarily at combating the left-wing Resistance movement. To this end, he created the collaborationist Security Battalions.</p><p>Greece suffered terrible privations during World War II as the Germans appropriated most of the country's agricultural production and prevented its fishing fleets from operating. As a result, and because a British blockade initially hindered foreign relief efforts, a Great Greek Famine resulted. Hundreds of thousands of Greeks perished, especially in the winter of 1941–1942. In the mountains of the Greek mainland, in the meantime, several Greek resistance movements sprang up, and by mid-1943, the Axis forces controlled only the main towns and the connecting roads, while a Free Greece was set up in the mountains.</p><p>The largest resistance group, the National Liberation Front (EAM), was controlled by the Communist Party of Greece, as was the Greek People's Liberation Army (Elas), led by Aris Velouchiotis, and a civil war soon broke out between it and non-Communist groups such as the National Republican Greek League (EDES) in those areas liberated from the Germans. The exiled government in Cairo was only intermittently in touch with the resistance movement and exercised virtually no influence in the occupied country. Part of this was due to the unpopularity of King George II in Greece itself, but despite efforts by Greek politicians, British support ensured his retention at the head of the Cairo government.</p><p>As the German defeat drew nearer, the various Greek political factions convened in Lebanon in May 1944 under British auspices and formed a government of national unity under George Papandreou, in which EAM was represented by six ministers.</p><h2>Civil War</h2><p> Main article: Greek civil war</p><p>German forces withdrew on 12 October 1944, and the government in exile returned to Athens. After the German withdrawal, the EAM-ELAS guerrilla army effectively controlled most of Greece, but its leaders were reluctant to take control of the country, as they knew that Soviet premier Joseph Stalin had agreed that Greece would be in the British sphere of influence after the war. Tensions between the British-backed Papandreou and EAM, especially over the issue of disarmament of the various armed groups, led to the resignation of the latter's ministers from the government.</p><p>A few days later, on 3 December 1944, a large-scale pro-EAM demonstration in Athens ended in violence and ushered an intense, house-to-house struggle with British and monarchist forces (the Dekemvriana). After three weeks, the Communists were defeated: the Varkiza agreement ended the conflict and disarmed ELAS, and an unstable coalition government was formed. The anti-EAM backlash grew into a full-scale White Terror, which exacerbated tensions.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/5/54/Gde.svg/220px-Gde.svg.png" width="220" height="148"><p>


				Organization and military bases of the "Democratic Army", as well as entry routes to Greece.


				</p><p>
					The Communists boycotted the March 1946 elections, and on the same day, fighting broke out again. By the end of 1946, the Communist Democratic Army of Greece had been formed, pitted against the governmental National Army, which was backed first by Britain and after 1947 by the United States.</p><p>Communist successes in 1947–1948 enabled them to move freely over much of mainland Greece, but with extensive reorganization, the deportation of rural populations and American material support, the National Army was slowly able to regain control over most of the countryside. In 1949, the insurgents suffered a major blow, as Yugoslavia closed its borders following the split between Marshal Josip Broz Tito with the Soviet Union. Finally, in August 1949, the National Army under Marshal Alexander Papagos launched an offensive that forced the remaining insurgents to surrender or flee across the northern border into the territory of Greece's northern Communist neighbors.</p><p>The civil war resulted in 100,000 killed and caused catastrophic economic disruption. In addition, at least 25,000 Greeks and an unspecified number of Macedonian Slavs were either voluntarily or forcibly evacuated to Eastern bloc countries, while 700,000 became displaced persons inside the country. Many more emigrated to Australia and other countries.</p><p>The postwar settlement ended Greece's territorial expansion, which had begun in 1832. The 1947 Treaty of Paris required Italy to hand over the Dodecanese islands to Greece. These were the last majority-Greek-speaking areas to be united with the Greek state, apart from Cyprus which was a British possession until it became independent in 1960. Greece's ethnic homogeneity was increased by the postwar expulsion of 25,000 Albanians from Epirus (see Cham Albanians). The only significant remaining minorities are the Muslims in Western Thrace (about 100,000) and a small Slavic-speaking minority in the north. Greek nationalists continued to claim southern Albania (which they called Northern Epirus), home of a significant Greek population (about 3%-12% in the whole of Albania[6]), and the Turkish-held islands of Imvros and Tenedos, where there were smaller Greek minorities.</p><h2>Postwar Greece (1950–1973)</h2><p>After the civil war, Greece sought to join the Western democracies and became a member of the North Atlantic Treaty Organization in 1952.</p><p>Since the Civil war (1946–49) but even more after that, the parties in the parliament were divided in three political concentrations. The political formation Right-Centre-Left, given the exacerbation of political animosity that had preceded dividing the country in the 40s, tended to turn the concurrence of parties into ideological positions.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/2/2f/Greece._Workmen_grade_the_street_in_front_of_new_housing_constructed_with_the_help_of_Marshall_Plan_funds_in_Greece_-_NARA_-_541700.tif/lossy-page1-220px-Greece._Workmen_grade_the_street_in_front_of_new_housing_constructed_with_the_help_of_Marshall_Plan_funds_in_Greece_-_NARA_-_541700.tif.jpg" width="220" height="178"><p>


				Workmen grade the street in front of new housing constructed with the help of Marshall Plan funds in Greece.


				</p><div class="gradientback"></div></div><div class="content"><p>
					In the beginning of the 1950s, the forces of the Centre (EPEK) succeeded in gaining the power and under the leadership of the aged general N. Plastiras they governed for about half a four-year term. These were a series of governments having limited manoeuvre ability and inadequate influence in the political arena. This government, as well as those that followed, was constantly under the American auspices. The defeat of EPEK in the elections of 1952, apart from increasing the repressive measures that concerned the defeated of the Civil war, also marked the end of the general political position that it represented, namely political consensus and social reconciliation.</p><p>The Left, which had been ostracized from the political life of the country, found a way of expression through the constitution of EDA (United Democratic Left) in 1951, which turned out to be a significant pole, yet steadily excluded from the decision making centres. After the disbandment of the Centre as an autonomous political institution, EDA practically expanded its electoral influence to a significant part of the EAM-based Centre-Left.</p><p>The 1960s are part of the period 1953-72, during which Greek economy developed rapidly and was structured within the scope of European and worldwide economic developments. One of the main characteristics of that period was the major political event - as we have come to accept it - of the country's accession in the EEC, in an attempt to create a common market. The relevant treaty was contracted in 1962.</p><p>The developmental strategy adopted by the country was embodied in centrally organized five-year plans; yet their orientation was indistinct. The average annual emigration, which absorbed the excess workforce and contributed to extremely high growth rates, exceeded the annual natural increase in population. The influx of large amounts of foreign private capital was being facilitated and consumption was expanded. These, associated with the rise of tourism, the expansion of shipping activity and with the migrant remittances, had a positive effect on the balance of payments.</p><p>The peak of development was registered principally in manufacture, mainly in the textile and chemical industry and in the sector of metallurgy, the growth rate of which tended to reach 11% during 1965-70. The other large branch where obvious economic and social consequences were brought about, was that of construction. The policy of a?t?pa???? (antiparochi, property-swap), a Greek invention which entailed the concession of construction land to developers in return for a share in the resulting multi-storey apartment buildings, favoured the creation of a class of small-medium contractors on the one hand and settled the housing system and property status on the other. However, it was also responsible for the demolition of much of the country's traditional and 19th-century neoclassical architecture, and the transformation of Greek cities, and especially Athens, into a form-less, border-less and placeless urban landscape.[7]</p><p>During that decade, youth came forth in society as a distinct social power with autonomous presence (creation of a new culture in music, fashion etc.) and displaying dynamism in the assertion of their social rights. The independence granted to Cyprus, which was mined from the very beginning, constituted the main focus of young activist mobilizations, along with struggles aiming at reforms in education, which were provisionally realized to a certain extent through the educational reform of 1964. The country reckoned on and was influenced by Europe - usually behind time - and by the current trends like never before. Thus, in a sense, the imposition of the military junta conflicted with the social and cultural occurrences.</p><h3>Greek military junta of 1967–1974</h3><p> Main article: Greek military junta of 1967–1974</p><p>The country descended into a prolonged political crisis, and elections were scheduled for late April 1967. On 21 April 1967 a group of right-wing colonels led by Colonel George Papadopoulos seized power in a coup d'état establishing the Regime of the Colonels. Civil liberties were suppressed, special military courts were established, and political parties were dissolved.</p><p>Several thousand suspected communists and political opponents were imprisoned or exiled to remote Greek islands. Alleged US support for the junta is claimed to be the cause of rising anti-Americanism in Greece during and following the junta's harsh rule. The junta's early years also saw a marked upturn in the economy, with increased foreign investment and large-scale infrastructure works. The junta was widely condemned abroad, but inside the country, discontent began to increase only after 1970, when the economy slowed down.</p><p>Even the armed forces, the regime's foundation, were not immune: In May 1973, a planned coup by the Hellenic Navy was narrowly suppressed, but led to the mutiny of the HNS Velos, whose officers sought political asylum in Italy. In response, junta leader Papadopoulos attempted to steer the regime towards a controlled democratization, abolishing the monarchy and declaring himself President of the Republic.</p><h2>Transition and democracy (1973–2009)</h2><p> Main articles: Metapolitefsi and Third Hellenic Republic</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/6/6c/Greekhistory.GIF/450px-Greekhistory.GIF" width="450" height="324"><p>


				Greek territorial changes between 1821 and 1947, showing territories awarded to Greece in 1919 and those lost in 1923.


				</p><p>
					On 25 November 1973, following the bloody suppression of Athens Polytechnic uprising on the 17th, the hardliner Brigadier Dimitrios Ioannides overthrew Papadopoulos and tried to continue the dictatorship despite the popular unrest the uprising had triggered. Ioannides' attempt in July 1974 to overthrow Archbishop Makarios, the President of Cyprus, brought Greece to the brink of war with Turkey, which invaded Cyprus and occupied part of the island.[8]</p><p>Senior Greek military officers then withdrew their support from the junta, which collapsed. Constantine Karamanlis returned from exile in France to establish a government of national unity until elections could be held. Karamanlis worked to defuse the risk of war with Turkey and also legalised the Communist Party, which had been illegal since 1947.[8] His newly organized party, New Democracy (ND), won the elections held in November 1974 by a wide margin, and he became prime minister.</p><p>Following the 1974 referendum which resulted in the abolition of the monarchy, a new constitution was approved by parliament on 19 June 1975. Parliament elected Constantine Tsatsos as President of the Republic. In the parliamentary elections of 1977, New Democracy again won a majority of seats. In May 1980, Prime Minister Karamanlis was elected to succeed Tsatsos as President. George Rallis succeeded Karamanlis as Prime Minister.</p><p>On 1 January 1981, Greece became the tenth member of the European Community (now the European Union).[9] In parliamentary elections held on 18 October 1981, Greece elected its first socialist government when the Panhellenic Socialist Movement (PASOK), led by Andreas Papandreou, won 172 of 300 seats. On 29 March 1985, after Prime Minister Papandreou declined to support President Karamanlis for a second term, Supreme Court Justice Christos Sartzetakis was elected president by the Greek parliament.</p><div class="gradientback"></div></div><div class="content"><p>Greece had two rounds of parliamentary elections in 1989; both produced weak coalition governments with limited mandates. Party leaders withdrew their support in February 1990, and elections were held on 8 April. New Democracy, led by Constantine Mitsotakis, won 150 seats in that election and subsequently gained two others. However, a split between Mitsotakis and his first Foreign Minister, Antonis Samaras, in 1992, led to Samaras' dismissal and the eventual collapse of the ND government. In new elections in September 1993, Papandreou returned to power.</p><p>On 17 January 1996, following a protracted illness, Papandreou resigned and was replaced as Prime Minister by former Minister of Trade and Industry Costas Simitis. Within days, the new prime minister had to handle a major Greek-Turkish crisis over the Imia/Kardak islands. Simitis subsequently won re-election in the 1996 and 2000 elections. In 2004, Simitis retired and George Papandreou succeeded him as PASOK leader.[10]</p><p>In the March 2004 elections, PASOK was defeated by New Democracy, led by Kostas Karamanlis, the nephew of the former President. The government called early elections in September 2007 (normally, elections would have been held in March 2008), and New Democracy again was the majority party in the Parliament. As a result of that defeat, PASOK undertook a party election for a new leader. In that contest, George Papandreou was reelected as the head of the socialist party in Greece. In the 2009 elections however, PASOK became the majority party in the Parliament and George Papandreou became Prime Minister of Greece. After PASOK lost its majority in the Parliament, ND and PASOK joined the smaller Popular Orthodox Rally in a grand coalition, pledging their parliamentary support for a government of national unity headed by former European Central Bank vice-president Lucas Papademos.</p><h2>Economic crisis (2009-present)</h2><p> Main article: Greek government-debt crisis</p><p>From late 2009, fears of a sovereign debt crisis developed among investors concerning Greece's ability to meet its debt obligations due to strong increase in government debt levels.[11][12] This led to a crisis of confidence, indicated by a widening of bond yield spreads and risk insurance on credit default swaps compared to other countries, most importantly Germany.[13][14] Downgrading of Greek government debt to junk bonds created alarm in financial markets.</p><p>On 2 May 2010, the Eurozone countries and the International Monetary Fund agreed on a €110 billion loan for Greece, conditional on the implementation of harsh austerity measures. In October 2011, Eurozone leaders also agreed on a proposal to write off 50% of Greek debt owed to private creditors, increasing the EFSF to about €1 trillion and requiring European banks to achieve 9% capitalization to reduce the risk of contagion to other countries. These austerity measures have proved extremely unpopular with the Greek public, precipitating demonstrations and civil unrest.</p><p>There are widespread fears that a Greek default on its debt would have global repercussions, endangering the economies of many other countries in the European Union, threatening the stability of the European currency, the euro, and possibly plunging the world into another recession. It has been speculated that the crisis may force Greece to abandon the euro and bring back its former currency, the drachma. In April 2014, Greece returned to the global bond market as it successfully sold €3 billion worth of five-year government bonds at a yield of 4.95%. According to the IMF, Greece will have real GDP growth of 0.6% in 2014 after 5 years of decline.</p><h3>Coalition Government</h3><p> Main article: Antonis Samaras</p><p>Following the May 2012 legislative election where the New Democracy party became the largest party in the Hellenic Parliament, Samaras, leader of ND, was asked by Greek President Karolos Papoulias to try to form a government.[15] However, after a day of hard negotiations with the other parties in Parliament, Samaras officially announced he was giving up the mandate to form a government. The task passed to Alexis Tsipras, leader of the SYRIZA (the second largest party) who was also unable to form a government.[16] After PASOK also failed to negotiate a successful agreement to form a government, emergency talks with the President ended with a new election being called while Panagiotis Pikrammenos was appointed as Prime Minister in a caretaker government.</p><p>Voters once again took to the polls in the widely watched June 2012 election. New Democracy came out on top in a stronger position with 129 seats, compared to 108 in the May election. On 20 June 2012, Samaras successfully formed a coalition with PASOK (now led by former Finance Minister Evangelos Venizelos) and DIMAR.[17] The new government would have a majority of 58, with SYRIZA, Independent Greeks (ANEL), Golden Dawn (XA) and the Communist Party (KKE) comprising the opposition. PASOK and DIMAR chose to take a limited role in Samaras' Cabinet, being represented by party officials and independent technocrats instead of MPs.[18]</p><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=First_National_Assembly_at_Epidaurus&amp;oldid=758780839"					
								Categories:  Hidden categories:</p><br><h1 lang="en">Constitution of Greece</h1><p> From Wikipedia, the free encyclopedia</p><p>The current Constitution of Greece (Greek: S??ta?µa / Sýntagma), was created by the Fifth Revisional Parliament of the Hellenes and entered into force in 1975. It has been revised three times since, most significantly in 1986, and also in 2001 and in 2008. The Constitutional history of Greece goes back to the Greek War of Independence (1821-1832), during which the first three revolutionary Greek constitutions were adopted. Syntagma Square (Plateia Syntagmatos) in Athens is named after the first constitution adopted in the modern Greek State.</p><h2>Contents</h2><h2>Context</h2><p>The Constitution consists of 120 articles and it is set out in 4 parts:</p><h2>Constitutional amendments</h2><p> Main articles: Greek constitutional amendment of 1986, Greek constitutional amendment of 2001, and Greek constitutional amendment of 2008</p><p>The Constitution of 1975 has been revised three times: in 1986, in 2001 and in 2008.</p><h2>Constitutional revision</h2><p>Parliament has the right to revise or amend the Constitution, except for the articles dealing with the Form of the State (i.e. the establishment of the presidential, parliamentary republic) and the articles safeguarding human rights and freedoms, which are unalterable. Revision of the Constitution is initiated by a motion by at least one sixth of MPs, and agreed by a supermajority of three fifths of MPs, expressed twice, in two separate votes at least one month apart. In this case, the business of revision is transferred to the next term of Parliament, i.e. after the following legislative elections. Parliament may then ratify the revision by a 50% plus one majority. If the initial motion for revision has only achieved a 50% plus one majority, then a three fifths supermajority of the new Parliament is required. A Parliament thus endowed by its predecessor with the powers of revising the Constitution is officially named a Revisional Parliament and is enumerated separately from Ordinary Parliamentary terms. In recent years, the 1974 Parliament was titled 5th Revisional, as it operated under, and amended, the 1952 constitution. The resulting constitution of 1975 was essentially an entirely new constitution, especially so since it incorporated the outcome of the 1974 plebiscite that established the presidential republic in the place of constitutional monarchy. Nevertheless, it was officially deemed a revision of the 1952 one. The 1986 parliament was the 6th Revisional; the 2001 one the 7th Revisional Parliament; the 2004 Parliament was the 11th Ordinary Parliament of the Third Hellenic Republic; the 2007 Parliament was the 8th Revisional Parliament; the 2009 Parliament was the 12th Ordinary; the first 2012 Parliament which resulted from the national election held on the 6th of May was the 13th Ordinary (also referred to as the Parliament of one day, because it formed for one day, only to be dismissed again in order for the 17th of June national election to be held, since no governmental majority could be secured) and the sitting 2012 Parliament is the 14th Ordinary. A minimum of five years must elapse after the successful conclusion of the revision process, before another may be initiated.</p><div class="gradientback"></div></div><div class="content"><h2>Constitutional history of Greece</h2><p> Main article: Constitutional history of Greece</p><p>During the modern history of Greece, the Constitution of 1975/1986/2001/2008 is the last in a series of democratically adopted Constitutions (with the exception of the Constitutions of 1968 and 1973 imposed by a dictatorship). The first of these Constitutions was adopted in 1822. The current constitution is formally a major revision of the constitution of 1952, as effected by the 5th Revisional Parliament</p><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Constitution_of_Greece&amp;oldid=782817624"					
								Categories:  Hidden categories:</p><br><h1 lang="en">Gross domestic product</h1><p> From Wikipedia, the free encyclopedia</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/7/79/Countries_by_GDP_%28Nominal%29_in_2014.svg/370px-Countries_by_GDP_%28Nominal%29_in_2014.svg.png" width="370" height="170"><p>


				A map of world economies by size of GDP (nominal) in USD, World Bank, 2014[1]



				<br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/5/5b/GDP_PPP_2016_Selection_EN.svg/270px-GDP_PPP_2016_Selection_EN.svg.png" width="270" height="270"><br>


				Selection of GDP PPP data (top 10 countries and blocks, 2016) in no particular order


				</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/5/5b/GDP_PPP_2016_Selection_EN.svg/270px-GDP_PPP_2016_Selection_EN.svg.png" width="270" height="270"><br><p>
					Gross domestic product (GDP) is a monetary measure of the market value of all final goods and services produced in a period (quarterly or yearly). Nominal GDP estimates are commonly used to determine the economic performance of a whole country or region, and to make international comparisons. Nominal GDP per capita does not, however, reflect differences in the cost of living and the inflation rates of the countries; therefore using a basis of GDP at purchasing power parity (PPP) is arguably more useful when comparing differences in living standards between nations.</p><h2>Contents</h2><h2>Definition</h2><p>The OECD defines GDP as an aggregate measure of production equal to the sum of the gross values added of all resident and institutional units engaged in production (plus any taxes, and minus any subsidies, on products not included in the value of their outputs).”[2] An IMF publication states that GDP measures the monetary value of final goods and services - that is, those that are bought by the final user - produced in a country in a given period of time (say a quarter or a year).[3]</p><p>Total GDP can also be broken down into the contribution of each industry or sector of the economy.[4] The ratio of GDP to the total population of the region is the per capita GDP and the same is called Mean Standard of Living.</p><h2>History</h2><p>William Petty came up with a basic concept of GDP to defend landlords against unfair taxation during warfare between the Dutch and the English between 1652 and 1674.[5] Charles Davenant developed the method further in 1695.[6] The modern concept of GDP was first developed by Simon Kuznets for a US Congress report in 1934.[7] In this report, Kuznets warned against its use as a measure of welfare (see below under limitations and criticisms). After the Bretton Woods conference in 1944, GDP became the main tool for measuring a country's economy.[8] At that time gross national product (GNP) was the preferred estimate, which differed from GDP in that it measured production by a country's citizens at home and abroad rather than its 'resident institutional units' (see OECD definition above). The switch from GNP to GDP in the US was in 1991, trailing behind most other nations.</p><p>The history of the concept of GDP should be distinguished from the history of changes in ways of estimating it. The value added by firms is relatively easy to calculate from their accounts, but the value added by the public sector, by financial industries, and by intangible asset creation is more complex. These activities are increasingly important in developed economies, and the international conventions governing their estimation and their inclusion or exclusion in GDP regularly change in an attempt to keep up with industrial advances. In the words of one academic economist The actual number for GDP is therefore the product of a vast patchwork of statistics and a complicated set of processes carried out on the raw data to fit them to the conceptual framework.[9]</p><h2>Determining gross domestic product (GDP)</h2><p>GDP can be determined in three ways, all of which should, in principle, give the same result. They are the production (or output or value added) approach, the income approach, or the expenditure approach.</p><p>The most direct of the three is the production approach, which sums the outputs of every class of enterprise to arrive at the total. The expenditure approach works on the principle that all of the product must be bought by somebody, therefore the value of the total product must be equal to people's total expenditures in buying things. The income approach works on the principle that the incomes of the productive factors (producers, colloquially) must be equal to the value of their product, and determines GDP by finding the sum of all producers' incomes.[10]</p><h3>Production approach</h3><p>This approach mirrors the OECD definition given above.</p><li>Estimate the gross value of domestic output out of the many various economic activities;</li><div class="gradientback"></div></div><div class="content"><li>Determine the intermediate consumption, i.e., the cost of material, supplies and services used to produce final goods or services.</li><li>Deduct intermediate consumption from gross value to obtain the gross value added.</li><p>Gross value added = gross value of output – value of intermediate consumption.</p><p>Value of output = value of the total sales of goods and services plus value of changes in the inventory.</p><p>The sum of the gross value added in the various economic activities is known as GDP at factor cost.</p><p>GDP at factor cost plus indirect taxes less subsidies on products = GDP at producer price.</p><p>For measuring output of domestic product, economic activities (i.e. industries) are classified into various sectors. After classifying economic activities, the output of each sector is calculated by any of the following two methods:</p><li>By multiplying the output of each sector by their respective market price and adding them together</li><li>By collecting data on gross sales and inventories from the records of companies and adding them together</li><p>The gross value of all sectors is then added to get the gross value added (GVA) at factor cost. Subtracting each sector's intermediate consumption from gross output gives the GDP at factor cost. Adding indirect tax minus subsidies in GDP at factor cost gives the GDP at producer prices.</p><h3>Income approach</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/9/9e/Countries_by_GDP_%28PPP%29_Per_Capita_in_2015.svg/294px-Countries_by_GDP_%28PPP%29_Per_Capita_in_2015.svg.png" width="294" height="135"><p>


				List of countries by GDP (PPP) per capita by 2014 International Monetary Fund.



				<br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/b/b2/GDP_per_capita_%28nominal%29_2015.png/294px-GDP_per_capita_%28nominal%29_2015.png" width="294" height="136"><br>


				Countries by 2015 GDP (nominal) per capita.[11]
				 




				<br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/6/69/U.S._GDP_Income_Basis.png/294px-U.S._GDP_Income_Basis.png" width="294" height="150"><br>


				U.S GDP computed on the income basis


				</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/b/b2/GDP_per_capita_%28nominal%29_2015.png/294px-GDP_per_capita_%28nominal%29_2015.png" width="294" height="136"><br><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/6/69/U.S._GDP_Income_Basis.png/294px-U.S._GDP_Income_Basis.png" width="294" height="150"><br><p>
					The second way of estimating GDP is to use the sum of primary incomes distributed by resident producer units.[2]</p><p>If GDP is calculated this way it is sometimes called gross domestic income (GDI), or GDP (I). GDI should provide the same amount as the expenditure method described later. (By definition, GDI = GDP. In practice, however, measurement errors will make the two figures slightly off when reported by national statistical agencies.)</p><p>This method measures GDP by adding incomes that firms pay households for factors of production they hire - wages for labour, interest for capital, rent for land and profits for entrepreneurship.</p><p>The US National Income and Expenditure Accounts divide incomes into five categories:</p><li>Wages, salaries, and supplementary labour income</li><li>Corporate profits</li><li>Interest and miscellaneous investment income</li><li>Farmers' incomes</li><li>Income from non-farm unincorporated businesses</li><p>These five income components sum to net domestic income at factor cost.</p><p>Two adjustments must be made to get GDP:</p><li>Indirect taxes minus subsidies are added to get from factor cost to market prices.</li><li>Depreciation (or capital consumption allowance) is added to get from net domestic product to gross domestic product.</li><p>Total income can be subdivided according to various schemes, leading to various formulae for GDP measured by the income approach. A common one is:</p><p>The sum of COE, GOS and GMI is called total factor income; it is the income of all of the factors of production in society. It measures the value of GDP at factor (basic) prices. The difference between basic prices and final prices (those used in the expenditure calculation) is the total taxes and subsidies that the government has levied or paid on that production. So adding taxes less subsidies on production and imports converts GDP at factor cost to GDP(I).</p><p>Total factor income is also sometimes expressed as:</p><h3>Expenditure approach</h3><p>The third way to estimate GDP is to calculate the sum of the final uses of goods and services (all uses except intermediate consumption) measured in purchasers' prices.[2]</p><p>Market goods which are produced are purchased by someone. In the case where a good is produced and unsold, the standard accounting convention is that the producer has bought the good from themselves. Therefore, measuring the total expenditure used to buy things is a way of measuring production. This is known as the expenditure method of calculating GDP.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/f/f6/GDP_Categories_-_United_States.png/231px-GDP_Categories_-_United_States.png" width="231" height="173"><div class="gradientback"></div></div><div class="content"><p>


				U.S. GDP computed on the expenditure basis.


				</p><p>
					GDP (Y) is the sum of consumption (C), investment (I), government spending (G) and net exports (X – M).</p><p>Here is a description of each GDP component:</p><p>Note that C, G, and I are expenditures on final goods and services; expenditures on intermediate goods and services do not count. (Intermediate goods and services are those used by businesses to produce other goods and services within the accounting year.[13])</p><p>According to the U.S. Bureau of Economic Analysis, which is responsible for calculating the national accounts in the United States, In general, the source data for the expenditures components are considered more reliable than those for the income components [see income method, below].[14]</p><h2>GDP vs GNI</h2><p>GDP can be contrasted with gross national product (GNP) or, as it is now known, gross national income (GNI). The difference is that GDP defines its scope according to location, while GNI defines its scope according to ownership. In a global context, world GDP and world GNI are, therefore, equivalent terms.</p><p>GDP is product produced within a country's borders; GNI is product produced by enterprises owned by a country's citizens. The two would be the same if all of the productive enterprises in a country were owned by its own citizens, and those citizens did not own productive enterprises in any other countries. In practice, however, foreign ownership makes GDP and GNI non-identical. Production within a country's borders, but by an enterprise owned by somebody outside the country, counts as part of its GDP but not its GNI; on the other hand, production by an enterprise located outside the country, but owned by one of its citizens, counts as part of its GNI but not its GDP.</p><p>For example, the GNI of the USA is the value of output produced by American-owned firms, regardless of where the firms are located. Similarly, if a country becomes increasingly in debt, and spends large amounts of income servicing this debt this will be reflected in a decreased GNI but not a decreased GDP. Similarly, if a country sells off its resources to entities outside their country this will also be reflected over time in decreased GNI, but not decreased GDP. This would make the use of GDP more attractive for politicians in countries with increasing national debt and decreasing assets.</p><p>Gross national income (GNI) equals GDP plus income receipts from the rest of the world minus income payments to the rest of the world.[15]</p><p>In 1991, the United States switched from using GNP to using GDP as its primary measure of production.[16] The relationship between United States GDP and GNP is shown in table 1.7.5 of the National Income and Product Accounts.[17]</p><h3>International standards</h3><p>The international standard for measuring GDP is contained in the book System of National Accounts (1993), which was prepared by representatives of the International Monetary Fund, European Union, Organization for Economic Co-operation and Development, United Nations and World Bank. The publication is normally referred to as SNA93 to distinguish it from the previous edition published in 1968 (called SNA68) [18]</p><p>SNA93 provides a set of rules and procedures for the measurement of national accounts. The standards are designed to be flexible, to allow for differences in local statistical needs and conditions.</p><h3>National measurement</h3><p>Within each country GDP is normally measured by a national government statistical agency, as private sector organizations normally do not have access to the information required (especially information on expenditure and production by governments).</p><p> Main article: National agencies responsible for GDP measurement</p><h2>Nominal GDP and adjustments to GDP</h2><p>The raw GDP figure as given by the equations above is called the nominal, historical, or current, GDP. When one compares GDP figures from one year to another, it is desirable to compensate for changes in the value of money – i.e., for the effects of inflation or deflation. To make it more meaningful for year-to-year comparisons, it may be multiplied by the ratio between the value of money in the year the GDP was measured and the value of money in a base year.</p><p>For example, suppose a country's GDP in 1990 was $100 million and its GDP in 2000 was $300 million. Suppose also that inflation had halved the value of its currency over that period. To meaningfully compare its GDP in 2000 to its GDP in 1990, we could multiply the GDP in 2000 by one-half, to make it relative to 1990 as a base year. The result would be that the GDP in 2000 equals $300 million × one-half = $150 million, in 1990 monetary terms. We would see that the country's GDP had realistically increased 50 percent over that period, not 200 percent, as it might appear from the raw GDP data. The GDP adjusted for changes in money value in this way is called the real, or constant, GDP.</p><p>The factor used to convert GDP from current to constant values in this way is called the GDP deflator. Unlike consumer price index, which measures inflation or deflation in the price of household consumer goods, the GDP deflator measures changes in the prices of all domestically produced goods and services in an economy including investment goods and government services, as well as household consumption goods.[19]</p><p>Constant-GDP figures allow us to calculate a GDP growth rate, which indicates how much a country's production has increased (or decreased, if the growth rate is negative) compared to the previous year.</p><p>Another thing that it may be desirable to account for is population growth. If a country's GDP doubled over a certain period, but its population tripled, the increase in GDP may not mean that the standard of living increased for the country's residents; the average person in the country is producing less than they were before. Per-capita GDP is a measure to account for population growth.</p><h2>Cross-border comparison and purchasing power parity</h2><p>The level of GDP in different countries may be compared by converting their value in national currency according to either the current currency exchange rate, or the purchasing power parity exchange rate.</p><p>The ranking of countries may differ significantly based on which method is used.</p><p>There is a clear pattern of the purchasing power parity method decreasing the disparity in GDP between high and low income (GDP) countries, as compared to the current exchange rate method. This finding is called the Penn effect.</p><p>For more information, see Measures of national income and output.</p><div class="gradientback"></div></div><div class="content"><h2>Standard of living and GDP: Wealth distribution and externalities</h2><p>GDP per capita is often used as an indicator of living standards.[20]</p><p>The major advantage of GDP per capita as an indicator of standard of living is that it is measured frequently, widely, and consistently. It is measured frequently in that most countries provide information on GDP on a quarterly basis, allowing trends to be seen quickly. It is measured widely in that some measure of GDP is available for almost every country in the world, allowing inter-country comparisons. It is measured consistently in that the technical definition of GDP is relatively consistent among countries.</p><p>GDP does not include several factors that influence the standard of living. In particular, it fails to account for:</p><p>It can be argued that GDP per capita as an indicator standard of living is correlated with these factors, capturing them indirectly.[20][24] As a result, GDP per capita as a standard of living is a continued usage because most people have a fairly accurate idea of what it is and know it is tough to come up with quantitative measures for such constructs as happiness, quality of life, and well-being.[20]</p><h2>Limitations and criticisms</h2><h3>Limitations at introduction</h3><p>Simon Kuznets, the economist who developed the first comprehensive set of measures of national income, stated in his first report to the US Congress in 1934, in a section titled Uses and Abuses of National Income Measurements:[7]</p><p>The valuable capacity of the human mind to simplify a complex situation in a compact characterization becomes dangerous when not controlled in terms of definitely stated criteria. With quantitative measurements especially, the definiteness of the result suggests, often misleadingly, a precision and simplicity in the outlines of the object measured. Measurements of national income are subject to this type of illusion and resulting abuse, especially since they deal with matters that are the center of conflict of opposing social groups where the effectiveness of an argument is often contingent upon oversimplification. [...]</p><p>All these qualifications upon estimates of national income as an index of productivity are just as important when income measurements are interpreted from the point of view of economic welfare. But in the latter case additional difficulties will be suggested to anyone who wants to penetrate below the surface of total figures and market values. Economic welfare cannot be adequately measured unless the personal distribution of income is known. And no income measurement undertakes to estimate the reverse side of income, that is, the intensity and unpleasantness of effort going into the earning of income. The welfare of a nation can, therefore, scarcely be inferred from a measurement of national income as defined above.</p><p>In 1962, Kuznets stated:[25]</p><p>Distinctions must be kept in mind between quantity and quality of growth, between costs and returns, and between the short and long run. Goals for more growth should specify more growth of what and for what.</p><h3>Further criticisms</h3><p>Ever since the development of GDP, multiple observers have pointed out limitations of using GDP as the overarching measure of economic and social progress.</p><p>Many environmentalists argue that GDP is a poor measure of social progress because it does not take into account harm to the environment.[26][27]</p><p>Although a high or rising level of GDP is often associated with increased economic and social progress within a country, a number of scholars have pointed out that this does not necessarily play out in many instances. For example, Jean Drèze and Amartya Sen have pointed out that an increase in GDP or in GDP growth does not necessarily lead to a higher standard of living, particularly in areas such as healthcare and education.[28] Another important area that does not necessarily improve along with GDP is political liberty, which is most notable in China, where GDP growth is strong yet political liberties are heavily restricted.[29]</p><p>GDP does not account for the distribution of income among the residents of a country, because GDP is merely an aggregate measure. An economy may be highly developed or growing rapidly, but also contain a wide gap between the rich and the poor in a society. These inequalities often occur on the lines of race, ethnicity, gender, religion, or other minority status within countries. This can lead to misleading characterizations of economic well-being if the income distribution is heavily skewed toward the high end, as the poorer residents will not directly benefit from the overall level of wealth and income generated in their country. Even GDP per capita measures may have the same downside if inequality is high. For example, South Africa during apartheid ranked high in terms of GDP per capita, but the benefits of this immense wealth and income were not shared equally among the country.[citation needed]</p><p>GDP does not take into account the value of household and other unpaid work. Some, including Martha Nussbaum, argue that this value should be included in measuring GDP, as household labor is largely a substitute for goods and services that would otherwise be purchased for value.[30] Even under conservative estimates, the value of unpaid labor in Australia has been calculated to be over 50% of the country's GDP.[31] A later study analyzed this value in other countries, with results ranging from a low of about 15% in Canada (using conservative estimates) to high of nearly 70% in the United Kingdom (using more liberal estimates). For the United States, the value was estimated to be between about 20% on the low end to nearly 50% on the high end, depending on the methodology being used.[32] Because many public policies are shaped by GDP calculations and by the related field of national accounts,[33] the non-inclusion of unpaid work in calculating GDP can create distortions in public policy, and some economists have advocated for changes in the way public policies are formed and implemented.[34]</p><p>The UK's Natural Capital Committee highlighted the shortcomings of GDP in its advice to the UK Government in 2013, pointing out that GDP focuses on flows, not stocks. As a result, an economy can run down its assets yet, at the same time, record high levels of GDP growth, until a point is reached where the depleted assets act as a check on future growth. They then went on to say that it is apparent that the recorded GDP growth rate overstates the sustainable growth rate. Broader measures of wellbeing and wealth are needed for this and there is a danger that short-term decisions based solely on what is currently measured by national accounts may prove to be costly in the long-term.</p><h3>Proposals to overcome GDP limitations</h3><p>In response to these and other limitations of using GDP, alternative approaches have emerged.</p><h2>Lists of countries by their GDP</h2><h2>Notes and references</h2><h3>Global</h3><h3>Data</h3><h3>Articles and books</h3><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Gross_domestic_product&amp;oldid=779237798"					
								Categories:  Hidden categories:</p><br><h1 lang="en">Alexis Tsipras</h1><p> From Wikipedia, the free encyclopedia</p><div class="gradientback"></div></div><div class="content"><p>Alexis Tsipras (Greek: ?????? ?s?p?a?, pronounced&nbsp;[a.'le.ksis 't?si.pras]; born 28 July 1974)[1] is the 185th and current Prime Minister of Greece, having been sworn in on 21 September 2015. He previously served as the 183rd Prime Minister of Greece from 26 January 2015 to 27 August 2015. Tsipras has been leader of the left-wing Greek political party Syriza since 4 October 2009.</p><p>Tsipras was born in Athens in 1974. He joined the Communist Youth of Greece in the late 1980s and in the 1990s was politically active in student protests against education reform plans, becoming the movement's spokesperson. He studied civil engineering at the National Technical University of Athens, graduating in 2000, and later undertook post-graduate studies in urban and regional planning. He worked as a civil engineer in the construction industry, based primarily in Athens.</p><p>From 1999 to 2003, Tsipras served as the secretary of Synaspismos Youth. He was elected as a member of the Central Committee of Synaspismos in 2004, and later the Political Secretariat. In the 2006 local election, he ran as Syriza's candidate for Mayor of Athens, winning 10.5%. In 2008, he was elected as leader of Syriza, succeeding Alekos Alavanos. He was first elected to the Hellenic Parliament representing Athens A in the 2009 election, and was re-elected in May and June 2012, subsequently becoming Leader of the Opposition and appointing his own shadow cabinet.</p><p>In January 2015, Tsipras led Syriza to victory in a snap legislative election, winning 149 out of 300 seats in the Hellenic Parliament and forming a coalition with the Independent Greeks. 20 August 2015, seven months into his term as Prime Minister he lost his majority after intraparty defections, Tsipras announced his resignation, and called for a snap election, to take place the following month. In the September 2015 election that followed, Tsipras led Syriza to another victory, winning 145 out of 300 seats and re-forming the coalition with the Independent Greeks. As Prime Minister, he has overseen negotiations regarding the Greek government-debt crisis, initiated the Greek bailout referendum and responded to the European migrant crisis.</p><p>In 2015, he was voted by TIME magazine as one of the 100 most influential people globally.[2]</p><h2>Contents</h2><h2>Early life and career</h2><p>Tsipras was born 28 July 1974 in Athens. His family has its roots in a village near Babaeski in an area of Eastern Thrace which was transferred from Turkey to Greece during the 1923 population exchange between Greece and Turkey.[3] His father was born in Epirus.[4][5] His mother was born in Eleftheroupoli.[6]</p><p>Tsipras joined the Communist Youth of Greece in the late 1980s. In the early 1990s, as a student at Ampelokipoi Multi-disciplinary High School, he was politically active in the student uprising against the controversial law of Education Minister Vasilis Kontogiannopoulos. He rose to prominence as a representative of the student movement when he was featured as a guest on a television show hosted by journalist Anna Panagiotarea. During the interview, Panagiotarea implied that Tsipras was being disingenuous in defending middle and high school students' right to absenteeism without parental notification in the context of protests.[7]</p><p>Tsipras studied civil engineering at the National Technical University of Athens, graduating in 2000, before undertaking postgraduate studies in Urban and Regional Planning following an inter-departmental MPhil at the School of Architecture of NTUA. Alongside his postgraduate studies, he began working as a civil engineer in the construction industry. He wrote several studies and projects on the theme of the city of Athens.[7][8][9]</p><p>As a university student, Tsipras joined the ranks of the renascent left-wing movement, particularly the Enceladus (Greek: ?????ad??) group, and as member of it was elected to the executive board of the students' union of the Civil Engineering School of NTUA, and also served as student representative on the University Senate. From 1995 to 1997 he was an elected member of the Central Council of the National Students Union of Greece (EFEE).[7]</p><h2>Political career, 1999–2015</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/7/76/Alexis_Tsipras3.jpg/220px-Alexis_Tsipras3.jpg" width="220" height="330"><p>


				Tsipras in Bologna giving a speech for The Other Europe alliance.


				</p><p>
					After the departure of the Communist Party of Greece from Synaspismos in 1991, Tsipras remained in the coalition. In May 1999 he became the first political secretary of Synaspismos' youth-wing, the Synaspismos Youth it was an honor to be in that role. During this period he was described as a centrist, other than the very clear radical, left-wing profile he would later maintain as leader of Synaspismos. He won many awards during this time. In November 2003 he was succeeded by Tasos Koronakis and moved on to the mother party. He managed quite efficiently to maintain a strong adherence to the policy of the party, effectively out talking both the left and right political wings. As secretary of Synaspismos Youth, he took an active part in the process of creating the Greek Social Forum and attended many of the international protests and marches against neoliberal globalization. In December 2004, at the 4th Congress of Synaspismos, he was elected a member of the party's Central Political Committee and consequently to the Political Secretariat, where he was responsible for educational and youth issues.[7]</p><p>Tsipras first entered the limelight of mainstream Greek politics during the 2006 local election when he ran for Mayor of Athens under the Anoihti Poli (Greek: ?????t? ????, Open City) Syriza ticket that gained 10.51% of the Athenian vote, finishing third overall. Tsipras won a seat on the Municipality of Athens council by virtue of him being first on the Syriza list.[7][10] He did not run for the Greek Parliament in the 2007 election, choosing to continue to complete his term as a member of the municipal council of Athens.</p><p>Tsipras was elected Leader of Synaspismos during its 5th Congress on 10 February 2008, after previous Leader Alekos Alavanos decided not to stand again due to personal reasons.[11] Tsipras became leader of Synaspismos at the age of 33, thus becoming the youngest leader of a Greek political party since 1931. In the 2009 election, he was elected to the Hellenic Parliament for Athens A and was subsequently voted unanimously to be the head of the Syriza parliamentary group.[12][13] Tsipras led SYRIZA through the 2012 elections, overseeing a swing of over 22% to the party, and becoming the Leader of the Opposition and head of the Shadow Cabinet of Alexis Tsipras.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/d/db/SYN_5th_Congress.jpg/220px-SYN_5th_Congress.jpg" width="220" height="73"><p>


				Alexis Tsipras giving his speech as a presidential candidate at the 5th Congress of Synaspismos.


				</p><div class="gradientback"></div></div><div class="content"><p>
					In December 2013 Tsipras was the first candidate proposed for the position of President of the Commission of the European Union by the European United Left–Nordic Green Left (GUE/NGL). The vote was a EU member states election to the Eur,opean Parliament in May 2014.</p><p>Tsipras campaigned as the only candidate of the south periphery countries. At the beginning of May 2014, in a speech in Berlin, he clarified many of his positions, in opposition to the allegedly Merkel-dominated neoliberal political course in Europe. Tsipras declared a substantial change for a better future for all Europeans is visible within 10 years. He addressed those who lost out in the fallout of the financial crises from 2008 to 2014, which produced unexpectedly high jobless rates in most of the EU. The speech was given in English to a German audience and intended to be listened to throughout Europe.[14] Although the GUE/NGL won in Greece, winning six of the 21 Greek seats in the European Parliament, it finished fifth in Europe overall.</p><h2>Prime Minister</h2><h3>First term (January–August 2015)</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/2/2f/Alexis_Tsipras_at_the_National_Resistance_Memorial%2C_Kaisariani.jpg/220px-Alexis_Tsipras_at_the_National_Resistance_Memorial%2C_Kaisariani.jpg" width="220" height="167"><p>


				Alexis Tsipras laying down red roses at the Kaisariani Memorial.


				</p><p>
					Tsipras led Syriza to victory in the general election held on 25 January 2015, falling short of an outright majority in Parliament by just two seats. The following morning, Tsipras reached an agreement with the right-wing populist Independent Greeks party to form a coalition.</p><p>On the same day he was sworn in by President Karolos Papoulias as the youngest Prime Minister in Greek history since 1865, using the words I declare in my name, honour and conscience to uphold the Constitution and its laws.[15] Tsipras was also the first prime minister to take a civil rather than a religious oath of office, marking a rupture with Greek orthodox ceremonial culture.[16] While reaffirming the good relations between his party and the Church, he generated further religious controversy during a meeting with Archbishop Ieronymos. Tsipras explained that as an atheist who neither married in a religious ceremony nor baptised his children, he would not take a religious oath of office.[17]</p><p>In his first act after being sworn in, Tsipras visited the Resistance Memorial in Kaisariani, laying down red roses to commemorate the 200 members of the Greek Resistance executed by the German Wehrmacht on 1 May 1944.[18]</p><p>During the first meeting of the new cabinet, Tsipras declared the priorities of his government to be the fight against the humanitarian crisis in Greece, negotiations with the EU and the International Monetary Fund on restructuring the Greek debt, and the implementation of promises made by SYRIZA such as the abolition of the previous government's privatization policies.[19]</p><p>On 3 February, Tsipras made his first official state visit, meeting with his Italian counterpart Matteo Renzi in Rome. They held a joint press conference expressing concerns about austerity measures imposed by the Juncker Commission and stated that economic growth is the only way to exit from the crisis. After the press conference, Renzi presented Tsipras with an Italian tie as a gift. Tsipras, who is notable for never wearing ties, thanked Renzi and said that he would wear the gift in celebration when Greece had successfully renegotiated the austerity measures.[20]</p><p>On 20 February, the Eurogroup came to an agreement with Greece to extend the Greek bailout for four months.[21] Tsipras had also announced a trip to Moscow on 8 April, in a bid to secure Russian support.[22]</p><p>On 31 May, Tsipras laid out his complaints and outlined his plan in a recap of events since his election. He concluded that there were at least two competing visions for the integration of Europe, both of which he seemed to reject, and that certain unnamed institutional actors had an obsession with their own technocratic programme.[23]</p><p>On 22 June, Tsipras presented a new Greek proposal, which included raising the retirement age gradually to 67 and curbing early retirement. It also offered to reform the value-added-tax system to set the main rate at 23 percent.[24] On 29 June Greek banks stayed shut and Tsipras said they would remain so to impose capital control. Trading in Greek stocks and bonds halted as well.[25][26]</p><p> Main article: Greek bailout referendum, 2015</p><p>On 27 June 2015, Tsipras announced a referendum to decide whether or not Greece should accept the bailout conditions proposed jointly by the Juncker Commission, the International Monetary Fund and the European Central Bank.</p><p>Tsipras recommended a No vote. On 3 July, during an address to at least 250,000 people gathered in the capital's Syntagma square in front of parliament, he rejected some leaders' warnings that a No result in Sunday's plebiscite could see Greece forced to leave the eurozone. He declared On Sunday, we are not simply deciding to remain in Europe—we are deciding to live with dignity in Europe.[27] The result of the referendum was 61.3 percent voting No.[28]</p><p>Fidel Castro sent a letter to Tsipras congratulating him for the victory of NO. In that letter he said that the courage of Greece was admired by the people of Latin America and Caribbean.[29]</p><p>After several days of negotiation, on 13 July 2015, Tsipras came to an agreement with lenders.[30] Greece was to get a loan of 82 to 86 billion euros, which would be handed to Greece gradually from 2015 until June 2018. In return, Greece would have to increase the VAT, reform the pension system, assure the independence of ELSTAT, automatically cut public spending to get primary surpluses, reform justice so decisions can be made faster, follow the reforms proposed by OECD, revoke the laws passed by Tsipras except for the one concerning the humanitarian crisis, recapitalize the banks, privatize 50 billion of state assets and decrease the cost of the public sector. In return, Greece would be given the Juncker package, 35 billion euros, which is meant to help the Greek economy grow.[31]</p><p>On 14 August, the Greek parliament backed the country's new bailout deal, although more than 40 MPs from Syriza voted against the deal and Tsipras had to rely on the support of the pro-European opposition: New Democracy, To Potami and PASOK. Tsipras told MPs they were facing a choice between staying alive or suicide. He also said: I have my conscience clear that it is the best we could achieve under the current balance of power in Europe, under conditions of economic and financial asphyxiation imposed upon us.[32]</p><p>On 20 August 2015, Tsipras resigned from position of the Prime Minister of Greece due to the rebellion of MPs from his own party SYRIZA and called for a snap election.[33] He made the announcement in a televised state address. After opposition parties failed to form a government, Vassiliki Thanou-Christophilou was appointed as an interim Prime Minister until elections can be held.</p><br><div class="gradientback"></div></div><div class="content"><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/c/cf/Alexis_Tsipras_on_Subversive_Festival.jpg/220px-Alexis_Tsipras_on_Subversive_Festival.jpg" width="220" height="147"><p>


				Alexis Tsipras speaking at the Subversive Festival 2013 in Zagreb, Croatia.


				</p><h3>Second term (2015–present)</h3><p>
					Despite a low turnout of only 57% versus 64% in previous elections, at the 20 September election, Tsipras received a solid vote of confidence, with Syriza achieving 35.50% of the vote,[34] enough to form an anti-austerity coalition with ANEL.[35] Among others, Tsipras appointed in his new government Dimitris Kammenos, a politician from ANEL, as deputy minister for infrastructure, transport and networks, causing reactions because of Kammenos' anti-Semitic, racist and homophobic comments on Twitter, such as accusations of 9/11 being a 'Jewish' plot.[36] The outcry against him eventually forced Kammenos to resign, being a minister for less than 12 hours.[37]</p><p>On 27 September, Tsipras talked in the Clinton Global Initiative to Bill Clinton about the need to restructure the Greek debt, to make reforms in public administration and bring investments.[38] On 30 September, Panos Kammenos, the Defense Minister, celebrated the Greek victory in the battle of Salamina, causing criticism by some due to its resemblance to the junta's celebrations of similar events with the same style.[39][40] On 9 October, Tsipras along with Panos Kammenos visited the military exercise named Parmenion, wearing a military jacket.[41]</p><p>On 22 October, Greece’s top tax collection official, Katerina Savvaidou, was sacked by Alexis Tsipras, because she had allegedly granted an extension to television stations to pay a 20 per cent tax on advertising.[42] The measures the government pushed through are causing a backlash. Farmers are threatening to bring their tractors into Athens and pharmacists have been on strike.[43] On 7 November, Tsipras received an angry reception at a refugee camp in Lesbos by around a hundred protesters, wearing life jackets and brandishing placards calling on the European Union to stop deaths by allowing asylum seekers safe and legal passage to Europe.[44] At the same day, Giannis Panousis, former Alternate Minister of Citizen Protection in the first cabinet, stated that there is connection between politicians and terrorists and that politicians of the current government want his political and physical extermination while he accused Tsipras of knowing about this. However, his accusations have not been proved yet.[45]</p><p>On 17 November, after being jeered by anarchists, Tsipras compared them in his speech in Parliament to Golden Dawn and said that there was no need for uncalled saviors who think that they can determinate life and death.[46] On 18 November, Tsipras, as the first Greek prime minister visiting Turkey's Aegean province of Izmir since the days of the Occupation of Smyrna, visited Turkey and met Prime Minister Ahmet Davutoglu; they agreed to cooperate and that there would be technical cooperation between Greek and Turkish coastal guards.[47]</p><p>On 8 May 2016, Tsipras passed in Parliament new austerity measures which included increasing taxes to middle and high level income earners and making cuts across the board that would save about three per cent of Greece’s GDP. The reforms also included removing value-added-tax discounts, cutting pensions and increasing deregulation. Tsipras called for calm on the streets but also defended the austerity package saying it fell in line with the agreement reached with the EU last year.[48] On 22 May Tsipras passed further austerity measures. Legislation included a provision for “contingency” measures, including wage and pension cuts, that would take effect automatically if budget targets were derailed next year. Taxes on cigarettes, coffee and craft beer were also raised, while an unpopular property tax was restructured to increase revenues from larger buildings. A new privatisation agency was set up which would have a 99-year remit to develop and sell state-owned property. Tsipras defended his adoption of new fiscal measures. “Spring may be almost over but we are looking forward to an economic spring and a return to growth this year,” the prime minister told parliament.[49]</p><h2>Personal life</h2><p>Tsipras is not married. His registered partner is Peristera Betty Batziana, an electrical and computer engineer. They met in 1987, at the age of 13, at Ampelokipoi Branch High School. Both eventually became members of the Communist Youth of Greece. They live together in Athens with their two sons.[50] Their youngest son's middle name is Ernesto, a tribute to Che Guevara. Tsipras is an avid football fan and, having grown up near the stadium, supports Panathinaikos, attending every home game that he can.[5] Tsipras is a self-described atheist,[51][52] making him at the time of his swearing-in among the three publicly recognised atheist heads of government and state in the European Union, along with French President François Hollande, and Czech President Miloš Zeman.[53]</p><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Alexis_Tsipras&amp;oldid=783375787"					
								Categories:  Hidden categories:</p><br><h1 lang="en">List of countries and dependencies by population</h1><p> From Wikipedia, the free encyclopedia</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/4/41/Countries_and_Dependencies_by_Population_in_2014.svg/300px-Countries_and_Dependencies_by_Population_in_2014.svg.png" width="300" height="138"><p>


				A map of world population in 2014



				<br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/3/35/World_population_percentage.png/220px-World_population_percentage.png" width="220" height="238"><br>


				World population percentage by country


				</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/3/35/World_population_percentage.png/220px-World_population_percentage.png" width="220" height="238"><br><p>
					This is a list of countries and dependent territories by population. It includes sovereign states, inhabited dependent territories and, in some cases, constituent countries of sovereign states, with inclusion within the list being primarily based on the ISO standard ISO 3166-1. For instance, the United Kingdom is considered as a single entity while the constituent countries of the Kingdom of the Netherlands are considered separately. In addition, this list includes certain states with limited recognition not found in ISO 3166-1.</p><p>The population figures do not reflect the practice of countries that report significantly different populations of citizens domestically and overall. Some countries, notably Thailand, do not report total population, exclusively counting citizens; for total populations an international agency must issue an estimate.[citation needed]</p><div class="gradientback"></div></div><div class="content"><p>Also given in percent is each country's population compared with the population of the world, which the United Nations estimated at 7.5 billion in December 2016.[1]</p><h2>Contents</h2><h2>Method</h2><p>Figures used in this chart are based on the most up to date estimate or projections[2] by the national census authority where available, and are usually rounded off. Where updated national data are not available, figures are based on the projections for 2016 by the Population Division of the United Nations Department of Economic and Social Affairs.[3]</p><p>Because the compiled figures are not collected at the same time in every country, or at the same level of accuracy, the resulting numerical comparisons may create misleading conclusions. Furthermore, the addition of figures from all countries may not equal the world total. A handful of nations have not conducted a census in over 30 years, providing high error margin estimates only.</p><p>Areas that form integral parts of sovereign states, such as the countries of the United Kingdom, are counted as part of the sovereign states concerned. Not included are other entities, such as the European Union,[Note 1] that are not sovereign states, and independent territories that do not have permanent populations, such as various countries' claims to Antarctica.</p><h2>Sovereign states and dependencies by population</h2><p>Note: All dependent territories or constituent countries that are parts of sovereign states are shown in italics.</p><p>Lists of countries by population</p><p>Continentals</p><p>Intercontinental</p><h2>Notes</h2><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=List_of_countries_and_dependencies_by_population&amp;oldid=783923779"					
								Categories:  Hidden categories:</p><br><br><img alt="This is a good article. Click here for more information." src="http://upload.wikimedia.org/wikipedia/en/thumb/9/94/Symbol_support_vote.svg/19px-Symbol_support_vote.svg.png" width="19" height="20"><br><img alt="Page semi-protected" src="http://upload.wikimedia.org/wikipedia/commons/thumb/f/fc/Padlock-silver.svg/20px-Padlock-silver.svg.png" width="20" height="20"><h1 lang="en">Greeks</h1><p> From Wikipedia, the free encyclopedia</p><p> This article is about the Greek people. For the asteroids sharing orbit with Jupiter, see List of Jupiter trojans (Greek camp). For other uses, see Greeks (disambiguation).</p><p>The Greeks or Hellenes (Greek: ?????e? ['elines]) are an ethnic group native to Greece, Cyprus, southern Albania, Turkey, Sicily, Egypt and, to a lesser extent, other countries surrounding the Mediterranean Sea. They also form a significant diaspora, with Greek communities established around the world.[43]</p><p>Greek colonies and communities have been historically established on the shores of the Mediterranean Sea and Black Sea, but the Greek people have always been centered on the Aegean and Ionian seas, where the Greek language has been spoken since the Bronze Age.[44][45] Until the early 20th century, Greeks were distributed between the Greek peninsula, the western coast of Asia Minor, the Black Sea coast, Cappadocia in central Anatolia, Egypt, the Balkans, Cyprus, and Constantinople.[45] Many of these regions coincided to a large extent with the borders of the Byzantine Empire of the late 11th century and the Eastern Mediterranean areas of ancient Greek colonization.[46] The cultural centers of the Greeks have included Athens, Thessalonica, Alexandria, Smyrna, and Constantinople at various periods.</p><p>Most ethnic Greeks live nowadays within the borders of the modern Greek state and Cyprus. The Greek genocide and population exchange between Greece and Turkey nearly ended the three millennia-old Greek presence in Asia Minor. Other longstanding Greek populations can be found from southern Italy to the Caucasus and southern Russia and Ukraine and in the Greek diaspora communities in a number of other countries. Today, most Greeks are officially registered as members of the Greek Orthodox Church.[47]</p><p>Greeks have greatly influenced and contributed to culture, arts, exploration, literature, philosophy, politics, architecture, music, mathematics, science and technology, business, cuisine, and sports, both historically and contemporarily.</p><h2>Contents</h2><h2>History</h2><p> Further information: History of Greece</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/f/fd/Proto_Greek_Area_reconstruction.png/240px-Proto_Greek_Area_reconstruction.png" width="240" height="198"><p>


				A reconstruction of the 3rd millennium BC "Proto-Greek area", by Vladimir I. Georgiev.[48]


				</p><p>
					The Greeks speak the Greek language, which forms its own unique branch within the Indo-European family of languages, the Hellenic.[45] They are part of a group of pre-modern ethnicities, described by Anthony D. Smith as an archetypal diaspora people.[49][50]</p><h3>Origins</h3><div class="gradientback"></div></div><div class="content"><p> Further information: Proto-Greek language and List of Ancient Greek tribes</p><p>The Proto-Greeks probably arrived at the area now called Greece, in the southern tip of the Balkan peninsula, at the end of the 3rd millennium BC,[51][52][note 1] The sequence of migrations into the Greek mainland during the 2nd millennium BC has to be reconstructed on the basis of the ancient Greek dialects, as they presented themselves centuries later and are therefore subject to some uncertainties. There were at least two migrations, the first being the Ionians and Aeolians, which resulted in Mycenaean Greece by the 16th century BC,[56][57] and the second, the Dorian invasion, around the 11th century BC, displacing the Arcadocypriot dialects, which descended from the Mycenaean period. Both migrations occur at incisive periods, the Mycenaean at the transition to the Late Bronze Age and the Doric at the Bronze Age collapse.</p><p>An alternative hypothesis has been put forth by linguist Vladimir Georgiev, who places Proto-Greek speakers in northwestern Greece by the Early Helladic period (3rd millennium BC), i.e. towards the end of the European Neolithic.[58] Linguists Russell Gray and Quentin Atkinson in a 2003 paper using computational methods on Swadesh lists have arrived at a somewhat earlier estimate, around 5000 BC for Greco-Armenian split and the emergence of Greek as a separate linguistic lineage around 4000 BC.[59]</p><h3>Mycenaean</h3><p> Main article: Mycenaean Greece</p><p>In c. 1600 BC, the Mycenaean Greeks borrowed from the Minoan civilization its syllabic writing system (i.e. Linear A) and developed their own syllabic script known as Linear B,[60] providing the first and oldest written evidence of Greek.[60][61] The Mycenaeans quickly penetrated the Aegean Sea and, by the 15th century BC, had reached Rhodes, Crete, Cyprus and the shores of Asia Minor.[45][62]</p><p>Around 1200 BC, the Dorians, another Greek-speaking people, followed from Epirus.[63] Traditionally, historians have believed that the Dorian invasion caused the collapse of the Mycenaean civilization, but it is likely the main attack was made by seafaring raiders (Sea Peoples) who sailed into the eastern Mediterranean around 1180 BC.[64] The Dorian invasion was followed by a poorly attested period of migrations, appropriately called the Greek Dark Ages, but by 800 BC the landscape of Archaic and Classical Greece was discernible.[65]</p><p>The Greeks of classical antiquity idealized their Mycenaean ancestors and the Mycenaean period as a glorious era of heroes, closeness of the gods and material wealth.[66] The Homeric Epics (i.e. Iliad and Odyssey) were especially and generally accepted as part of the Greek past and it was not until the 19th century that scholars began to question Homer's historicity.[65] As part of the Mycenaean heritage that survived, the names of the gods and goddesses of Mycenaean Greece (e.g. Zeus, Poseidon and Hades) became major figures of the Olympian Pantheon of later antiquity.[67]</p><h3>Classical</h3><p> Main article: Classical Greece</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/7/7a/Hoplites_fight_Louvre_E735.jpg/220px-Hoplites_fight_Louvre_E735.jpg" width="220" height="146"><p>


				Hoplites fighting. Detail from an Attic black-figure hydria, ca. 560 BC–550 BC. Louvre, Paris.


				</p><p>
					The ethnogenesis of the Greek nation is linked to the development of Pan-Hellenism in the 8th century BC.[68] According to some scholars, the foundational event was the Olympic Games in 776 BC, when the idea of a common Hellenism among the Greek tribes was first translated into a shared cultural experience and Hellenism was primarily a matter of common culture.[43] The works of Homer (i.e. Iliad and Odyssey) and Hesiod (i.e. Theogony) were written in the 8th century BC, becoming the basis of the national religion, ethos, history and mythology.[69] The Oracle of Apollo at Delphi was established in this period.[70]</p><p>The classical period of Greek civilization covers a time spanning from the early 5th century BC to the death of Alexander the Great, in 323 BC (some authors prefer to split this period into Classical, from the end of the Greco-Persian Wars to the end of the Peloponnesian War, and Fourth Century, up to the death of Alexander). It is so named because it set the standards by which Greek civilization would be judged in later eras.[71] The Classical period is also described as the Golden Age of Greek civilization, and its art, philosophy, architecture and literature would be instrumental in the formation and development of Western culture.</p><p>While the Greeks of the classical era understood themselves to belong to a common Hellenic genos,[72] their first loyalty was to their city and they saw nothing incongruous about warring, often brutally, with other Greek city-states.[73] The Peloponnesian War, the large scale civil war between the two most powerful Greek city-states Athens and Sparta and their allies, left both greatly weakened.[74]</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/e/e1/Alexander_the_Great_mosaic.jpg/220px-Alexander_the_Great_mosaic.jpg" width="220" height="132"><p>


				Alexander the Great, whose conquests led to the Hellenistic Age.


				</p><p>
					Most of the feuding Greek city-states were, in some scholars' opinions, united under the banner of Philip's and Alexander the Great's Pan-Hellenic ideals, though others might generally opt, rather, for an explanation of Macedonian conquest for the sake of conquest or at least conquest for the sake of riches, glory and power and view the ideal as useful propaganda directed towards the city-states.[75]</p><p>In any case, Alexander's toppling of the Achaemenid Empire, after his victories at the battles of the Granicus, Issus and Gaugamela, and his advance as far as modern-day Pakistan and Tajikistan,[76] provided an important outlet for Greek culture, via the creation of colonies and trade routes along the way.[77] While the Alexandrian empire did not survive its creator's death intact, the cultural implications of the spread of Hellenism across much of the Middle East and Asia were to prove long lived as Greek became the lingua franca, a position it retained even in Roman times.[78] Many Greeks settled in Hellenistic cities like Alexandria, Antioch and Seleucia.[79] Two thousand years later, there are still communities in Pakistan and Afghanistan, like the Kalash, who claim to be descended from Greek settlers.[80]</p><h3>Hellenistic</h3><p> Main article: Hellenistic Greece</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/b/b0/Diadochen1.png/250px-Diadochen1.png" width="250" height="120"><div class="gradientback"></div></div><div class="content"><p>


				The major Hellenistic realms c. 300 BC; the Ptolemaic Kingdom (dark blue) and the Seleucid Empire (yellow).



				<br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/3/3e/Kleopatra-VII.-Altes-Museum-Berlin1.jpg/140px-Kleopatra-VII.-Altes-Museum-Berlin1.jpg" width="140" height="186"><br>


				Bust of Cleopatra VII. Altes Museum, Berlin.


				</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/3/3e/Kleopatra-VII.-Altes-Museum-Berlin1.jpg/140px-Kleopatra-VII.-Altes-Museum-Berlin1.jpg" width="140" height="186"><br><p>
					The Hellenistic civilization was the next period of Greek civilization, the beginnings of which are usually placed at Alexander's death.[81] This Hellenistic age, so called because it saw the partial Hellenization of many non-Greek cultures,[82] lasted until the conquest of Egypt by Rome in 30 BC.[81]</p><p>This age saw the Greeks move towards larger cities and a reduction in the importance of the city-state. These larger cities were parts of the still larger Kingdoms of the Diadochi.[83][84] Greeks, however, remained aware of their past, chiefly through the study of the works of Homer and the classical authors.[85] An important factor in maintaining Greek identity was contact with barbarian (non-Greek) peoples, which was deepened in the new cosmopolitan environment of the multi-ethnic Hellenistic kingdoms.[85] This led to a strong desire among Greeks to organize the transmission of the Hellenic paideia to the next generation.[85] Greek science, technology and mathematics are generally considered to have reached their peak during the Hellenistic period.[86]</p><p>In the Indo-Greek and Greco-Bactrian kingdoms, Greco-Buddhism was spreading and Greek missionaries would play an important role in propagating it to China.[87] Further east, the Greeks of Alexandria Eschate became known to the Chinese people as the Dayuan.[88]</p><h3>Roman Empire</h3><p> Further information: Greco-Roman relations and Greco-Roman mysteries</p><p>Following the time of the conquest of the last of the independent Greek city-states and Hellenistic (post-Alexandrine) kingdoms, almost all of the world's Greek speakers lived as citizens or subjects of the Roman Empire. Despite their military superiority, the Romans admired and became heavily influenced by the achievements of Greek culture, hence Horace's famous statement: Graecia capta ferum victorem cepit (Greece, although captured, took its wild conqueror captive).[89]</p><p>In the religious sphere, this was a period of profound change. The spiritual revolution that took place, saw a waning of the old Greek religion, whose decline beginning in the 3rd century BC continued with the introduction of new religious movements from the East.[43] The cults of deities like Isis and Mithra were introduced into the Greek world.[84][90] Greek-speaking communities of the Hellenized East were instrumental in the spread of early Christianity in the 2nd and 3rd centuries,[91] and Christianity's early leaders and writers (notably Saint Paul) were generally Greek-speaking,[92] though none were from Greece. However, Greece itself had a tendency to cling to paganism and was not one of the influential centers of early Christianity: in fact, some ancient Greek religious practices remained in vogue until the end of the 4th century,[93] with some areas such as the southeastern Peloponnese remaining pagan until well into the 10th century AD.[94]</p><h3>Byzantine Empire</h3><p> Main article: Byzantine Greeks</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/8/84/Statue%2C_Saints_Cyril_and_Methodius%2C_Trebic%2C_Czech_Republic.JPG/160px-Statue%2C_Saints_Cyril_and_Methodius%2C_Trebic%2C_Czech_Republic.JPG" width="160" height="213"><p>


				Statues of Saints Cyril and Methodius, missionaries of Christianity among the Slavic peoples, Trebíc, Czech Republic.


				</p><p>
					Of the new eastern religions introduced into the Greek world, the most successful was Christianity. From the early centuries of the Common Era, the Greeks self-identified as Romaioi (Romans),[95] as well as Graikoi (Greeks);[96] by that time, the name Hellenes denoted pagans but was revived as an ethnonym in the 11th century.[97] While ethnic distinctions still existed in the Roman Empire, they became secondary to religious considerations and the renewed empire used Christianity as a tool to support its cohesion and promoted a robust Roman national identity.[98] According to the teachings and the dogmas of the Eastern Orthodox Church, the old idea of nationalism was not acceptable, and though was replaced by the concept of Romiosini (Romanitas, but in a Cristian Orthodox manner), which became synonymous to the civilized world.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/4/48/Family_marriage.jpg/220px-Family_marriage.jpg" width="220" height="137"><p>


				Scenes of marriage and family life in Constantinople.


				</p><p>
					Concurrently, the secular, urban civilization of Late Antiquity survived in the Eastern Mediterranean along with the Greco-Roman educational system; the Greeks' essential values were drawn from both Christianity and the Homeric tradition of their classical ancestors.[99][100]</p><p>The Eastern Roman Empire (today conventionally named the Byzantine Empire, a name not used during its own time[101]) became increasingly influenced by Greek culture after the 7th century when Emperor Heraclius (r. 610–641 AD) decided to make Greek the empire's official language.[102][103] Certainly from then on, but likely earlier, the Greek and Roman cultures were virtually fused into a single Greco-Roman world. Although the Latin West recognized the Eastern Empire's claim to the Roman legacy for several centuries, after Pope Leo III crowned Charlemagne, king of the Franks, as the Roman Emperor on 25 December 800, an act which eventually led to the formation of the Holy Roman Empire, the Latin West started to favour the Franks and began to refer to the Eastern Roman Empire largely as the Empire of the Greeks (Imperium Graecorum).[104][105]</p><div class="gradientback"></div></div><div class="content"><p>These Byzantine Greeks were largely responsible for the preservation of the literature of the classical era.[100][106][107] Byzantine grammarians were those principally responsible for carrying, in person and in writing, ancient Greek grammatical and literary studies to the West during the 15th century, giving the Italian Renaissance a major boost.[108][109] The Aristotelian philosophical tradition was nearly unbroken in the Greek world for almost two thousand years, until the Fall of Constantinople in 1453.[110]</p><p>To the Slavic world, Roman-era Greeks contributed by the dissemination of literacy and Christianity. The most notable example of the later was the work of the two Byzantine Greek brothers, the monks Saints Cyril and Methodius from the port city of Thessalonica, in Greek Macedonia, who are credited today with formalizing the first Slavic alphabet.[111]</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/a/a7/Benozzo_Gozzoli%2C_Pletone%2C_Cappella_dei_Magi.jpg/140px-Benozzo_Gozzoli%2C_Pletone%2C_Cappella_dei_Magi.jpg" width="140" height="197"><p>


				Gemistus Pletho


				</p><p>
					A distinct Greek political identity re-emerged in the 11th century in educated circles and became more forceful after the fall of Constantinople to the Crusaders of the Fourth Crusade in 1204, so that when the empire was revived in 1261, it became in many ways a Greek national state.[112] That new notion of nationhood engendered a deep interest in the classical past culminating the ideas of the Neoplatonist philosopher Gemistus Pletho, who was a supporter for the use of the old term Hellene (?????a?) and who abandoned Christianity.[112] However, it was the combination of Orthodox Christianity with a specifically Greek identity that shaped the Greeks' notion of themselves in the empire's twilight years.[112] The interest in the Classical Greek heritage was complemented by a renewed emphasis on Greek Orthodox identity, which was reinforced in the late Medieval and Ottoman Greeks' links with their fellow Orthodox Christians in the Russian Empire. These were further strengthened following the fall of the Empire of Trebizond in 1461, after which and until the second Russo-Turkish War of 1828–29 hundreds of thousands of Pontic Greeks fled or migrated from the Pontic Alps and Armenian Highlands to southern Russia and the Russian South Caucasus ( Greeks in Russia, Greeks in Armenia, Greeks in Georgia, and Caucasian Greeks).[113]</p><h3>Ottoman Empire</h3><p> Main article: Ottoman Greeks</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/5/57/Greek_merchant_16th_century_%28cropped%29.JPG/120px-Greek_merchant_16th_century_%28cropped%29.JPG" width="120" height="210"><p>


				Engraving of a Greek merchant by Cesare Vecellio (16th century).


				</p><p>
					Following the Fall of Constantinople on 29 May 1453, many Greeks sought better employment and education opportunities by leaving for the West, particularly Italy, Central Europe, Germany and Russia.[108] Greeks are greatly credited for the European cultural revolution, later called, the Renaissance. In Greek-inhabited territory itself, Greeks came to play a leading role in the Ottoman Empire, due in part to the fact that the central hub of the empire, politically, culturally, and socially, was based on Western Thrace and Greek Macedonia, both in Northern Greece, and of course was centred on the mainly Greek-populated, former Byzantine capital, Constantinople. As a direct consequence of this situation, Greek-speakers came to play a hugely important role in the Ottoman trading and diplomatic establishment, as well as in the church. Added to this, in the first half of the Ottoman period men of Greek origin made up a significant proportion of the Ottoman army, navy, and state bureaucracy, having been levied as adolescents (along with especially Albanians and Serbs) into Ottoman service through the devshirme. Many Ottomans of Greek (or Albanian or Serb) origin were therefore to be found within the Ottoman forces which governed the provinces, from Ottoman Egypt, to Ottomans occupied Yemen and Algeria, frequently as provincial governors.</p><p>For those that remained under the Ottoman Empire's millet system, religion was the defining characteristic of national groups (milletler), so the exonym Greeks (Rumlar from the name Rhomaioi) was applied by the Ottomans to all members of the Orthodox Church, regardless of their language or ethnic origin.[114] The Greek speakers were the only ethnic group to actually call themselves Romioi,[115] (as opposed to being so named by others) and, at least those educated, considered their ethnicity (genos) to be Hellenic.[116] There were, however, many Greeks who escaped the second-class status of Christians inherent in the Ottoman millet system, according to which Muslims were explicitly awarded senior status and preferential treatment. These Greeks either emigrated, particularly to their fellow Greek Orthodox protector, the Russian Empire, or simply converted to Islam, often only very superficially and whilst remaining crypto-Christian. The most notable examples of large-scale conversion to Turkish Islam among those today defined as Greek Muslims—excluding those who had to convert as a matter of course on being recruited through the devshirme—were to be found in Crete (Cretan Turks), Greek Macedonia (for example among the Vallahades of western Macedonia), and among Pontic Greeks in the Pontic Alps and Armenian Highlands. Several Ottoman sultans and princes were also of part Greek origin, with mothers who were either Greek concubines or princesses from Byzantine noble families, one famous example being sultan Selim the Grim (r. 1517–1520), whose mother Gülbahar Hatun was a Pontic Greek.</p><p>The roots of Greek success in the Ottoman Empire can be traced to the Greek tradition of education and commerce exemplified in the Phanariotes.[117] It was the wealth of the extensive merchant class that provided the material basis for the intellectual revival that was the prominent feature of Greek life in the half century and more leading to the outbreak of the Greek War of Independence in 1821.[118] Not coincidentally, on the eve of 1821, the three most important centres of Greek learning were situated in Chios, Smyrna and Aivali, all three major centres of Greek commerce.[118] Greek success was also favoured by Greek domination of the Christian Orthodox church.</p><h3>Modern</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/f/fd/Hermes_the_scholar.jpg/140px-Hermes_the_scholar.jpg" width="140" height="221"><div class="gradientback"></div></div><div class="content"><p>


				The cover of Hermes o Logios, a Greek literary publication of the late 18th and early 19th century with major contribution to the Modern Greek Enlightenment.


				</p><p>
					The relationship between ethnic Greek identity and Greek Orthodox religion continued after the creation of the modern Greek nation-state in 1830. According to the second article of the first Greek constitution of 1822, a Greek was defined as any native Christian resident of the Kingdom of Greece, a clause removed by 1840.[119] A century later, when the Treaty of Lausanne was signed between Greece and Turkey in 1923, the two countries agreed to use religion as the determinant for ethnic identity for the purposes of population exchange, although most of the Greeks displaced (over a million of the total 1.5 million) had already been driven out by the time the agreement was signed.[note 2][120] The Greek genocide, in particular the harsh removal of Pontian Greeks from the southern shore area of the Black Sea, contemporaneous with and following the failed Greek Asia Minor Campaign, was part of this process of Turkification of the Ottoman Empire and the placement of its economy and trade, then largely in Greek hands under ethnic Turkish control.[121]</p><h2>Identity</h2><p>The terms used to define Greekness have varied throughout history but were never limited or completely identified with membership to a Greek state.[122] By Western standards, the term Greeks has traditionally referred to any native speakers of the Greek language, whether Mycenaean, Byzantine or modern Greek.[114][123] Byzantine Greeks self-identified as Romaioi (Romans), Graikoi (Greeks) and Christianoi (Christians) since they were the political heirs of imperial Rome, the descendants of their classical Greek forebears and followers of the Apostles;[124] during the mid-to-late Byzantine period (11th–13th century), a growing number of Byzantine Greek intellectuals deemed themselves Hellenes although for most Greek-speakers, Hellene still meant pagan.[97][125] On the eve of the Fall of Constantinople the Last Emperor urged his soldiers to remember that they were the descendants of Greeks and Romans.[126]</p><p>Before the establishment of the modern Greek nation-state, the link between ancient and modern Greeks was emphasized by the scholars of Greek Enlightenment especially by Rigas Feraios. In his Political Constitution, he addresses to the nation as the people descendant of the Greeks.[127] The modern Greek state was created in 1829, when the Greeks liberated a part of their historic homelands, Peloponnese, from the Ottoman Empire.[128] The large Greek diaspora and merchant class were instrumental in transmitting the ideas of western romantic nationalism and philhellenism,[118] which together with the conception of Hellenism, formulated during the last centuries of the Byzantine Empire, formed the basis of the Diafotismos and the current conception of Hellenism.[112][114][129]</p><p>The Greeks today are a nation in the meaning of an ethnos, defined by possessing Greek culture and having a Greek mother tongue, not by citizenship, race, and religion or by being subjects of any particular state.[130] In ancient and medieval times and to a lesser extent today the Greek term was genos, which also indicates a common ancestry.[131][132]</p><h3>Names</h3><p> Main articles: Achaeans (Homer) and Names of the Greeks</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/1/17/Ancient_Regions_Mainland_Greece.png/220px-Ancient_Regions_Mainland_Greece.png" width="220" height="255"><p>


				Map showing the major regions of mainland ancient Greece, and adjacent "barbarian" lands.


				</p><p>
					Greeks and Greek-speakers have used different names to refer to themselves collectively. The term Achaeans (??a???) is one of the collective names for the Greeks in Homer's Iliad and Odyssey (the Homeric long-haired Achaeans would have been a part of the Mycenaean civilization that dominated Greece from c. 1600 BC until 1100 BC). The other common names are Danaans (?a?a??) and Argives (???e???) while Panhellenes (?a??????e?) and Hellenes (?????e?) both appear only once in the Iliad;[133] all of these terms were used, synonymously, to denote a common Greek identity.[134][135] In the historical period, Herodotus identified the Achaeans of the northern Peloponnese as descendants of the earlier, Homeric Achaeans.[136]</p><p>Homer refers to the Hellenes (/'h?li?nz/) as a relatively small tribe settled in Thessalic Phthia, with its warriors under the command of Achilleus.[137] The Parian Chronicle says that Phthia was the homeland of the Hellenes and that this name was given to those previously called Greeks (G?a????).[138] In Greek mythology, Hellen, the patriarch of the Hellenes who ruled around Phthia, was the son of Pyrrha and Deucalion, the only survivors after the Great Deluge.[139] The Greek philosopher Aristotle names ancient Hellas as an area in Epirus between Dodona and the Achelous river, the location of the Great Deluge of Deucalion, a land occupied by the Selloi and the Greeks who later came to be known as Hellenes.[140] In the Homeric tradition, the Selloi were the priests of Dodonian Zeus.[141]</p><p>In the Hesiodic Catalogue of Women, Graecus is presented as the son of Zeus and Pandora II, sister of Hellen the patriarch of the Hellenes.[142] According to the Parian Chronicle, when Deucalion became king of Phthia, the Graikoi (G?a????) were named Hellenes.[138] Aristotle notes in his Meteorologica that the Hellenes were related to the Graikoi.[140]</p><h3>Continuity</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/2/27/Funerary_stele.jpg/220px-Funerary_stele.jpg" width="220" height="165"><p>


				Family group on a funerary stele from Athens, National Archaeological Museum, Athens.


				</p><p>
					The most obvious link between modern and ancient Greeks is their language, which has a documented tradition from at least the 14th century BC to the present day, albeit with a break during the Greek Dark Ages (lasting from the 11th to the 8th century BC).[143] Scholars compare its continuity of tradition to Chinese alone.[143][144] Since its inception, Hellenism was primarily a matter of common culture and the national continuity of the Greek world is a lot more certain than its demographic.[43][145] Yet, Hellenism also embodied an ancestral dimension through aspects of Athenian literature that developed and influenced ideas of descent based on autochthony.[146] During the later years of the Eastern Roman Empire, areas such as Ionia and Constantinople experienced a Hellenic revival in language, philosophy, and literature and on classical models of thought and scholarship.[145] This revival provided a powerful impetus to the sense of cultural affinity with ancient Greece and its classical heritage.[145] Throughout their history, the Greeks have retained their language and alphabet, certain values and cultural traditions, customs, a sense of religious and cultural difference and exclusion (the word barbarian was used by 12th-century historian Anna Komnene to describe non-Greek speakers),[147] a sense of Greek identity and common sense of ethnicity despite the undeniable socio-political changes of the past two millennia.[145] In recent anthropological studies, both ancient and modern Greek osteological samples were analyzed demonstrating a bio-genetic affinity and continuity shared between both groups.[148][149]</p><div class="gradientback"></div></div><div class="content"><h3>Demographics</h3><p> Main articles: Demographics of Greece and Demographics of Cyprus</p><p>Today, Greeks are the majority ethnic group in the Hellenic Republic,[150] where they constitute 93% of the country's population,[151] and the Republic of Cyprus where they make up 78% of the island's population (excluding Turkish settlers in the occupied part of the country).[152] Greek populations have not traditionally exhibited high rates of growth; a large percentage of Greek population growth since Greece's foundation in 1832 was attributed to annexation of new territories, as well as the influx of 1.5 million Greek refugees after the 1923 population exchange between Greece and Turkey.[153] About 80% of the population of Greece is urban, with 28% concentrated in the city of Athens.[154]</p><p>Greeks from Cyprus have a similar history of emigration, usually to the English-speaking world because of the island's colonization by the British Empire. Waves of emigration followed the Turkish invasion of Cyprus in 1974, while the population decreased between mid-1974 and 1977 as a result of emigration, war losses, and a temporary decline in fertility.[155] After the ethnic cleansing of a third of the Greek population of the island in 1974,[156][157] there was also an increase in the number of Greek Cypriots leaving, especially for the Middle East, which contributed to a decrease in population that tapered off in the 1990s.[155] Today more than two-thirds of the Greek population in Cyprus is urban.[155]</p><p>There is a sizeable Greek minority of approximately 200,000 people in Albania.[14] The Greek minority of Turkey, which numbered upwards of 200,000 people after the 1923 exchange, has now dwindled to a few thousand, after the 1955 Constantinople Pogrom and other state sponsored violence and discrimination.[158] This effectively ended, though not entirely, the three-thousand-year-old presence of Hellenism in Asia Minor.[159][160] There are smaller Greek minorities in the rest of the Balkan countries, the Levant and the Black Sea states, remnants of the Old Greek Diaspora (pre-19th century).[161]</p><h3>Diaspora</h3><p> Main article: Greek diaspora</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/7/70/ZachGalifianakisMar07.jpg/150px-ZachGalifianakisMar07.jpg" width="150" height="183"><p>


				Zach Galifianakis, American stand-up comedian and actor of Greek ancestry.


				</p><p>
					The total number of Greeks living outside Greece and Cyprus today is a contentious issue. Where Census figures are available, they show around 3 million Greeks outside Greece and Cyprus. Estimates provided by the SAE - World Council of Hellenes Abroad put the figure at around 7 million worldwide.[162] According to George Prevelakis of Sorbonne University, the number is closer to just below 5 million.[161] Integration, intermarriage, and loss of the Greek language influence the self-identification of the Omogeneia. Important centres of the New Greek Diaspora today are London, New York, Melbourne and Toronto.[161] In 2010, the Hellenic Parliament introduced a law that enables Diaspora Greeks in Greece to vote in the elections of the Greek state.[163] This law was later repealed in early 2014.[164]</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/a/a9/Griechischen_und_ph%C3%B6nizischen_Kolonien.jpg/220px-Griechischen_und_ph%C3%B6nizischen_Kolonien.jpg" width="220" height="125"><p>


				Greek colonization in antiquity.


				</p><p>
					In ancient times, the trading and colonizing activities of the Greek tribes and city states spread the Greek culture, religion and language around the Mediterranean and Black Sea basins, especially in Sicily and southern Italy (also known as Magna Grecia), Spain, the south of France and the Black sea coasts.[165] Under Alexander the Great's empire and successor states, Greek and Hellenizing ruling classes were established in the Middle East, India and in Egypt.[165] The Hellenistic period is characterized by a new wave of Greek colonization that established Greek cities and kingdoms in Asia and Africa.[166] Under the Roman Empire, easier movement of people spread Greeks across the Empire and in the eastern territories, Greek became the lingua franca rather than Latin.[102] The modern-day Griko community of southern Italy, numbering about 60,000,[18][19] may represent a living remnant of the ancient Greek populations of Italy.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/b/bc/Distribution_Of_Races_1918_National_Geographic.jpg/220px-Distribution_Of_Races_1918_National_Geographic.jpg" width="220" height="118"><p>


				Distribution of ethnic groups in 1918, National Geographic



				<br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/e/e4/50_largest_Greek_diaspora.png/220px-50_largest_Greek_diaspora.png" width="220" height="96"><br>


				Greek Diaspora (20th century).


				</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/e/e4/50_largest_Greek_diaspora.png/220px-50_largest_Greek_diaspora.png" width="220" height="96"><br><p>
					During and after the Greek War of Independence, Greeks of the diaspora were important in establishing the fledgling state, raising funds and awareness abroad.[167] Greek merchant families already had contacts in other countries and during the disturbances many set up home around the Mediterranean (notably Marseilles in France, Livorno in Italy, Alexandria in Egypt), Russia (Odessa and Saint Petersburg), and Britain (London and Liverpool) from where they traded, typically in textiles and grain.[168] Businesses frequently comprised the extended family, and with them they brought schools teaching Greek and the Greek Orthodox Church.[168]</p><div class="gradientback"></div></div><div class="content"><p>As markets changed and they became more established, some families grew their operations to become shippers, financed through the local Greek community, notably with the aid of the Ralli or Vagliano Brothers.[169] With economic success, the Diaspora expanded further across the Levant, North Africa, India and the USA.[169][170]</p><p>In the 20th century, many Greeks left their traditional homelands for economic reasons resulting in large migrations from Greece and Cyprus to the United States, Great Britain, Australia, Canada, Germany, and South Africa, especially after the Second World War (1939–1945), the Greek Civil War (1946–1949), and the Turkish Invasion of Cyprus in 1974.[171]</p><p>While official figures remain scarce, polls and anecdotal evidence point to renewed Greek emigration as a result of the Greek financial crisis.[172] According to data published by the Federal Statistical Office of Germany in 2011, 23,800 Greeks emigrated to Germany, a significant increase over the previous year. By comparison, about 9,000 Greeks emigrated to Germany in 2009 and 12,000 in 2010.[173][174]</p><h2>Culture</h2><p> Main article: Culture of Greece</p><p>Greek culture has evolved over thousands of years, with its beginning in the Mycenaean civilization, continuing through the classical era, the Hellenistic period, the Roman and Byzantine periods and was profoundly affected by Christianity, which it in turn influenced and shaped.[175] Ottoman Greeks had to endure through several centuries of adversity that culminated in genocide in the 20th century.[176][177] The Diafotismos is credited with revitalizing Greek culture and giving birth to the synthesis of ancient and medieval elements that characterize it today.[112][114]</p><h3>Language</h3><p> Main article: Greek language</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/a/a5/AGMA_Ostrakon_Cimon.jpg/220px-AGMA_Ostrakon_Cimon.jpg" width="220" height="139"><p>


				Ancient Greek Ostracon bearing the name of Cimon. Museum of the Ancient Agora, Athens.


				</p><p>
					Most Greeks speak the Greek language, an Indo-European language that forms a branch itself, with its closest relations being Armenian (see Graeco-Armenian) and the Indo-Iranian languages (see Graeco-Aryan).[143] It has one of the longest documented histories of any language and Greek literature has a continuous history of over 2,500 years.[178] Several notable literary works, including the Homeric epics, Euclid's Elements and the New Testament, were originally written in Greek.</p><p>Greek demonstrates several linguistic features that are shared with other Balkan languages, such as Albanian, Bulgarian and Eastern Romance languages (see Balkan sprachbund), and has absorbed many foreign words, primarily of Western European and Turkish origin.[179] Because of the movements of Philhellenism and the Diafotismos in the 19th century, which emphasized the modern Greeks' ancient heritage, these foreign influences were excluded from official use via the creation of Katharevousa, a somewhat artificial form of Greek purged of all foreign influence and words, as the official language of the Greek state. In 1976, however, the Hellenic Parliament voted to make the spoken Dimotiki the official language, making Katharevousa obsolete.[180]</p><p>Modern Greek has, in addition to Standard Modern Greek or Dimotiki, a wide variety of dialects of varying levels of mutual intelligibility, including Cypriot, Pontic, Cappadocian, Griko and Tsakonian (the only surviving representative of ancient Doric Greek).[181] Yevanic is the language of the Romaniotes, and survives in small communities in Greece, New York and Israel. In addition to Greek, many Greeks in Greece and the Diaspora are bilingual in other languages or dialects such as English, Arvanitika/Albanian, Aromanian, Macedonian Slavic, Russian and Turkish.[143][182]</p><h3>Religion</h3><p> Main articles: Religion in ancient Greece and Orthodox Church</p><p>Most Greeks are Christians, belonging to the Greek Orthodox Church.[183] During the first centuries after Jesus Christ, the New Testament was originally written in Koine Greek, which remains the liturgical language of the Greek Orthodox Church, and most of the early Christians and Church Fathers were Greek-speaking.[175] There are small groups of ethnic Greeks adhering to other Christian denominations like Greek Catholics, Greek Evangelicals, Pentecostals, and groups adhering to other religions including Romaniot and Sephardic Jews and Greek Muslims. About 2,000 Greeks are members of Hellenic Polytheistic Reconstructionism congregations.[184][185][186]</p><p>Greek-speaking Muslims live mainly outside Greece in the contemporary era. There are both Christian and Muslim Greek-speaking communities in Lebanon and Syria, while in the Pontus region of Turkey there is a large community of indeterminate size who were spared from the population exchange because of their religious affiliation.[187]</p><h3>Arts</h3><p>Greek art has a long and varied history. Greeks have contributed to the visual, literary and performing arts.[188] In the West, classical Greek art was influential in shaping the Roman and later the modern Western artistic heritage. Following the Renaissance in Europe, the humanist aesthetic and the high technical standards of Greek art inspired generations of European artists.[188] Well into the 19th century, the classical tradition derived from Greece played an important role in the art of the Western world.[189] In the East, Alexander the Great's conquests initiated several centuries of exchange between Greek, Central Asian and Indian cultures, resulting in Greco-Buddhist art, whose influence reached as far as Japan.[190]</p><p>Byzantine Greek art, which grew from classical art and adapted the pagan motifs in the service of Christianity, provided a stimulus to the art of many nations.[191] Its influences can be traced from Venice in the West to Kazakhstan in the East.[191][192] In turn, Greek art was influenced by eastern civilizations (i.e. Egypt, Persia, etc.) during various periods of its history.[193]</p><p>Notable modern Greek artists include Renaissance painter Dominikos Theotokopoulos (El Greco), Panagiotis Doxaras, Nikolaos Gyzis, Nikiphoros Lytras, Yannis Tsarouchis, Nikos Engonopoulos, Constantine Andreou, Jannis Kounellis, sculptors such as Leonidas Drosis, Georgios Bonanos, Yannoulis Chalepas and Joannis Avramidis, conductor Dimitri Mitropoulos, soprano Maria Callas, composers such as Mikis Theodorakis, Nikos Skalkottas, Iannis Xenakis, Manos Hatzidakis, Eleni Karaindrou, Yanni and Vangelis, one of the best-selling singers worldwide Nana Mouskouri and poets such as Kostis Palamas, Dionysios Solomos, Angelos Sikelianos and Yannis Ritsos. Alexandrian Constantine P. Cavafy and Nobel laureates Giorgos Seferis and Odysseas Elytis are among the most important poets of the 20th century. Novel is also represented by Alexandros Papadiamantis and Nikos Kazantzakis.</p><p>Notable Greek actors include Marika Kotopouli, Melina Mercouri, Ellie Lambeti, Academy Award winner Katina Paxinou, Dimitris Horn, Manos Katrakis and Irene Papas. Alekos Sakellarios, Michael Cacoyannis and Theo Angelopoulos are among the most important directors.</p><h3>Science</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/2/2b/Aristarchus_working.jpg/220px-Aristarchus_working.jpg" width="220" height="146"><div class="gradientback"></div></div><div class="content"><p>


				Aristarchus of Samos was the first known individual to propose a heliocentric system, in the 3rd century BC


				</p><p>
					The Greeks of the Classical and Hellenistic eras made seminal contributions to science and philosophy, laying the foundations of several western scientific traditions, such as astronomy, geography, historiography, mathematics, medicine and philosophy. The scholarly tradition of the Greek academies was maintained during Roman times with several academic institutions in Constantinople, Antioch, Alexandria and other centers of Greek learning, while Byzantine science was essentially a continuation of classical science.[194] Greeks have a long tradition of valuing and investing in paideia (education).[85] Paideia was one of the highest societal values in the Greek and Hellenistic world while the first European institution described as a university was founded in 5th century Constantinople and operated in various incarnations until the city's fall to the Ottomans in 1453.[195] The University of Constantinople was Christian Europe's first secular institution of higher learning since no theological subjects were taught,[196] and considering the original meaning of the world university as a corporation of students, the world's first university as well.[195]</p><p>As of 2007, Greece had the eighth highest percentage of tertiary enrollment in the world (with the percentages for female students being higher than for male) while Greeks of the Diaspora are equally active in the field of education.[154] Hundreds of thousands of Greek students attend western universities every year while the faculty lists of leading Western universities contain a striking number of Greek names.[197] Notable modern Greek scientists of modern times include Dimitrios Galanos, Georgios Papanikolaou (inventor of the Pap test), Nicholas Negroponte, Constantin Carathéodory, Manolis Andronikos, Michael Dertouzos, John Argyris, Panagiotis Kondylis, John Iliopoulos (2007 Dirac Prize for his contributions on the physics of the charm quark, a major contribution to the birth of the Standard Model, the modern theory of Elementary Particles), Joseph Sifakis (2007 Turing Award, the Nobel Prize of Computer Science), Christos Papadimitriou (2002 Knuth Prize, 2012 Gödel Prize), Mihalis Yannakakis (2005 Knuth Prize) and Dimitri Nanopoulos.</p><h3>Symbols</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/c/c7/Flag_of_the_Greek_Orthodox_Church.svg/180px-Flag_of_the_Greek_Orthodox_Church.svg.png" width="180" height="120"><p>


				The flag of the Greek Orthodox Church is based on the coat of arms of the Palaiologoi, the last dynasty of the Byzantine Empire.



				<br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/e/ee/Greek_Independence_1821.svg/180px-Greek_Independence_1821.svg.png" width="180" height="120"><br>


				Traditional Greek flag.


				</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/e/ee/Greek_Independence_1821.svg/180px-Greek_Independence_1821.svg.png" width="180" height="120"><br><p>
					The most widely used symbol is the flag of Greece, which features nine equal horizontal stripes of blue alternating with white representing the nine syllables of the Greek national motto Eleftheria i Thanatos (Freedom or Death), which was the motto of the Greek War of Independence.[198] The blue square in the upper hoist-side corner bears a white cross, which represents Greek Orthodoxy. The Greek flag is widely used by the Greek Cypriots, although Cyprus has officially adopted a neutral flag to ease ethnic tensions with the Turkish Cypriot minority (see flag of Cyprus).[199]</p><p>The pre-1978 (and first) flag of Greece, which features a Greek cross (crux immissa quadrata) on a blue background, is widely used as an alternative to the official flag, and they are often flown together. The national emblem of Greece features a blue escutcheon with a white cross surrounded by two laurel branches. A common design involves the current flag of Greece and the pre-1978 flag of Greece with crossed flagpoles and the national emblem placed in front.[200]</p><p>Another highly recognizable and popular Greek symbol is the double-headed eagle, the imperial emblem of the last dynasty of the Eastern Roman Empire and a common symbol in Asia Minor and, later, Eastern Europe.[201] It is not part of the modern Greek flag or coat-of-arms, although it is officially the insignia of the Greek Army and the flag of the Church of Greece. It had been incorporated in the Greek coat of arms between 1925 and 1926.[202]</p><h3>Surnames and personal names</h3><p>Greek surnames began to appear in the 9th and 10th century, at first among ruling families, eventually supplanting the ancient tradition of using the father's name as disambiguator.[203][204] Nevertheless, Greek surnames are most commonly patronymics,[203] such those ending in the suffix -opoulos or -ides, while others derive from trade professions, physical characteristics, or a location such as a town, village, or monastery.[204] Commonly, Greek male surnames end in -s, which is the common ending for Greek masculine proper nouns in the nominative case. Occasionally (especially in Cyprus), some surnames end in -ou, indicating the genitive case of a patronymic name.[205] Many surnames end in suffixes that are associated with a particular region, such as -akis (Crete), -eas or -akos (Mani Peninsula), -atos (island of Cephalonia), and so forth.[204] In addition to a Greek origin, some surnames have Turkish or Latin/Italian origin, especially among Greeks from Asia Minor and the Ionian Islands, respectively.[206] Female surnames end in a vowel and are usually the genitive form of the corresponding males surname, although this usage is not followed in the diaspora, where the male version of the surname is generally used.</p><p>With respect to personal names, the two main influences are Christianity and classical Hellenism; ancient Greek nomenclatures were never forgotten but have become more widely bestowed from the 18th century onwards.[204] As in antiquity, children are customarily named after their grandparents, with the first born male child named after the paternal grandfather, the second male child after the maternal grandfather, and similarly for female children.[207] Personal names are often familiarized by a diminutive suffix, such as -akis for male names and -itsa or -oula for female names.[204] Greeks generally do not use middle names, instead using the genitive of the father's first name as a middle name. This usage has been passed on to the Russians and other East Slavs (otchestvo).</p><h3>Sea</h3><p> Main article: Greek shipping</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/4/46/Aristotle_Onassis.JPG/200px-Aristotle_Onassis.JPG" width="200" height="218"><div class="gradientback"></div></div><div class="content"><p>


				Aristotle Onassis, the best known Greek shipping magnate.


				</p><p>
					The traditional Greek homelands have been the Greek peninsula and the Aegean Sea, Southern Italy (Magna Graecia), the Black Sea, the Ionian coasts of Asia Minor and the islands of Cyprus and Sicily. In Plato's Phaidon, Socrates remarks, we (Greeks) live around a sea like frogs around a pond when describing to his friends the Greek cities of the Aegean.[208][209] This image is attested by the map of the Old Greek Diaspora, which corresponded to the Greek world until the creation of the Greek state in 1832. The sea and trade were natural outlets for Greeks since the Greek peninsula is rocky and does not offer good prospects for agriculture.[43]</p><p>Notable Greek seafarers include people such as Pytheas of Marseilles, Scylax of Caryanda who sailed to Iberia and beyond, Nearchus, the 6th century merchant and later monk Cosmas Indicopleustes (Cosmas who Sailed to India) and the explorer of the Northwestern Passage, Apostolos Valerianos also known as Juan de Fuca.[210] In later times, the Byzantine Greeks plied the sea-lanes of the Mediterranean and controlled trade until an embargo imposed by the Byzantine emperor on trade with the Caliphate opened the door for the later Italian pre-eminence in trade.[211]</p><p>The Greek shipping tradition recovered during Ottoman rule when a substantial merchant middle class developed, which played an important part in the Greek War of Independence.[112] Today, Greek shipping continues to prosper to the extent that Greece has the largest merchant fleet in the world, while many more ships under Greek ownership fly flags of convenience.[154] The most notable shipping magnate of the 20th century was Aristotle Onassis, others being Yiannis Latsis, George Livanos, and Stavros Niarchos.[212][213]</p><h2>Physical appearance</h2><p>A study from 2013 for prediction of hair and eye colour from DNA of the Greek people showed that the self-reported phenotype frequencies according to hair and eye colour categories was as follows: 119 individuals – hair colour, 11 was blond, 45 dark blond/light brown, 49 dark brown, 3 brown red/auburn and 11 had black hair; eye colour, 13 with blue, 15 with intermediate (green, heterochromia) and 91 had brown eye colour.[214]</p><p>Another study from 2012 included 150 dental school students from the University of Athens, and the results of the study showed that light hair colour (blonde/light ash brown) was predominant in 10.7% of the students. 36% had medium hair colour (light brown/medium darkest brown), 32% had darkest brown and 21% black (15.3 off black, 6% midnight black). In conclusion, the hair colour of young Greeks are mostly brown, ranging from light to dark brown with significant minorities having black and blonde hair. The same study also showed that the eye colour of the students was 14.6% blue/green, 28% medium (light brown) and 57.4% dark brown.[215]</p><h2>Timeline</h2><p>The history of the Greek people is closely associated with the history of Greece, Cyprus, Constantinople, Asia Minor and the Black Sea. During the Ottoman rule of Greece, a number of Greek enclaves around the Mediterranean were cut off from the core, notably in Southern Italy, the Caucasus, Syria and Egypt. By the early 20th century, over half of the overall Greek-speaking population was settled in Asia Minor (now Turkey), while later that century a huge wave of migration to the United States, Australia, Canada and elsewhere created the modern Greek diaspora.</p><h2>Notes</h2><li>^ Though there is a range of interpretations; Carl Blegen dates the arrival of the Greeks around 1900 BC, John Caskey believes that there were two waves of immigrants and Robert Drews places the event as late as 1600 BC.[53][54] A variety of more theories has also been supported,[55] but there is a general consensus that the coming of the Greek tribes occurred around 2100 BC.</li><li>^ While Greek authorities signed the agreement legalizing the population exchange this was done on the insistence of Mustafa Kemal Atatürk and after a million Greeks had already been expelled from Asia Minor (Gilbar 1997, p.&nbsp;8).</li><h2>Citations</h2><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Greeks&amp;oldid=782495608"					
								Categories:  Hidden categories:</p><br><br><img alt="Page semi-protected" src="http://upload.wikimedia.org/wikipedia/commons/thumb/f/fc/Padlock-silver.svg/20px-Padlock-silver.svg.png" width="20" height="20"><h1 lang="en">Coordinated Universal Time</h1><p> From Wikipedia, the free encyclopedia</p><p> This article is about the time standard abbreviated as "UTC". For the time offset between UTC-1 and UTC+1, see UTC±00:00.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/e/e8/Standard_World_Time_Zones.png/440px-Standard_World_Time_Zones.png" width="440" height="233"><p>


				World map of current time zones


				</p><p>
					Coordinated Universal Time (French: Temps universel coordonné), abbreviated to UTC, is the primary time standard by which the world regulates clocks and time. It is within about 1 second of mean solar time at 0° longitude;[1] it does not observe daylight saving time. It is one of several closely related successors to Greenwich Mean Time (GMT). For most purposes, UTC is considered interchangeable with GMT, but GMT is no longer precisely defined by the scientific community.</p><p>The first Coordinated Universal Time was informally adopted on 1 January 1960.[2]</p><div class="gradientback"></div></div><div class="content"><p>The system was adjusted several times, including a brief period where time coordination radio signals broadcast both UTC and Stepped Atomic Time (SAT) until a new UTC was adopted in 1970 and implemented in 1972. This change also adopted leap seconds to simplify future adjustments. This CCIR Recommendation 460 stated that (a) carrier frequencies and time intervals should be maintained constant and should correspond to the definition of the SI second; (b) step adjustments, when necessary, should be exactly 1 s to maintain approximate agreement with Universal Time (UT); and (c) standard signals should contain information on the difference between UTC and UT.[2]</p><p>A number of proposals have been made to replace UTC with a new system that would eliminate leap seconds, but no consensus has yet been reached.</p><p>The current version of UTC is defined by International Telecommunications Union Recommendation (ITU-R TF.460-6), Standard-frequency and time-signal emissions[3] and is based on International Atomic Time (TAI) with leap seconds added at irregular intervals to compensate for the slowing of Earth's rotation.[4] Leap seconds are inserted as necessary to keep UTC within 0.9&nbsp;seconds of universal time, UT1.[5] See the Current number of leap seconds section for the number of leap seconds inserted to date.</p><h2>Contents</h2><h2>Etymology</h2><p>The official abbreviation for Coordinated Universal Time is UTC. This abbreviation arose from a desire by the International Telecommunication Union and the International Astronomical Union to use the same abbreviation in all languages. English speakers originally proposed CUT (for coordinated universal time), while French speakers proposed TUC (for temps universel coordonné). The compromise that emerged was UTC,[6] which conforms to the pattern for the abbreviations of the variants of Universal Time (UT0, UT1, UT2, UT1R, etc.).[7]</p><h2>Uses</h2><p>Time zones around the world are expressed using positive or negative offsets from UTC, as in the list of time zones by UTC offset.</p><p>The westernmost time zone uses UTC-12, being twelve hours behind UTC; the easternmost time zone, theoretically, uses UTC+12, being twelve hours ahead of UTC. In 1995, the island nation of Kiribati moved those of its atolls in the Line Islands from UTC-10 to UTC+14 so that Kiribati would all be on the same day.</p><p>UTC is used in many internet and World Wide Web standards. The Network Time Protocol, designed to synchronise the clocks of computers over the internet, encodes times using the UTC system.[8] Computer servers, online services and other entities that rely on having a universally accepted time use UTC as it is more specific than GMT. If only limited precision is needed, clients can obtain the current UTC from a number of official internet UTC servers. For sub-microsecond precision, clients can obtain the time from satellite signals.</p><p>UTC is also the time standard used in aviation,[9] e.g.,&nbsp;for flight plans and air traffic control clearances. Weather forecasts and maps all use UTC to avoid confusion about time zones and daylight saving time. The International Space Station also uses UTC as a time standard.</p><p>Amateur radio operators often schedule their radio contacts in UTC, because transmissions on some frequencies can be picked up by many time zones.[10]</p><p>UTC is also used in digital tachographs used on large goods vehicles (LGV) under EU and AETR rules.</p><h2>Mechanism</h2><p>UTC divides time into days, hours, minutes and seconds. Days are conventionally identified using the Gregorian calendar, but Julian day numbers can also be used. Each day contains 24 hours and each hour contains 60&nbsp;minutes. The number of seconds in a minute is usually 60, but with an occasional leap second, it may be 61 or 59 instead.[11] Thus, in the UTC time scale, the second and all smaller time units (millisecond, microsecond, etc.) are of constant duration, but the minute and all larger time units (hour, day, week, etc.) are of variable duration. Decisions to introduce a leap second are announced at least six months in advance in Bulletin&nbsp;C produced by the International Earth Rotation and Reference Systems Service.[12][13] The leap seconds cannot be predicted far in advance due to the unpredictable rate of rotation of the Earth.[14]</p><p>Nearly all UTC days contain exactly 86,400 SI seconds with exactly 60&nbsp;seconds in each minute. However, because the mean solar day is slightly longer than 86,400 SI seconds, occasionally the last minute of a UTC day is adjusted to have 61&nbsp;seconds. The extra second is called a leap second. It accounts for the grand total of the extra length (about 2&nbsp;milliseconds each) of all the mean solar days since the previous leap second. The last minute of a UTC day is permitted to contain 59&nbsp;seconds to cover the remote possibility of the Earth rotating faster, but that has not yet been necessary. The irregular day lengths mean that fractional Julian days do not work properly with UTC.</p><p>Since 1972, UTC is calculated by subtracting the accumulated leap seconds from International Atomic Time (TAI), which is a coordinate time scale tracking notional proper time on the rotating surface of the Earth (the geoid). In order to maintain a close approximation to UT1 (equivalent to GMT), UTC occasionally has discontinuities where it changes from one linear function of TAI to another. These discontinuities take the form of leap seconds implemented by a UTC day of irregular length. Discontinuities in UTC have occurred only at the end of June or December, although there is provision for them to happen at the end of March and September as well as a second preference.[15][16] The International Earth Rotation and Reference Systems Service (IERS) tracks and publishes the difference between UTC and Universal Time, DUT1 = UT1 - UTC, and introduces discontinuities into UTC to keep DUT1 in the interval (-0.9&nbsp;s, +0.9&nbsp;s).</p><p>As with TAI, UTC is only known with the highest precision in retrospect. Users who require an approximation in real time must obtain it from a time laboratory, which disseminates an approximation using techniques such as GPS or radio time signals. Such approximations are designated UTC(k), where k is an abbreviation for the time laboratory.[17] The time of events may be provisionally recorded against one of these approximations; later corrections may be applied using the International Bureau of Weights and Measures (BIPM) monthly publication of tables of differences between canonical TAI/UTC and TAI(k)/UTC(k) as estimated in real time by participating laboratories.[18] (See the article on International Atomic Time for details.)</p><p>Because of time dilation, a standard clock not on the geoid, or in rapid motion, will not maintain synchronicity with UTC. Therefore, telemetry from clocks with a known relation to the geoid is used to provide UTC when required, on locations such as those of spacecraft.</p><p>It is not possible to compute the exact time interval elapsed between two UTC timestamps without consulting a table that describes how many leap seconds occurred during that interval. By extension, it is not possible to compute the duration of a time interval that ends in the future and may encompass an unknown number of leap seconds (for example, the number of TAI seconds between now and 2099-12-31 23:59:59). Therefore, many scientific applications that require precise measurement of long (multi-year) intervals use TAI instead. TAI is also commonly used by systems that cannot handle leap seconds. GPS time always remains exactly 19 seconds behind TAI (neither system is affected by the leap seconds introduced in UTC).</p><p>For most common and legal-trade purposes, the fractional second difference between UTC and UT (GMT) is inconsequentially small. Greenwich Mean Time is the legal standard in Britain during the winter, and this notation is familiar to and used by the population.[19]</p><h3>Time zones</h3><p> Main articles: Time zone and Lists of time zones</p><p>Time zones are usually defined as differing from UTC by an integer number of hours,[20] although the laws of each jurisdiction would have to be consulted if sub-second accuracy was required. Several jurisdictions have established time zones that differ by an integer number of half-hours or quarter-hours from UT1 or UTC.</p><div class="gradientback"></div></div><div class="content"><p>Current civil time in a particular time zone can be determined by adding or subtracting the number of hours and minutes specified by the UTC offset, which ranges from UTC-12:00 in the west to UTC+14:00 in the east (see List of UTC time offsets).</p><p>The time zone using UTC is sometimes denoted UTC±00:00 or by the letter Z—a reference to the equivalent nautical time zone (GMT), which has been denoted by a Z since about 1950. Time zones were identified by successive letters of the alphabet and the Greenwich time zone was marked by a Z as it was the point of origin. The letter also refers to the zone description of zero hours, which has been used since 1920 (see time zone history). Since the NATO phonetic alphabet word for Z is Zulu, UTC is sometimes known as Zulu time. This is especially true in aviation, where Zulu is the universal standard.[21] This ensures all pilots regardless of location are using the same 24-hour clock, thus avoiding confusion when flying between time zones.[22] See the list of military time zones for letters used in addition to Z in qualifying time zones other than Greenwich.</p><p>On electronic devices that only allow the current time zone to be configured using maps or city names, UTC can be selected indirectly by selecting Reykjavík, Iceland, which is always on UTC and does not use daylight saving time.[23]</p><h3>Daylight saving time</h3><p> Main article: Daylight saving time</p><p>UTC does not change with a change of seasons, but local time or civil time may change if a time zone jurisdiction observes daylight saving time (summer time). For example, local time on the east coast of the United States is five hours behind UTC during winter, but four hours behind while daylight saving is observed there.[24]</p><h2>History</h2><p>At the 1884 International Meridian Conference held in Washington, D.C., the local mean solar time at the Royal Observatory, Greenwich in England was chosen to define the Universal day, counted from 0&nbsp;hours at mean midnight. This agreed with civil Greenwich Mean Time (GMT), used on the island of Great Britain since 1847. In contrast, astronomical GMT began at mean noon, 12 hours after mean midnight of the same date until 1 January 1925, whereas nautical GMT began at mean noon, 12&nbsp;hours before mean midnight of the same date, at least until 1805 in the Royal Navy, but persisted much later elsewhere because it was mentioned at the 1884 conference. In 1884, the Greenwich Meridian was used for two-thirds of all charts and maps as their Prime Meridian.[25] In 1928, the term Universal Time (UT) was introduced by the International Astronomical Union to refer to GMT, with the day starting at midnight.[26] Until the 1950s, broadcast time signals were based on UT, and hence on the rotation of the Earth.</p><p>In 1955, the caesium atomic clock was invented. This provided a form of timekeeping that was both more stable and more convenient than astronomical observations. In 1956, the U.S.&nbsp;National Bureau of Standards and U.S.&nbsp;Naval Observatory started to develop atomic frequency time scales; by 1959, these time scales were used in generating the WWV time signals, named for the shortwave radio station that broadcasts them. In 1960, the U.S.&nbsp;Naval Observatory, the Royal Greenwich Observatory, and the UK National Physical Laboratory coordinated their radio broadcasts so time steps and frequency changes were coordinated, and the resulting time scale was informally referred to as Coordinated Universal Time.[27]</p><p>In a controversial decision, the frequency of the signals was initially set to match the rate of UT, but then kept at the same frequency by the use of atomic clocks and deliberately allowed to drift away from UT. When the divergence grew significantly, the signal was phase shifted (stepped) by 20 ms to bring it back into agreement with UT. Twenty-nine such steps were used before 1960.[28]</p><p>In 1958, data was published linking the frequency for the caesium transition, newly established, with the ephemeris second. The ephemeris second is the duration of time that, when used as the independent variable in the laws of motion that govern the movement of the planets and moons in the solar system, cause the laws of motion to accurately predict the observed positions of solar system bodies. Within the limits of observing accuracy, ephemeris seconds are of constant length, as are atomic seconds. This publication allowed a value to be chosen for the length of the atomic second that would work properly with the celestial laws of motion.[29]</p><p>In 1961, the Bureau International de l'Heure began coordinating the UTC process internationally (but the name Coordinated Universal Time was not adopted by the International Astronomical Union until 1967).[30][31] Time steps occurred every few months thereafter, and frequency changes at the end of each year. The jumps increased in size to 100&nbsp;ms. This UTC was intended to permit a very close approximation to UT2.[27]</p><p>In 1967, the SI second was redefined in terms of the frequency supplied by a caesium atomic clock. The length of second so defined was practically equal to the second of ephemeris time.[32] This was the frequency that had been provisionally used in TAI since 1958. It was soon recognised that having two types of second with different lengths, namely the UTC second and the SI second used in TAI, was a bad idea. It was thought that it would be better for time signals to maintain a consistent frequency, and that that frequency should match the SI&nbsp;second. Thus it would be necessary to rely on time steps alone to maintain the approximation of UT. This was tried experimentally in a service known as Stepped Atomic Time (SAT), which ticked at the same rate as TAI and used jumps of 200&nbsp;ms to stay synchronised with UT2.[33]</p><p>There was also dissatisfaction with the frequent jumps in UTC (and SAT). In 1968, Louis Essen, the inventor of the caesium atomic clock, and G.&nbsp;M.&nbsp;R.&nbsp;Winkler both independently proposed that steps should be of 1&nbsp;s only.[34] This system was eventually approved, along with the idea of maintaining the UTC second equal to the TAI second. At the end of 1971, there was a final irregular jump of exactly 0.107758 TAI seconds, so that 1 January 1972 00:00:00 UTC was 1 January 1972 00:00:10 TAI exactly, making the difference between UTC and TAI an integer number of seconds. At the same time, the tick rate of UTC was changed to exactly match TAI. UTC also started to track UT1 rather than UT2. Some time signals started to broadcast the DUT1 correction (UT1 - UTC) for applications requiring a closer approximation of UT1 than UTC now provided.[35][36]</p><h3>Current number of leap seconds</h3><p>The first leap second occurred on 30 June 1972. Since then, leap seconds have occurred on average about once every 19&nbsp;months, always on 30 June or 31 December. As of January 2017, there have been 27&nbsp;leap seconds in total, all positive, putting UTC 37&nbsp;seconds behind TAI.[37]</p><h2>Rationale</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/f/fb/Leapsecond.ut1-utc.svg/250px-Leapsecond.ut1-utc.svg.png" width="250" height="200"><p>


				Graph showing the difference DUT1 between UT1 and UTC (in seconds). Vertical segments correspond to leap seconds.


				</p><div class="gradientback"></div></div><div class="content"><p>
					Earth's rotational speed is very slowly decreasing because of tidal deceleration; this increases the length of the mean solar day. The length of the SI&nbsp;second was calibrated on the basis of the second of ephemeris time[29][32] and can now be seen to have a relationship with the mean solar day observed between 1750 and 1892, analysed by Simon Newcomb. As a result, the SI&nbsp;second is close to 1/86400 of a mean solar day in the mid-19th century.[38] In earlier centuries, the mean solar day was shorter than 86,400 SI seconds, and in more recent centuries it is longer than 86,400 seconds. Near the end of the 20th century, the length of the mean solar day (also known simply as length of day or LOD) was approximately 86,400.0013&nbsp;s.[39] For this reason, UT is now slower than TAI by the difference (or excess LOD) of 1.3&nbsp;ms/day.</p><p>The excess of the LOD over the nominal 86,400&nbsp;s accumulates over time, causing the UTC day, initially synchronised with the mean sun, to become desynchronised and run ahead of it. Near the end of the 20th century, with the LOD at 1.3&nbsp;ms above the nominal value, UTC ran faster than UT by 1.3&nbsp;ms per day, getting a second ahead roughly every 800 days. Thus, leap seconds were inserted at approximately this interval, retarding UTC to keep it synchronised in the long term.[40] The actual rotational period varies on unpredictable factors such as tectonic motion and has to be observed, rather than computed.</p><p>Just as adding a leap day every four years does not mean the year is getting longer by one day every four years, the insertion of a leap second every 800 days does not indicate that the mean solar day is getting longer by a second every 800 days. It will take about 50,000 years for a mean solar day to lengthen by one second (at a rate of 2&nbsp;ms/cy, where cy means century). This rate fluctuates within the range of 1.7–2.3&nbsp;ms/cy. While the rate due to tidal friction alone is about 2.3&nbsp;ms/cy, the uplift of Canada and Scandinavia by several metres since the last Ice Age has temporarily reduced this to 1.7&nbsp;ms/cy over the last 2,700&nbsp;years.[41] The correct reason for leap seconds, then, is not the current difference between actual and nominal LOD, but rather the accumulation of this difference over a period of time: Near the end of the 20th&nbsp;century, this difference was about 1/800 of a second per day; therefore, after about 800 days, it accumulated to 1&nbsp;second (and a leap second was then added).</p><p>In the graph of DUT1 above, the excess of LOD above the nominal 86,400&nbsp;s corresponds to the downward slope of the graph between vertical segments. (The slope became shallower in the 2000s (decade), because of a slight acceleration of Earth's crust temporarily shortening the day.) Vertical position on the graph corresponds to the accumulation of this difference over time, and the vertical segments correspond to leap seconds introduced to match this accumulated difference. Leap seconds are timed to keep DUT1 within the vertical range depicted by this graph. The frequency of leap seconds therefore corresponds to the slope of the diagonal graph segments, and thus to the excess LOD.</p><h2>Future</h2><p>As the Earth's rotation continues to slow, positive leap seconds will be required more frequently. The long-term rate of change of LOD is approximately +1.7&nbsp;ms per century. At the end of the 21st century, LOD will be roughly 86,400.004&nbsp;s, requiring leap seconds every 250 days. Over several centuries, the frequency of leap seconds will become problematic.</p><p>Some time in the 22nd century, two leap seconds will be required every year. The current use of only the leap second opportunities in June and December will be insufficient, and the March and September options will have to be used. In the 25th&nbsp;century, four leap seconds will be required every year, so the current quarterly options will be insufficient. Thereafter there will need to be the possibility of leap seconds at the end of any month. In about two thousand years, even that will be insufficient, and there will have to be leap seconds that are not at the end of a month.[42] In a few tens of thousands of years (the timing is uncertain), LOD will exceed 86,401&nbsp;s, causing UTC to require more than one leap second per day.</p><p>In April 2001, Rob Seaman of the National Optical Astronomy Observatory proposed that leap seconds be allowed to be added monthly rather than twice yearly.[43]</p><p>There is a proposal to redefine UTC and abolish leap seconds, such that sundials would slowly get further out of sync with civil time.[44] The resulting gradual shift of the sun's movements relative to civil time is analogous to the shift of seasons relative to the yearly calendar that results from the calendar year not precisely matching the tropical year length. This would be a major practical change in civil timekeeping, but would take effect slowly over several centuries. UTC (and TAI) would be more and more ahead of UT; it would coincide with local mean time along a meridian drifting slowly eastward (reaching Paris and beyond).[45] Thus, the time system would lose its fixed connection to the geographic coordinates based on the IERS meridian. The difference between UTC and UT could reach 0.5 hour after the year 2600 and 6.5 hours around 4600.[42]</p><p>ITU-R Study Group&nbsp;7 and Working Party&nbsp;7A were unable to reach consensus on whether to advance the proposal to the 2012 Radiocommunications Assembly; the chairman of Study Group&nbsp;7 elected to advance the question to the 2012 Radiocommunications Assembly (20 January 2012),[46] but consideration of the proposal was postponed by the ITU until the World Radio Conference in 2015, convening on 2 November.[47]</p><p>The possibility of suppressing the leap second was considered in November 2015 at the World Radiocommunication Conference (WRC-15), which is the international regulatory body which defines Coordinated Universal Time.[48] No decision to suppress leap seconds was reached; the issue will be studied further and reconsidered in 2023.[49]</p><h3>Notes</h3><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Coordinated_Universal_Time&amp;oldid=783823852"					
								Categories:  Hidden categories:</p><br><h1 lang="en">Eastern European Summer Time</h1><p> From Wikipedia, the free encyclopedia</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/7/71/Time_zones_of_Europe.svg/300px-Time_zones_of_Europe.svg.png" width="300" height="307"><p>


				Time in Europe:
				 
				Light colours indicate where standard time is observed all year; dark colours indicate where a summer time is observed.



				<br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/0/07/Time_Zones_of_the_Middle_East.svg/300px-Time_Zones_of_the_Middle_East.svg.png" width="300" height="197"><br>


				Time in the Middle East
				 
				Light colors indicate where standard time is observed all year; dark colors indicate where daylight savings is observed.



				</p><div class="gradientback"></div></div><div class="content"><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/0/07/Time_Zones_of_the_Middle_East.svg/300px-Time_Zones_of_the_Middle_East.svg.png" width="300" height="197"><br><p>
					Eastern European Summer Time (EEST) is one of the names of UTC+3 time zone, 3 hours ahead of Coordinated Universal Time. It is used as a summer daylight saving time in some European and Middle Eastern countries, which makes it the same as Arabia Standard Time, East Africa Time and Moscow Time. During the winter periods, Eastern European Time (UTC+2) is used.</p><p>Since 1996 European Summer Time has been observed from the last Sunday in March to the last Sunday in October; previously the rules were not uniform across the European Union.[1]</p><h2>Usage</h2><p>The following countries and territories use Eastern European Summer Time during the summer:</p><p>In one year 1991 EEST was used also in Moscow and Samara time zones of Russia. Egypt has previously used EEST from 1957–2010 and 2014–2015. Turkey, has previously used EEST from 1970-1978 EEST, Moscow Summer Time from 1979–1983, and EEST from 1985-2016.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/8/8e/Tzdiff-Europe-summer.png/300px-Tzdiff-Europe-summer.png" width="300" height="308"><p>


				European summer



				 

				 


									
										</p><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Eastern_European_Summer_Time&amp;oldid=742737492"					
								Categories:  				
											
						<br>
							

											 
										
				<br><img alt="Page semi-protected" src="http://upload.wikimedia.org/wikipedia/commons/thumb/f/fc/Padlock-silver.svg/20px-Padlock-silver.svg.png" width="20" height="20">

							</p><br><br><img alt="Page semi-protected" src="http://upload.wikimedia.org/wikipedia/commons/thumb/f/fc/Padlock-silver.svg/20px-Padlock-silver.svg.png" width="20" height="20"><h1 lang="en">Anno Domini</h1><p>
					 From Wikipedia, the free encyclopedia</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/8/89/Austria_Klagenfurt_Dome_12.jpg/220px-Austria_Klagenfurt_Dome_12.jpg" width="220" height="163"><p>


				Anno Domini inscription at a cathedral in Carinthia, Austria.


				</p><p>
					The terms anno Domini[a][1][2] (AD) and before Christ[3][4][5][6] (BC) are used to label or number years in the Julian and Gregorian calendars. The term anno Domini is Medieval Latin and means in the year of the Lord,[7] but is often translated as in the year of our Lord.[8][9]</p><p>This calendar era is based on the traditionally reckoned year of the conception or birth of Jesus of Nazareth, with AD counting years from the start of this epoch, and BC denoting years before the start of the era. There is no year zero in this scheme, so the year AD&nbsp;1 immediately follows the year 1&nbsp;BC. This dating system was devised in 525 by Dionysius Exiguus of Scythia Minor, but was not widely used until after 800.[10][11]</p><p>The Gregorian calendar is the most widely used calendar in the world today. For decades, it has been the unofficial global standard, adopted in the pragmatic interests of international communication, transportation, and commercial integration, and recognized by international institutions such as the United Nations.[12]</p><p>Traditionally, English followed Latin usage by placing the AD abbreviation before the year number.[b] However, BC is placed after the year number (for example: AD&nbsp;2017, but 68&nbsp;BC), which also preserves syntactic order. The abbreviation is also widely used after the number of a century or millennium, as in fourth century AD or second millennium AD (although conservative usage formerly rejected such expressions).[14] Because BC is the English abbreviation for Before Christ, it is sometimes incorrectly concluded that AD means After Death, i.e., after the death of Jesus. However, this would mean that the approximate 33 years commonly associated with the life of Jesus would not be included in either of the BC and the AD time scales.[15]</p><p>Terminology that is viewed by some as being more neutral and inclusive of non-Christian people is to call this the Current or Common Era (abbreviated as CE), with the preceding years referred to as Before the Common or Current Era (BCE). Astronomical year numbering and ISO 8601 avoid words or abbreviations related to Christianity, but use the same numbers for AD years.</p><h2>Contents</h2><h2>History</h2><p>The Anno Domini dating system was devised in 525 by Dionysius Exiguus to enumerate the years in his Easter table. His system was to replace the Diocletian era that had been used in an old Easter table because he did not wish to continue the memory of a tyrant who persecuted Christians.[16] The last year of the old table, Diocletian 247, was immediately followed by the first year of his table, AD 532. When he devised his table, Julian calendar years were identified by naming the consuls who held office that year—he himself stated that the present year was the consulship of Probus Junior, which was 525 years since the incarnation of our Lord Jesus Christ.[17] Thus Dionysius implied that Jesus' Incarnation occurred 525 years earlier, without stating the specific year during which his birth or conception occurred. However, nowhere in his exposition of his table does Dionysius relate his epoch to any other dating system, whether consulate, Olympiad, year of the world, or regnal year of Augustus; much less does he explain or justify the underlying date.[18]</p><p>Blackburn &amp; Holford-Strevens briefly present arguments for 2 BC, 1 BC, or AD 1 as the year Dionysius intended for the Nativity or Incarnation. Among the sources of confusion are:[11]</p><div class="gradientback"></div></div><div class="content"><p>It is not known how Dionysius established the year of Jesus's birth. Two major theories are that Dionysius based his calculation on the Gospel of Luke, which states that Jesus was about thirty years old shortly after the fifteenth year of the reign of Tiberius Caesar, and hence subtracted thirty years from that date, or that Dionysius counted back 532 years (the period during which the dates of Alexandrian Easter repeat) from the first year of his new table.[19][20] It is convenient to initiate a calendar not from the very day of an event but from the beginning of a cycle which occurs in close proximity. For example, the Islamic calendar begins not from the date of the Hegira, but rather weeks later, on the first subsequent occurrence of the month of Muharram (corresponding to 16 July AD 622).</p><p>It has also been speculated by Georges Declercq[21] that Dionysius' desire to replace Diocletian years with a calendar based on the incarnation of Christ was intended to prevent people from believing the imminent end of the world. At the time, it was believed by some that the Resurrection and end of the world would occur 500 years after the birth of Jesus. The old Anno Mundi calendar theoretically commenced with the creation of the world based on information in the Old Testament. It was believed that, based on the Anno Mundi calendar, Jesus was born in the year 5500 (or 5500 years after the world was created) with the year 6000 of the Anno Mundi calendar marking the end of the world.[22][23] Anno Mundi 6000 (approximately AD 500) was thus equated with the resurrection and the end of the world[24] but this date had already passed in the time of Dionysius.</p><h3>Popularization</h3><p>The Anglo-Saxon historian the Venerable Bede, who was familiar with the work of Dionysius Exiguus, used Anno Domini dating in his Ecclesiastical History of the English People, completed in 731. In this same history, he also used another Latin term, ante vero incarnationis dominicae tempus anno sexagesimo (in fact in the 60th year before the time of the Lord's incarnation), equivalent to the English before Christ, to identify years before the first year of this era.[25] Both Dionysius and Bede regarded Anno Domini as beginning at the incarnation of Jesus, but the distinction between Incarnation and Nativity was not drawn until the late 9th century, when in some places the Incarnation epoch was identified with Christ's conception, i.e., the Annunciation on March 25 (Annunciation style).[26]</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/d/d0/Charlemagne_Agostino_Cornacchini_Vatican_2.jpg/220px-Charlemagne_Agostino_Cornacchini_Vatican_2.jpg" width="220" height="283"><p>


				Statue of Charlemagne by Agostino Cornacchini (1725), at St. Peter's Basilica, Vatican City. Charlemagne promoted the usage of the Anno Domini epoch throughout the Carolingian Empire


				</p><p>
					On the continent of Europe, Anno Domini was introduced as the era of choice of the Carolingian Renaissance by the English cleric and scholar Alcuin in the late eighth century. Its endorsement by Emperor Charlemagne and his successors popularizing the use of the epoch and spreading it throughout the Carolingian Empire ultimately lies at the core of the system's prevalence. According to the Catholic Encyclopedia, popes continued to date documents according to regnal years for some time, but usage of AD gradually became more common in Roman Catholic countries from the 11th to the 14th centuries.[27] In 1422, Portugal became the last Western European country to switch to the system begun by Dionysius.[28] Eastern Orthodox countries only began to adopt AD instead of the Byzantine calendar in 1700 when Russia did so, with others adopting it in the 19th and 20th centuries.</p><p>Although Anno Domini was in widespread use by the 9th century, the term Before Christ (or its equivalent) did not become common until much later. Bede the Venerable used the expression anno igitur ante incarnationem Dominicam (so in the year before the Incarnation of the Lord) twice. Anno an xpi nativitate (in the year before the birth of Christ) is found in 1474 in a work by a German monk.[29] In 1627, the French Jesuit theologian Denis Pétau (Dionysius Petavius in Latin), with his work De doctrina temporum, popularized the usage ante Christum (Latin for Before Christ) to mark years prior to AD.[30][31][32]</p><h3>Change of year</h3><p>When the reckoning from Jesus' incarnation began replacing the previous dating systems in western Europe, various people chose different Christian feast days to begin the year: Christmas, Annunciation, or Easter. Thus, depending on the time and place, the year number changed on different days in the year, which created slightly different styles in chronology:[33]</p><p>With these various styles, the same day could, in some cases, be dated in 1099, 1100 or 1101.</p><h2>Historical birth date of Jesus</h2><p>The date of birth of Jesus of Nazareth is not stated in the gospels or in any secular text, but most scholars assume a date of birth between 6 BC and 4 BC.[34] The historical evidence is too sketchy to allow a definitive dating,[35] but the date is estimated through two different approaches - one by analyzing references to known historical events mentioned in the Nativity accounts in the Gospels of Luke and Matthew, and the second by working backwards from the estimation of the start of the ministry of Jesus.[36][37]</p><h2>Other eras</h2><p> Further information: Calendar era</p><p>During the first six centuries of what would come to be known as the Christian era, European countries used various systems to count years. Systems in use included consular dating, imperial regnal year dating, and Creation dating.</p><p>Although the last non-imperial consul, Basilius, was appointed in 541 by Emperor Justinian I, later emperors through Constans II (641–668) were appointed consuls on the first 1 January after their accession. All of these emperors, except Justinian, used imperial post-consular years for the years of their reign, along with their regnal years.[38] Long unused, this practice was not formally abolished until Novell XCIV of the law code of Leo VI did so in 888.</p><p>Another calculation had been developed by the Alexandrian monk Annianus around the year AD 400, placing the Annunciation on 25 March AD 9 (Julian)—eight to ten years after the date that Dionysius was to imply. Although this incarnation was popular during the early centuries of the Byzantine Empire, years numbered from it, an Era of Incarnation, were exclusively used and are yet used, in Ethiopia. This accounts for the seven- or eight-year discrepancy between the Gregorian and Ethiopian calendars. Byzantine chroniclers like Maximus the Confessor, George Syncellus, and Theophanes dated their years from Annianus' creation of the world. This era, called Anno Mundi, year of the world (abbreviated AM), by modern scholars, began its first year on 25 March 5492 BC. Later Byzantine chroniclers used Anno Mundi years from 1 September 5509 BC, the Byzantine Era. No single Anno Mundi epoch was dominant throughout the Christian world. Eusebius of Caesarea in his Chronicle used an era beginning with the birth of Abraham, dated in 2016 BC (AD 1 = 2017 Anno Abrahami).[39]</p><p>Spain and Portugal continued to date by the Era of the Caesars or Spanish Era, which began counting from 38 BC, well into the Middle Ages. In 1422, Portugal became the last Catholic country to adopt the Anno Domini system.[27]</p><div class="gradientback"></div></div><div class="content"><p>The Era of Martyrs, which numbered years from the accession of Diocletian in 284, who launched the last yet most severe persecution of Christians, was used by the Church of Alexandria and is still used, officially, by the Coptic Orthodox and Coptic Catholic churches. It was also used by the Ethiopian church. Another system was to date from the crucifixion of Jesus Christ, which as early as Hippolytus and Tertullian was believed to have occurred in the consulate of the Gemini (AD 29), which appears in some medieval manuscripts.</p><h2>CE and BCE</h2><p> Main article: Common Era</p><p>Alternative names for the Anno Domini era include vulgaris aerae (found 1615 in Latin),[40] Vulgar Era (in English, as early as 1635),[41] Christian Era (in English, in 1652),[42] Common Era (in English, 1708),[43] and Current Era.[44] Since 1856,[45] the alternative abbreviations CE and BCE, (sometimes written C.E. and B.C.E.) are sometimes used in place of AD and BC.</p><p>The Common/Current Era (CE) terminology is often preferred by those who desire a term that does not explicitly make religious references.[46][47] For example, Cunningham and Starr (1998) write that B.C.E./C.E. …do not presuppose faith in Christ and hence are more appropriate for interfaith dialog than the conventional B.C./A.D.[48] Upon its foundation, the Republic of China adopted the Minguo Era, but used the Western calendar for international purposes. The translated term was ?? (xi yuán, Western Era). Later, in 1949, the People's Republic of China adopted ?? (gongyuán, Common Era) for all purposes domestic and foreign.</p><h2>No year zero / Start and end of a century</h2><p> Further information: 0 (year), Astronomical year numbering, and Millennium</p><p>In the AD year numbering system, whether applied to the Julian or Gregorian calendars, AD 1 is preceded by 1 BC. There is no year 0 between them. Because of this, most experts agree that a new century begins in a year which has 01 as the final digits (e.g., 1801, 1901, 2001). New millennia likewise are considered to have begun in 1001 and 2001. This is at odds with the much more common conception that centuries and millennia begin when the trailing digits are zeroes (1800, 1900, 2000, etc.); for example, the worldwide celebration of the new millennium took place on New Year's Eve 1999, when the year number ticked over to 2000.[10]</p><p>For computational reasons, astronomical year numbering and the ISO 8601 standard designate years so that AD 1 = year 1, 1 BC = year 0, 2 BC = year -1, etc.[c] In common usage, ancient dates are expressed in the Julian calendar, but ISO 8601 uses the Gregorian calendar and astronomers may use a variety of time scales depending on the application. Thus dates using the year 0 or negative years may require further investigation before being converted to BC or AD.</p><h2>Notes</h2><h3>Citations</h3><h3>Sources</h3><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Anno_Domini&amp;oldid=782411048"					
								Categories:  Hidden categories:</p><br><h1 lang="en">Telephone numbers in Greece</h1><p> From Wikipedia, the free encyclopedia</p><p>This is a list of dialing codes in Greece. The first digit represents type of service. 1 is used for short codes, 2 for geographical numbers (3 and 4 are reserved for that purpose too), 5 is used for inter-network routing purposes (non-dialable codes) and VPNs, 6 for mobile services, 7 is reserved for universal access numbers (not active), 8 for reduced fee services (like 800 toll-free, 801 local call, 89 dial-up and data services), 9 is used for premium rate services (901 for general purpose and 909 for adult-only services). All dialable numbers are ten digits, except for short codes (3-5 digits on the 1 range), 807-XXXX (seven digits) used for calling card access codes, and numbers on the 5 range, used for routing purposes and not dialable by end subscribers.</p><h2>Contents</h2><h2>Overview</h2><p>Geographical area codes start with the digit 2. There are currently two-, three-, and four-digit area codes. The only two-digit area code is 21 for the Athens Metropolitan area: three-digit codes are used for the cities Thessaloniki, Patras, Larissa, Heraklion, Kavala, Tripoli. The rest of the codes are four-digit codes.</p><p>Generally speaking, the second digit of a geographical area code signifies a broader geographical area of Greece, That is how area codes are sorted in this article.</p><p>Two-digit codes are used with eight-digit subscriber numbers, three-digit codes with seven-digit numbers, and four-digit codes with six-digit numbers so the full telephone number is always ten digits.</p><p>Subscriber numbers in most areas start with 0. That is the digit that was inserted between the area code and the subscriber number to form the new ten-digit numbering plan back in 2002. Thus, many Greeks erroneously think that the area codes include this leading 0. For example, they think that Athens's area code is 210 while, actually, Athens's area code is 21, 0 being the first digit of the subscriber number.</p><p>Subscriber numbers starting with 0 are assigned to the former monopoly OTE. In bigger cities like Athens and Thessaloniki, subscriber numbers starting with other digits except 0 are becoming more and more common, especially amongst business subscribers. In this case many people think that the area code is different. For example, a subscriber number in Athens might start with 211, with people thinking that 211 is a distinct area code from 210 while, in reality, both numbers are in the 21 area code and the third digit of the number belongs to the subscriber number.</p><p>The international call prefix depends on the country from which you are calling, for example, 00 for most European countries and 011 from North America.</p><p>In 2001-2002, Greece moved to a closed ten-digit numbering scheme in two stages, with the result that subscribers' numbers changed twice. For example, before the change, a number in Athens would have been dialed as follows:</p><p>In 2001, a '0' was added after the area code, which was incorporated into the subscriber's number:</p><p>Finally, in 2002, the leading '0' was changed to a '2' (for geographic numbers)&nbsp;:</p><p>For mobile phone numbers, the leading '0' was changed to a '6'.</p><p>Note that because of number portability, for both geographical and non-geographical (mobile, toll-free, premium rate) numbers, one cannot be sure about the operator that a number belongs to. All geographical codes (21x, 231x) end in a number from 0 to 6 (210 or 212 for Athens, 2310 or 2312 for Thessaloniki). Numbers that their code ends in 0 are or were originally operated by OTE. The same is with mobile phones: All mobile codes (69x) end in 0,3,4,5,7,8 or 9 (690, 698). Mobile code 696 is assigned to OTE pagers. Numbers starting with 690 and 693 are originally assigned to WIND, with 694 and 695 to Vodafone, with 697 and 698 to Cosmote and with 699 to Q-Telecom until 2007 when it merged with WIND.</p><h2>Zone 21: Greater Athens Metropolitan Area</h2><div class="gradientback"></div></div><div class="content"><h2>Zone 22: Central Greece and the Aegean Islands</h2><h3>222x - Euboea</h3><h3>223x - Evrytania and Phthiotis</h3><h3>224x - Dodecanese</h3><h3>225x - Lesbos, Lemnos</h3><h3>226x - Boeotia, eastern Phocis</h3><h3>227x - Chios, Samos and Icaria islands</h3><h3>228x - Cyclades</h3><h3>229x - Attica excluding the area that uses 21</h3><h2>Zone 23: Central Macedonia and Florina</h2><h3>231 - Thessaloniki</h3><h3>232x - Serres prefecture</h3><h3>233x - Imathia prefecture</h3><h3>234x - Kilkis prefecture</h3><h3>235x - Pieria prefecture</h3><h3>237x - Chalkidiki prefecture</h3><h3>238x - Pella and Florina Prefectures</h3><h3>239x - parts of Chalkidiki and Thessaloniki prefectures</h3><p>236x is not used.</p><h2>Zone 24: Thessaly and West Macedonia (excluding Florina)</h2><h3>241 - Larissa area</h3><h3>242x - Magnesia including the Northern Sporades</h3><h3>243x - Trikala prefecture</h3><h3>244x - Karditsa</h3><h3>246x - West Macedonia excluding the Florina area</h3><h3>249x - Larissa prefecture except for the Larissa area</h3><p>245x, 247x and 248x are not used.</p><h2>Zone 25: East Macedonia and Thrace</h2><div class="gradientback"></div></div><div class="content"><h3>251 - Kavala area</h3><h3>252x - Drama prefecture</h3><h3>253x - Rhodope prefecture</h3><h3>254x- Xanthi prefecture</h3><h3>255x - Evros Prefecture</h3><h3>259x - Kavala prefecture except for the Kavala area</h3><p>256x through 258x are not used.</p><h2>Zone 26: West Greece, Ionian Island and Epirus</h2><h3>261 - Patras and Area</h3><h3>262x - Elis Prefecture</h3><h3>263x - Aetolia and western Phocis</h3><h3>264x - Acarnania, Lefkada</h3><h3>265x - Ioannina Prefecture</h3><h3>266x - Corfu prefecture and Thesprotia</h3><h3>267x - Kefalonia</h3><h3>268x - Arta and Preveza</h3><h3>269x - Achaea (except Patras) and Zakynthos</h3><h2>Zone 27: Peloponnese and Kythera</h2><h3>271 - Tripoli and area</h3><p>271: Tripoli (and area)</p><h3>272x - southern and eastern part of Messenia</h3><h3>273x - Laconia and Kythera</h3><h3>274x - Corinthia</h3><h3>275x - eastern Arcadia and Argolis</h3><h3>276x - Messenia</h3><h3>279x - Western Arcadia</h3><p>277x and 278x are not used.</p><h2>Zone 28: Crete</h2><h3>281 - Heraklion prefecture</h3><h3>282x - Chania prefecture</h3><div class="gradientback"></div></div><div class="content"><h3>283x - Rethymno prefecture</h3><h3>284x - Lasithi</h3><h3>289x - rest of Heraklion prefecture</h3><p>285x through 288x are not used.</p><h2>Non-geographic numbers</h2><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Telephone_numbers_in_Greece&amp;oldid=783195211"					
								Categories:  				
											
						<br>
							

											 
										
				<br><img alt="Page semi-protected" src="http://upload.wikimedia.org/wikipedia/commons/thumb/f/fc/Padlock-silver.svg/20px-Padlock-silver.svg.png" width="20" height="20">

							</p><br><br><img alt="Page semi-protected" src="http://upload.wikimedia.org/wikipedia/commons/thumb/f/fc/Padlock-silver.svg/20px-Padlock-silver.svg.png" width="20" height="20"><h1 lang="en">European Union</h1><p> From Wikipedia, the free encyclopedia</p><p>The European Union (EU) is a political and economic union of 28 member states that are located primarily in Europe. It has an area of 4,475,757&nbsp;km2 (1,728,099&nbsp;sq&nbsp;mi), and an estimated population of over 510 million. The EU has developed an internal single market through a standardised system of laws that apply in all member states. EU policies aim to ensure the free movement of people, goods, services, and capital within the internal market,[11] enact legislation in justice and home affairs, and maintain common policies on trade,[12] agriculture,[13] fisheries, and regional development.[14] Within the Schengen Area, passport controls have been abolished.[15] A monetary union was established in 1999 and came into full force in 2002, and is composed of 19 EU member states which use the euro currency.</p><p>The EU traces its origins from the European Coal and Steel Community (ECSC) and the European Economic Community (EEC), formed by the Inner Six countries in 1951 and 1958, respectively. Next the treaty of Rome of 1957 created the European Community made up of the six core countries of Belgium, France, Italy, Luxembourg, the Netherlands and West Germany. The decades following many new members joined them while at the same time integration of economic, cultural, judicial and so forth would then deepen the relationships distinct European entity. The community and its successors have grown in size by the accession of new member states and in power by the addition of policy areas to its remit. While no member state has left the EU or its antecedent organisations, the United Kingdom enacted the result of a membership referendum in June 2016 and is currently negotiating its withdrawal. The Maastricht Treaty established the European Union in 1993 and introduced European citizenship.[16] The latest major amendment to the constitutional basis of the EU, the Treaty of Lisbon, came into force in 2009.</p><p>The European Union accumulated a higher portion of GDP as a form of foreign aid than any other economic union.[17] Covering 7.3% of the world population,[18] the EU in 2016 generated a nominal gross domestic product (GDP) of 16.477 trillion US dollars, constituting approximately 22.2% of global nominal GDP and 16.9% when measured in terms of purchasing power parity.[19] Additionally, 27 out of 28 EU countries have a very high Human Development Index, according to the United Nations Development Programme. In 2012, the EU was awarded the Nobel Peace Prize.[20] Through the Common Foreign and Security Policy, the EU has developed a role in external relations and defence. The union maintains permanent diplomatic missions throughout the world and represents itself at the United Nations, the World Trade Organization, the G7, and the G20. Because of its global influence, the European Union has been described as an emerging superpower.[21]</p><h2>Contents</h2><h2>Overview of the institutions of the EU</h2><p> Main article: Institutions of the European Union</p><p>The EU operates through a hybrid system of supranational and intergovernmental decision-making.[22][23]</p><p>EU policy is in general promulgated by EU directives, which are then implemented in the domestic legislation of its member states, and EU regulations, which are immediately enforceable in all member states. The EU's seven principal decision making bodies—known as the Institutions of the European Union are:</p><div class="gradientback"></div></div><div class="content"><h3>Relation to the Council of Europe</h3><p> Main article: Council of Europe</p><p>Beyond the EU institutions is the Council of Europe (CoE) which is a wider international organisation with 47 member states whose stated aim is to uphold human rights, democracy and the rule of law in Europe. Its legislative principles are promulgated by the European Convention on Human Rights and its judicial agent is the European Court of Human Rights. These ethical institutions are distinct from the legislative European Union institutions mentioned above, although ECHR decisions are enforcable upon the EU institutions and upon the several judiciaries of sovereign member states of the EU[24]</p><p>The Venice Commission formally The European Commission for Democracy through Law provides advise regarding constitutional matters in order to improve functioning of democratic institutions and the protection of human rights in member states of the Council of Europe</p><h3>Relations between the EU and its electorate</h3><p>Apart from the national political structures within member states and the directly elected European Parliament the EU also encourages citizen participation via development projects such as CORDIS (the EU Community Research and Development Information Service) and the ERASMUS (The European Region Action Scheme for the Mobility of University Students).</p><p>Lobbying at EU level by special interest groups is regulated to try to balance the aspirations of private initiatives with public interest decision-making process [25]</p><p>The Five Presidents (in 2015) were led by</p><p>By working together, they seek provide a forward policy consideration nucleus for the various European “think-tanks” which discuss various possible future social and economic scenarios that will eventually require ratification by the EU electorate. [26]</p><h2>History of the EU</h2><p> Main articles: History of the European Union and History of Europe</p><h3>Preliminary (1945–57)</h3><br><img alt="File:Schuman Declaration.ogg" style="width:220px;height:165px" src="http://upload.wikimedia.org/wikipedia/en/thumb/0/00/Schuman_Declaration.ogg/220px-seek%3D23-Schuman_Declaration.ogg.jpg"><p>After World War II, European integration was seen as an antidote to the extreme nationalism which had devastated the continent.[27] The 1948 Hague Congress was a pivotal moment in European federal history, as it led to the creation of the European Movement International and of the College of Europe, where Europe's future leaders would live and study together.[28] 1952 saw the creation of the European Coal and Steel Community, which was declared to be a first step in the federation of Europe.[29] The supporters of the Community included Alcide De Gasperi, Jean Monnet, Robert Schuman, and Paul-Henri Spaak.[30] These men and others are officially credited as the Founding fathers of the European Union.</p><h3>Treaty of Rome (1957–92)</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/b/bb/EC-EU-enlargement_animation.gif/280px-EC-EU-enlargement_animation.gif" width="280" height="214"><p>


				The continental territories of the member states of the European Union (European Communities pre-1993), coloured in order of accession.


				</p><p>
					In 1957, Belgium, France, Italy, Luxembourg, the Netherlands and West Germany signed the Treaty of Rome, which created the European Economic Community (EEC) and established a customs union. They also signed another pact creating the European Atomic Energy Community (Euratom) for co-operation in developing nuclear energy. Both treaties came into force in 1958.[30]</p><p>The EEC and Euratom were created separately from the ECSC, although they shared the same courts and the Common Assembly. The EEC was headed by Walter Hallstein (Hallstein Commission) and Euratom was headed by Louis Armand (Armand Commission) and then Étienne Hirsch. Euratom was to integrate sectors in nuclear energy while the EEC would develop a customs union among members.[31][32]</p><p>During the 1960s, tensions began to show, with France seeking to limit supranational power. Nevertheless, in 1965 an agreement was reached and on 1 July 1967 the Merger Treaty created a single set of institutions for the three communities, which were collectively referred to as the European Communities.[33][34] Jean Rey presided over the first merged Commission (Rey Commission).[35]</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/5/52/Thefalloftheberlinwall1989.JPG/220px-Thefalloftheberlinwall1989.JPG" width="220" height="166"><p>


				In 1989, the Iron Curtain fell, enabling the union to expand further (Berlin Wall pictured).


				</p><p>
					In 1973, the Communities were enlarged to include Denmark (including Greenland, which later left the Community in 1985, following a dispute over fishing rights), Ireland, and the United Kingdom.[36] Norway had negotiated to join at the same time, but Norwegian voters rejected membership in a referendum. In 1979, the first direct elections to the European Parliament were held.[37]</p><p>Greece joined in 1981, Portugal and Spain following in 1986.[38] In 1985, the Schengen Agreement paved the way for the creation of open borders without passport controls between most member states and some non-member states.[39] In 1986, the European flag began to be used by the Community[40] and the Single European Act was signed.</p><div class="gradientback"></div></div><div class="content"><p>In 1990, after the fall of the Eastern Bloc, the former East Germany became part of the Community as part of a reunified Germany.[41] A close fiscal integration with the introduction of the euro was not matched by institutional oversight making things more troubling. Attempts to solve the problems and to make the EU more efficient and coherent had limited success.[42]&nbsp;With further enlargement planned to include the former communist states of Central and Eastern Europe, as well as Cyprus and Malta, the Copenhagen criteria for candidate members to join the EU were agreed upon in June 1993. The expansion of the EU introduced a new level of complexity and discord.[42]</p><h3>Maastricht Treaty (1992–2007)</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/4/4b/Euro_banknotes_2002.png/220px-Euro_banknotes_2002.png" width="220" height="161"><p>


				The euro was introduced in 2002, replacing 12 national currencies. Seven countries have since joined.


				</p><p>
					The European Union was formally established when the Maastricht Treaty—whose main architects were Helmut Kohl and François Mitterrand—came into force on 1 November 1993.[16][43] The treaty also gave the name European Community to the EEC, even if it was referred as such before the treaty. In 1995, Austria, Finland, and Sweden joined the EU.</p><p>In 2002, euro banknotes and coins replaced national currencies in 12 of the member states. Since then, the eurozone has increased to encompass 19 countries. The euro currency became the second largest reserve currency in the world. In 2004, the EU saw its biggest enlargement to date when Cyprus, the Czech Republic, Estonia, Hungary, Latvia, Lithuania, Malta, Poland, Slovakia and Slovenia joined the Union.[44]</p><h3>Lisbon Treaty (2007–present)</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/7/7c/Tratado_de_Lisboa_13_12_2007_%28081%29.jpg/220px-Tratado_de_Lisboa_13_12_2007_%28081%29.jpg" width="220" height="131"><p>


				In 2009, the Lisbon Treaty entered into force.


				</p><p>
					In 2007, Bulgaria and Romania became EU members. The same year, Slovenia adopted the euro,[44] followed in 2008 by Cyprus and Malta, by Slovakia in 2009, by Estonia in 2011, by Latvia in 2014 and by Lithuania in 2015.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/7/78/Nobel_Peace_Concert_2012_IMG_4451.JPG/220px-Nobel_Peace_Concert_2012_IMG_4451.JPG" width="220" height="165"><p>


				EU representatives receive the Nobel Peace Prize in 2012


				</p><p>
					On 1 December 2009, the Lisbon Treaty entered into force and reformed many aspects of the EU. In particular, it changed the legal structure of the European Union, merging the EU three pillars system into a single legal entity provisioned with a legal personality, created a permanent President of the European Council, the first of which was Herman Van Rompuy, and strengthened the position of the High Representative of the Union for Foreign Affairs and Security Policy.[45][46]</p><p>In 2012, the EU received the Nobel Peace Prize for having contributed to the advancement of peace and reconciliation, democracy, and human rights in Europe.[47][48] In 2013, Croatia became the 28th EU member.[49]</p><p>From the beginning of the 2010s, the cohesion of the European Union has been tested by several issues, including a debt crisis in some of the Eurozone countries, increasing migration from the Middle East and the United Kingdom's withdrawal from the EU.[50] A referendum in the UK on its membership of the European Union was held on 23 June 2016, with a very slight majority of participants voting to leave.[51] This is referred to in common parlance throughout Europe as the Brexit. The UK formally notified the European Council of its decision to leave on 29 March 2017 initiating the formal withdrawal procedure for leaving the EU, slating the UK to leave the EU on 29 March 2019.[52]</p><h3>Structural evolution</h3><p> Main article: Treaties of the European Union</p><p>The following timeline illustrates the integration that has led to the formation of the present union, in terms of structural development driven by international treaties:</p><h2>Geography</h2><p> Main article: Geography of the European Union</p><br><img alt="Coast of Cyprus" src="http://upload.wikimedia.org/wikipedia/commons/thumb/3/35/2rocks.jpg/208px-2rocks.jpg" width="208" height="129"><br><img alt="Mont Blanc" src="http://upload.wikimedia.org/wikipedia/commons/thumb/b/bd/Mont-Blanc_and_Lake_of_Passy.JPG/173px-Mont-Blanc_and_Lake_of_Passy.JPG" width="173" height="129"><p>The EU's member states cover an area of 4,423,147 square kilometres (1,707,787&nbsp;sq&nbsp;mi).[f] The EU's highest peak is Mont Blanc in the Graian Alps, 4,810.45 metres (15,782&nbsp;ft) above sea level.[53] The lowest points in the EU are Lammefjorden, Denmark and Zuidplaspolder, Netherlands, at 7&nbsp;m (23&nbsp;ft) below sea level.[54] The landscape, climate, and economy of the EU are influenced by its coastline, which is 65,993 kilometres (41,006&nbsp;mi) long.</p><div class="gradientback"></div></div><div class="content"><p>Including the overseas territories of France which are located outside the continent of Europe, but which are members of the union, the EU experiences most types of climate from Arctic (North-East Europe) to tropical (French Guiana), rendering meteorological averages for the EU as a whole meaningless. The majority of the population lives in areas with a temperate maritime climate (North-Western Europe and Central Europe), a Mediterranean climate (Southern Europe), or a warm summer continental or hemiboreal climate (Northern Balkans and Central Europe).[55]</p><p>The EU's population is highly urbanised, with some 75% of inhabitants living in urban areas as of 2006. Cities are largely spread out across the EU, although with a large grouping in and around the Benelux.[56]</p><h3>Member states</h3><p> Main article: Member state of the European Union</p><p>Through successive enlargements, the European Union has grown from the six founding states (Belgium, France, West Germany, Italy, Luxembourg, and the Netherlands) to the current 28. Countries accede to the union by becoming party to the founding treaties, thereby subjecting themselves to the privileges and obligations of EU membership. This entails a partial delegation of sovereignty to the institutions in return for representation within those institutions, a practice often referred to as pooling of sovereignty.[57][58]</p><p>To become a member, a country must meet the Copenhagen criteria, defined at the 1993 meeting of the European Council in Copenhagen. These require a stable democracy that respects human rights and the rule of law; a functioning market economy; and the acceptance of the obligations of membership, including EU law. Evaluation of a country's fulfilment of the criteria is the responsibility of the European Council.[59] No member state has yet left the Union, although Greenland (an autonomous province of Denmark) withdrew in 1985.[60] The Lisbon Treaty now contains a clause under Article 50, providing for a member to leave the EU.[61]</p><p>There are six countries that are recognised as candidates for membership: Albania, Iceland, Macedonia,[g] Montenegro, Serbia, and Turkey,[62] though Iceland suspended negotiations in 2013.[63] Bosnia and Herzegovina and Kosovo are officially recognised as potential candidates,[62] with Bosnia and Herzegovina having submitted a membership application.</p><p>The four countries forming the European Free Trade Association (EFTA) are not EU members, but have partly committed to the EU's economy and regulations: Iceland, Liechtenstein and Norway, which are a part of the single market through the European Economic Area, and Switzerland, which has similar ties through bilateral treaties.[64][65] The relationships of the European microstates, Andorra, Monaco, San Marino, and the Vatican include the use of the euro and other areas of co-operation.[66] The following 28 sovereign states (of which the map only shows territories situated in and around Europe) constitute the European Union:[67]</p><br><img alt="Map showing the member states of the European Union (clickable)" src="http://upload.wikimedia.org/wikipedia/commons/thumb/5/59/Member_States_of_the_European_Union_%28polar_stereographic_projection%29_EN.svg/650px-Member_States_of_the_European_Union_%28polar_stereographic_projection%29_EN.svg.png" width="650" height="601" usemap="#ImageMap_1_181665494"><br><img alt="About this image" src="http:/w/extensions/ImageMap/desc-20.png?15600" style="border: none;"><h3>Environment</h3><p> Further information: European Commissioner for the Environment and European Climate Change Programme</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/4/4d/EE-Lahemaa-Bagno_Viru.jpg/220px-EE-Lahemaa-Bagno_Viru.jpg" width="220" height="165"><p>


				Viru Bog in Lahemaa National Park in Estonia, a protected habitat under the Habitats Directive


				</p><p>
					In 1957, when the EEC was founded, it had no environmental policy.[68] Over the past 50 years, an increasingly dense network of legislation has been created, extending to all areas of environmental protection, including air pollution, water quality, waste management, nature conservation, and the control of chemicals, industrial hazards and biotechnology.[69] According to the Institute for European Environmental Policy, environmental law comprises over 500 Directives, Regulations and Decisions, making environmental policy a core area of European politics.[70]</p><p>European policy-makers originally increased the EU's capacity to act on environmental issues by defining it as a trade problem.[71] Trade barriers and competitive distortions in the Common Market could emerge due to the different environmental standards in each member state.[72] In subsequent years, the environment became a formal policy area, with its own policy actors, principles and procedures. The legal basis for EU environmental policy was established with the introduction of the Single European Act in 1987.[70]</p><br><div class="gradientback"></div></div><div class="content"><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/2/2e/Ciconia_nigra_1_%28Lukasz_Lukasik%29_edit.jpg/220px-Ciconia_nigra_1_%28Lukasz_Lukasik%29_edit.jpg" width="220" height="165"><p>


				A black stork, a protected species under Regulation (EC) No. 338/97


				</p><p>
					Initially, EU environmental policy focused on Europe. More recently, the EU has demonstrated leadership in global environmental governance, e.g. the role of the EU in securing the ratification and coming into force of the Kyoto Protocol despite opposition from the United States. This international dimension is reflected in the EU's Sixth Environmental Action Programme,[73] which recognises that its objectives can only be achieved if key international agreements are actively supported and properly implemented both at EU level and worldwide. The Lisbon Treaty further strengthened the leadership ambitions.[74] EU law has played a significant role in improving habitat and species protection in Europe, as well as contributing to improvements in air and water quality and waste management.[70]</p><p>Mitigating climate change is one of the top priorities of EU environmental policy. In 2007, member states agreed that, in future, 20% of the energy used across the EU must be renewable, and carbon dioxide emissions have to be lower in 2020 by at least 20% compared to 1990 levels.[75] The EU has adopted an emissions trading system to incorporate carbon emissions into the economy.[76] The European Green Capital is an annual award given to cities that focuses on the environment, energy efficiency and quality of life in urban areas to create smart city.</p><h2>Politics</h2><p> Main article: Politics of the European Union</p><p>The European Union operates according to the principles of conferral (which says that it should act only within the limits of the competences conferred on it by the treaties) and of subsidiarity (which says that it should act only where an objective cannot be sufficiently achieved by the member states acting alone). Laws made by the EU institutions are passed in a variety of forms. Generally speaking, they can be classified into two groups: those which come into force without the necessity for national implementation measures (regulations) and those which specifically require national implementation measures (directives).[77]</p><h3>Constitutional nature</h3><p> Further information: Treaties of the European Union</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/a/ac/Political_System_of_the_European_Union.svg/400px-Political_System_of_the_European_Union.svg.png" width="400" height="281"><p>


				Political system of the European Union


				</p><p>
					The classification of the EU in terms of international or constitutional law has been much debated. It began life as an international organisation and gradually developed into a confederation of states. However, since the mid-1960s it has also added several of the key attributes of a federation, such as the direct effect of the law of the general level of government upon the individual[78] and majority voting in the decision-making process of the general level of government,[79] without becoming a federation per se. Scholars thus today see it as an intermediate form lying between a confederation and a federation, being an instance of neither political structure.[80] For this reason, the organisation is termed sui generis (incomparable, one of a kind),[81] although some argue that this designation is no longer valid.[82][83]</p><p>The organisation has traditionally used the terms Community and later Union to describe itself. The difficulties of classification involve the difference between national law (where the subjects of the law include natural persons and corporations) and international law (where the subjects include sovereign states and international organisations). They can also be seen in the light of differing European and American constitutional traditions.[82] Especially in terms of the European tradition, the term federation is equated with a sovereign federal state in international law; so the EU cannot be called a federation — at least, not without qualification. It is, however, described as being based on a federal model or federal in nature; and so it may be appropriate to consider it a federal union of states, a conceptual structure lying between the confederation of states and the federal state.[84] The German Constitutional Court refers to the EU as a Staatenverbund, an intermediate structure between the Staatenbund (confederation of states) and the Bundesstaat (federal state), consistent with this concept.[85] This may be a long-lived political form. Professor Andrew Moravcsik claims that the EU is unlikely to develop further into a federal state, but instead has reached maturity as a constitutional system.[86]</p><h3>Governance</h3><p> Main articles: Institutions of the European Union and Legislature of the European Union</p><p>The European Union has seven institutions: the European Council, the Council of the European Union, the European Parliament, the European Commission, the Court of Justice of the European Union, the European Central Bank and the European Court of Auditors. Competence in scrutinising and amending legislation is shared between the Council of the European Union and the European Parliament, while executive tasks are performed by the European Commission and in a limited capacity by the European Council (not to be confused with the aforementioned Council of the European Union). The monetary policy of the eurozone is determined by the European Central Bank. The interpretation and the application of EU law and the treaties are ensured by the Court of Justice of the European Union. The EU budget is scrutinised by the European Court of Auditors. There are also a number of ancillary bodies which advise the EU or operate in a specific area.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/d/d9/Donald_Tusk_2013-12-19.jpg/170px-Donald_Tusk_2013-12-19.jpg" width="170" height="220"><div class="gradientback"></div></div><div class="content"><p>


				President of the European Council, Donald Tusk


				</p><p>
					The European Council gives political direction to the EU. It convenes at least four times a year and comprises the President of the European Council (currently Donald Tusk), the President of the European Commission and one representative per member state (either its head of state or head of government). The High Representative of the Union for Foreign Affairs and Security Policy (currently Federica Mogherini) also takes part in its meetings. It has been described by some as the Union's supreme political authority.[88] It is actively involved in the negotiation of treaty changes and defines the EU's policy agenda and strategies.</p><p>The European Council uses its leadership role to sort out disputes between member states and the institutions, and to resolve political crises and disagreements over controversial issues and policies. It acts externally as a collective head of state and ratifies important documents (for example, international agreements and treaties).[89]</p><p>Tasks for the President of the European Council are ensuring the external representation of the EU,[90] driving consensus and resolving divergences among member states, both during meetings of the European Council and over the periods between them.</p><p>The European Council should not be mistaken for the Council of Europe, an international organisation independent of the EU based in Strasbourg.</p><p>The Council of the European Union (also called the Council[91] and the Council of Ministers, its former title)[92] forms one half of the EU's legislature. It consists of a government minister from each member state and meets in different compositions depending on the policy area being addressed. Notwithstanding its different configurations, it is considered to be one single body.[93] In addition to its legislative functions, the Council also exercises executive functions in relations to the Common Foreign and Security Policy.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/2/2c/European_Parliament_Strasbourg_Hemicycle_-_Diliff.jpg/220px-European_Parliament_Strasbourg_Hemicycle_-_Diliff.jpg" width="220" height="124"><p>


				The hemicycle of the European Parliament in Strasbourg


				</p><p>
					The European Parliament forms the other half of the EU's legislature. The 751 Members of the European Parliament (MEPs) are directly elected by EU citizens every five years on the basis of proportional representation. Although MEPs are elected on a national basis, they sit according to political groups rather than their nationality. Each country has a set number of seats and is divided into sub-national constituencies where this does not affect the proportional nature of the voting system.[94] The European Union council, the Council of Ministers, and the Commission fulfilled the duties as the executive for the parliament.&nbsp;[17]</p><p>The European Parliament and the Council of the European Union pass legislation jointly in nearly all areas under the ordinary legislative procedure. This also applies to the EU budget. The European Commission is accountable to Parliament, requiring its approval to take office, having to report back to it and subject to motions of censure from it. The President of the European Parliament (currently Antonio Tajani) carries out the role of speaker in Parliament and represents it externally. The President and Vice-Presidents are elected by MEPs every two and a half years.[95]</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/4/4b/Ioannes_Claudius_Juncker_die_7_Martis_2014.jpg/170px-Ioannes_Claudius_Juncker_die_7_Martis_2014.jpg" width="170" height="235"><p>


				Commission President, Jean-Claude Juncker


				</p><p>
					The European Commission acts as the EU's executive arm and is responsible for initiating legislation and the day-to-day running of the EU. The Commission is also seen as the motor of European integration. It operates as a cabinet government, with 28 Commissioners for different areas of policy, one from each member state, though Commissioners are bound to represent the interests of the EU as a whole rather than their home state.</p><p>One of the 28 is the President of the European Commission (currently Jean-Claude Juncker) appointed by the European Council. After the President, the most prominent Commissioner is the High Representative of the Union for Foreign Affairs and Security Policy, who is ex-officio a Vice-President of the Commission and is also chosen by the European Council.[96] The other 26 Commissioners are subsequently appointed by the Council of the European Union in agreement with the nominated President. The 28 Commissioners as a single body are subject to a vote of approval by the European Parliament.</p><h3>Budget</h3><p> Main article: Budget of the European Union</p><br><img alt="Circle frame.svg" src="http://upload.wikimedia.org/wikipedia/commons/thumb/1/18/Circle_frame.svg/200px-Circle_frame.svg.png" width="200" height="200"><p>The 2011 EU budget (€141.9 bn)[97]</p><p>The EU had an agreed budget of €120.7&nbsp;billion for the year 2007 and €864.3&nbsp;billion for the period 2007–2013,[98] representing 1.10% and 1.05% of the EU-27's GNI forecast for the respective periods. In 1960, the budget of the then European Economic Community was 0.03% of GDP.[99]</p><div class="gradientback"></div></div><div class="content"><p>In the 2010 budget of €141.5&nbsp;billion, the largest single expenditure item is cohesion &amp; competitiveness with around 45% of the total budget.[100] Next comes agriculture with approximately 31% of the total.[100] Rural development, environment and fisheries takes up around 11%.[100] Administration accounts for around 6%.[100] The EU as a global partner and citizenship, freedom, security and justice bring up the rear with approximately 6% and 1% respectively.[100]</p><p>The Court of Auditors is legally obliged to provide the Parliament and the Council with a statement of assurance as to the reliability of the accounts and the legality and regularity of the underlying transactions.[101] The Court also gives opinions and proposals on financial legislation and anti-fraud actions.[102] The Parliament uses this to decide whether to approve the Commission's handling of the budget.</p><p>The European Court of Auditors has signed off the European Union accounts every year since 2007[when?] and, while making it clear that the European Commission has more work to do, has highlighted that most of the errors take place at national level.[103][104] In their report on 2009 the auditors found that five areas of Union expenditure, agriculture and the cohesion fund, were materially affected by error.[105] The European Commission estimated in 2009 that the financial effect of irregularities was €1,863&nbsp;million.[106]</p><h3>Competences</h3><p>EU member states retain all powers not explicitly handed to the European Union. In some areas the EU enjoys exclusive competence. These are areas in which member states have renounced any capacity to enact legislation. In other areas the EU and its member states share the competence to legislate. While both can legislate, member states can only legislate to the extent to which the EU has not. In other policy areas the EU can only co-ordinate, support and supplement member state action but cannot enact legislation with the aim of harmonising national laws.[107]</p><p>That a particular policy area falls into a certain category of competence is not necessarily indicative of what legislative procedure is used for enacting legislation within that policy area. Different legislative procedures are used within the same category of competence, and even with the same policy area.</p><p>The distribution of competences in various policy areas between Member States and the Union is divided in the following three categories:</p><h2>Legal system</h2><p> Further information: European Union law, Treaties of the European Union, and Charter of Fundamental Rights of the European Union</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/d/d9/European_Court_of_Justice_-_Luxembourg_%281674586821%29.jpg/220px-European_Court_of_Justice_-_Luxembourg_%281674586821%29.jpg" width="220" height="165"><p>


				The Court of Justice, seated in Luxembourg.


				</p><p>
					The EU is based on a series of treaties. These first established the European Community and the EU, and then made amendments to those founding treaties.[108] These are power-giving treaties which set broad policy goals and establish institutions with the necessary legal powers to implement those goals. These legal powers include the ability to enact legislation[i] which can directly affect all member states and their inhabitants.[j] The EU has legal personality, with the right to sign agreements and international treaties.[109]</p><p>Under the principle of supremacy, national courts are required to enforce the treaties that their member states have ratified, and thus the laws enacted under them, even if doing so requires them to ignore conflicting national law, and (within limits) even constitutional provisions.[k]</p><h3>Courts of Justice</h3><p>The judicial branch of the EU—formally called the Court of Justice of the European Union—consists of three courts: the Court of Justice, the General Court, and the European Union Civil Service Tribunal. Together they interpret and apply the treaties and the law of the EU.[110]</p><p>The Court of Justice primarily deals with cases taken by member states, the institutions, and cases referred to it by the courts of member states.[111] The General Court mainly deals with cases taken by individuals and companies directly before the EU's courts,[112] and the European Union Civil Service Tribunal adjudicates in disputes between the European Union and its civil service.[113] Decisions from the General Court can be appealed to the Court of Justice but only on a point of law.[114]</p><h3>Fundamental rights</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/a/a7/Remise_du_Prix_Sakharov_%C3%A0_Aung_San_Suu_Kyi_Strasbourg_22_octobre_2013-14.jpg/220px-Remise_du_Prix_Sakharov_%C3%A0_Aung_San_Suu_Kyi_Strasbourg_22_octobre_2013-14.jpg" width="220" height="147"><p>


				The ceremony of the 1990 Sakharov Prize awarded to Aung San Suu Kyi by Martin Schulz, inside the Parliament's Strasbourg hemicycle, in 2013.


				</p><p>
					The treaties declare that the EU itself is founded on the values of respect for human dignity, freedom, democracy, equality, the rule of law and respect for human rights, including the rights of persons belonging to minorities&nbsp;... in a society in which pluralism, non-discrimination, tolerance, justice, solidarity and equality between women and men prevail.[115]</p><p>In 2009, the Lisbon Treaty gave legal effect to the Charter of Fundamental Rights of the European Union. The charter is a codified catalogue of fundamental rights against which the EU's legal acts can be judged. It consolidates many rights which were previously recognised by the Court of Justice and derived from the constitutional traditions common to the member states.[116] The Court of Justice has long recognised fundamental rights and has, on occasion, invalidated EU legislation based on its failure to adhere to those fundamental rights.[117]</p><p>Although signing the European Convention on Human Rights (ECHR) is a condition for EU membership,[l] previously, the EU itself could not accede to the Convention as it is neither a state[m] nor had the competence to accede.[n] The Lisbon Treaty and Protocol 14 to the ECHR have changed this: the former binds the EU to accede to the Convention while the latter formally permits it.</p><p>Although, the EU is independent from Council of Europe, they share purpose and ideas especially on rule of law, human rights and democracy. Further European Convention on Human Rights and European Social Charter, the source of law of Charter of Fundamental Rights are created by Council of Europe. The EU also promoted human rights issues in the wider world. The EU opposes the death penalty and has proposed its worldwide abolition. Abolition of the death penalty is a condition for EU membership.[118]</p><div class="gradientback"></div></div><div class="content"><h3>Acts</h3><p>The main legal acts of the EU come in three forms: regulations, directives, and decisions. Regulations become law in all member states the moment they come into force, without the requirement for any implementing measures,[o] and automatically override conflicting domestic provisions.[i] Directives require member states to achieve a certain result while leaving them discretion as to how to achieve the result. The details of how they are to be implemented are left to member states.[p] When the time limit for implementing directives passes, they may, under certain conditions, have direct effect in national law against member states.</p><p>Decisions offer an alternative to the two above modes of legislation. They are legal acts which only apply to specified individuals, companies or a particular member state. They are most often used in competition law, or on rulings on State Aid, but are also frequently used for procedural or administrative matters within the institutions. Regulations, directives, and decisions are of equal legal value and apply without any formal hierarchy.[119]</p><h3>Area of freedom, security and justice</h3><p> Further information: Area of freedom, security and justice</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/7/76/OffeneGrenzeNiederndorf-Oberaudorf.jpg/220px-OffeneGrenzeNiederndorf-Oberaudorf.jpg" width="220" height="165"><p>


				The borders inside the Schengen Area between Germany and Austria



				<br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/a/a3/Europol_Building%3B_The_Hague%3B_Eisenhowerlaan%3B_Statenkwartier%3B_2014%3B_photo_nr._41860.jpg/220px-Europol_Building%3B_The_Hague%3B_Eisenhowerlaan%3B_Statenkwartier%3B_2014%3B_photo_nr._41860.jpg" width="220" height="165"><br>


				Europol Headquarters in The Hague, Netherlands


				</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/a/a3/Europol_Building%3B_The_Hague%3B_Eisenhowerlaan%3B_Statenkwartier%3B_2014%3B_photo_nr._41860.jpg/220px-Europol_Building%3B_The_Hague%3B_Eisenhowerlaan%3B_Statenkwartier%3B_2014%3B_photo_nr._41860.jpg" width="220" height="165"><br><p>
					Since the creation of the EU in 1993, it has developed its competencies in the area of freedom, security and justice, initially at an intergovernmental level and later by supranationalism. To this end, agencies have been established that co-ordinate associated actions: Europol for co-operation of police forces,[120] Eurojust for co-operation between prosecutors,[121] and Frontex for co-operation between border control authorities.[122] The EU also operates the Schengen Information System[15] which provides a common database for police and immigration authorities. This co-operation had to particularly be developed with the advent of open borders through the Schengen Agreement and the associated cross border crime.</p><p>Furthermore, the Union has legislated in areas such as extradition,[123] family law,[124] asylum law,[125] and criminal justice.[126] Prohibitions against sexual and nationality discrimination have a long standing in the treaties.[q] In more recent years, these have been supplemented by powers to legislate against discrimination based on race, religion, disability, age, and sexual orientation.[r] By virtue of these powers, the EU has enacted legislation on sexual discrimination in the work-place, age discrimination, and racial discrimination.[s]</p><h2>Foreign relations</h2><p> Main articles: Foreign relations of the European Union, Common Foreign and Security Policy, and European External Action Service</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/5/52/Federica_Mogherini_Official.jpg/170px-Federica_Mogherini_Official.jpg" width="170" height="217"><p>


				High Representative of the Union for Foreign Affairs and Security Policy, Federica Mogherini



				<br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/0/03/Prime_Minister_Narendra_Modi_at_the_G20_Summit_in_Hangzhou%2C_China.jpg/220px-Prime_Minister_Narendra_Modi_at_the_G20_Summit_in_Hangzhou%2C_China.jpg" width="220" height="128"><br>


				The EU participates in all G8 and G20 summits. (G20 summit in Hangzhou, 2016)



				<br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/2/22/Juncker_Trump_Tusk_Brussels_2017.jpg/220px-Juncker_Trump_Tusk_Brussels_2017.jpg" width="220" height="147"><br>


				Donald Tusk and Jean-Claude Juncker with U.S. President Donald Trump


				</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/0/03/Prime_Minister_Narendra_Modi_at_the_G20_Summit_in_Hangzhou%2C_China.jpg/220px-Prime_Minister_Narendra_Modi_at_the_G20_Summit_in_Hangzhou%2C_China.jpg" width="220" height="128"><br><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/2/22/Juncker_Trump_Tusk_Brussels_2017.jpg/220px-Juncker_Trump_Tusk_Brussels_2017.jpg" width="220" height="147"><br><p>
					Foreign policy co-operation between member states dates from the establishment of the Community in 1957, when member states negotiated as a bloc in international trade negotiations under the common commercial policy.[127] Steps for a more wide-ranging co-ordination in foreign relations began in 1970 with the establishment of European Political Cooperation which created an informal consultation process between member states with the aim of forming common foreign policies. It was not, however, until 1987 when European Political Cooperation was introduced on a formal basis by the Single European Act. EPC was renamed as the Common Foreign and Security Policy (CFSP) by the Maastricht Treaty.[128]</p><p>The aims of the CFSP are to promote both the EU's own interests and those of the international community as a whole, including the furtherance of international co-operation, respect for human rights, democracy, and the rule of law.[129] The CFSP requires unanimity among the member states on the appropriate policy to follow on any particular issue. The unanimity and difficult issues treated under the CFSP sometimes lead to disagreements, such as those which occurred over the war in Iraq.[130]</p><div class="gradientback"></div></div><div class="content"><p>The coordinator and representative of the CFSP within the EU is the High Representative of the Union for Foreign Affairs and Security Policy who speaks on behalf of the EU in foreign policy and defence matters, and has the task of articulating the positions expressed by the member states on these fields of policy into a common alignment. The High Representative heads up the European External Action Service (EEAS), a unique EU department[131] that has been officially implemented and operational since 1 December 2010 on the occasion of the first anniversary of the entry into force of the Treaty of Lisbon.[132] The EEAS will serve as a foreign ministry and diplomatic corps for the European Union.[133]</p><p>Besides the emerging international policy of the European Union, the international influence of the EU is also felt through enlargement. The perceived benefits of becoming a member of the EU act as an incentive for both political and economic reform in states wishing to fulfil the EU's accession criteria, and are considered an important factor contributing to the reform of European formerly Communist countries.[134]:762 This influence on the internal affairs of other countries is generally referred to as soft power, as opposed to military hard power.[135]</p><h3>Military</h3><p> Main article: Military of the European Union</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/2/21/Frontex_HQ_Warsaw_Spire_office_complex_Warsaw.jpg/170px-Frontex_HQ_Warsaw_Spire_office_complex_Warsaw.jpg" width="170" height="225"><p>


				Seat of Frontex in Warsaw


				</p><p>
					The predecessors of the European Union were not devised as a military alliance because NATO was largely seen as appropriate and sufficient for defence purposes.[136] 22 EU members are members of NATO[137] while the remaining member states follow policies of neutrality.[138] The Western European Union, a military alliance with a mutual defence clause, was disbanded in 2010 as its role had been transferred to the EU.[139]</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/b/ba/A400M.jpg/220px-A400M.jpg" width="220" height="172"><p>


				An A400M military transport aircraft built by Airbus Group SE (Societas Europaea; Latin: European company)


				</p><p>
					According to the Stockholm International Peace Research Institute (SIPRI), the United Kingdom spent $61 billion on defence in 2014, placing it fifth in the world, while France spent $53 billion, the sixth largest.[140] Together, the UK and France account for approximately 40 per cent of European countries' defence budget and 50 per cent of their military capacity.[141] Both are officially recognised nuclear weapon states holding permanent seats on the United Nations Security Council.</p><p>Following the Kosovo War in 1999, the European Council agreed that the Union must have the capacity for autonomous action, backed by credible military forces, the means to decide to use them, and the readiness to do so, in order to respond to international crises without prejudice to actions by NATO. To that end, a number of efforts were made to increase the EU's military capability, notably the Helsinki Headline Goal process. After much discussion, the most concrete result was the EU Battlegroups initiative, each of which is planned to be able to deploy quickly about 1500&nbsp;personnel.[142]</p><p>EU forces have been deployed on peacekeeping missions from middle and northern Africa to the western Balkans and western Asia.[143] EU military operations are supported by a number of bodies, including the European Defence Agency, European Union Satellite Centre and the European Union Military Staff.[144] Frontex is an agency of the EU established to manage the cooperation between national border guards securing its external borders. It aims to detect and stop illegal immigration, human trafficking and terrorist infiltration. In 2015 the European Commission presented its proposal for a new European Border and Coast Guard Agency having a stronger role and mandate along with national authorities for border management. In an EU consisting of 28 members, substantial security and defence co-operation is increasingly relying on collaboration among all member states.[145]</p><h3>Humanitarian aid</h3><p> Further information: Directorate-General for European Civil Protection and Humanitarian Aid Operations</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/1/19/ECHO_plane.jpg/220px-ECHO_plane.jpg" width="220" height="147"><p>


				Collectively, the EU is the largest contributor of foreign aid in the world.[146][147]



				<br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/4/4a/IAHV%2C_Jordan_Program_At_Syrian_Refugee_Camp.jpg/220px-IAHV%2C_Jordan_Program_At_Syrian_Refugee_Camp.jpg" width="220" height="165"><br>


				The European Union co-funds psychosocial support by the IAHV, Jordan at the Zaatari refugee camp for the Syrian refugees.


				</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/4/4a/IAHV%2C_Jordan_Program_At_Syrian_Refugee_Camp.jpg/220px-IAHV%2C_Jordan_Program_At_Syrian_Refugee_Camp.jpg" width="220" height="165"><br><p>
					The European Commission's Humanitarian Aid and Civil Protection department, or ECHO, provides humanitarian aid from the EU to developing countries. In 2012, its budget amounted to €874 million, 51% of the budget went to Africa and 20% to Asia, Latin America, the Caribbean and Pacific, and 20% to the Middle East and Mediterranean.[148]</p><p>Humanitarian aid is financed directly by the budget (70%) as part of the financial instruments for external action and also by the European Development Fund (30%).[149] The EU's external action financing is divided into 'geographic' instruments and 'thematic' instruments.[149] The 'geographic' instruments provide aid through the Development Cooperation Instrument (DCI, €16.9 billion, 2007–2013), which must spend 95% of its budget on overseas development assistance (ODA), and from the European Neighbourhood and Partnership Instrument (ENPI), which contains some relevant programmes.[149] The European Development Fund (EDF, €22.7 bn, 2008–2013) is made up of voluntary contributions by member states, but there is pressure to merge the EDF into the budget-financed instruments to encourage increased contributions to match the 0.7% target and allow the European Parliament greater oversight.[149]</p><div class="gradientback"></div></div><div class="content"><p>However, five countries have reached the 0.7% target: Sweden, Luxembourg, the Netherlands, Denmark and the United Kingdom.[150][151]</p><h2>Economy</h2><p> Main articles: Economy of the European Union and Regional policy of the European Union</p><br><img usemap="#timeline_fa1ebd3b5720f6ccccd2c926bfbe040f" src="http://upload.wikimedia.org/wikipedia/en/timeline/fa1ebd3b5720f6ccccd2c926bfbe040f.png"><p>The European Union has established a single market across the territory of all its members representing 510 million citizens. In 2014, the EU had a combined GDP of 18.640 trillion international dollars, a 20% share of global gross domestic product by purchasing power parity (PPP).[153] As a political entity the European Union is represented in the World Trade Organization (WTO). EU member states own the estimated largest net wealth in the world, equal to 30% of the $223 trillion global wealth.[citation needed]</p><p>19 member states have joined a monetary union known as the eurozone, which uses the Euro as a single currency. The currency union represents 338 million EU citizens.[154] The euro is the second largest reserve currency as well as the second most traded currency in the world after the United States dollar.[155][156][157]</p><p>Of the top 500 largest corporations in the world measured by revenue in 2010, 161 have their headquarters in the EU.[158] In 2016, unemployment in the EU stood at 8.9%[159] while inflation was at 2.2%, and the current account balance at -0.9% of GDP. The average annual net wage in the European Union was around $20,000 in 2015, which was about half of that in the United States.[160]</p><p>There is a significant variance for GDP (PPP) per capita within individual EU states. The difference between the richest and poorest regions (276 NUTS-2 regions of the Nomenclature of Territorial Units for Statistics) ranged, in 2014, from 30% of the EU28 average to 539%, or from €8,200 to €148,000 (about US$9,000 to US$162,000).[161]</p><p>Structural Funds and Cohesion Funds are supporting the development of underdeveloped regions of the EU. Such regions are primarily located in the states of central and southern Europe.[162][163] Several funds provide emergency aid, support for candidate members to transform their country to conform to the EU's standard (Phare, ISPA, and SAPARD), and support to the Commonwealth of Independent States (TACIS). TACIS has now become part of the worldwide EuropeAid programme. EU research and technological framework programmes sponsor research conducted by consortia from all EU members to work towards a single European Research Area.[164]</p><h3>Internal market</h3><p> Main article: European Single Market</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/d/d7/Eirepas.JPG/170px-Eirepas.JPG" width="170" height="239"><p>


				A standardised passport design, displaying the name of the member state, the national arms and the words "European Union" given in their official language(s). (Irish model)



				<br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/DE_Licence_2013_Front.jpg/220px-DE_Licence_2013_Front.jpg" width="220" height="143"><br>


				German version of an EU driving licence card with the EU flag on it



				<br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/8/8f/SK-number-plate-2004.svg/220px-SK-number-plate-2004.svg.png" width="220" height="49"><br>


				The common EU format of vehicle registration plate
				(Slovak version pictured)


				</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/DE_Licence_2013_Front.jpg/220px-DE_Licence_2013_Front.jpg" width="220" height="143"><br><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/8/8f/SK-number-plate-2004.svg/220px-SK-number-plate-2004.svg.png" width="220" height="49"><br><p>
					Two of the original core objectives of the European Economic Community were the development of a common market, subsequently becoming a single market, and a customs union between its member states. The single market involves the free circulation of goods, capital, people, and services within the EU,[154] and the customs union involves the application of a common external tariff on all goods entering the market. Once goods have been admitted into the market they cannot be subjected to customs duties, discriminatory taxes or import quotas, as they travel internally. The non-EU member states of Iceland, Norway, Liechtenstein and Switzerland participate in the single market but not in the customs union.[64] Half the trade in the EU is covered by legislation harmonised by the EU.[165]</p><p>Free movement of capital is intended to permit movement of investments such as property purchases and buying of shares between countries.[166] Until the drive towards economic and monetary union the development of the capital provisions had been slow. Post-Maastricht there has been a rapidly developing corpus of ECJ judgements regarding this initially neglected freedom. The free movement of capital is unique insofar as it is granted equally to non-member states.</p><p>The free movement of persons means that EU citizens can move freely between member states to live, work, study<br>
							

											 
										
				<br><img alt="Page semi-protected" src="http://upload.wikimedia.org/wikipedia/commons/thumb/f/fc/Padlock-silver.svg/20px-Padlock-silver.svg.png" width="20" height="20">

							</p><br><br><img alt="Page semi-protected" src="http://upload.wikimedia.org/wikipedia/commons/thumb/f/fc/Padlock-silver.svg/20px-Padlock-silver.svg.png" width="20" height="20"><h1 lang="en">List of countries by GDP (PPP)</h1><p> From Wikipedia, the free encyclopedia</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/5/5b/GDP_PPP_2016_Selection_EN.svg/270px-GDP_PPP_2016_Selection_EN.svg.png" width="270" height="270"><div class="gradientback"></div></div><div class="content"><p>


				The top ten largest economies by GDP (PPP)


				</p><p>
					This article includes a list of countries by their forecasted estimated gross domestic product (PPP).[2] Countries are sorted by GDP PPP forecasted estimates from financial and statistical institutions in the limited period January-April 2017, which are calculated at market or government official exchange rates. The GDP dollar (INT$) data given on this page are derived from purchasing power parity (PPP) calculations.</p><p>Comparisons using PPP are arguably more useful than nominal when assessing a nation's domestic market because PPP takes into account the relative cost of local goods, services and inflation rates of the country, rather than using international market exchange rates which may distort the real differences in per capita income.[3] It is however limited when measuring financial flows between countries.[4] PPP is often used to gauge global poverty thresholds and is used by the United Nations in constructing the human development index.[3] These surveys such as the International Comparison Program include both tradable and non-tradable goods in an attempt to estimate a representative basket of all goods.[3]</p><p>The first table includes estimation for the year 2017, for all current 191 International Monetary Fund (IMF) members, as well as Hong Kong and Taiwan (the official list uses Taiwan, Province of China). Data are in millions of international dollars and were calculated by the IMF. Figures were published in April 2017. The second table includes data mostly for the year 2015 for 180 of the 193 current United Nations member states, as well as the two Chinese Special Administrative Regions (Hong Kong and Macau). Data are in billions of international dollars and were compiled by the World Bank. The third table is a tabulation of the CIA World Factbook Gross Domestic Product (GDP) (Purchasing Power Parity) data update of 2016. The data for GDP at purchasing power parity have also been rebased using the new International Comparison Program price surveys and extrapolated to 2007.</p><h2>Contents</h2><h2>Lists</h2><p>Click on one of the small triangles in the headings to re-order the list according to that category.</p><h2>Notes</h2><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=List_of_countries_by_GDP_(PPP)&amp;oldid=783197763"					
								Categories:  Hidden categories:</p><br><h1 lang="en">List of countries by GDP (nominal) per capita</h1><p> From Wikipedia, the free encyclopedia</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/b/b2/GDP_per_capita_%28nominal%29_2015.png/500px-GDP_per_capita_%28nominal%29_2015.png" width="500" height="231"><p>


				Countries by 2015 GDP (nominal) per capita.[1]
				 



				</p><p>
					The world sorted by their gross domestic product per capita at nominal values. This is the value of all final goods and services produced within a nation in a given year, converted at market exchange rates to current U.S. dollars, divided by the average (or mid-year) population for the same year.</p><p>The figures presented here do not take into account differences in the cost of living in different countries, and the results may vary greatly from one year to another based on fluctuations in the exchange rates of the country's currency. Such fluctuations may change a country's ranking from one year to the next, even though they often make little or no difference to the standard of living of its population.</p><p>Therefore, these figures should be used with caution. GDP per capita is often considered an indicator of a country's standard of living;[2][3] although this can be problematic because GDP per capita is not a measure of personal income.</p><p>Comparisons of national income are also frequently made on the basis of purchasing power parity (PPP), to adjust for differences in the cost of living in different countries. (See List of countries by GDP (PPP) per capita.) PPP largely removes the exchange rate problem but not others; it does not reflect the value of economic output in international trade, and it also requires more estimation than GDP per capita. On the whole, PPP per capita figures are more narrowly spread than nominal GDP per capita figures.</p><p>Non-sovereign entities (the world, and some dependent territories) are included in the list because they appear in the sources. These economies are not ranked in the charts here, but are listed in sequence by GDP for comparison. They are marked in italics.</p><p>All data are in current United States dollars.</p><h2>Contents</h2><h2>List of per capita nominal GDP for countries and dependencies</h2><h2>Notes and references</h2><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=List_of_countries_by_GDP_(nominal)_per_capita&amp;oldid=782854524"					
								Categories:  				
											
						<br>
							

											 
										

							</p><br><h1 lang="en">ISO 4217</h1><p> From Wikipedia, the free encyclopedia</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/3/3b/Flugschein.JPG/220px-Flugschein.JPG" width="220" height="97">
				<div class="gradientback"></div></div><div class="content">
				<br><h2>Safavid dynasty (1501–1736)</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/4/40/Safavid_dynasty_%28greatest_extent%29.svg/220px-Safavid_dynasty_%28greatest_extent%29.svg.png" width="220" height="220"><br><h2>Afsharid dynasty (1736–1796)</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/4/44/Afsharid_dynasty_%28greatest_extent%29.svg/220px-Afsharid_dynasty_%28greatest_extent%29.svg.png" width="220" height="220"><br><h2>Zand dynasty (1751–1794)</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/2/26/Zand_dynasty.svg/220px-Zand_dynasty.svg.png" width="220" height="220"><br><h2>Qajar dynasty (1794–1925)</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/c/c9/Qajar_dynasty_%28greatest_extent%29.svg/220px-Qajar_dynasty_%28greatest_extent%29.svg.png" width="220" height="220"><br><h2>Pahlavi dynasty (1925–1979)</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/a/a8/Iran_%28orthographic_projection%29.svg/220px-Iran_%28orthographic_projection%29.svg.png" width="220" height="220"><br><h2>Notes and references</h2><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=List_of_monarchs_of_Persia&amp;oldid=781609043"					
								Categories:  Hidden categories:</p><br><h1 lang="en">Pishdadian dynasty</h1><p>
					 From Wikipedia, the free encyclopedia</p><p>Pishdadian (Persian: ???????????) is the first dynasty of Iranian people in the Shahnameh, Avesta and Iranian mythology. The Pishdadian Dynasty is said to have produced the first kings who ruled over the land of Persia. Some of the Pishdadian kings are thought to have ruled for thousands of years.</p><h2>Contents</h2><h2>Pishdadi Kings in Shahnameh</h2><p>The Pishdadi kings are as follows:</p><div class="gradientback"></div></div><div class="content"><li>Keyumars</li><li>Hushang</li><li>Tahmuras</li><li>Jamshid</li><li>Zahhak</li><li>Fereydun</li><li>Iraj</li><li>Manuchehr</li><li>Nowzar</li><li>Zaav or Zou (King)</li><li>Garshasp (King)</li><h2>Family Tree</h2><h2>Capital</h2><p>Amol, the capital Nowzar, Kai Kobad, Fereydun and Kai Khosrow.[1][2]</p><li>^ Damavand MT</li><li>^ The Early Rulers of Persia, Part I: The Pishdadian Dynasty</li><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Pishdadian_dynasty&amp;oldid=769858471"					
								Categories:  Hidden categories:</p><br><h1 lang="en">Mannaeans</h1><p> From Wikipedia, the free encyclopedia</p><p>The Mannaeans /m?'ni??nz/ (country name usually Mannea; Akkadian: Mannai, possibly Biblical Minni, ????) were an ancient people who lived in the territory of present-day northwestern Iran south of lake Urmia, around the 10th to 7th centuries BC. At that time they were neighbors of the empires of Assyria and Urartu, as well as other small buffer states between the two, such as Musasir and Zikirta.</p><p>In the Bible (Jeremiah 51:27) the Mannaeans are called Minni. In the Jewish Encyclopedia (1906), Minni is identified with Armenia,[1][2] but it could refer to one of the provinces in ancient Armenia; Minni, Ararat and Ashkenaz.[3][4] According to examinations of the place and personal names found in Assyrian and Urartian texts, the Mannaeans, or at least their rulers, spoke Hurrian, a non-Semitic and non-Indo-European language related to Urartian, with no modern language connections.[5]</p><h2>Contents</h2><h2>Location</h2><p>Their kingdom was situated east and south of the Lake Urmia, roughly centered around the Urmia plain in this part of what is today named Azerbaijan region of Iran.[6] Excavations that began in 1956 succeeded in uncovering the fortified city of Hasanlu, once thought to be a potential Mannaean site. More recently, the site of Qalaichi (possibly ancient Izirtu/Zirta) has been linked to the Mannaeans based on a stela with this toponym found at the site.</p><p>After suffering several defeats at the hands of both Scythians and Assyrians, the remnants of the Mannaean populace were absorbed by an Iranian people known as the Matieni and the area became known as Matiene.[7][8] It was then annexed by the Medes in about 609 BC.</p><h2>Ethnicity</h2><p>According to the Encyclopædia Iranica:[9]</p><p>According to the Archaeological Institute of America, 1964:[10]</p><p>In the Bible (Jeremiah 51:27), the Mannaeans are called Minni. The Jewish Encyclopedia (1906), identified Minni with Armenia,[1][2] but it could refer to one of the provinces in ancient Armenia; Minni, Ararat and Ashkenaz.[3] According to examinations of the place and personal names found in Assyrian and Urartian texts, the Mannaeans, or at least their rulers, spoke Hurrian, a non-Semitic and non-Indo-European language related to Urartian, with no modern language connections.[5]</p><h2>History</h2><p>The Mannaean kingdom began to flourish around 850 BC. The Mannaeans were mainly a settled people, practicing irrigation and breeding cattle and horses. The capital was another fortified city, Izirtu (Zirta).</p><p>By the 820s BC they had expanded to become the first large state to occupy this region since the Gutians, later followed by the unrelated Iranian peoples, the Medes and the Persians. By this time they had a prominent aristocracy as a ruling class, which somewhat limited the power of the king.</p><p>Beginning around 800 BC, the region became contested ground between Urartu, who built several forts on the territory of Mannae, and Assyria. During open conflict between the two, ca. 750-730 BC, Mannae seized the opportunity to enlarge its holdings. The Mannaean kingdom reached the pinnacle of its power during the reign of Iranzu (ca. 725-720 BC).</p><p>In 716 BC, king Sargon II of Assyria moved against Mannae, where the ruler Aza, son of Iranzu, had been deposed by Ullusunu with the help of the Urartians. Sargon took Izirtu, and stationed troops in Parsua (Parsua was distinct from Parsumash located further southeast in what is today known as Fars province in Iran[citation needed]). The Assyrians thereafter used the area to breed, train and trade horses.</p><p>According to one Assyrian inscription, the Cimmerians (Gimirru) originally went forth from their homeland of Gamir or Uishdish on the shores of the Black Sea in the midst of Mannai around this time. The Cimmerians first appear in the annals in the year 714 BC, when they apparently helped the Assyrians to defeat Urartu. Urartu chose to submit to the Assyrians, and together the two defeated the Cimmerians and thus kept them out of the Fertile Crescent. At any rate, the Cimmerians had again rebelled against Sargon by 705, and he was killed whilst driving them out. By 679 they had instead migrated to the east and west of Mannae.</p><p>The Mannaeans are recorded as rebelling against Esarhaddon of Assyria in 676 BC, when they attempted to interrupt the horse trade between Assyria and its colony of Parsuash.</p><p>The king Ahsheri, who ruled until the 650s BC, continued to enlarge the territory of Mannae, although paying tribute to Assyria. However, Mannae suffered a crushing defeat at the hands of the Assyrians around 660 BC, and subsequently an internal revolt broke out, continuing until Ahsheri's death. Also in the 7th century BC, Mannae was defeated by the advancing Scythians, who had already raided Urartu and been repelled by the Assyrians. Somewhat later (585 BC) destroying Mannae. This defeat contributed to the further break-up of the Mannaean kingdom.</p><p>King Ahsheri's successor, Ualli, as a vassal of Assyria, took the side of the Assyrians against the Iranian Medes (Madai), who were at this point still based to the east along the southwest shore of the Caspian Sea and revolting against Assyrian domination. The Medes and Persians were subjugated by Assyria. However, the Neo Assyrian Empire which had dominated the region for three hundred years began to unravel, consumed by civil war after the death of Ashurbanipal in 627 BC. The upheavals in Assyria allowed the Medes to free themselves from Assyrian vassalage and make themselves the major power in ancient Iran at the expense of the Persians, Mannaeans and the remnants of the indigenous Elamites whose kingdom had been destroyed by the Assyrians. The Mede kingdom conquered the remnants of Mannae in 616 BC and absorbed the populace.</p><div class="gradientback"></div></div><div class="content"><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Mannaeans&amp;oldid=783310175"					
								Categories:  Hidden categories:</p><br><h1 lang="en">Atropatene</h1><p> From Wikipedia, the free encyclopedia</p><p>Atropatene (Greek: ?t??pat???; originally known as Atropatkan and Atorpatkan ) was an ancient kingdom established and ruled under local ethnic Iranian dynasties, first with Darius III of Persia and later Alexander the Great of Macedonia[1] starting in the 4th century BC and includes the territory of modern-day Iranian Azerbaijan,[2] Iranian Kurdistan,[3] and a small part of the contemporary Azerbaijan Republic. Its capital was Ganzak. Atropatene also was the nominal ancestor of the name Azerbaijan.[4]</p><h2>Contents</h2><h2>History</h2><p>Following the death of Alexander the Great in 323 BC, the Macedonian's conquests were divided amongst the diadochi at the Partition of Babylon. The former Achaemenid satrapy of Media was divided into two states: The greater (southern) part — Media Magna was assigned to Peithon, one of Alexander's bodyguards. The smaller (northern) region, which had been the sub-satrapy of Matiene, became Media Atropatene under Atropates, the former Achaemenid governor of all Media, who had by then become father-in-law of Perdiccas, regent of Alexander's designated successor.</p><p>Shortly thereafter, Atropates refused to pay allegiance to Seleucus, and made Media Atropatene an independent kingdom. It subsequently lost the Media prefix in the name and came to be known simply as Atropatene. The dynasty Atropates founded would rule the kingdom for several centuries, first independently, then as vassals of the Arsacids (who called it 'Aturpatakan'). It was eventually annexed by the Arsacids, who then lost it to the Sassanids, who again called it 'Aturpatakan'. At some time between 639 and 643 the Arabs under the Rashidun took control of the area during the reign of Umar. Atropatene formed a separate province of the early Islamic caliphate and was considered to have had strategic importance. It was during the Arab period that Middle Iranian (i.e. Parthian and Middle Persian) Aturpatakan became Adarbaygan, Adarbayjan or Azerbaijan.</p><h2>List of rulers</h2><p>Although the below list is incomplete, they are the known ruling Kings of Media Atropatene.</p><h2>Sources</h2><p>Coordinates: 37°N 48°E? / ?37°N 48°E? / 37; 48</p><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Atropatene&amp;oldid=782553238"					
								Categories:  Hidden categories:</p><br><h1 lang="en">Qarinvand dynasty</h1><p> From Wikipedia, the free encyclopedia</p><p>The Qarinvand dynasty (also spelled Karinvand, Karenvand, and Qarenvand), or simply the Karinids or Qarinids, was an Iranian dynasty that ruled in parts of Tabaristan (Mazandaran) in what is now northern Iran from the 550s until the 11th-century. They considered themselves as the inheritors of the Dabuyid dynasty, and were known by their titles of Gilgilan and Ispahbadh. They were descended from Sukhra, a Parthian nobleman from the House of Karen, who was the de facto ruler of the Sasanian Empire from 484 to 493.</p><h2>Contents</h2><h2>History</h2><p>The dynasty was founded by Karin, who in return for aiding the Sasanian king Khosrow I (r. 531–579) against the Turks, received land to the south of Amol in Tabaristan. During the 7th century, a unnamed ruler Qarinvand dynasty was granted parts of Tabaristan by the Dabuyids who ruled in the area. In 760, the Dabuyid ruler Khurshid was defeated, his dynasty abolished and Tabaristan annexed by the Abbasids, but the Qarinvand and other minor local dynasties continued in existence. At this time, a certain Vindadhhurmuzd is mentioned as the Qarinvand ruler, while his younger brother Vindaspagan ruled as a subordinate ruler over the western Qarinvand regions, which reached as far as Dailam,[1] a region controlled by the Dailamites, who like the Qarinvands and other rulers of Tabaristan were Zoroastrians.</p><p>Vindadhhurmuzd, along with the Bavandid ruler Sharwin I, led the native resistance to Muslim rule and the efforts at Islamization and settlement begun by the Abbasid governor, Khalid ibn Barmak (768–772). Following his departure, the native princes destroyed the towns he had built in the highlands, and although in 781 they affirmed loyalty to the Caliphate, in 782 they launched a general anti-Muslim revolt that was not suppressed until 785, when Sa'id al-Harashi led 40,000 troops into the region.[2] Relations with the caliphal governors in the lowlands improved thereafter, but the Qarinvand and Bavandid princes remained united in their opposition to Muslim penetration of the highlands, to the extent that they prohibited even the burial of Muslims there. Isolated acts of defiance like the murder of a tax collector occurred, but when the two princes were summoned before Harun al-Rashid in 805 they promised loyalty and the payment of a tax, and were forced to leave their sons behind as hostages for four years.[3]</p><p>Vindadhhurmuzd later died in 815, and was succeeded by his son Qarin ibn Vindadhhurmuzd, who along with Sharwin's successor Shahriyar I was requested by the Abbasid caliph al-Ma'mun to aid in the Arab–Byzantine wars. Shahriyar declined the request, while Qarin accepted, and became successful in his campaign against the Byzantines.[4] Qarin was then bestowed with many honors by Al-Ma'mun. Shahriyar, jealous of Qarin's fame, began annexing some of the latter's territory. In 817, during the reign of Qarin's son Mazyar, Shahriyar, with the aid of Mazyar's uncle Vinda-Umid, expelled the latter from Tabaristan, and seized all his territories.[4]</p><p>Mazyar fled to the court of al-Ma'mun, became a Muslim and in 822/23 returned with the support of the Abbasid governor to exact revenge: Shahriyar's son and successor, Shapur, was defeated and killed, and Mazyar united the highlands under his own rule. His growing power brought him into conflict with the Muslim settlers at Amul, but he was able to take the city and receive acknowledgement of his rule over all of Tabaristan from the caliphal court. Eventually, however, he quarreled with Abdallah ibn Tahir, and in 839, he was captured by the Tahirids, who now took over control of Tabaristan.[5] The Bavandids exploited the opportunity to regain their ancestral lands: Shapur's brother, Qarin I, assisted the Tahirids against Mazyar, and was rewarded with his brother's lands and royal title.</p><p>Quhyar, a brother of Mazyar, who had betrayed the latter and chose to aid the Tahirids, who promised him the Qarinvand throne, shortly ascended the Qarivand throne, but was shortly killed by his own Dailamite soldiers because of his betrayal against his brother. Although many scholars considered the death of Quhyar as the fall of the Qarinvand dynasty, the dynasty continued to rule in parts of Tabaristan, and a certain Baduspan ibn Gurdzad is mentioned in 864 as the ruler of the Qarinvand dynasty, and is known to have supported the Alid Hasan ibn Zayd. However, his son and successor Shahriyar ibn Baduspan was hostile to Hasan ibn Zayd, but was along with the Bavandid ruler Rustam I forced to acknowledge his authority.[6] Shahriyar's son Muhammad ibn Shahriyar is later mentioned as the later of the Qarivand dynasty in 917, and was like his father hostile to the Alids.[7] Two centuries later, a certain Qarinvand ruler named Amir Mahdi is mentioned in 1106 as one of the vassals of the Bavandid ruler Shahriyar IV. After him, no other Qarinvand ruler is known, but they continued to rule until the 11th-century.[5]</p><h2>Known Qarinvand rulers</h2><div class="gradientback"></div></div><div class="content"><h2>Sources</h2><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Qarinvand_dynasty&amp;oldid=742703446"					
								Categories:  Hidden categories:</p><br><h1 lang="en">Dabuyid dynasty</h1><p> From Wikipedia, the free encyclopedia</p><p>The Dabuyid or Gaubarid Dynasty was a Zoroastrian[1] Iranian dynasty that started in the early seventh century as an independent group of rulers, reigning over Tabaristan and parts of western Khorasan.[2] Dabuyid rule over Tabaristan and Khorasan lasted from ca. AD 642 to the Abbasid conquest in 760.</p><h2>Contents</h2><h2>History</h2><p>The family's early history is semi-mythical, and recorded by the later historian Ibn Isfandiyar. According to this story, the Dabuyids were descended from a brother of the Sassanid shah Kavadh I. His grandson Firuz conquered Gilan, and Firuz's grandson Gil, surnamed Gavbara, then extended the family's rule over Tabaristan as well. This led to the formal conferment of the titles of Gil-Gilan (ruler of Gilan) and Padashwargarshah (Shah of Patashwargar, the old name of Tabaristan's mountains), to Gil's son Dabuya or Daboe, by the last Sassanid shah, Yazdegerd III. Following the Muslim conquest of Persia the Dabuyids established their domain as a quasi-independent principality, owing only nominal allegiance to the Arab Caliphate. In addition to the titles granted by Yazdegerd, the Dabuyid rulers also bore the old Iranian military rank of ispahbadh as their regnal title.</p><p>The first documented ruler of the Dabuyid line, however, is Farrukhan the Great, who repelled a great Muslim invasion under Yazid ibn al-Muhallab in 716–717, and who may in reality be the true founder of Dabuyid rule in Tabaristan; more recent research places his assumption of power there in the 670s instead of the early 710s, as hitherto assumed. Farrokhan died in 728, and was succeeded by his son, Dadmihr. Little is known of his reign, and he died at an early age in 740/741. His son and successor, Khurshid, was still a boy, and his uncle Farrukhan the Little ruled as regent for seven years. Khurshid ruled a prosperous state, and tried repeatedly, though without success, to break his ties to the Caliphate, exploiting the turmoil of the final years of the Umayyads and of the Abbasid Revolution. These attempts led to a large-scale invasion of Tabaristan in 759, forcing Khurshid to seek refuge in Gilan, where he poisoned himself in 761.</p><h2>Dabuyid rulers</h2><h2>Sources</h2><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Dabuyid_dynasty&amp;oldid=767564875"					
								Categories:  Hidden categories:</p><br><h1 lang="en">List of countries and dependencies by area</h1><p> From Wikipedia, the free encyclopedia</p><p>This is a list of the world's countries and their dependent territories by area, ranked by total area.</p><p>Entries in this list, include, but are not limited to, those in the ISO standard 3166-1, which includes sovereign states and dependent territories. Largely unrecognised states not in ISO 3166-1 are included in the list in ranked order, but are not actually given a rank number. The areas of such largely unrecognised states are in most cases also included in the areas of the more widely recognised states that claim the same territory; see the notes in the Notes column for each country for clarification.</p><p>Not included in the list are individual country claims to parts of the continent of Antarctica, entities such as the European Union[Note 1] (4,324,782&nbsp;km2 or 1,669,808&nbsp;sq&nbsp;mi total area) that have some degree of sovereignty but do not consider themselves to be sovereign countries or dependent territories, and unrecognized micronations such as the Principality of Sealand.</p><p>This list includes three measurements of area:</p><p>Data is taken from the United Nations Statistics Division unless otherwise noted.[3]</p><h2>Contents</h2><h2>Map</h2><br><img alt="World map color-coded by areas of countries in square kilometers" src="http://upload.wikimedia.org/wikipedia/commons/thumb/4/4f/Area_by_country.PNG/600px-Area_by_country.PNG" width="600" height="263"><h2>Countries and dependencies by area</h2><h2>Graphical charts</h2><p>The charts below are based on the CIA World Factbook[35] as of February 15, 2005.</p><p>Sovereign states with areas greater than 100,000&nbsp;km2 are shown in green. In addition, non-sovereign territories are included for purposes of comparison, and are shown in gray. Areas include inland water bodies (lakes, reservoirs, rivers). Claims to parts of Antarctica by various countries are not included.</p><h3>Countries greater than 1.5 million km2</h3><br><img usemap="#timeline_0eeb081a6e9f6c5557a057cca01782a3" src="http://upload.wikimedia.org/wikipedia/en/timeline/0eeb081a6e9f6c5557a057cca01782a3.png"><h3>Countries less than 1.5 million km2</h3><br><img usemap="#timeline_fddf07ca1e1be8a457a6b46cc95ffdb3" src="http://upload.wikimedia.org/wikipedia/en/timeline/fddf07ca1e1be8a457a6b46cc95ffdb3.png"><h2>Notes</h2><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=List_of_countries_and_dependencies_by_area&amp;oldid=784076193"					
								Categories:  Hidden categories:</p><div class="gradientback"></div></div><div class="content"><br><h1 lang="en">Umayyad Caliphate</h1><p> From Wikipedia, the free encyclopedia</p><p>The Umayyad Caliphate (Arabic: ??????? ?????????, trans. Al-Khilafah al-?umawiyya), also spelled Omayyad,[1] was the second of the four major caliphates established after the death of Muhammad. This caliphate was centred on the Umayyad dynasty (Arabic: ??????????, al-?Umawiyyun, or ??? ????, Banu ?Umayya, Sons of Umayya), hailing from Mecca. The Umayyad family had first come to power under the third caliph, Uthman ibn Affan (r. 644–656), but the Umayyad regime was founded by Muawiya ibn Abi Sufyan, long-time governor of Syria, after the end of the First Muslim Civil War in AD 661/41 AH. Syria remained the Umayyads' main power base thereafter, and Damascus was their capital. The Umayyads continued the Muslim conquests, incorporating the Caucasus, Transoxiana, Sindh, the Maghreb and the Iberian Peninsula (Al-Andalus) into the Muslim world. At its greatest extent, the Umayyad Caliphate covered 11,100,000&nbsp;km2 (4,300,000&nbsp;sq&nbsp;mi)[2] and 62 million people (29% of the world's population),[3] making it one of the largest empires in history in both area and proportion of the world's population.</p><p>The Umayyad Caliphate was secular by nature.[4] At the time, the Umayyad taxation and administrative practice were perceived as unjust by some Muslims. The Christian and Jewish population still had autonomy; their judicial matters were dealt with in accordance with their own laws and by their own religious heads or their appointees, although they did pay a poll tax for policing to the central state.[5] Muhammad had stated explicitly during his lifetime that Abrahamic religious groups (still a majority in times of the Umayyad Caliphate), should be allowed to practice their own religion, provided that they paid the jizya taxation. The welfare state of both the Muslim and the non-Muslim poor started by Umar ibn al Khattab had also continued, financed by the zakat tax levied only on Muslims.[5] Muawiya's wife Maysum (Yazid's mother) was also a Christian. The relations between the Muslims and the Christians in the state were stable in this time. The Umayyads were involved in frequent battles with the Christian Byzantines without being concerned with protecting themselves in Syria, which had remained largely Christian like many other parts of the empire.[5] Prominent positions were held by Christians, some of whom belonged to families that had served in Byzantine governments. The employment of Christians was part of a broader policy of religious assimilation that was necessitated by the presence of large Christian populations in the conquered provinces, as in Syria. This policy also boosted Muawiya's popularity and solidified Syria as his power base.[6][7]</p><h2>Contents</h2><h2>Origins</h2><p>According to tradition, the Umayyad family (also known as the Banu Abd-Shams) and Muhammad both descended from a common ancestor, Abd Manaf ibn Qusai, and they originally came from the city of Mecca. Muhammad descended from Abd Manaf via his son Hashim, while the Umayyads descended from Abd Manaf via a different son, Abd-Shams, whose son was Umayya. The two families are therefore considered to be different clans (those of Hashim and of Umayya, respectively) of the same tribe (that of the Quraish). However Muslim Shia historians suspect that Umayya was an adopted son of Abd Shams so he was not a blood relative of Abd Manaf ibn Qusai. Umayya was later discarded from the noble family.[8] Sunni historians disagree with this and view Shia claims as nothing more than outright polemics due to their hostility to the Umayyad family in general. They point to the fact that the grand sons of Uthman, Zaid bin Amr bin Uthman bin Affan and Abdullah bin Amr bin Uthman got married to Sukaina and Fatima, the daughters of Hussein son of Ali, to show closeness of Banu hashem and Bani Ummayah.[9]</p><p>While the Umayyads and the Hashimites may have had bitterness between the two clans before Muhammad, the rivalry turned into a severe case of tribal animosity after the Battle of Badr. The battle saw three top leaders of the Umayyad clan (Utba ibn Rabi'ah, Walid ibn Utbah and Shaybah) killed by Hashimites (Ali, Hamza ibn ‘Abd al-Muttalib and Ubaydah ibn al-Harith) in a three-on-three melee.[10] This fueled the opposition of Abu Sufyan ibn Harb, the grandson of Umayya, to Muhammad and to Islam. Abu Sufyan sought to exterminate the adherents of the new religion by waging another battle with Muslims based in Medina only a year after the Battle of Badr. He did this to avenge the defeat at Badr. The Battle of Uhud is generally believed by scholars to be the first defeat for the Muslims, as they had incurred greater losses than the Meccans. After the battle, Abu Sufyan's wife Hind, who was also the daughter of Utba ibn Rabi'ah, is reported to have cut open the corpse of Hamza, taking out his liver which she then attempted to eat.[11] Within five years after his defeat in the Battle of Uhud, however, Muhammad took control of Mecca[12] and announced a general amnesty for all. Abu Sufyan and his wife Hind embraced Islam on the eve of the conquest of Mecca, as did their son (the future caliph Muawiyah I).</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/7/72/Map_of_expansion_of_Caliphate.svg/220px-Map_of_expansion_of_Caliphate.svg.png" width="220" height="101"><p>


				Expansion of the caliphate under the Umayyads:
				&nbsp;&nbsp;Expansion under Muhammad, 622–632
				&nbsp;&nbsp;Expansion during the Rashidun Caliphate, 632–661
				&nbsp;&nbsp;Expansion during the Umayyad Caliphate, 661–750



				</p><p>
					Most historians[who?] consider Caliph Muawiyah (661–80) to have been the second ruler of the Umayyad dynasty, even though he was the first to assert the Umayyads' right to rule on a dynastic principle. It was really the caliphate of Uthman Ibn Affan (644–656), a member of Umayyad clan himself, that witnessed the revival and then the ascendancy of the Umayyad clan to the corridors of power. Uthman placed some of the trusted members of his clan at prominent and strong positions throughout the state. Most notable was the appointment of Marwan ibn al-Hakam, Uthman's first cousin, as his top advisor, which created a stir among the Hashimite companions of Muhammad, as Marwan along with his father Al-Hakam ibn Abi al-'As had been permanently exiled from Medina by Muhammad during his lifetime. Uthman also appointed as governor of Kufa his half-brother, Walid ibn Uqba, who was accused by Hashmites of leading prayer while under the influence of alcohol.[13] Uthman also consolidated Muawiyah's governorship of Syria by granting him control over a larger area[14] and appointed his foster brother Abdullah ibn Saad as the Governor of Egypt. However, since Uthman never named an heir, he cannot be considered the founder of a dynasty.</p><p>In 639, Muawiyah I was appointed as the governor of Syria after the previous governor Abu Ubaidah ibn al-Jarrah died in a plague along with 25,000 other people.[15][16] To stop the Byzantine harassment from the sea during the Arab-Byzantine Wars, in 649 Muawiyah I set up a navy manned by Monophysite Christian, Copt and Jacobite Syrian Christian sailors and Muslim troops. This resulted in the defeat of the Byzantine navy at the Battle of the Masts in 655, opening up the Mediterranean.[17][18][19][20][21]</p><p>Muawiyah I was a very successful governor and built up a very loyal and disciplined army from the old Roman Syrian army. He also befriended Amr ibn al-As who had conquered Egypt but was removed by Uthman ibn al-Affan.</p><p>The Quran and Muhammad talked about racial equality and justice as in The Farewell Sermon.[22][23][24][25][26][27][28] Tribal and nationalistic differences were discouraged. But after Muhammad's passing, the old tribal differences between the Arabs started to resurface. Following the Roman–Persian Wars and the Byzantine–Sassanid Wars, deep rooted differences between Iraq, formerly under the Persian Sassanid Empire, and Syria, formerly under the Byzantine Empire, also existed. Each wanted the capital of the newly established Islamic State to be in their area.[29] Previously, the second caliph Umar ibn Al-Khattab was very firm on the governors and his spies kept an eye on them. If he felt that a governor or a commander was becoming attracted to wealth, he had him removed from his position.[30]</p><div class="gradientback"></div></div><div class="content"><p>Early Muslim armies stayed in encampments away from cities because Umar ibn Al-Khattab feared that they might get attracted to wealth and luxury. In the process, they might turn away from the worship of God and start accumulating wealth and establishing dynasties.[30][31][32][33] When Uthman ibn al-Affan became very old, Marwan I, a relative of Muawiyah I, slipped into the vacuum, became his secretary, slowly assumed more control and relaxed some of these restrictions. Marwan I had previously been excluded from positions of responsibility. In 656, Muhammad ibn Abi Bakr, the son of Abu Bakr, the adopted son of Ali ibn Abi Talib, and the great grandfather of Ja'far al-Sadiq, showed some Egyptians the house of Uthman ibn al-Affan. Later the Egyptians ended up killing Uthman ibn al-Affan.[34]</p><p>After the assassination of Uthman in 656, Ali, a member of the Quraysh tribe and the cousin and son-in-law of Muhammad, was elected as the caliph. He soon met with resistance from several factions, owing to his relative political inexperience. Ali moved his capital from Medina to Kufa. The resulting conflict, which lasted from 656 until 661, is known as the First Fitna (civil war). Muawiyah I, the governor of Syria, a relative of Uthman ibn al-Affan and Marwan I, wanted the culprits arrested. Marwan I manipulated everyone and created conflict. Aisha, the wife of Muhammad, and Talhah and Al-Zubayr, two of the companions of Muhammad, went to Basra to tell Ali to arrest the culprits who murdered Uthman. Marwan I and other people who wanted conflict manipulated everyone to fight. The two sides clashed at the Battle of the Camel in 656, where Ali won a decisive victory.</p><p>Following this battle, Ali fought a battle against Muawiyah, known as the Battle of Siffin. The battle was stopped before either side had achieved victory, and the two parties agreed to arbitrate their dispute. After the battle Amr ibn al-As was appointed by Muawiyah as an arbitrator, and Ali appointed Abu Musa Ashaari. Seven months later, in February 658, the two arbitrators met at Adhruh, about 10 miles north west of Maan in Jordon. Amr ibn al-As convinced Abu Musa Ashaari that both Ali and Muawiyah should step down and a new Caliph be elected. Ali and his supporters were stunned by the decision which had lowered the Caliph to the status of the rebellious Muawiyah I. Ali was therefore outwitted by Muawiyah and Amr. Ali refused to accept the verdict and found himself technically in breach of his pledge to abide by the arbitration. This put Ali in a weak position even amongst his own supporters. The most vociferous opponents in Ali's camp were the very same people who had forced Ali into the ceasefire. They broke away from Ali's force, rallying under the slogan, arbitration belongs to God alone. This group came to be known as the Kharijites (those who leave). In 659 Ali's forces and the Kharijites met in the Battle of Nahrawan. Although Ali won the battle, the constant conflict had begun to affect his standing, and in the following years some Syrians seem to have acclaimed Muawiyah as a rival caliph.[35]</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/1/17/Califate_750.jpg/220px-Califate_750.jpg" width="220" height="184"><p>


				Umayyad Caliphate in 750



				</p><p>
					Ali was assassinated in 661 by a Kharijite partisan. Six months later in the same year, in the interest of peace, Hasan ibn Ali, highly regarded for his wisdom and as a peacemaker, and the Second Imam for the Shias, and the grandson of Muhammad, made a peace treaty with Muawiyah I. In the Hasan-Muawiya treaty, Hasan ibn Ali handed over power to Muawiya on the condition that he be just to the people and keep them safe and secure, and after his death he not establish a dynasty.[36][37] This brought to an end the era of the Rightly Guided Caliphs for the Sunnis, and Hasan ibn Ali was also the last Imam for the Shias to be a Caliph. Following this, Mu'awiyah broke the conditions of the agreement and began the Umayyad dynasty, with its capital in Damascus.[38]</p><p>After Mu'awiyah's death in 680, conflict over succession broke out again in a civil war known as the Second Fitna. After making every one else fight,[39] the Umayyad dynasty later fell into the hands of Marwan I, who was also an Umayyad.</p><p>Syria would remain the base of Umayyad power until the end of the dynasty in 750. However, this Dynasty became reborn in Cordoba (Al Andalus, today's Portugal and Spain) in the form of an Emirate and then a Caliphate, lasting until AD 1031. Muslim rule continued in Iberia for another 500 years in several forms: Taifas, Berber kingdoms, and under the Kingdom of Granada until the 16th century.</p><p>In the year 712, Muhammad bin Qasim, an Umayyad general, sailed from the Persian Gulf into Sindh in Pakistan and conquered both the Sindh and the Punjab regions along the Indus river. The conquest of Sindh and Punjab, in modern-day Pakistan, although costly, were major gains for the Umayyad Caliphate. However, further gains were halted by Hindu kingdoms in India in the Caliphate campaigns in India. The Arabs tried to invade India but they were defeated by the north Indian king Nagabhata of the Gurjara Pratihara Dynasty and by the south Indian Emperor Vikramaditya II of the Chalukya dynasty in the early 8th century. After this the Arab chroniclers admit that the Caliph Mahdi gave up the project of conquering any part of India.</p><p>During the later period of its existence, and particularly from 1031 under the Ta'ifa system of Islamic Emirates (Princedoms) in the southern half of Iberia, the Emirate/Sultanate of Granada maintained its independence largely due to the payment of Tributes to the northern Christian kingdoms, which from 1031 began to gradually expand south at its expense.</p><p>Muslim rule in Iberia came to an end on 2 January 1492 with the conquest of the Nasrid kingdom of Granada. The last Muslim ruler of Granada, Muhammad XII, better known as Boabdil, surrendered his kingdom to Ferdinand II of Aragon and Isabella I of Castile, the Catholic Monarchs, los Reyes Católicos.</p><h2>History</h2><h3>Sufyanids</h3><p>Muawiyah's personal dynasty, the Sufyanids (descendants of Abu Sufyan), reigned from 661 to 684, until his grandson Muawiya II. The reign of Muawiyah I was marked by internal security and external expansion. On the internal front, only one major rebellion is recorded, that of Hujr ibn Adi in Kufa. Hujr ibn Adi supported the claims of the descendants of Ali to the caliphate, but his movement was easily suppressed by the governor of Iraq, Ziyad ibn Abi Sufyan.</p><p>Muawiyah also encouraged peaceful coexistence with the Christian communities of Syria, granting his reign with peace and prosperity for Christians and Arabs alike,[40] and one of his closest advisers was Sarjun, the father of John of Damascus. At the same time, he waged unceasing war against the Byzantine Roman Empire. During his reign, Rhodes and Crete were occupied, and several assaults were launched against Constantinople. After their failure, and faced with a large-scale Christian uprising in the form of the Mardaites, Muawiyah concluded a peace with Byzantium. Muawiyah also oversaw military expansion in North Africa (the foundation of Kairouan) and in Central Asia (the conquest of Kabul, Bukhara, and Samarkand).</p><p>Following Muawiyah's death in 680, he was succeeded by his son, Yazid I. The hereditary accession of Yazid was opposed by a number of prominent Muslims, most notably Abd-Allah ibn al-Zubayr, son of one of the companions of Muhammad, and Husayn ibn Ali, grandson of Muhammad and younger son of Ali. The resulting conflict is known as the Second Fitna.</p><p>In 680 Ibn al-Zubayr fled Medina for Mecca. Hearing about Husayn's opposition to Yazid I, the people of Kufa sent to Husayn asking him to take over with their support. Al-Husayn sent his cousin Muslim bin Aqeel to verify if they would rally behind him. When the news reached Yazid I, he sent Ubayd-Allah bin Ziyad, ruler of Basrah, with the instruction to prevent the people of Kufa rallying behind Al-Husayn. Ubayd-Allah bin Ziyad managed to disperse the crowd that gathered around Muslim bin Aqeel and captured him. Realizing Ubayd-Allah bin Ziyad had been instructed to prevent Husayn from establishing support in Kufa, Muslim bin Aqeel requested a message to be sent to Husayn to prevent his immigration to Kufa. The request was denied and Ubayd-Allah bin Ziyad killed Muslim bin Aqeell. While Ibn al-Zubayr would stay in Mecca until his death, Husayn decided to travel on to Kufa with his family, unaware of the lack of support there. Husayn and his family were intercepted by Yazid I's forces led by Amru bin Saad, Shamar bin Thi Al-Joshan, and Hussain bin Tamim, who fought Al-Husayn and his male family members until they were killed. There were 200 people in Husayn's caravan, many of whom were women, including his sisters, wives, daughters and their children. The women and children from Husayn's camp were taken as prisoners of war and led back to Damascus to be presented to Yazid I. They remained imprisoned until public opinion turned against him as word of Husayn's death and his family's capture spread. They were then granted passage back to Medina. The sole adult male survivor from the caravan was Ali ibn Husayn who was with fever too ill to fight when the caravan was attacked.[41]</p><div class="gradientback"></div></div><div class="content"><p>Following the death of Husayn, Ibn al-Zubayr, although remaining in Mecca, was associated with two opposition movements, one centered in Medina and the other around Kharijites in Basra and Arabia. Because Medina had been home to Muhammad and his family, including Husayn, word of his death and the imprisonment of his family led to a large opposition movement. In 683, Yazid dispatched an army to subdue both movements. The army suppressed the Medinese opposition at the Battle of al-Harrah. The Grand Mosque in Medina was severely damaged and widespread pillaging caused deep-seated dissent. Yazid's army continued on and laid siege to Mecca. At some point during the siege, the Kaaba was badly damaged in a fire. The destruction of the Kaaba and Grand Mosque became a major cause for censure of the Umayyads in later histories of the period.</p><p>Yazid died while the siege was still in progress, and the Umayyad army returned to Damascus, leaving Ibn al-Zubayr in control of Mecca. Yazid's son Muawiya II (683–84) initially succeeded him but seems to have never been recognized as caliph outside of Syria. Two factions developed within Syria: the Confederation of Qays, who supported Ibn al-Zubayr, and the Quda'a, who supported Marwan, a descendant of Umayya via Wa'il ibn Umayyah. The partisans of Marwan triumphed at a battle at Marj Rahit, near Damascus, in 684, and Marwan became caliph shortly thereafter.</p><h3>First Marwanids</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/1/14/Dome_of_the_Rock1.jpg/220px-Dome_of_the_Rock1.jpg" width="220" height="165"><p>


				Dome of the Rock in Jerusalem



				</p><p>
					Marwan's first task was to assert his authority against the rival claims of Ibn al-Zubayr, who was at this time recognized as caliph throughout most of the Islamic world. Marwan recaptured Egypt for the Umayyads, but died in 685, having reigned for only nine months.</p><p>Marwan was succeeded by his son, Abd al-Malik (685–705), who reconsolidated Umayyad control of the caliphate. The early reign of Abd al-Malik was marked by the revolt of Al-Mukhtar, which was based in Kufa. Al-Mukhtar hoped to elevate Muhammad ibn al-Hanafiyyah, another son of Ali, to the caliphate, although Ibn al-Hanafiyyah himself may have had no connection to the revolt. The troops of al-Mukhtar engaged in battles both with the Umayyads in 686, defeating them at the river Khazir near Mosul, and with Ibn al-Zubayr in 687, at which time the revolt of al-Mukhtar was crushed. In 691, Umayyad troops reconquered Iraq, and in 692 the same army captured Mecca. Ibn al-Zubayr was killed in the attack.</p><p>The second major event of the early reign of Abd al-Malik was the construction of the Dome of the Rock in Jerusalem. Although the chronology remains somewhat uncertain, the building seems to have been completed in 692, which means that it was under construction during the conflict with Ibn al-Zubayr. This had led some historians, both medieval and modern, to suggest that the Dome of the Rock was built as a destination for pilgrimage to rival the Kaaba, which was under the control of Ibn al-Zubayr.</p><p>Abd al-Malik is credited with centralizing the administration of the Caliphate and with establishing Arabic as its official language. He also introduced a uniquely Muslim coinage, marked by its aniconic decoration, which supplanted the Byzantine and Sasanian coins that had previously been in use. Abd al-Malik also recommenced offensive warfare against Byzantium, defeating the Byzantines at Sebastopolis and recovering control over Armenia and Caucasian Iberia.</p><p>Following Abd al-Malik's death, his son, Al-Walid I (705–15), became caliph. Al-Walid was also active as a builder, sponsoring the construction of Al-Masjid al-Nabawi in Medina and the Great Mosque of Damascus.</p><p>A major figure during the reigns of both al-Walid and Abd al-Malik was the Umayyad governor of Iraq, Al-Hajjaj bin Yousef. Many Iraqis remained resistant to Umayyad rule, and to maintain order al-Hajjaj imported Syrian troops, which he housed in a new garrison town, Wasit. These troops became crucial in the suppression of a revolt led by an Iraqi general, Ibn al-Ash'ath, in the early eighth century.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/6/6e/Umayyad_calif_Sassanian_prototype_copper_falus_Aleppo_Syria_circa_695_CE.jpg/220px-Umayyad_calif_Sassanian_prototype_copper_falus_Aleppo_Syria_circa_695_CE.jpg" width="220" height="443"><p>


				Two coins of the Umayyad Caliphate, based on Byzantine prototypes. Copper falus, Aleppo, Syria, circa 695


				</p><p>
					Al-Walid was succeeded by his brother, Sulayman (715–17), whose reign was dominated by a protracted siege of Constantinople. The failure of the siege marked the end of serious Arab ambitions against the Byzantine capital. However, the first two decades of the eighth century witnessed the continuing expansion of the Caliphate, which pushed into the Iberian Peninsula in the west, and into Transoxiana (under Qutayba ibn Muslim) and northern India in the east.</p><div class="gradientback"></div></div><div class="content"><p>Sulayman was succeeded by his cousin, Umar ibn Abd al-Aziz (717–20), whose position among the Umayyad caliphs is somewhat unusual. He is the only Umayyad ruler to have been recognized by subsequent Islamic tradition as a genuine caliph (khalifa) and not merely as a worldly king (malik).</p><p>Umar is honored for his attempt to resolve the fiscal problems attendant upon conversion to Islam. During the Umayyad period, the majority of people living within the caliphate were not Muslim, but Christian, Jewish, Zoroastrian, or members of other small groups. These religious communities were not forced to convert to Islam, but were subject to a tax (jizyah) which was not imposed upon Muslims. This situation may actually have made widespread conversion to Islam undesirable from the point of view of state revenue, and there are reports that provincial governors actively discouraged such conversions. It is not clear how Umar attempted to resolve this situation, but the sources portray him as having insisted on like treatment of Arab and non-Arab (mawali) Muslims, and on the removal of obstacles to the conversion of non-Arabs to Islam.</p><p>After the death of Umar, another son of Abd al-Malik, Yazid II (720–24) became caliph. Yazid is best known for his iconoclastic edict, which ordered the destruction of Christian images within the territory of the Caliphate. In 720, another major revolt arose in Iraq, this time led by Yazid ibn al-Muhallab.</p><h3>Hisham and the limits of military expansion</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/3/34/Rusafa_gate.jpg/220px-Rusafa_gate.jpg" width="220" height="147"><p>


				North gate of the city of Resafa, site of Hisham's palace and court


				</p><p>
					The final son of Abd al-Malik to become caliph was Hisham (724–43), whose long and eventful reign was above all marked by the curtailment of military expansion. Hisham established his court at Resafa in northern Syria, which was closer to the Byzantine border than Damascus, and resumed hostilities against the Byzantines, which had lapsed following the failure of the last siege of Constantinople. The new campaigns resulted in a number of successful raids into Anatolia, but also in a major defeat (the Battle of Akroinon), and did not lead to any significant territorial expansion.</p><p>From the caliphate's north-western African bases, a series of raids on coastal areas of the Visigothic Kingdom paved the way to the permanent occupation of most of Iberia by the Umayyads (starting in 711), and on into south-eastern Gaul (last stronghold at Narbonne in 759). Hisham's reign witnessed the end of expansion in the west, following the defeat of the Arab army by the Franks at the Battle of Tours in 732. In 739 a major Berber Revolt broke out in North Africa, which was subdued only with difficulty, but it was followed by the collapse of Umayyad authority in al-Andalus. In India the Arab armies were defeated by the south Indian Chalukya dynasty and by the north Indian Pratiharas Dynasty in the 8th century and the Arabs were driven out of India.[42][43][44] In the Caucasus, the confrontation with the Khazars peaked under Hisham: the Arabs established Derbent as a major military base and launched several invasions of the northern Caucasus, but failed to subdue the nomadic Khazars. The conflict was arduous and bloody, and the Arab army even suffered a major defeat at the Battle of Marj Ardabil in 730. Marwan ibn Muhammad, the future Marwan II, finally ended the war in 737 with a massive invasion that is reported to have reached as far as the Volga, but the Khazars remained unsubdued.</p><p>Hisham suffered still worse defeats in the east, where his armies attempted to subdue both Tokharistan, with its center at Balkh, and Transoxiana, with its center at Samarkand. Both areas had already been partially conquered, but remained difficult to govern. Once again, a particular difficulty concerned the question of the conversion of non-Arabs, especially the Sogdians of Transoxiana. Following the Umayyad defeat in the Day of Thirst in 724, Ashras ibn 'Abd Allah al-Sulami, governor of Khurasan, promised tax relief to those Sogdians who converted to Islam, but went back on his offer when it proved too popular and threatened to reduce tax revenues. Discontent among the Khurasani Arabs rose sharply after the losses suffered in the Battle of the Defile in 731, and in 734, al-Harith ibn Surayj led a revolt that received broad backing from Arabs and natives alike, capturing Balkh but failing to take Merv. After this defeat, al-Harith's movement seems to have been dissolved, but the problem of the rights of non-Arab Muslims would continue to plague the Umayyads.</p><h3>Third Fitna</h3><p> Main article: Third Fitna</p><p>Hisham was succeeded by Al-Walid II (743–44), the son of Yazid II. Al-Walid is reported to have been more interested in earthly pleasures than in religion, a reputation that may be confirmed by the decoration of the so-called desert palaces (including Qusayr Amra and Khirbat al-Mafjar) that have been attributed to him. He quickly attracted the enmity of many, both by executing a number of those who had opposed his accession, and by persecuting the Qadariyya.</p><p>In 744, Yazid III, a son of al-Walid I, was proclaimed caliph in Damascus, and his army tracked down and killed al-Walid II. Yazid III has received a certain reputation for piety, and may have been sympathetic to the Qadariyya. He died a mere six months into his reign.</p><p>Yazid had appointed his brother, Ibrahim, as his successor, but Marwan II (744–50), the grandson of Marwan I, led an army from the northern frontier and entered Damascus in December 744, where he was proclaimed caliph. Marwan immediately moved the capital north to Harran, in present-day Turkey. A rebellion soon broke out in Syria, perhaps due to resentment over the relocation of the capital, and in 746 Marwan razed the walls of Homs and Damascus in retaliation.</p><p>Marwan also faced significant opposition from Kharijites in Iraq and Iran, who put forth first Dahhak ibn Qays and then Abu Dulaf as rival caliphs. In 747, Marwan managed to reestablish control of Iraq, but by this time a more serious threat had arisen in Khorasan.</p><h3>Abbasid Revolution</h3><p> Main article: Abbasid Revolution</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/8/8a/Revolt.png/220px-Revolt.png" width="220" height="138"><p>


				The Caliphate at the beginning of the Abbasid revolt, before the Battle of the Zab


				</p><p>
					The Hashimiyya movement (a sub-sect of the Kaysanites Shia), led by the Abbasid family, overthrew the Umayyad caliphate. The Abbasids were members of the Hashim clan, rivals of the Umayyads, but the word Hashimiyya seems to refer specifically to Abu Hashim, a grandson of Ali and son of Muhammad ibn al-Hanafiyya. According to certain traditions, Abu Hashim died in 717 in Humeima in the house of Muhammad ibn Ali, the head of the Abbasid family, and before dying named Muhammad ibn Ali as his successor. This tradition allowed the Abbasids to rally the supporters of the failed revolt of Mukhtar, who had represented themselves as the supporters of Muhammad ibn al-Hanafiyya.</p><div class="gradientback"></div></div><div class="content"><p>Beginning around 719, Hashimiyya missions began to seek adherents in Khurasan. Their campaign was framed as one of proselytism (dawah). They sought support for a member of the family of Muhammad, without making explicit mention of the Abbasids. These missions met with success both among Arabs and non-Arabs (mawali), although the latter may have played a particularly important role in the growth of the movement.</p><p>Around 746, Abu Muslim assumed leadership of the Hashimiyya in Khurasan. In 747, he successfully initiated an open revolt against Umayyad rule, which was carried out under the sign of the black flag. He soon established control of Khurasan, expelling its Umayyad governor, Nasr ibn Sayyar, and dispatched an army westwards. Kufa fell to the Hashimiyya in 749, the last Umayyad stronghold in Iraq, Wasit, was placed under siege, and in November of the same year Abul Abbas as-Saffah was recognized as the new caliph in the mosque at Kufa.[citation needed] At this point Marwan mobilized his troops from Harran and advanced toward Iraq. In January 750 the two forces met in the Battle of the Zab, and the Umayyads were defeated. Damascus fell to the Abbasids in April, and in August, Marwan was killed in Egypt.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/5/57/Spain_Andalusia_Cordoba_BW_2015-10-27_13-54-14.jpg/220px-Spain_Andalusia_Cordoba_BW_2015-10-27_13-54-14.jpg" width="220" height="131"><p>


				The Great Mosque of Córdoba in Spain, built by Banu Umayya


				</p><p>
					The victors desecrated the tombs of the Umayyads in Syria, sparing only that of Umar II, and most of the remaining members of the Umayyad family were tracked down and killed. When Abbasids declared amnesty for members of the Umayyad family, eighty gathered to receive pardons, and all were massacred. One grandson of Hisham, Abd al-Rahman I, survived and established a kingdom in Al-Andalus (Moorish Iberia), proclaiming his family to be the Umayyad Caliphate revived.</p><p>Previté-Orton argues that the reasons for the decline of the Umayyads was the rapid expansion of Islam. During Umayyad period, mass conversions brought Persians, Berbers, Copts, and Aramaics to Islam. These mawalis (enslaved) were often better educated and more civilised than their Arab invaders. The new converts, on the basis of equality of all Muslims, transformed the political landscape. Previté-Orton also argues that the feud between Syria and Iraq further weakened the empire.[45]</p><h2>Umayyad administration</h2><p>The first four caliphs created a stable administration for the empire, following the practices and administrative institutions of the Byzantine Empire which had ruled the same region previously.[46] These consisted of four main governmental branches: political and military affairs, tax collection, and religious administration. Each of these was further subdivided into more branches, offices, and departments.</p><h3>Provinces</h3><p>Geographically, the empire was divided into several provinces, the borders of which changed numerous times during the Umayyad reign. Each province had a governor appointed by the khalifah. The governor was in charge of the religious officials, army leaders, police, and civil administrators in his province. Local expenses were paid for by taxes coming from that province, with the remainder each year being sent to the central government in Damascus. As the central power of the Umayyad rulers waned in the later years of the dynasty, some governors neglected to send the extra tax revenue to Damascus and created great personal fortunes.[47]</p><h3>Government workers</h3><p>As the empire grew, the number of qualified Arab workers was too small to keep up with the rapid expansion of the empire. Therefore, Muawiya allowed many of the local government workers in conquered provinces to keep their jobs under the new Umayyad government. Thus, much of the local government's work was recorded in Greek, Coptic, and Persian. It was only during the reign of Abd al-Malik that government work began to be regularly recorded in Arabic.[47]</p><h3>Currency</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/b/bd/First_Umayyad_gold_dinar%2C_Caliph_Abd_al-Malik%2C_695_CE.jpg/220px-First_Umayyad_gold_dinar%2C_Caliph_Abd_al-Malik%2C_695_CE.jpg" width="220" height="218"><p>


				Coin of the Umayyad Caliphate, based on a Byzantine prototype, 695



				<br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/3/34/Al-Walid_ibn_Abdul-Rahman_-_Inscribed_Pound_Weight_-_Walters_476_-_Three_Quarter_Left.jpg/220px-Al-Walid_ibn_Abdul-Rahman_-_Inscribed_Pound_Weight_-_Walters_476_-_Three_Quarter_Left.jpg" width="220" height="225"><br>


				A coin weight from the Umayyad Dynasty, dated 743, made of glass. One of the oldest Islamic objects in an American museum, the Walters Art Museum.


				</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/3/34/Al-Walid_ibn_Abdul-Rahman_-_Inscribed_Pound_Weight_-_Walters_476_-_Three_Quarter_Left.jpg/220px-Al-Walid_ibn_Abdul-Rahman_-_Inscribed_Pound_Weight_-_Walters_476_-_Three_Quarter_Left.jpg" width="220" height="225"><br><p>
					The Byzantine and Sassanid Empires relied on money economies before the Muslim conquest, and that system remained in effect during the Umayyad period. Byzantine copper coins were used until 658, while Byzantine gold coins were still in use until the monetary reforms c.700.[48] In addition to this, the Umayyad government began to mint its own coins in Damascus, these were initially similar to pre-existing coins but evolved in an independent direction. These were the first coins minted by a Muslim government in history. Gold coins were called dinars while silver coins were called dirhams.[47]</p><h3>Central diwans</h3><p>To assist the Caliph in administration there were six Boards at the Centre: Diwan al-Kharaj (the Board of Revenue), Diwan al-Rasa'il (the Board of Correspondence), Diwan al-Khatam (the Board of Signet), Diwan al-Barid (the Board of Posts), Diwan al-Qudat (the Board of Justice) and Diwan al-Jund (the Military Board)</p><p>The Central Board of Revenue administered the entire finances of the empire. It also imposed and collected taxes and disbursed revenue.</p><div class="gradientback"></div></div><div class="content"><p>A regular Board of Correspondence was established under the Umayyads. It issued state missives and circulars to the Central and Provincial Officers. It co-ordinated the work of all Boards and dealt with all correspondence as the chief secretariat.</p><p>In order to check forgery, Diwan al-Khatam (Bureau of Registry), a kind of state chancellery, was instituted by Mu'awiyah. It used to make and preserve a copy of each official document before sealing and despatching the original to its destination. Thus in the course of time a state archive developed in Damascus by the Umayyads under Abd al-Malik. This department survived till the middle of the Abbasid period.</p><p> Main article: Barid (caliphate)</p><p>Mu'awiyah introduced postal service, Abd al-Malik extended it throughout his empire, and Walid made full use of it. The Umayyad Caliph Abd al-Malik developed a regular postal service. Umar bin Abdul-Aziz developed it further by building caravanserais at stages along the Khurasan highway. Relays of horses were used for the conveyance of dispatches between the caliph and his agents and officials posted in the provinces. The main highways were divided into stages of 12 miles (19&nbsp;km) each and each stage had horses, donkeys or camels ready to carry the post. Primarily the service met the needs of Government officials, but travellers and their important dispatches were also benefitted by the system. The postal carriages were also used for the swift transport of troops. They were able to carry fifty to a hundred men at a time. Under Governor Yusuf bin Umar, the postal department of Iraq cost 4,000,000 dirhams a year.</p><p>[citation needed]</p><p>In the early period of Islam, justice was administered by Muhammad and the orthodox Caliphs in person. After the expansion of the Islamic State, Umar al-Faruq had to separate judiciary from the general administration and appointed the first qadi in Egypt as early as AD 643/23 AH. After 661, a series of judges succeeded one after another in Egypt under the Umayyad Caliphs, Hisham and Walid II.</p><p>The Diwan of Umar, assigning annuities to all Arabs and to the Muslim soldiers of other races, underwent a change in the hands of the Umayyads. The Umayyads meddled with the register and the recipients regarded pensions as the subsistence allowance even without being in active service. Hisham reformed it and paid only to those who participated in battle. On the pattern of the Byzantine system the Umayyads reformed their army organization in general and divided it into five corps: the centre, two wings, vanguards and rearguards, following the same formation while on march or on a battle field. Marwan II (740–50) abandoned the old division and introduced Kurdus (cohort), a small compact body. The Umayyad troops were divided into three divisions: infantry, cavalry and artillery. Arab troops were dressed and armed in Greek fashion. The Umayyad cavalry used plain and round saddles. The artillery used arradah (ballista), manjaniq (the mangonel) and dabbabah or kabsh (the battering ram). The heavy engines, siege machines and baggage were carried on camels behind the army.</p><h2>Social organization</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/en/thumb/6/6f/Humeima_ivory.jpg/220px-Humeima_ivory.jpg" width="220" height="252"><p>


				Ivory (circa 8th century) discovered in the Abbasid homestead in Humeima, Jordan. The style indicates an origin in northeastern Iran, the base of Hashimiyya military power.[49]


				</p><p>
					The Umayyad Caliphate exhibited four main social classes:</p><li>Muslim Arabs</li><li>Muslim non-Arabs (clients of the Muslim Arabs)</li><li>Non-Muslim free persons (Christians, Jews, and Zoroastrians)</li><li>Slaves</li><p>The Muslim Arabs were at the top of the society and saw it as their duty to rule over the conquered areas. Despite the fact that Islam teaches the equality of all Muslims, the Arab Muslims held themselves in higher esteem than Muslim non-Arabs and generally did not mix with other Muslims.</p><p>The inequality of Muslims in the empire led to social unrest. As Islam spread, more and more of the Muslim population was constituted of non-Arabs. This caused tension as the new converts were not given the same rights as Muslim Arabs. Also, as conversions increased, tax revenues from non-Muslims decreased to dangerous lows. These issues continued to grow until they helped cause the Abbasid Revolt in the 740s.[50]</p><h3>Non-Muslims</h3><p>Non-Muslim groups in the Umayyad Caliphate, which included Christians, Jews, Zoroastrians, and pagan Berbers, were called dhimmis. They were given a legally protected status as second-class citizens as long as they accepted and acknowledged the political supremacy of the ruling Muslims. They were allowed to have their own courts, and were given freedom of their religion within the empire.[citation needed] Although they could not hold the highest public offices in the empire, they had many bureaucratic positions within the government. Christians and Jews still continued to produce great theological thinkers within their communities, but as time wore on, many of the intellectuals converted to Islam, leading to a lack of great thinkers in the non-Muslim communities.[51]</p><h2>Legacy</h2><p>Currently many Sunni scholars agree that Muawiyah's family, including his progenitors, Abu Sufyan ibn Harb and Hind bint Utbah, were originally opponents of Islam and particularly of Muhammad until the Conquest of Mecca.</p><p>However many early history books like the Islamic Conquest of Syria Fatuhusham by al-Imam al-Waqidi state that after the conversion to Islam Muawiyah's father Abu Sufyan ibn Harb and his brothers Yazid ibn Abi Sufyan were appointed as commanders in the Muslim armies by Muhammad. Muawiyah, Abu Sufyan ibn Harb, Yazid ibn Abi Sufyan and Hind bint Utbah[52][53][53][54][55][56] fought in the Battle of Yarmouk. The defeat of the Byzantine Emperor Heraclius at the Battle of Yarmouk opened the way for the Muslim expansion into Jerusalem and Syria.</p><div class="gradientback"></div></div><div class="content"><p>In 639, Muawiyah was appointed as the governor of Syria by the second caliph Umar after his brother the previous governor Yazid ibn Abi Sufyan and the governor before him Abu Ubaidah ibn al-Jarrah died in a plague along with 25,000 other people.[57][58] 'Amr ibn al-'As was sent to take on the Roman Army in Egypt. Fearing an attack by the Romans, Umar asked Muawiyah to defend against a Roman attack.</p><p>With limited resources Muawiyah went about creating allies. Muawiyah married Maysum the daughter of the chief of the Kalb tribe, that was a large Jacobite Christian Arab tribe in Syria. His marriage to Maysum was politically motivated. The Kalb tribe had remained largely neutral when the Muslims first went into Syria.[59] After the plague that killed much of the Muslim Army in Syria, by marrying Maysum, Muawiyah started to use the Jacobite Christians, against the Romans. Muawiya's wife Maysum (Yazid's mother) was also a Jacobite Christian.[60] With limited resources and the Byzantine just over the border, Muawiyah worked in cooperation with the local Christian population. To stop Byzantine harassment from the sea during the Arab-Byzantine Wars, in 649 Muawiyah set up a navy; manned by Monophysitise Christians, Copts and Jacobite Syrian Christians sailors and Muslim troops.[61][62]</p><p>Muawiya was one of the first to realize the full importance of having a navy; as long as the Byzantine fleet could sail the Mediterranean unopposed, the coast line of Syria, Palestine and Egypt would never be safe. Muawiyah along with Adbullah ibn Sa'd the new governor of Egypt successfully persuaded Uthman to give them permission to construct a large fleet in the dockyards of Egypt and Syria[61][62]</p><p>The first real naval engagement between the Muslim and the Byzantine navy was the so-called Battle of the Masts (Dhat al-sawari) or battle of Phoenix off the Lycian coast in 655.[63] This resulted in the defeat of the Byzantine navy at the Battle of the Masts in 655, opening up the Mediterranean.[61][62][64][65][66][67][68]</p><p>Muawiyah came to power after the death of Ali and established a dynasty.</p><h3>Historical significance</h3><p>The Umayyad caliphate was marked both by territorial expansion and by the administrative and cultural problems that such expansion created. Despite some notable exceptions, the Umayyads tended to favor the rights of the old Arab families, and in particular their own, over those of newly converted Muslims (mawali). Therefore, they held to a less universalist conception of Islam than did many of their rivals. As G.R. Hawting has written, Islam was in fact regarded as the property of the conquering aristocracy.[69]</p><p>During the period of the Umayyads, Arabic became the administrative language. State documents and currency were issued in the language. Mass conversions brought a large influx of Muslims to the caliphate. The Umayyads also constructed famous buildings such as the Dome of the Rock at Jerusalem, and the Umayyad Mosque at Damascus.[70]</p><p>According to one common view, the Umayyads transformed the caliphate from a religious institution (during the rashidun) to a dynastic one.[70] However, the Umayyad caliphs do seem to have understood themselves as the representatives of God on earth, and to have been responsible for the definition and elaboration of God's ordinances, or in other words the definition or elaboration of Islamic law.[71]</p><p>The Umayyads have met with a largely negative reception from later Islamic historians, who have accused them of promoting a kingship (mulk, a term with connotations of tyranny) instead of a true caliphate (khilafa). In this respect it is notable that the Umayyad caliphs referred to themselves not as khalifat rasul Allah (successor of the messenger of God, the title preferred by the tradition), but rather as khalifat Allah (deputy of God). The distinction seems to indicate that the Umayyads regarded themselves as God's representatives at the head of the community and saw no need to share their religious power with, or delegate it to, the emergent class of religious scholars.[72] In fact, it was precisely this class of scholars, based largely in Iraq, that was responsible for collecting and recording the traditions that form the primary source material for the history of the Umayyad period. In reconstructing this history, therefore, it is necessary to rely mainly on sources, such as the histories of Tabari and Baladhuri, that were written in the Abbasid court at Baghdad.</p><p>Modern Arab nationalism regards the period of the Umayyads as part of the Arab Golden Age which it sought to emulate and restore.[dubious – discuss] This is particularly true of Syrian nationalists and the present-day state of Syria, centered like that of the Umayyads on Damascus.[citation needed] White, one of the four Pan-Arab colors which appear in various combinations on the flags of most Arab countries, is considered as representing the Umayyads.[citation needed]</p><h3>Theological opinions concerning the Umayyads</h3><p>Many Muslims criticized the Umayyads for having too many non-Muslim, former Roman administrators in their government. St John of Damascus was also a high administrator in the Umayyad administration.[73] As the Muslims took over cities, they left the peoples political representatives and the Roman tax collectors and the administrators. The taxes to the central government were calculated and negotiated by the peoples political representatives. The Central government got paid for the services it provided and the local government got the money for the services it provided. Many Christian cities also used some of the taxes on maintain their churches and run their own organizations. Later the Umayyads were criticized by some Muslims for not reducing the taxes of the people who converted to Islam. These new converts continues to pay the same taxes that were previously negotiated.[74]</p><p>Later when Umar ibn Abd al-Aziz came to power, he reduced these taxes. He is therefore praised as one of the greatest Muslim rulers after the four Rightly Guided Caliphs. Imam Abu Muhammad Adbullah ibn Abdul Hakam who lived in 829 and wrote a biography on Umar Ibn Adbul Aziz[75] stated that the reduction in these taxes stimulated the economy and created wealth but it also reduced the government budget and this then led to a reduction in the defense budget.</p><p>Only Umayyad ruler (Caliphs of Damascus), Umar ibn Abd al-Aziz, is unanimously praised by Sunni sources for his devout piety and justice. In his efforts to spread Islam he established liberties for the Mawali by abolishing the jizya tax for converts to Islam. Imam Abu Muhammad Adbullah ibn Abdul Hakam stated that Umar ibn Abd al-Aziz also stopped the personal allowance offered to his relatives stating that he could only give them an allowance if he gave an allowance to everyone else in the empire. Umar ibn Abd al-Aziz was later poisoned in the year 720. When successive governments tried to reverse Umar ibn Abd al-Aziz's tax policies it created rebellion.</p><h2>Early literature</h2><p>The book Al Muwatta by Imam Malik was written in the early Abbasid period in Madina. It does not contain any anti-Umayyad content because it was more concerned with what the Quran and what Muhammad said and was not a history book on the Umayyads.</p><p>Even the earliest pro-Shia accounts of al-Masudi are more balanced. al-Masudi in Ibn Hisham is the earliest Shia account of Muawiyah. He recounted that Muawiyah spent a great deal of time in prayer, in spite of the burden of managing a large empire.[76]</p><p>Az-Zuhri stated that Muawiya led the Hajj Pilgrimage with the people twice during his era as caliph.</p><p>Books written in the early Abbasid period like al-Baladhuri's The Origins of the Islamic State provide a more accurate and balanced history. Ibn Hisham also wrote about these events.</p><p>Much of the anti-Umayyad literature started to appear in the later Abbasid period in Persia.</p><p>After killing off most of the Umayyads and destroying the graves of the Umayyad rulers apart from Muawiyah and Umar Ibn Adbul Aziz, the history books written during the later Abbasid period are more anti-Umayyad.[77] The Abbasids justified their rule by saying that their ancestor Abbas ibn Abd al Muttalib was a cousin of Muhammad.</p><p>The books written later in the Abbasid period in Iran are more anti-Umayyad. Iran was Sunni at the time. There was much anti-Arab feeling in Iran after the fall of the Persian empire.[78] This anti-Arab feeling also influenced the books on Islamic history. Al-Tabri was also written in Iran during that period. Al-Tabri was a huge collection including all the texts that he could find, from all the sources. It was a collection preserving everything for future generations to codify and for future generations to judge whether the histories were true or false.</p><div class="gradientback"></div></div><div class="content"><h3>Shi'a opinions</h3><p>The negative view of the Umayyads by Shias is briefly expressed in the Shi'a book Sulh al-Hasan.[79] According to some sources Ali described them as the worst Fitna.[80]</p><h3>Bahá'í standpoint</h3><p>Asked for an explanation of the prophecies in the Book of Revelation (12:3), `Abdu'l-Bahá suggests in Some Answered Questions that the great red dragon, having seven heads and ten horns, and seven crowns upon his heads,[81] refers to the Umayyad caliphs who rose against the religion of Prophet Muhammad and against the reality of Ali.[82][83]</p><p>The seven heads of the dragon is symbolic of the seven provinces of the lands dominated by the Umayyads: Damascus, Persia, Arabia, Egypt, Africa, Andalusia, and Transoxania. The ten horns represent the ten names of the leaders of the Umayyad dynasty; Abu Sufyan, Muawiya, Yazid, Marwan, Abd al-Malik, Walid, Sulayman, Umar, Hisham, and Ibrahim. Some names were re-used, as in the case of Yazid II and Yazid III, which were not counted for this interpretation.</p><h2>List of Umayyad Caliphs</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/3/3b/Umayads.svg/220px-Umayads.svg.png" width="220" height="272"><p>


				Genealogic tree of the Umayyad family. In blue: Caliph Uthman, one of the four Rashidun Caliphs. In green, the Umayyad Caliphs of Damascus. In yellow, the Umayyad emirs of Córdoba. In orange, the Umayyad Caliphs of Córdoba. Abd Al-Rahman III was an emir until 929 when he proclaimed himself Caliph. Muhammad is included (in caps) to show the kinship of the Umayyads with him.



				<br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/f/fd/Mezquita_de_C%C3%B3rdoba._Fachada_del_mihrab.jpg/220px-Mezquita_de_C%C3%B3rdoba._Fachada_del_mihrab.jpg" width="220" height="165"><br>


				Mosque of Córdoba, Spain. Mi?rab


				 

				 

				 
				 

				 

				 
				 
				 
				 

				 


				 


				 



									
										</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/f/fd/Mezquita_de_C%C3%B3rdoba._Fachada_del_mihrab.jpg/220px-Mezquita_de_C%C3%B3rdoba._Fachada_del_mihrab.jpg" width="220" height="165"><br><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Umayyad_Caliphate&amp;oldid=783929282"					
								Categories:  Hidden categories:</p><br><br><img alt="Page semi-protected" src="http://upload.wikimedia.org/wikipedia/commons/thumb/f/fc/Padlock-silver.svg/20px-Padlock-silver.svg.png" width="20" height="20"><h1 lang="en">Wikipedia:Featured articles</h1><p>
					 From Wikipedia, the free encyclopedia</p><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Wikipedia:Featured_articles&amp;oldid=784126852"					
								Categories:  Hidden categories:</p><br><br><img alt="Page semi-protected" src="http://upload.wikimedia.org/wikipedia/commons/thumb/f/fc/Padlock-silver.svg/20px-Padlock-silver.svg.png" width="20" height="20"><h1 lang="en">Sasanian Empire</h1><p> From Wikipedia, the free encyclopedia</p><p>The Sasanian Empire (/s?'s??ni?n/ or /s?'se?ni?n/), also known as Sassanian, Sasanid, Sassanid or Neo-Persian Empire),[11] known to its inhabitants as Eranshahr[1] in Middle Persian,[a] was the last imperial dynasty in Persia (Iran) before the rise of Islam, ruled by and named after the Sasanian dynasty from 224 to 651 AD.[2][13] The Sasanian Empire, which succeeded the Parthian Empire, was recognized as one of the leading world powers alongside its neighboring arch-rival the Roman-Byzantine Empire, for a period of more than 400 years.[14][15][16]</p><p>The Sasanian Empire was founded by Ardashir I, after the fall of the Parthian Empire and the defeat of the last Arsacid king, Artabanus V. At its greatest extent, the Sasanian Empire encompassed all of today's Iran, Iraq, Eastern Arabia (Bahrain, Kuwait, Oman, Qatif, Qatar, UAE), the Levant (Syria, Palestine, Lebanon, Israel, Jordan), Armenia, the Caucasus (Georgia, Azerbaijan, Dagestan, South Ossetia, Abkhazia), Egypt, large parts of Turkey, much of Central Asia (Afghanistan, Turkmenistan, Uzbekistan, Tajikistan), Yemen and Pakistan. According to a legend, the vexilloid of the Sasanian Empire was the Derafsh Kaviani.[17]</p><p>The Sasanian Empire during Late Antiquity is considered to have been one of Iran's most important and influential historical periods, and constituted the last great Iranian empire before the Muslim conquest and the adoption of Islam.[18] In many ways, the Sasanian period witnessed the peak of ancient Iranian civilization. Persia influenced Roman culture considerably during the Sasanian period.[19] The Sasanians' cultural influence extended far beyond the empire's territorial borders, reaching as far as Western Europe,[20] Africa,[21] China and India.[22] It played a prominent role in the formation of both European and Asian medieval art.[23] Much of what later became known as Islamic culture in art, architecture, music and other subject matter was transferred from the Sasanians throughout the Muslim world.[24]</p><h2>Contents</h2><h2>History</h2><h3>Origins and early history (205–310)</h3><div class="gradientback"></div></div><div class="content"><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/4/4e/Ghal%27eh_Dokhtar2.jpg/220px-Ghal%27eh_Dokhtar2.jpg" width="220" height="68"><p>


				Ghal'eh Dokhtar (or "The Maiden's Castle") in present-day Fars, Firuzabad, Iran, built by Ardashir in 209, before he was finally able to defeat the Parthian empire.



				<br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/8/8a/Ctesiphon.jpg/220px-Ctesiphon.jpg" width="220" height="128"><br>


				Taq Kasra is the most famous Persian monument from the Sasanian era.


				</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/8/8a/Ctesiphon.jpg/220px-Ctesiphon.jpg" width="220" height="128"><br><p>
					Conflicting accounts shroud the details of the fall of the Parthian Empire and subsequent rise of the Sasanian Empire in mystery.[25] The Sassanid Empire was established in Estakhr by Ardashir I.</p><p>Papak was originally the ruler of a region called Khir. However, by the year 200, he managed to overthrow Gochihr, and appoint himself as the new ruler of the Bazrangids. His mother, Rodhagh, was the daughter of the provincial governor of Pars. Papak and his eldest son Shapur managed to expand their power over all of Pars. The subsequent events are unclear, due to the elusive nature of the sources. It is certain, however, that following the death of Papak, Ardashir, who at the time was the governor of Darabgerd, got involved in a power struggle of his own with his elder brother Shapur. Sources reveal that Shapur, leaving for a meeting with his brother, was killed when the roof of a building collapsed on him. By the year 208, over the protests of his other brothers who were put to death, Ardashir declared himself ruler of Pars.[26][27]</p><p>Once Ardashir was appointed shahanshah, he moved his capital further to the south of Pars and founded Ardashir-Khwarrah (formerly Gur, modern day Firuzabad). The city, well supported by high mountains and easily defendable through narrow passes, became the center of Ardashir's efforts to gain more power. The city was surrounded by a high, circular wall, probably copied from that of Darabgird, and on the north-side included a large palace, remains of which still survive today. After establishing his rule over Pars, Ardashir I rapidly extended his territory, demanding fealty from the local princes of Fars, and gaining control over the neighboring provinces of Kerman, Isfahan, Susiana and Mesene. This expansion quickly came to the attention of Artabanus V, the Parthian king, who initially ordered the governor of Khuzestan to wage war against Ardashir in 224, but the battles were victories for Ardashir. In a second attempt to destroy Ardashir, Artabanus V himself met Ardashir in battle at Hormozgan, where Artabanus V met his death. Following the death of the Parthian ruler, Ardashir I went on to invade the western provinces of the now defunct Parthian Empire.[28]</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/4/40/Bas_relief_nagsh-e-rostam_al.jpg/220px-Bas_relief_nagsh-e-rostam_al.jpg" width="220" height="165"><p>


				Rock-face relief at Naqsh-e Rustam of Persian emperor Shapur I (on horseback) capturing Roman emperor Valerian (standing) and Philip the Arab (kneeling), suing for peace, following the victory at Edessa.


				</p><p>
					At that time the Arsacid dynasty was divided between supporters of Artabanus V and Vologases VI, which probably allowed Ardashir to consolidate his authority in the south with little or no interference from the Parthians. Ardashir was aided by the geography of the province of Fars, which was separated from the rest of Iran.[29] Crowned in 224 at Ctesiphon as the sole ruler of Persia, Ardashir took the title shahanshah, or King of Kings (the inscriptions mention Adhur-Anahid as his Banbishnan banbishn, Queen of Queens, but her relationship with Ardashir is not established), bringing the 400-year-old Parthian Empire to an end, and beginning four centuries of Sassanid rule.[30]</p><p>In the next few years, local rebellions would form around the empire. Nonetheless, Ardashir I further expanded his new empire to the east and northwest, conquering the provinces of Sistan, Gorgan, Khorasan, Margiana (in modern Turkmenistan), Balkh and Chorasmia. He also added Bahrain and Mosul to Sassanid's possessions. Later Sassanid inscriptions also claim the submission of the Kings of Kushan, Turan and Mekran to Ardashir, although based on numismatic evidence, it is more likely that these actually submitted to Ardashir's son, the future Shapur I. In the west, assaults against Hatra, Armenia and Adiabene met with less success. In 230, he raided deep into Roman territory, and a Roman counter-offensive two years later ended inconclusively, although the Roman emperor, Alexander Severus, celebrated a triumph in Rome.[31][32][33]</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/a/a2/HumiliationValerianusHolbein.jpg/220px-HumiliationValerianusHolbein.jpg" width="220" height="230"><p>


				The Humiliation of Valerian by Shapur (Hans Holbein the Younger, 1521, pen and black ink on a chalk sketch, Kunstmuseum Basel)


				</p><p>
					Ardashir I's son Shapur I continued the expansion of the empire, conquering Bactria and the western portion of the Kushan Empire, while leading several campaigns against Rome. Invading Roman Mesopotamia, Shapur I captured Carrhae and Nisibis, but in 243 the Roman general Timesitheus defeated the Persians at Rhesaina and regained the lost territories.[34] The emperor Gordian III's (238–244) subsequent advance down the Euphrates was defeated at Meshike (244), leading to Gordian's murder by his own troops and enabling Shapur to conclude a highly advantageous peace treaty with the new emperor Philip the Arab, by which he secured the immediate payment of 500,000 denarii and further annual payments.</p><p>Shapur soon resumed the war, defeated the Romans at Barbalissos (253), and then probably took and plundered Antioch.[34][35] Roman counter-attacks under the emperor Valerian ended in disaster when the Roman army was defeated and besieged at Edessa and Valerian was captured by Shapur, remaining his prisoner for the rest of his life. Shapur celebrated his victory by carving the impressive rock reliefs in Naqsh-e Rostam and Bishapur, as well as a monumental inscription in Persian and Greek in the vicinity of Persepolis. He exploited his success by advancing into Anatolia (260), but withdrew in disarray after defeats at the hands of the Romans and their Palmyrene ally Odaenathus, suffering the capture of his harem and the loss of all the Roman territories he had occupied.[36][37]</p><br><div class="gradientback"></div></div><div class="content"><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/5/57/ManichaeismSpread.jpg/220px-ManichaeismSpread.jpg" width="220" height="119"><p>


				The spread of Manichaeism (300– 500)[38]


				</p><p>
					Shapur had intensive development plans. He ordered the construction of the first dam bridge in Iran and founded many cities, some settled in part by emigrants from the Roman territories, including Christians who could exercise their faith freely under Sassanid rule. Two cities, Bishapur and Nishapur, are named after him. He particularly favored Manichaeism, protected Mani (who dedicated one of his books, the Shabuhragan, to him) and sent many Manichaean missionaries abroad. He also befriended a Babylonian rabbi called Samuel.</p><p>This friendship was advantageous for the Jewish community and gave them a respite from the oppressive laws enacted against them. Later kings reversed Shapur's policy of religious tolerance. Under pressure from Zoroastrian Magi and influenced by the high-priest Kartir, Bahram I killed Mani and persecuted his followers. Bahram II was, like his father, amenable to the wishes of the Zoroastrian priesthood.[39][40] During his reign, the Sassanid capital Ctesiphon was sacked by the Romans under Emperor Carus, and most of Armenia, after half a century of Persian rule, was ceded to Diocletian.[41]</p><p>Succeeding Bahram III (who ruled briefly in 293), Narseh embarked on another war with the Romans. After an early success against the Emperor Galerius near Callinicum on the Euphrates in 296, Narseh was decisively defeated. Galerius had been reinforced, probably in the spring of 298, by a new contingent collected from the empire's Danubian holdings.[42] Narseh did not advance from Armenia and Mesopotamia, leaving Galerius to lead the offensive in 298 with an attack on northern Mesopotamia via Armenia. Narseh retreated to Armenia to fight Galerius' force, to Narseh's disadvantage: the rugged Armenian terrain was favorable to Roman infantry, but not to Sassanid cavalry. Local aid gave Galerius the advantage of surprise over the Persian forces, and, in two successive battles, Galerius secured victories over Narseh.[43]</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/8/8f/Caucasus_300_map_alt_de.png/220px-Caucasus_300_map_alt_de.png" width="220" height="171"><p>


				Rome and vassal Armenia around 300, after Narseh's defeat


				</p><p>
					During the second encounter, Roman forces seized Narseh's camp, his treasury, his harem, and his wife.[43] Galerius advanced into Media and Adiabene, winning successive victories, most prominently near Erzurum, and securing Nisibis (Nusaybin, Turkey) before October 1, 298. He moved down the Tigris, taking Ctesiphon. Narseh had previously sent an ambassador to Galerius to plead for the return of his wives and children. Peace negotiations began in the spring of 299, with both Diocletian and Galerius presiding.</p><p>The conditions of the peace were heavy: Persia would give up territory to Rome, making the Tigris the boundary between the two empires. Further terms specified that Armenia was returned to Roman domination, with the fort of Ziatha as its border; Caucasian Iberia would pay allegiance to Rome under a Roman appointee; Nisibis, now under Roman rule, would become the sole conduit for trade between Persia and Rome; and Rome would exercise control over the five satrapies between the Tigris and Armenia: Ingilene, Sophanene (Sophene), Arzanene (Aghdznik), Corduene, and Zabdicene (near modern Hakkâri, Turkey).[44]</p><p>The Sassanids ceded five provinces west of the Tigris, and agreed not to interfere in the affairs of Armenia and Georgia.[45] In the aftermath of this defeat, Narseh gave up the throne and died a year later, leaving the Sassanid throne to his son, Hormizd II. Unrest spread throughout the land, and while Hormizd II suppressed revolts in Sakastan and Kushan, he was unable to control the nobles and was subsequently killed by Bedouins in a hunting trip in 309.</p><h3>First Golden Era (309–379)</h3><p>Following Hormizd II's death, Arabs from the north started to ravage and plunder the western cities of the empire, even attacking the province of Fars, the birthplace of the Sassanid kings. Meanwhile, Persian nobles killed Hormizd II's eldest son, blinded the second, and imprisoned the third (who later escaped to Roman territory). The throne was reserved for Shapur II, the unborn child of one of Hormizd II's wives who was crowned in utero: the crown was placed upon his mother's stomach.[46] During his youth the empire was controlled by his mother and the nobles. Upon Shapur II's coming of age, he assumed power and quickly proved to be an active and effective ruler.</p><p>Shapur II first led his small but disciplined army south against the Arabs, whom he defeated, securing the southern areas of the empire.[47] He then started his first campaign against the Romans in the west, where Persian forces won a series of battles but were unable to make territorial gains due to the failure of repeated sieges of the key frontier city of Nisibis, and Roman success in retaking the cities of Singara and Amida, after they had fallen to the Persians.</p><p>These campaigns were halted by nomadic raids along the eastern borders of the empire, which threatened Transoxiana, a strategically critical area for control of the Silk Road. Shapur therefore marched east toward Transoxiana to meet the eastern nomads, leaving his local commanders to mount nuisance raids on the Romans.[48] He crushed the Central Asian tribes, and annexed the area as a new province. He completed the conquest of the area now known as Afghanistan.</p><p>Cultural expansion followed this victory, and Sassanid art penetrated Turkestan, reaching as far as China. Shapur, along with the nomad King Grumbates, started his second campaign against the Romans in 359 and soon succeeded in taking Singara and Amida again. In response, the Roman emperor Julian struck deep into Persian territory and defeated Shapur's forces at Ctesiphon. He failed to take the capital, however, and was killed while trying to retreat to Roman territory.[49] His successor Jovian, trapped on the east bank of the Tigris, had to hand over all the provinces the Persians had ceded to Rome in 298, as well as Nisibis and Singara, to secure safe passage for his army out of Persia.</p><p>Shapur II pursued a harsh religious policy. Under his reign, the collection of the Avesta, the sacred texts of Zoroastrianism, was completed, heresy and apostasy were punished, and Christians were persecuted. The latter was a reaction against the Christianization of the Roman Empire by Constantine the Great. Shapur II, like Shapur I, was amicable towards Jews, who lived in relative freedom and gained many advantages in his period ( Raba). At the time of Shapur's death, the Persian Empire was stronger than ever, with its enemies to the east pacified and Armenia under Persian control.[49]</p><h3>Intermediate Era (379–498)</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/4/49/Folio_from_a_Khamsa-c.jpg/220px-Folio_from_a_Khamsa-c.jpg" width="220" height="491"><div class="gradientback"></div></div><div class="content"><p>


				Bahram V is a great favorite in Persian literature and poetry. "Bahram and the Indian princess in the black pavilion." Depiction of a Khamsa (Quintet) by the great Persian poet Nizami, mid-16th-century Safavid era.


				</p><p>
					From Shapur II's death until Kavadh I's first coronation, there was a largely peaceful period with the Romans (by this time the Eastern Roman or Byzantine Empire), interrupted only by two brief wars, the first in 421–422 and the second in 440.[50][51][52][53][54] Throughout this era, Sassanid religious policy differed dramatically from king to king. Despite a series of weak leaders, the administrative system established during Shapur II's reign remained strong, and the empire continued to function effectively.[50]</p><p>After Shapur II died in 379, he left a powerful empire to his half-brother Ardashir II (379–383; son of Vahram of Kushan) and his son Shapur III (383–388), neither of whom demonstrated his predecessor's talent. Ardashir II, who was raised as the half-brother of the emperor, failed to fill his brother's shoes, and Shapur III was too much of a melancholy character to achieve anything. Bahram IV (388–399), although not as inactive as his father, still failed to achieve anything important for the empire. During this time Armenia was divided by treaty between the Roman and Sassanid empires. The Sassanids reestablished their rule over Greater Armenia, while the Byzantine Empire held a small portion of western Armenia.</p><p>Bahram IV's son Yazdegerd I (399–421) is often compared to Constantine I. Both were powerful both physically and diplomatically, opportunistic, practiced religious tolerance and provided freedom for the rise of religious minorities. Yazdegerd stopped the persecution against the Christians and even punished nobles and priests who persecuted them. His reign marked a relatively peaceful era with the Romans and he even took the young Theodosius II (408–450) under his guardianship. Yarzdegerd also married a Jewish princess who bore him a son called Narsi.</p><p>Yazdegerd I's successor was his son Bahram V (421–438), one of the most well-known Sassanid kings and the hero of many myths. These myths persisted even after the destruction of the Sassanid empire by the Arabs. Bahram V, better known as Bahram-e Gur, gained the crown after Yazdegerd I's sudden death (or assassination) against the opposition of the grandees with the help of al-Mundhir, the Arabic dynast of al-Hirah. Bahram V's mother was Shushandukht, the daughter of the Jewish Exilarch. In 427, he crushed an invasion in the east by the nomadic Hephthalites, extending his influence into Central Asia, where his portrait survived for centuries on the coinage of Bukhara (in modern Uzbekistan). Bahram V deposed the vassal King of the Persian part of Armenia and made it a province.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/8/86/HormizdI.jpg/220px-HormizdI.jpg" width="220" height="223"><p>


				Coin of Hormizd I, issued in Khorasan, and derived from Kushan designs


				</p><p>
					Bahram V has many well known stories of valor, beauty, victories over the Romans, Turkic peoples, Indians and Africans, hunting and love; he is called Bahram-e Gur, Gur meaning onager, on account of his love for hunting and, in particular, hunting onagers. He symbolized a king at the height of a golden age, embodying royal prosperity. He had won his crown by competing with his brother and spent time fighting foreign enemies, but mostly kept himself amused by hunting, court parties and a famous band of ladies and courtiers. During his time, the best pieces of Sassanid literature were written, notable pieces of Sassanid music were composed, and sports such as polo became royal pastimes, a tradition that continues to this day in many kingdoms.[55]</p><p>Bahram V's son Yazdegerd II (438–457) was in some ways a moderate ruler, but in contrast to Yazdegerd I, practiced a harsh policy towards minority religions, particularly Christianity.[56] However, by the 451 Battle of Avarayr, the Armenian subjects led by Vardan Mamikonian managed to affirm Armenia's right to profess Christianity freely.[57][58] This was to be later confirmed by the Nvarsak Treaty (484).</p><p>At the beginning of his reign, Yazdegerd II gathered a mixed army of various nations, including his Indian allies, and attacked the Eastern Roman Empire in 441, but peace was soon restored after small-scale fighting. He then gathered his forces in Nishapur in 443 and launched a prolonged campaign against the Kidarites. Finally, after a number of battles, he crushed the Kidarites and drove them out beyond the Oxus river in 450.[59]</p><p>During his eastern campaign, Yazdegerd II grew suspicious of the Christians in the army and expelled them all from the governing body and army. He then persecuted the Christians and, to a much lesser extent, the Jews.[60] In order to reestablish Zoroastrianism in Armenia, he crushed an uprising of Armenian Christians at the Battle of Vartanantz in 451. The Armenians, however, remained primarily Christian. In his later years, he was engaged yet again with Kidarites until his death in 457. Hormizd III (457–459), younger son of Yazdegerd II, ascended to the throne. During his short rule, he continually fought with his elder brother Peroz I, who had the support of nobility,[60] and with the Hephthalites in Bactria. He was killed by his brother Peroz in 459.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/7/78/YazdegerdIICoinHistoryofIran.jpg/220px-YazdegerdIICoinHistoryofIran.jpg" width="220" height="107"><p>


				A coin of Yazdegerd II


				</p><p>
					In the beginning of the 5th century, the Hephthalites (White Huns), along with other nomadic groups, attacked Persia. At first Bahram V and Yazdegerd II inflicted decisive defeats against them and drove them back eastward. The Huns returned at the end of the 5th century and defeated Peroz I (457–484) in 483. Following this victory, the Huns invaded and plundered parts of eastern Persia for two years. They exacted heavy tribute for some years thereafter.</p><div class="gradientback"></div></div><div class="content"><p>These attacks brought instability and chaos to the kingdom. Peroz I tried again to drive out the Hephthalites, but on the way to Herat, his army was trapped by the Huns in the desert; Peroz I was killed, and his army was wiped out. After this victory, the Hephthalites advanced forward to the city of Herat, throwing the empire into chaos. Eventually, a noble Iranian from the old family of Karen, Sukhra, restored some degree of order. He raised Balash, one of Peroz I's brothers, to the throne, although the Hunnic threat persisted until the reign of Khosrau I. Balash (484–488) was a mild and generous monarch, who made concessions to the Christians; however, he took no action against the empire's enemies, particularly, the White Huns. Balash, after a reign of four years, was blinded and deposed (attributed to magnates), and his nephew Kavadh I was raised to the throne.</p><p>Kavadh I (488–531) was an energetic and reformist ruler. Kavadh I gave his support to the sect founded by Mazdak, son of Bamdad, who demanded that the rich should divide their wives and their wealth with the poor. His intention evidently was, by adopting the doctrine of the Mazdakites, to break the influence of the magnates and growing aristocracy. These reforms led to his being deposed and imprisoned in the Castle of Oblivion in Susa, and his younger brother Jamasp (Zamaspes), was raised to the throne in 496. Kavadh I, however, escaped in 498 and was given refuge by the White Hun king.</p><p>Djamasp (496–498) was installed on the Sassanid throne upon the deposition of Kavadh I by members of the nobility. Djamasp was a good and kind king, and he reduced taxes in order to relieve the peasants and the poor. He was also an adherent of the mainstream Zoroastrian religion, diversions from which had cost Kavadh I his throne and freedom. His reign soon ended when Kavadh I, at the head of a large army granted to him by the Hephthalite king, returned to the empire's capital. Djamasp stepped down from his position and restored the throne to his brother. No further mention of Djamasp is made after the restoration of Kavadh I, but it is widely believed that he was treated favorably at the court of his brother.[61]</p><h3>Second Golden Era (498–622)</h3><p>The second golden era began after the second reign of Kavadh I. With the support of the Hephtalites, Kavadh I launched a campaign against the Romans. In 502, he took Theodosiopolis in Armenia, but lost it soon afterwards. In 503 he took Amida on the Tigris. In 504, an invasion of Armenia by the western Huns from the Caucasus led to an armistice, the return of Amida to Roman control and a peace treaty in 506. In 521/522 Kavadh lost control of Lazica, whose rulers switched their allegiance to the Romans; an attempt by the Iberians in 524/525 to do likewise triggered a war between Rome and Persia.</p><p>In 527, a Roman offensive against Nisibis was repulsed and Roman efforts to fortify positions near the frontier were thwarted. In 530, Kavadh sent an army under Perozes to attack the important Roman frontier city of Dara. The army was met by the Roman general Belisarius, and though superior in numbers, was defeated at the Battle of Dara. In the same year, a second Persian army under Mihr-Mihroe was defeated at Satala by Roman forces under Sittas and Dorotheus, but in 531 a Persian army accompanied by a Lakhmid contingent under Al-Mundhir III defeated Belisarius at the Battle of Callinicum, and in 532 an eternal peace was concluded.[62] Although he could not free himself from the yoke of the Hephthalites, Kavadh succeeded in restoring order in the interior and fought with general success against the Eastern Romans, founded several cities, some of which were named after him, and began to regulate the taxation and internal administration.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/4/4c/ChosroesHuntingScene.JPG/220px-ChosroesHuntingScene.JPG" width="220" height="216"><p>


				Hunting scene on a gilded silver bowl showing king Khosrau I


				</p><p>
					After Kavadh I, his son Khosrau I, also known as Anushirvan (with the immortal soul; ruled 531–579), ascended to the throne. He is the most celebrated of the Sassanid rulers. Khosrau I is most famous for his reforms in the aging governing body of Sassanids. He introduced a rational system of taxation based upon a survey of landed possessions, which his father had begun, and he tried in every way to increase the welfare and the revenues of his empire. Previous great feudal lords fielded their own military equipment, followers, and retainers. Khosrau I developed a new force of dehqans, or knights, paid and equipped by the central government[63] and the bureaucracy, tying the army and bureaucracy more closely to the central government than to local lords.[64]</p><p>Emperor Justinian I (527–565) paid Khosrau I 440,000 pieces of gold as a part of the eternal peace treaty of 532. In 540, Khosrau broke the treaty and invaded Syria, sacking Antioch and extorting large sums of money from a number of other cities. Further successes followed: in 541 Lazica defected to the Persian side, and in 542 a major Byzantine offensive in Armenia was defeated at Anglon. In the same year of 541, upon requests of the Lazic king, king Khosrau I, entered Lazica, captured the Byzantine main stronghold of Petra, and established another protectorate over the country,[65] commencing the Lazic War. A five-year truce agreed to in 545 was interrupted in 547 when Lazica again switched sides and eventually expelled its Persian garrison with Byzantine help; the war resumed but remained confined to Lazica, which was retained by the Byzantines when peace was concluded in 562.</p><p>In 565, Justinian I died and was succeeded by Justin II (565–578), who resolved to stop subsidies to Arab chieftains to restrain them from raiding Byzantine territory in Syria. A year earlier, the Sassanid governor of Armenia, Chihor-Vishnasp of the Suren family, built a fire temple at Dvin near modern Yerevan, and he put to death an influential member of the Mamikonian family, touching off a revolt which led to the massacre of the Persian governor and his guard in 571, while rebellion also broke out in Iberia. Justin II took advantage of the Armenian revolt to stop his yearly payments to Khosrau I for the defense of the Caucasus passes.</p><p>The Armenians were welcomed as allies, and an army was sent into Sassanid territory which besieged Nisibis in 573. However, dissension among the Byzantine generals not only led to an abandonment of the siege, but they in turn were besieged in the city of Dara, which was taken by the Persians who then ravaged Syria, causing Justin II to agree to make annual payments in exchange for a five-year truce on the Mesopotamian front, although the war continued elsewhere. In 576 Khosrau I led his last campaign, an offensive into Anatolia which sacked Sebasteia and Melitene, but ended in disaster: defeated outside Melitene, the Persians suffered heavy losses as they fled across the Euphrates under Byzantine attack. Taking advantage of Persian disarray, the Byzantines raided deep into Khosrau's territory, even mounting amphibious attacks across the Caspian Sea. Khosrau sued for peace, but he decided to continue the war after a victory by his general Tamkhosrau in Armenia in 577, and fighting resumed in Mesopotamia. The Armenian revolt came to an end with a general amnesty, which brought Armenia back into the Sassanid Empire.[63]</p><p>Around 570, Ma 'd-Karib, half-brother of the King of Yemen, requested Khosrau I's intervention. Khosrau I sent a fleet and a small army under a commander called Vahriz to the area near present Aden, and they marched against the capital San'a'l, which was occupied. Saif, son of Mard-Karib, who had accompanied the expedition, became King sometime between 575 and 577. Thus, the Sassanids were able to establish a base in south Arabia to control the sea trade with the east. Later, the south Arabian kingdom renounced Sassanid overlordship, and another Persian expedition was sent in 598 that successfully annexed southern Arabia as a Sassanid province, which lasted until the time of troubles after Khosrau II.[63]</p><p>Khosrau I's reign witnessed the rise of the dihqans (literally, village lords), the petty landholding nobility who were the backbone of later Sassanid provincial administration and the tax collection system.[66] Khosrau I was a great builder, embellishing his capital and founding new towns with the construction of new buildings. He rebuilt the canals and restocked the farms destroyed in the wars. He built strong fortifications at the passes and placed subject tribes in carefully chosen towns on the frontiers to act as guardians against invaders. He was tolerant of all religions, though he decreed that Zoroastrianism should be the official state religion, and was not unduly disturbed when one of his sons became a Christian.</p><div class="gradientback"></div></div><div class="content"><p>After Khosrau I, Hormizd IV (579–590) took the throne. The war with the Byzantines continued to rage intensely but inconclusively until the general Bahram Chobin, dismissed and humiliated by Hormizd, rose in revolt in 589. The following year, Hormizd was overthrown by a palace coup and his son Khosrau II (590–628) placed on the throne. However, this change of ruler failed to placate Bahram, who defeated Khosrau, forcing him to flee to Byzantine territory, and seized the throne for himself as Bahram VI. Khosrau asked the Byzantine Emperor Maurice (582–602) for assistance against Bahram, offering to cede the western Caucasus to the Byzantines. To cement the alliance, Khosrau also married Maurice's daughter Miriam. Under the command of Khosrau and the Byzantine generals Narses and John Mystacon, the new combined Byzantine-Persian army raised a rebellion against Bahram, defeating him at the Battle of Blarathon in 591. When Khosrau was subsequently restored to power he kept his promise, handing over control of western Armenia and Caucasian Iberia. The new peace arrangement allowed the two empires to focus on military matters elsewhere: Khosrau expanded the Sassanid Empire's eastern frontier while Maurice restored Byzantine control of the Balkans.</p><p>After Maurice was overthrown and killed by Phocas (602–610) in 602, however, Khosrau II used the murder of his benefactor as a pretext to begin a new invasion, which benefited from continuing civil war in the Byzantine Empire and met little effective resistance. Khosrau's generals systematically subdued the heavily fortified frontier cities of Byzantine Mesopotamia and Armenia, laying the foundations for unprecedented expansion. The Persians overran Syria and captured Antioch in 611.</p><p>In 613, outside Antioch, the Persian generals Shahrbaraz and Shahin decisively defeated a major counter-attack led in person by the Byzantine emperor Heraclius. Thereafter, the Persian advance continued unchecked. Jerusalem fell in 614, Alexandria in 619, and the rest of Egypt by 621. The Sassanid dream of restoring the Achaemenid boundaries was almost complete, while the Byzantine Empire was on the verge of collapse. This remarkable peak of expansion was paralleled by a blossoming of Persian art, music, and architecture.</p><h3>Decline and fall (622–651)</h3><p> Main articles: Byzantine–Sasanian War of 602–628, Fall of the Sasanian Empire, and Muslim conquest of Persia</p><p>While successful at the first stage (from 602 to 622), the campaign of Khosrau II had actually exhausted the Persian army and Persian treasuries. In an effort to rebuild the national treasuries, Khosrau overtaxed the population. Thus, while his empire was on the verge of total defeat, Heraclius (610–641) drew on all his diminished and devastated empire's remaining resources, reorganized his armies, and mounted a remarkable, risky counter-offensive. Between 622 and 627, he campaigned against the Persians in Anatolia and the Caucasus, winning a string of victories against Persian forces under Shahrbaraz, Shahin, and Shahraplakan (whose competition to claim the glory of personally defeating the Byzantine emperor contributed to their failure), and Khusrau, sacking the great Zoroastrian temple at Ganzak, and securing assistance from the Khazars and Western Turkic Khaganate.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/8/8f/Moldovita_murals_2010_16.jpg/300px-Moldovita_murals_2010_16.jpg" width="300" height="193"><p>


				The Siege of Constantinople in 626 by the combined Sassanid, Avar, and Slavic forces depicted on the murals of the Moldovi?a Monastery, Romania


				</p><p>
					As a response, Khusrau, in coordination with Avar and Slavic forces, launched a siege on the Byzantine capital of Constantinople in 626. The Sassanids led by Shahrbaraz attacked the city the eastern side of the Bosphorus, while the Avar and Slavic allies invaded from the western side. Attempts to ferry the Persian forces across to aid their Slavic and Avar allies, the former being by far the strongest in siege warfare, were blocked by the Byzantine fleet who heavily guarded the Bosphorus and the siege ended in failure. In 627-628, Heraclius mounted a winter invasion of Mesopotamia and, despite the departure of his Khazar allies, defeated a Persian army commanded by Rhahzadh in the Battle of Nineveh. He then marched down the Tigris, devastating the country and sacking Khosrau's palace at Dastagerd. He was prevented from attacking Ctesiphon by the destruction of the bridges on the Nahrawan Canal and conducted further raids before withdrawing up the Diyala into north-western Iran.[67]</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/c/c5/BorandukhtCoinHistoryofIran.jpg/180px-BorandukhtCoinHistoryofIran.jpg" width="180" height="178"><p>


				Queen Boran, daughter of Khosrau II, the last woman and one of the last rulers on the throne of the Sasanian Empire, she reigned from 17 June 629 to 16 June 630


				</p><p>
					The impact of Heraclius's victories, the devastation of the richest territories of the Sassanid Empire, and the humiliating destruction of high-profile targets such as Ganzak and Dastagerd fatally undermined Khosrau's prestige and his support among the Persian aristocracy. In early 628, he was overthrown and murdered by his son Kavadh II (628), who immediately brought an end to the war, agreeing to withdraw from all occupied territories. In 629, Heraclius restored the True Cross to Jerusalem in a majestic ceremony.[67] Kavadh died within months, and chaos and civil war followed. Over a period of four years and five successive kings, including two daughters of Khosrau II and spahbed Shahrbaraz, the Sassanid Empire weakened considerably. The power of the central authority passed into the hands of the generals. It would take several years for a strong king to emerge from a series of coups, and the Sassanids never had time to recover fully.[66]</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/4/48/SassanidEmpirebeforeArabConquest.png/350px-SassanidEmpirebeforeArabConquest.png" width="350" height="157"><p>


				Extent of the Sasanian Empire in 632


				</p><p>
					In early 632, a grandson of Khosrau I who had lived in hiding in Estakhr, Yazdegerd III, ascended the throne. The same year, the first raiders from the Arab tribes, newly united by Islam, arrived in Persian territory. According to Howard-Johnston, years of warfare had exhausted both the Byzantines and the Persians. The Sassanids were further weakened by economic decline, heavy taxation, religious unrest, rigid social stratification, the increasing power of the provincial landholders, and a rapid turnover of rulers, facilitating the Islamic conquest of Persia.[68]</p><div class="gradientback"></div></div><div class="content"><p>The Sassanids never mounted a truly effective resistance to the pressure applied by the initial Arab armies. Yazdegerd was a boy at the mercy of his advisers and incapable of uniting a vast country crumbling into small feudal kingdoms, despite the fact that the Byzantines, under similar pressure from the newly expansive Arabs, no longer threatened. Caliph Abu Bakr's commander Khalid ibn Walid, once one of Muhammad's chosen companions-in-arms and leader of the Arab army, moved to capture Iraq in a series of lightning battles. Redeployed to the Syrian front against the Byzantines in June 634, Khalid's successor in Iraq failed him, and Muslims were defeated in the Battle of the Bridge in 634, which resulted in a Sassanid victory. However, the Arab threat did not stop there and reappeared shortly from the disciplined armies of Khalid ibn Walid.</p><p>In 637, a Muslim army under the Caliph Umar ibn al-Khattab defeated a larger Persian force led by general Rostam Farrokhzad at the plains of al-Qadisiyyah and advanced on Ctesiphon, which fell after a prolonged siege. Yazdegerd fled eastward from Ctesiphon, leaving behind him most of the Empire's vast treasury. The Arabs captured Ctesiphon shortly afterward, acquiring a powerful financial resource and leaving the Sassanid government strapped for funds. A number of Sassanid governors attempted to combine their forces to throw back the invaders, but the effort was crippled by the lack of a strong central authority, and the governors were defeated at the Battle of Nihawand. The empire, with its military command structure non-existent, its non-noble troop levies decimated, its financial resources effectively destroyed, and the Asawaran (Azatan) knightly caste destroyed piecemeal, was now utterly helpless in the face of the invaders.</p><p>Upon hearing of the defeat in Nihawand, Yazdegerd along with Farrukhzad and with some of the Persian nobles fled further inland to the eastern province of Khorasan. Yazdegerd was assassinated by a miller in Merv in late 651, while some of the nobles settled in Central Asia, where they contributed greatly to spreading Persian culture and language in those regions and to the establishment of the first native Iranian Islamic dynasty, the Samanid dynasty, which sought to revive Sassanid traditions.</p><p>The abrupt fall of the Sassanid Empire was completed in a period of five years, and most of its territory was absorbed into the Islamic caliphate; however, many Iranian cities resisted and fought against the invaders several times. Islamic caliphates repeatedly suppressed revolts in cities such as Rey, Isfahan, and Hamadan.[69] The local population was initially under little pressure to convert to Islam, remaining as dhimmi subjects of the Muslim state and paying a jizya.[70] Jizya practically replaced poll taxes imposed by the Sassanids. In addition, the old Sassanid land tax (known in Arabic as Kharaj) was also adopted. Caliph Umar is said to have occasionally set up a commission to survey the taxes, to judge if they were more than the land could bear.[71] Conversion of the Persian population to Islam would take place gradually, particularly as Persian-speaking elites attempted to gain positions of prestige under the Abbasid Caliphate.</p><h3>Descendants</h3><p>It is believed that the following dynasties and noble-families have ancestors among the Sassanian rulers:</p><h2>Government</h2><p>The Sassanids established an empire roughly within the frontiers achieved by the Parthian Arsacids, with the capital at Ctesiphon in the Asoristan province. In administering this empire, Sassanid rulers took the title of shahanshah (King of Kings), becoming the central overlords and also assumed guardianship of the sacred fire, the symbol of the national religion. This symbol is explicit on Sassanid coins where the reigning monarch, with his crown and regalia of office, appears on the obverse, backed by the sacred fire, the symbol of the national religion, on the coin's reverse.[75] Sassanid queens had the title of Banbishnan banbishn (Queen of Queens).</p><p>On a smaller scale, the territory might also be ruled by a number of petty rulers from a noble family, known as shahrdar, overseen directly by the shahanshah. The districts of the provinces were ruled by a shahrab and a mowbed (chief priest). The mowbed's job was to deal with estates and other things relating to legal matters. [76] Sasanian rule was characterized by considerable centralization, ambitious urban planning, agricultural development, and technological improvements.[66] Below the king, a powerful bureaucracy carried out much of the affairs of government; the head of the bureaucracy was the wuzurg framadar (vizier or prime minister). Within this bureaucracy the Zoroastrian priesthood was immensely powerful. The head of the Magi priestly class, the mowbedan mowbed, along with the commander-in-chief, the spahbed, the head of traders and merchants syndicate Ho Tokhshan Bod and minister of agriculture (wastaryoshan-salar), who was also head of farmers, were, below the emperor, the most powerful men of the Sassanid state.[77]</p><p>The Sassanian rulers always considered the advice of their ministers. A Muslim historian, Masudi, praised the excellent administration of the Sasanian kings, their well-ordered policy, their care for their subjects, and the prosperity of their domains. In normal times, the monarchical office was hereditary, but might be transferred by the king to a younger son; in two instances the supreme power was held by queens. When no direct heir was available, the nobles and prelates chose a ruler, but their choice was restricted to members of the royal family.[78]</p><p>The Sasanian nobility was a mixture of old Parthian clans, Persian aristocratic families, and noble families from subjected territories. Many new noble families had risen after the dissolution of the Parthian dynasty, while several of the once-dominant Seven Parthian clans remained of high importance. At the court of Ardashir I, the old Arsacid families of the House of Karen and the House of Suren, along with several other families, the Varazes and Andigans, held positions of great honor. Alongside these Iranian and non-Iranian noble families, the kings of Merv, Abarshahr, Kirman, Sakastan, Iberia, and Adiabene, who are mentioned as holding positions of honor amongst the nobles, appeared at the court of the shahanshah. Indeed, the extensive domains of the Surens, Karens and Varazes, had become part of the original Sassanid state as semi-independent states. Thus, the noble families that attended at the court of the Sassanid empire continued to be ruling lines in their own right, although subordinate to the shahanshah.</p><p>In general, Wuzurgan from Iranian families held the most powerful positions in the imperial administration, including governorships of border provinces (marzban). Most of these positions were patrimonial, and many were passed down through a single family for generations. The marzbans of greatest seniority were permitted a silver throne, while marzbans of the most strategic border provinces, such as the Caucasus province, were allowed a golden throne.[79] In military campaigns, the regional marzbans could be regarded as field marshals, while lesser spahbeds could command a field army.[80]</p><p>Culturally, the Sassanids implemented a system of social stratification. This system was supported by Zoroastrianism, which was established as the state religion. Other religions appear to have been largely tolerated, although this claim has been debated.[81] Sassanid emperors consciously sought to resuscitate Persian traditions and to obliterate Greek cultural influence.[66]</p><h3>Sasanian military</h3><p> Main article: Military of the Sasanian Empire</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/7/79/Sassanid_army_helmet_by_Nickmard_Khoey.jpg/220px-Sassanid_army_helmet_by_Nickmard_Khoey.jpg" width="220" height="237"><div class="gradientback"></div></div><div class="content"><p>


				Sasanian army helmet


				</p><p>
					The active army of the Sassanid Empire originated from Ardashir I, the first shahanshah of the empire. Ardashir restored the Achaemenid military organizations, retained the Parthian cavalry model, and employed new types of armour and siege warfare techniques.</p><p>The relationship between priests and warriors was important, because the concept of Eranshahr had been revived by the priests. Without this relationship, the Sassanid Empire would not have survived in its beginning stages. Because of this relationship between the warriors and the priests, religion and state were considered inseparable in the Zoroastrian religion. However, it is this same relationship that caused the weakening of the Empire, when each group tried to impose their power onto the other. Disagreements between the priests and the warriors led to fragmentation within the empire, which led to its downfall.[82]</p><p>The Paygan formed the bulk of the Sassanid infantry, and were often recruited from the peasant population. Each unit was headed by an officer called a Paygan-salar, which meant commander of the infantry and their main task was to guard the baggage train, serve as pages to the Asvaran (a higher rank), storm fortification walls, undertake entrenchment projects, and excavate mines.[83]</p><p>Those serving in the infantry were fitted with shields and lances. To make the size of their army larger, the Sassanids added soldiers provided by the Medes and the Dailamites to their own. The Medes provided the Sassanid army with high-quality javelin throwers, slingers and heavy infantry. Iranian infantry are described by Ammianus Marcellinus as armed like gladiators and obey orders like so many horse-boys.[84] The Dailamite people also served as infantry and were Iranian people who lived mainly within Gilan, Iranian Azerbaijan and Mazandaran. They are reported as having fought with weapons such as daggers, swords and javelins and reputed to have been recognized by Romans for their skills and hardiness in close-quarter combat. One account of Dailamites recounted their participation in an invasion of Yemen where 800 of them were led by the Dailamite officer Vahriz.[83] Vahriz would eventually defeat the Arab forces in Yemen and its capital Sana'a making it a Sasanian vassal until the invasion of Persia by Arabs.[85]</p><p>The Sasanian navy was an important constituent of the Sasanian military from the time that Ardashir I conquered the Arab side of the Persian gulf. Because controlling the Persian gulf was an economic necessity, the Sasanian navy worked to keep it safe from piracy, prevent Roman encroachment, and keep the Arab tribes from getting hostile. However, it is believed by many historians that the naval force could not have been a strong one, as the men serving in the navy were those who were confined in prisons.[86] The leader of the navy bore the title of navbed.[87]</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/a/a6/Knight-Iran.JPG/220px-Knight-Iran.JPG" width="220" height="324"><p>


				A Sassanid king posing as an armored cavalryman, Taq-e Bostan, Iran


				</p><p>
					The cavalry used during the Sassanid Empire were two types of heavy cavalry units: Clibanarii and Cataphracts. The first cavalry force, composed of elite noblemen trained since youth for military service, was supported by light cavalry, infantry and archers.[88] Mercenaries and tribal people of the empire, including the Turks, Kushans, Sarmatians, Khazars, Georgians, and Armenians were included in these first cavalry units. The second cavalry involved the use of the war elephants. In fact, it was their specialty to deploy elephants as cavalry support.</p><p>Unlike the Parthians, the Sassanids developed advanced siege engines. The development of siege weapons was a useful weapon during conflicts with Rome, in which success hinged upon the ability to seize cities and other fortified points; conversely, the Sassanids also developed a number of techniques for defending their own cities from attack. The Sassanid army was much like the preceding Parthian army, although some of the Sassanid's heavy cavalry were equipped with lances, while Parthian armies were heavily equipped with bows.[89] The Roman historian Ammianus Marcellinus's description of Shapur II's clibanarii cavalry manifestly shows how heavily equipped it was, and how only a portion were spear equipped:</p><p>Horsemen in the Sassanid cavalry lacked a stirrup. Instead, they used a war saddle which had a cantle at the back and two guard clamps which curved across the top of the rider's thighs. This allowed the horsemen to stay in the saddle at all times during the battle, especially during violent encounters.[90]</p><p>The Byzantine emperor Maurikios also emphasizes in his Strategikon that many of the Sassanid heavy cavalry did not carry spears, relying on their bows as their primary weapons. However the Taq-i Bustan reliefs and Al-Tabari's famed list of equipment required for dihqan knights which included the lance, provide a contrast. What is certain is that the horseman's paraphernalia was extensive.</p><p>The amount of money involved in maintaining a warrior of the Asawaran (Azatan) knightly caste required a small estate, and the Asawaran (Azatan) knightly caste received that from the throne, and in return, were the throne's most notable defenders in time of war.</p><h2>Relations with neighboring regimes</h2><h3>Frequent warfare with the Romans and to a lesser extent others</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/7/7f/Cameo_Shapur_Valerianus_Bab360_CdM_Paris.jpg/220px-Cameo_Shapur_Valerianus_Bab360_CdM_Paris.jpg" width="220" height="147"><p>


				A fine cameo showing an equestrian combat of Shapur I and Byzantine emperor Valerian in which the Roman emperor is seized following the Battle of Edessa, according to Shapur's own statement, "with our own hand", in year 256


				</p><div class="gradientback"></div></div><div class="content"><p>
					The Sassanids, like the Parthians, were in constant hostilities with the Roman Empire. The Sassanids, who thus succeeded the Parthians, were recognized as one of the leading world powers alongside its neighboring archrival the Roman-Byzantine Empire, for a period of more than 400 years.[14][15][16] Following the division of the Roman Empire in 395, the Eastern Roman Empire (Byzantine Empire), with its capital at Constantinople, continue as Persia's principal western enemy, and main enemy in general. Hostilities between the two empires became more frequent.[66] The Sassanids, similar to the Roman Empire, were in a constant state of conflict with neighboring kingdoms and nomadic hordes. Although the threat of nomadic incursions could never be fully resolved, the Sassanids generally dealt much more successfully with these matters than did the Romans, due to their policy of making coordinated campaigns against threatening nomads.[91]</p><p>The last of the many and frequent wars with the Byzantines, the climactic Byzantine–Sasanian War of 602–628, which included the siege of the Byzantine capital Constantinople, ended with both rivalling sides having drastically exhausted their human and material resources. Furthermore, social conflict within the Empire had considerably weakened it even further.[92][93] Consequently, they were vulnerable to the sudden emergence of the Islamic Rashidun Caliphate, whose forces invaded both empires only a few years after the war. The Muslim forces swiftly conquered the entire Sasanian Empire and deprived the Byzantine Empire of its territories in the Levant, the Caucasus, Egypt, and North Africa. Over the following centuries, half the Byzantine Empire and the entire Sasanian Empire came under Muslim rule.</p><p>In general, over the span of the centuries, in the west, Sassanid territory abutted that of the large and stable Roman state, but to the east, its nearest neighbors were the Kushan Empire and nomadic tribes such as the White Huns. The construction of fortifications such as Tus citadel or the city of Nishapur, which later became a center of learning and trade, also assisted in defending the eastern provinces from attack.</p><p>In south and central Arabia, Bedouin Arab tribes occasionally raided the Sassanid empire. The Kingdom of Al-Hirah, a Sassanid vassal kingdom, was established to form a buffer zone between the empire's heartland and the Bedouin tribes. The dissolution of the Kingdom of Al-Hirah by Khosrau II in 602, contributed greatly to decisive Sassanid defeats suffered against Bedouin Arabs later in the century. These defeats resulted in a sudden takeover of the Sassanid empire by Bedouin tribes under the Islamic banner.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/2/2d/Derbent_winter.jpg/220px-Derbent_winter.jpg" width="220" height="156"><p>


				Sassanian fortress in Derbent, Dagestan. Now inscribed on Russia's UNESCO world heritage list since 2003.


				</p><p>
					In the north, Khazars and other Turkic nomads frequently assaulted the northern provinces of the empire. They plundered Media in 634. Shortly thereafter, the Persian army defeated them and drove them out. The Sassanids built numerous fortifications in the Caucasus region to halt these attacks, of which perhaps the most notably are the imposing fortifications built in Derbent (Dagestan, North Caucasus, now a part of Russia) that to a large extent, have remained intact up to this day.</p><p>On the eastern side of the Caspian Sea, the Sassanians erected the Great Wall of Gorgan, a 200&nbsp;km-long defensive structure probably aimed to protect the empire from northern peoples, such as the White Huns.</p><h3>War with Axum</h3><p> Main article: Ethiopian–Persian wars</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/5/58/Khosrau_I_Textile.jpg/220px-Khosrau_I_Textile.jpg" width="220" height="375"><p>


				Egyptian woven pattern woolen curtain or trousers, which was a copy of a Sassanid silk import, which was in turn based on a fresco of King Khosrau II fighting Axum Ethiopian forces in Yemen, 5–6th century


				</p><p>
					In 522, before Khosrau's reign, a group of monophysite Axumites led an attack on the dominant Himyarites of southern Arabia. The local Arab leader was able to resist the attack but appealed to the Sassanians for aid, while the Axumites subsequently turned towards the Byzantines for help. The Axumites sent another force across the Red Sea and this time successfully killed the Arab leader and replaced him with an Axumite man to be king of the region.[94]</p><p>In 531, Justinian suggested that the Axumites of Yemen should cut out the Persians from Indian trade by maritime trade with the Indians. The Ethiopians never met this request because an Axumite general named Abraha took control of the Yemenite throne and created an independent nation.[94] After Abraha's death one of his sons, Ma'd-Karib, went into exile while his half-brother took the throne. After being denied by Justinian, Ma'd-Karib sought help from Khosrau, who sent a small fleet and army under commander Vahriz to depose the new king of Yemen. After capturing the capital city San'a'l, Ma'd-Karib's son, Saif, was put on the throne.[94]</p><p>Justinian was ultimately responsible for Sassanian maritime presence in Yemen. By not providing the Yemenite Arabs support, Khosrau was able to help Ma'd-Karib and subsequently established Yemen as a principality of the Sassanian Empire.[95]</p><h3>Relations with China</h3><p> Main article: Iran-China relations</p><p>Like their predecessors the Parthians, the Sassanid Empire carried out active foreign relations with China, and ambassadors from Persia frequently traveled to China. Chinese documents report on thirteen Sassanid embassies to China. Commercially, land and sea trade with China was important to both the Sassanid and Chinese Empires. Large numbers of Sassanid coins have been found in southern China, confirming maritime trade.</p><p>On different occasions, Sassanid kings sent their most talented Persian musicians and dancers to the Chinese imperial court at Luoyang during the Jin and Northern Wei dynasties, and to Chang'an during the Sui and Tang dynasties. Both empires benefited from trade along the Silk Road and shared a common interest in preserving and protecting that trade. They cooperated in guarding the trade routes through central Asia, and both built outposts in border areas to keep caravans safe from nomadic tribes and bandits.</p><div class="gradientback"></div></div><div class="content"><p>Politically, there is evidence of several Sassanid and Chinese efforts in forging alliances against the common enemy, the Hephthalites. Upon the rise of the nomadic Göktürks in Inner Asia, there is also what looks like a collaboration between China and Sassanid to defuse Turkic advances. Documents from Mt. Mogh talk about the presence of a Chinese general in the service of the king of Sogdiana at the time of the Arab invasions.</p><p>Following the invasion of Iran by Muslim Arabs, Peroz III, son of Yazdegerd III, escaped along with a few Persian nobles and took refuge in the Chinese imperial court. Both Peroz and his son Narsieh (Chinese neh-shie) were given high titles at the Chinese court. On at least two occasions, the last possibly in 670, Chinese troops were sent with Peroz in order to restore him to the Sassanid throne with mixed results, one possibly ending in a short rule of Peroz in Sakastan, from which we have a few remaining numismatic evidences. Narsieh later attained the position of a commander of the Chinese i<br>
							

											 
										

							</p><br><h1 lang="en">Achaemenid Empire</h1><p> From Wikipedia, the free encyclopedia</p><p>The Achaemenid Empire (/?'ki?m?n?d/, from Old Persian ???????????????????????????????????? Haxamanišiya,[11] c. 550–330 BC), also called the First Persian Empire,[12] was an empire based in Western Asia, founded by Cyrus the Great. Ranging at its greatest extent from the Balkans and Eastern Europe proper in the west to the Indus Valley in the east, it was one of the largest empires in history, spanning 5.5 million square kilometers, and was larger than any previous empire in history. It is equally notable for its successful model of a centralised, bureaucratic administration (through satraps under the King of Kings), for building infrastructure such as road systems and a postal system, the use of an official language across its territories, and the development of civil services and a large professional army. The empire's successes inspired similar systems in later empires.[13] It is noted in Western history as the antagonist of the Greek city-states during the Greco-Persian Wars and for the emancipation of the Jewish exiles in Babylon. The Mausoleum at Halicarnassus, one of the Seven Wonders of the Ancient World, was built in a Hellenistic style in the empire as well.</p><p>By the 7th century BC, the Persians had settled in the southwestern portion of the Iranian Plateau in the region of Persis,[14] which came to be their heartland.[15] From this region, Cyrus the Great advanced to defeat the Medes, Lydia, and the Neo-Babylonian Empire, establishing the Achaemenid Empire. Alexander the Great, an avid admirer of Cyrus the Great,[16] conquered most of the empire by 330 BC.[17] Upon his death, most of the empire's former territory came under the rule of the Ptolemaic Kingdom and Seleucid Empire, in addition to other minor territories which gained independence at that time. The Iranian population of the central plateau reclaimed power by the second century BC under the Parthian Empire.[15]</p><p>The historical mark of the Achaemenid Empire went far beyond its territorial and military influences and included cultural, social, technological and religious influences as well. Many Athenians adopted Achaemenid customs in their daily lives in a reciprocal cultural exchange,[18] some being employed by or allied to the Persian kings. The impact of Cyrus's edict is mentioned in Judeo-Christian texts, and the empire was instrumental in the spread of Zoroastrianism as far east as China. The empire also set the tone for the politics, heritage and history of modern Iran.[19]</p><h2>Contents</h2><h2>History</h2><h3>Achaemenid timeline</h3><p>Astronomical year numbering</p><br><img usemap="#timeline_37f569a2041e1d4c4a502dfff8e1c188" src="http://upload.wikimedia.org/wikipedia/en/timeline/37f569a2041e1d4c4a502dfff8e1c188.png"><h3>Origin</h3><p> Main articles: Achaemenes, Teispids, and Achaemenid family tree</p><p>The Persian nation contains a number of tribes as listed here.&nbsp;...&nbsp;: the Pasargadae, Maraphii, and Maspii, upon which all the other tribes are dependent. Of these, the Pasargadae are the most distinguished; they contain the clan of the Achaemenids from which spring the Perseid kings. Other tribes are the Panthialaei, Derusiaei, Germanii, all of which are attached to the soil, the remainder -the Dai, Mardi, Dropici, Sagarti, being nomadic.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/7/78/Olympic_Park_Cyrus-3.jpg/120px-Olympic_Park_Cyrus-3.jpg" width="120" height="161"><p>


				Relief of Cyrus the Great.



				<br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/d/d2/The_maussolleion_model_dsc02711-miniaturk_nevit.jpg/220px-The_maussolleion_model_dsc02711-miniaturk_nevit.jpg" width="220" height="293"><br>


				The Mausoleum at Halicarnassus, one of the Seven wonders of the ancient world, was built by Greek architects for the local Persian satrap of Caria, Mausolus (Scale model)


				</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/d/d2/The_maussolleion_model_dsc02711-miniaturk_nevit.jpg/220px-The_maussolleion_model_dsc02711-miniaturk_nevit.jpg" width="220" height="293"><br><p>
					The Achaemenid Empire was created by nomadic Persians. The name Persia is a Greek and Latin pronunciation of the native word referring to the country of the people originating from Persis (Old Persian: Parsa), their home territory located north of the Persian Gulf in southwestern Iran.[20]</p><p>The Achaemenid Empire was not the first Iranian empire, as by 6th century BC another group of ancient Iranian peoples had already established the short lived Median Empire.[20] The Medes had originally been the dominant Iranian group in the region, freeing themselves of Assyrian domination and rising to power at the end of the seventh century BC, incorporating the Persians into their empire.</p><p>The Iranian peoples had arrived in the region of what is today Iran c. 1000 BC[21] and had for a number of centuries fallen under the domination of the Neo-Assyrian Empire (911–609 BC), based in northern Mesopotamia. However, the Medes and Persians (together with the Scythians, Babylonians), Cimmerians, Persians and Chaldeans played a major role in the overthrow of the Assyrian empire and establishment of the first Persian empire.</p><div class="gradientback"></div></div><div class="content"><p>The term Achaemenid means of the family of the Achaemenis/Achaemenes (Old Persian: Haxamaniš; a bahuvrihi compound translating to having a friend's mind).[22] Despite the derivation of the name, Achaemenes was himself a minor seventh-century ruler of the Anshan in southwestern Iran, and a vassal of Assyria.[20] It was not until the time of Cyrus the Great (Cyrus II of Persia), a descendant of Achaemenes, that the Achaemenid Empire developed the prestige of an empire and set out to incorporate the existing empires of the ancient east, becoming the vast Persian Empire of ancient legend.[23]</p><p>At some point in 550 BC, Cyrus rose in rebellion against the Medes (most likely due to their mismanagement of Persis), eventually conquering the Medes and creating the first Persian empire. Cyrus the Great utilized his tactical genius,[24] as well as his understanding of the socio-political conditions governing his territories, to eventually incorporate into the Empire neighbouring Lydia and the Neo-Babylonian Empire, also leading the way for his successor, Cambyses II, to venture into Egypt and defeat the Twenty-sixth Dynasty of Egypt.</p><p>Cyrus the Great's political acumen was reflected in his management of his newly formed empire, as the Persian Empire became the first to attempt to govern many different ethnic groups on the principle of equal responsibilities and rights for all people, so long as subjects paid their taxes and kept the peace.[25] Additionally, the king agreed not to interfere with the local customs, religions, and trades of its subject states,[25] a unique quality that eventually won Cyrus the support of the Babylonians. This system of management ultimately became an issue for the Persians, as with a larger empire came the need for order and control, leading to expenditure of resources and mobilization of troops to quell local rebellions, and weakening the central power of the king. By the time of Darius III, this disorganization had almost led to a disunited realm.[15]</p><p>The Persians from whom Cyrus hailed were originally nomadic pastoralists in the western Iranian Plateau and by 850 BC were calling themselves the Parsa and their constantly shifting territory Parsua, for the most part localized around Persis.[15] As Persians gained power, they developed the infrastructure to support their growing influence, including creation of a capital named Pasargadae and an opulent city named Persepolis.</p><p>Begun during the rule of Darius I the Great and completed some 100 years later,[26] Persepolis was a symbol of the empire serving both as a ceremonial centre and a center of government.[26] It had a special set of gradually progressive stairways named All Countries[26] around which carved relief decoration depicted scenes of heroism, hunting, natural themes, and presentation of the gifts to the Achaemenid kings by their various subjects, possibly during the spring festival, Nowruz. The core structure was composed of a multitude of square rooms or halls, the biggest of which was called Apadana.[26] Tall, decorated columns welcomed visitors and emphasized the height of the structure. Later on, Darius also utilized Susa and Ecbatana as his governmental centres, developing them to a similar metropolitan status.</p><p>Accounts of the Achaemenid family tree can be derived from either documented Greek or Roman accounts, or from existing documented Persian accounts such as those found in the Behistun Inscription. However, since most existing accounts of this vast empire are in works of Greek philosophers and historians, and since many of the original Persian documents are lost, not to mention being subject to varying scholarly views on their origin and possible motivations behind them, it is difficult to create a definitive and completely objective list. Nonetheless, it is clear that Cyrus and Darius were critical in the expansion of the empire. Cyrus is often believed to be the son of Cambyses I, grandson of Cyrus I, the father of Cambyses II, and a relative of Darius through a shared ancestor, Teispes. Cyrus the Great is also believed to have been a family member (possibly grandson) of the Median king Astyages through his mother, Mandane of Media. A minority of scholars argue that perhaps Achaemenes was a retrograde creation of Darius in order to reconcile his connection with Cyrus after gaining power.[20]</p><p>Ancient Greek writers provide some legendary information about Achaemenes by calling his tribe the Pasargadae and stating that he was raised by an eagle. Plato, when writing about the Persians, identified Achaemenes with Perses, ancestor of the Persians in Greek mythology.[27] According to Plato, Achaemenes was the same person as Perses, a son of the Ethiopian queen Andromeda and the Greek hero Perseus, and a grandson of Zeus. Later writers believed that Achaemenes and Perseus were different people, and that Perses was an ancestor of the king.[28] This account further confirms that Achaemenes could well have been a significant Anshan leader and an ancestor of Cyrus the Great. Regardless, both Cyrus the Great and Darius the Great were related, prominent kings of Persia, under whose rule the empire expanded to include much of the ancient world.</p><h3>Formation and expansion</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/2/22/CyrustheGreatTomb_22057.jpg/250px-CyrustheGreatTomb_22057.jpg" width="250" height="188"><p>


				The tomb of Cyrus the Great, founder of the Achaemenid Empire



				<br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/d/d7/Gate_of_nations.JPG/250px-Gate_of_nations.JPG" width="250" height="167"><br>


				The Gate of All Nations, Persepolis



				<br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/2/25/Perspolis.jpg/250px-Perspolis.jpg" width="250" height="337"><br>


				A well preserved Persian column showing the details of the capital of the columns in Persepolis



				<br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/7/76/Achaemenid_Empire_under_different_kings_%28flat_map%29.svg/350px-Achaemenid_Empire_under_different_kings_%28flat_map%29.svg.png" width="350" height="230"><br>


				Map of the expansion process of Achaemenid territories



				</p><div class="gradientback"></div></div><div class="content"><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/d/d7/Gate_of_nations.JPG/250px-Gate_of_nations.JPG" width="250" height="167"><br><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/2/25/Perspolis.jpg/250px-Perspolis.jpg" width="250" height="337"><br><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/7/76/Achaemenid_Empire_under_different_kings_%28flat_map%29.svg/350px-Achaemenid_Empire_under_different_kings_%28flat_map%29.svg.png" width="350" height="230"><br><p> Further information: Battle of the Persian Border, Persian Revolt, Battle of Pteria, Battle of Opis, Battle of Pelusium (525 BC), Achaemenid invasion of the Indus Valley, and European Scythian campaign of Darius I</p><p>
					The empire took its unified form with a central administration around Pasargadae erected by Cyrus the Great. The empire ended up conquering and enlarging the Median Empire to include in addition many more territories, for example in Europe, the Caucasus, Asia Minor, Egypt, and Central Asia. During the reigns of Darius I and his son Xerxes I it engaged in military conflict with some of the major city-states of Ancient Greece, and although it came close to defeating the Greek army, this war ultimately led to the empire's overthrow.[29]</p><p>In 559 BC, Cambyses I the Elder was succeeded as the king of Anšan by his son Cyrus the Great, who also succeeded the still-living Arsames as the King of Persia, thus reuniting the two realms. Cyrus is considered to be the first true king of the Persian Empire, as his predecessors were subservient to the Medes. Cyrus the Great conquered Media, Lydia, and Babylon. Cyrus was politically shrewd, modeling himself as the savior of conquered nations, often allowing displaced people to return, and giving his subjects freedom to practice local customs. To reinforce this image, he instituted policies of religious freedom, and restored temples and other infrastructure in the newly acquired cities (Most notably the Jewish inhabitants of Babylon, as recorded in the Cyrus Cylinder and the Tanakh). As a result of his tolerant policies he came to be known by those of the Jewish faith as the anointed of the Lord.[30][31]</p><p>His immediate successors were less successful. Cyrus' son Cambyses II conquered Egypt in 525 BC, but died in July 522 BC during a revolt led by a sacerdotal clan that had lost its power following Cyrus' conquest of Media. The cause of his death remains uncertain, although it may have been the result of an accident.[32]</p><p>According to Herodotus, Cambyses II had originally ventured into Egypt to take revenge for the pharaoh Amasis's trickery when he sent a fake Egyptian bride whose family Amasis had murdered,[33] instead of his own daughter, to wed Cambyses II. Additionally negative reports of mistreatment caused by Amasis, given by Phanes of Halicarnassus, a wise counsellor serving Amasis, further bolstered Cambyses's resolve to venture into Egypt. Amasis died before Cambyses II could face him, but his successor Psamtik III was defeated by Cambyses II in the Battle of Pelusium.</p><p>While Cambyses II was in Egypt, the Zoroastrian priests, whom Herodotus called Magi, usurped the throne for one of their own, Gaumata, who then pretended to be Cambyses II's younger brother Bardiya (Greek: Smerdis or Tanaoxares/Tanyoxarkes[32]), who had been assassinated some three years earlier. Owing to the strict rule of Cambyses II, especially his stance on taxation,[34] and his long absence in Egypt, the whole people, Perses, Medes and all the other nations, acknowledged the usurper, especially as he granted a remission of taxes for three years.[35] Cambyses II himself would not be able to quell the imposters, as he died on the way back from Egypt.</p><p>The claim that Gaumata had impersonated Bardiya (Smerdis), is derived from Darius the Great and the records at the Behistun Inscription. Historians are divided over the possibility that the story of the impostor was invented by Darius as justification for his coup.[36] Darius made a similar claim when he later captured Babylon, announcing that the Babylonian king was not, in fact, Nebuchadnezzar III, but an impostor named Nidintu-bel.[37]</p><p>According to the Behistun Inscription, Gaumata ruled for seven months before being overthrown in 522 BC by Darius the Great (Darius I) (Old Persian Daryavuš, who holds firm the good, also known as Darayarahush or Darius the Great). The Magi, though persecuted, continued to exist, and a year following the death of the first pseudo-Smerdis (Gaumata), saw a second pseudo-Smerdis (named Vahyazdata) attempt a coup. The coup, though initially successful, failed.[38]</p><p>Herodotus writes[39] that the native leadership debated the best form of government for the empire. It was agreed that an oligarchy would divide them against one another, and democracy would bring about mob rule resulting in a charismatic leader resuming the monarchy. Therefore, they decided a new monarch was in order, particularly since they were in a position to choose him. Darius I was chosen monarch from among the leaders. He was cousin to Cambyses II and Bardiya (Smerdis), claiming Ariaramnes as his ancestor.</p><p>The Achaemenids thereafter consolidated areas firmly under their control. It was Cyrus the Great and Darius the Great who, by sound and farsighted administrative planning, brilliant military maneuvering, and a humanistic world view, established the greatness of the Achaemenids and, in less than thirty years, raised them from an obscure tribe to a world power. It was during the reign of Darius the Great (Darius I) that Persepolis was built (518–516 BC) and which would serve as capital for several generations of Achaemenid kings. Ecbatana (Hagmatana City of Gatherings, modern: Hamadan) in Media was greatly expanded during this period and served as the summer capital.</p><p>Ever since the Macedonian king Amyntas I surrendered his country to the Persians in about 512-511, Macedonians and Persians were strangers no more as well.[40] Subjugation of Macedonia was part of Persian military operations initiated by Darius the Great (521–486) in 513 - after immense preparations - a huge Achaemenid army invaded the Balkans and tried to defeat the European Scythians roaming to the north of the Danube river.[40] Darius' army subjugated several Thracian peoples, and virtually all other regions that touch the European part of the Black Sea, such as parts of nowadays Bulgaria, Romania, Ukraine, and Russia, before it returned to Asia Minor.[40][41] Darius left in Europe one of his commanders named Megabazus whose task was to accomplish conquests in the Balkans.[40] The Persian troops subjugated gold-rich Thrace, the coastal Greek cities, as well as defeating and conquering the powerful Paeonians.[40][42][43] Finally, Megabazus sent envoys to Amyntas, demanding acceptance of Persian domination, which the Macedonians did. The Balkans provided many soldiers for the multi-ethnic Achaemenid army. Many of the Macedonian and Persian elite intermarried, such as the Persian official Bubares who married Amyntas' daughter, Gygaea. Family ties the Macedonian rulers Amyntas and Alexander enjoyed with Bubares ensured them good relations with the Persian kings Darius and Xerxes I.[40] The Persian invasion led indirectly to Macedonia's rise in power and Persia had some common interests in the Balkans; with Persian aid, the Macedonians stood to gain much at the expense of some Balkan tribes such as the Paeonians and Greeks. All in all, the Macedonians were willing and useful Persian allies. Macedonian soldiers fought against Athens and Sparta in Xerxes' army.[40] The Persians referred to both Greeks and Macedonians as Yauna (Ionians, their term for Greeks), and to Macedonians specifically as Yaunã Takabara or Greeks with hats that look like shields, possibly referring to the Macedonian kausia hat.[44]</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/d/d6/Iranian_queen.jpg/170px-Iranian_queen.jpg" width="170" height="202"><p>


				The Persian queen Atossa, Darius the Great's wife and mother of Xerxes I


				</p><p>
					By the 5th century BC the Kings of Persia were either ruling over or had subordinated territories encompassing not just all of the Persian Plateau and all of the territories formerly held by the Assyrian Empire (Mesopotamia, the Levant, Cyprus and Egypt), but beyond this all of Anatolia and Armenia, as well as the Southern Caucasus and parts of the North Caucasus, Azerbaijan, Uzbekistan, Tajikistan, all of Bulgaria, Paeonia, Thrace and Macedonia to the north and west, most of the Black Sea coastal regions, parts of Central Asia as far as the Aral Sea, the Oxus and Jaxartes to the north and north-east, the Hindu Kush and the western Indus basin (corresponding to modern Afghanistan and Pakistan) to the far east, parts of northern Arabia to the south, and parts of northern Libya to the south-west, and parts of Oman, China, and the UAE.[45][46][47][48][49][50]</p><div class="gradientback"></div></div><div class="content"><h3>Greco-Persian Wars</h3><p> Main article: Greco-Persian Wars</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/2/22/Greek-Persian_duel.jpg/220px-Greek-Persian_duel.jpg" width="220" height="218"><p>


				Greek hoplite and Persian warrior depicted fighting, on an ancient kylix, 5th century BC


				</p><p>
					The Ionian Revolt in 499 BC, and associated revolts in Aeolis, Doris, Cyprus and Caria, were military rebellions by several regions of Asia Minor against Persian rule, lasting from 499 to 493 BC. At the heart of the rebellion was the dissatisfaction of the Greek cities of Asia Minor with the tyrants appointed by Persia to rule them, along with the individual actions of two Milesian tyrants, Histiaeus and Aristagoras. In 499 BC, the then tyrant of Miletus, Aristagoras, launched a joint expedition with the Persian satrap Artaphernes to conquer Naxos, in an attempt to bolster his position in Miletus (both financially and in terms of prestige). The mission was a debacle, and sensing his imminent removal as tyrant, Aristagoras chose to incite the whole of Ionia into rebellion against the Persian king Darius the Great.</p><p>The Persians continued to reduce the cities along the west coast that still held out against them, before finally imposing a peace settlement in 493 BC on Ionia that was generally considered to be both just and fair. The Ionian Revolt constituted the first major conflict between Greece and the Achaemenid Empire, and as such represents the first phase of the Greco-Persian Wars. Asia Minor had been brought back into the Persian fold, but Darius had vowed to punish Athens and Eretria for their support of the revolt.[51] Moreover, seeing that the political situation in Greece posed a continued threat to the stability of his Empire, he decided to embark on the conquest of all of Greece. The first campaign of the invasion was to bring the territories in the Balkan peninsula back within the empire.[52] The Persian grip over these territories had loosened following the Ionian Revolt. In 492 BC, the Persian general Mardonius re-subjugated Thrace and made Macedon a fully subordinate part of the empire; it had been a vassal as early as the late 6th century BC, but retained a great deal of autonomy.[52] However, in 490 BC the Persian forces were defeated by the Athenians at the Battle of Marathon and Darius would die before having the chance to launch an invasion of Greece.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Map_Greco-Persian_Wars-en.svg/300px-Map_Greco-Persian_Wars-en.svg.png" width="300" height="240"><p>


				Map showing events of the first phases of the Greco-Persian Wars


				</p><p>
					Xerxes I (485–465 BC, Old Persian Xšayarša Hero Among Kings), son of Darius I, vowed to complete the job. He organized a massive invasion aiming to conquer Greece. His army entered Greece from the north, meeting little or no resistance through Macedonia and Thessaly, but was delayed by a small Greek force for three days at Thermopylae. A simultaneous naval battle at Artemisium was tactically indecisive as large storms destroyed ships from both sides. The battle was stopped prematurely when the Greeks received news of the defeat at Thermopylae and retreated. The battle was a strategic victory for the Persians, giving them uncontested control of Artemisium and the Aegean Sea.</p><p>Following his victory at the Battle of Thermopylae, Xerxes sacked the evacuated city of Athens and prepared to meet the Greeks at the strategic Isthmus of Corinth and the Saronic Gulf. In 480 BC the Greeks won a decisive victory over the Persian fleet at the Battle of Salamis and forced Xerxes to retire to Sardis. The land army which he left in Greece under Mardonius retook Athens but was eventually destroyed in 479 BC at the Battle of Plataea. The final defeat of the Persians at Mycale encouraged the Greek cities of Asia to revolt, and the Persians lost all of their territories in Europe; Macedonia once again became independent.[40]</p><h3>Cultural phase</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/6/65/Cyrus_II_le_Grand_et_les_H%C3%A9breux.jpg/200px-Cyrus_II_le_Grand_et_les_H%C3%A9breux.jpg" width="200" height="237"><p>


				Cyrus the Great king of Iran (ancient Persia) is said in the Bible to have liberated the Hebrew captives in Babylon to resettle and rebuild Jerusalem, earning him an honored place in Judaism.


				</p><p>
					After Xerxes I was assassinated, he was succeeded by his eldest son Artaxerxes I. It was during his reign that Elamite ceased to be the language of government, and Aramaic gained in importance. It was probably during this reign that the solar calendar was introduced as the national calendar. Under Artaxerxes I, Zoroastrianism became the de facto religion of state, and for this Artaxerxes I is today also known as the Constantine of that faith.</p><p>After Persia had been defeated at Battle of Eurymedon (469 BC), military action between Greece and Persia was halted. When Artaxerxes&nbsp;I took power, he introduced a new Persian strategy of weakening the Athenians by funding their enemies in Greece. This indirectly caused the Athenians to move the treasury of the Delian League from the island of Delos to the Athenian acropolis. This funding practice inevitably prompted renewed fighting in 450&nbsp;BC, where the Greeks attacked at the Battle of Cyprus. After Cimon's failure to attain much in this expedition, the Peace of Callias was agreed between Athens, Argos and Persia in 449&nbsp;BC.</p><p>Artaxerxes&nbsp;I offered asylum to Themistocles, who was the winner of the Battle of Salamis, after Themistocles was ostracized from Athens. Also, Artaxerxes I gave him Magnesia, Myus, and Lampsacus to maintain him in bread, meat, and wine. In addition, Artaxerxes I gave him Palaescepsis to provide him with clothes, and he also gave him Percote with bedding for his house.[53]</p><div class="gradientback"></div></div><div class="content"><p>When Artaxerxes died in 424 BC at Susa, his body was taken to the tomb already built for him in the Naqsh-e Rustam Necropolis. It was Persian tradition that kings begin constructing their own tombs while they were still alive. Artaxerxes I was immediately succeeded by his eldest son Xerxes II, who was the only legitimate son of Artaxerxes.[54] However, after a few days on the throne, he was assassinated while drunk by Pharnacyas and Menostanes on the orders of his illegitimate brother: Sogdianus who apparently had gained the support of his regions. He reigned for six months and fifteen days before being captured by his half-brother, Ochus, who had rebelled against him. Sogdianus was executed by being suffocated in ash because Ochus had promised he would not die by the sword, by poison or by hunger.[55] Ochus then took the royal name Darius II. Darius' ability to defend his position on the throne ended the short power vacuum.</p><p>From 412 BC Darius II, at the insistence of Tissaphernes, gave support first to Athens, then to Sparta, but in 407 BC, Darius' son Cyrus the Younger was appointed to replace Tissaphernes and aid was given entirely to Sparta which finally defeated Athens in 404 BC. In the same year, Darius fell ill and died in Babylon. His death gave an Egyptian rebel named Amyrtaeus the opportunity to throw off Persian control over Egypt. At his death bed, Darius' Babylonian wife Parysatis pleaded with him to have her second eldest son Cyrus (the Younger) crowned, but Darius refused. Queen Parysatis favoured Cyrus more than her eldest son Artaxerxes II. Plutarch relates (probably on the authority of Ctesias) that the displaced Tissaphernes came to the new king on his coronation day to warn him that his younger brother Cyrus (the Younger) was preparing to assassinate him during the ceremony. Artaxerxes had Cyrus arrested and would have had him executed if their mother Parysatis had not intervened. Cyrus was then sent back as Satrap of Lydia, where he prepared an armed rebellion. Cyrus hired an army of Ten Thousand Greek mercenaries and made his way deeper into Persia. The army of Cyrus was stopped by the royal Persian army of Artaxerxes II at Cunaxa in 401 BC, where Cyrus was killed. The Ten Thousand Greek Mercenaries including Xenophon were now deep in Persian territory and were at risk of attack. So they searched for others to offer their services to but eventually had to return to Greece.[56]</p><p>Artaxerxes II was the longest reigning of the Achaemenid kings and it was during this 45-year period of relative peace and stability that many of the monuments of the era were constructed. Artaxerxes moved the capital back to Persepolis, which he greatly extended. Also the summer capital at Ecbatana was lavishly extended with gilded columns and roof tiles of silver and copper.[57] The extraordinary innovation of the Zoroastrian shrines can also be dated to his reign, and it was probably during this period that Zoroastrianism spread from Armenia throughout Asia Minor and the Levant. The construction of temples, though serving a religious purpose, was not a purely selfless act, as they also served as an important source of income. From the Babylonian kings, the Achaemenids had taken over the concept of a mandatory temple tax, a one-tenth tithe which all inhabitants paid to the temple nearest to their land or other source of income.[58] A share of this income called the Quppu Sha Sharri, kings chest—an ingenious institution originally introduced by Nabonidus—was then turned over to the ruler. In retrospect, Artaxerxes is generally regarded as an amiable man who lacked the moral fibre to be a really successful ruler. However, six centuries later Ardeshir I, founder of the second Persian Empire, would consider himself Artaxerxes' successor, a grand testimony to the importance of Artaxerxes to the Persian psyche.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/6/69/Double_daric_330-300_obverse_CdM_Paris.jpg/240px-Double_daric_330-300_obverse_CdM_Paris.jpg" width="240" height="240"><p>


				Daric of Artaxerxes II


				</p><p>
					Artaxerxes II became involved in a war with Persia's erstwhile allies, the Spartans, who, under Agesilaus II, invaded Asia Minor. In order to redirect the Spartans' attention to Greek affairs, Artaxerxes II subsidized their enemies: in particular the Athenians, Thebans and Corinthians. These subsidies helped to engage the Spartans in what would become known as the Corinthian War. In 386 BC, Artaxerxes II betrayed his allies and came to an arrangement with Sparta, and in the Treaty of Antalcidas he forced his erstwhile allies to come to terms. This treaty restored control of the Greek cities of Ionia and Aeolis on the Anatolian coast to the Persians, while giving Sparta dominance on the Greek mainland. In 385 BC he campaigned against the Cadusians. Although successful against the Greeks, Artaxerxes II had more trouble with the Egyptians, who had successfully revolted against him at the beginning of his reign. An attempt to reconquer Egypt in 373 BC was completely unsuccessful, but in his waning years the Persians did manage to defeat a joint Egyptian–Spartan effort to conquer Phoenicia. He quashed the Revolt of the Satraps in 372–362 BC. He is reported to have had a number of wives. His main wife was Stateira, until she was poisoned by Artaxerxes II's mother Parysatis in about 400 BC. Another chief wife was a Greek woman of Phocaea named Aspasia (not the same as the concubine of Pericles). Artaxerxes II is said to have more than 115 sons from 350 wives.[59]</p><p>In 358 BC Artaxerxes II died and was succeeded by his son Artaxerxes III. In 355 BC, Artaxerxes III forced Athens to conclude a peace which required the city's forces to leave Asia Minor and to acknowledge the independence of its rebellious allies.[60] Artaxerxes started a campaign against the rebellious Cadusians, but he managed to appease both of the Cadusian kings. One individual who successfully emerged from this campaign was Darius Codomannus, who later occupied the Persian throne as Darius III.</p><p>Artaxerxes III then ordered the disbanding of all the satrapal armies of Asia Minor, as he felt that they could no longer guarantee peace in the west and was concerned that these armies equipped the western satraps with the means to revolt.[61] The order was however ignored by Artabazus of Lydia, who asked for the help of Athens in a rebellion against the king. Athens sent assistance to Sardis. Orontes of Mysia also supported Artabazus and the combined forces managed to defeat the forces sent by Artaxerxes III in 354&nbsp;BC. However, in 353&nbsp;BC, they were defeated by Artaxerxes III's army and were disbanded. Orontes was pardoned by the king, while Artabazus fled to the safety of the court of Philip II of Macedon. In around 351 BC, Artaxerxes embarked on a campaign to recover Egypt, which had revolted under his father, Artaxerxes II. At the same time a rebellion had broken out in Asia Minor, which, being supported by Thebes, threatened to become serious. Levying a vast army, Artaxerxes marched into Egypt, and engaged Nectanebo II. After a year of fighting the Egyptian Pharaoh, Nectanebo inflicted a crushing defeat on the Persians with the support of mercenaries led by the Greek generals Diophantus and Lamius.[62] Artaxerxes was compelled to retreat and postpone his plans to reconquer Egypt. Soon after this defeat, there were rebellions in Phoenicia, Asia Minor and Cyprus. In 343&nbsp;BC, Artaxerxes committed responsibility for the suppression of the Cyprian rebels to Idrieus, prince of Caria, who employed 8,000 Greek mercenaries and forty triremes, commanded by Phocion the Athenian, and Evagoras, son of the elder Evagoras, the Cypriot monarch.[63][64] Idrieus succeeded in reducing Cyprus. Artaxerxes initiated a counter-offensive against Sidon by commanding Belesys, satrap of Syria and Mezseus, satrap of Cilicia to invade the city and to keep the Phoenicians in check. Both satraps suffered crushing defeats at the hands of Tennes, the Sidonese king, who was aided by 40,000 Greek mercenaries sent to him by Nectanebo II and commanded by Mentor of Rhodes. As a result, the Persian forces were driven out of Phoenicia.[64]</p><p>After this, Artaxerxes personally led an army of 330,000 men against Sidon. Artaxerxes' army comprised 300,000 foot soldiers, 30,000 cavalry, 300 triremes, and 500 transports or provision ships. After gathering this army, he sought assistance from the Greeks. Though refused aid by Athens and Sparta, he succeeded in obtaining a thousand Theban heavy-armed hoplites under Lacrates, three thousand Argives under Nicostratus, and six thousand Æolians, Ionians, and Dorians from the Greek cities of Asia Minor. This Greek support was numerically small, amounting to no more than 10,000 men, but it formed, together with the Greek mercenaries from Egypt who went over to him afterwards, the force on which he placed his chief reliance, and to which the ultimate success of his expedition was mainly due. The approach of Artaxerxes sufficiently weakened the resolution of Tennes that he endeavoured to purchase his own pardon by delivering up 100 principal citizens of Sidon into the hands of the Persian king, and then admitting Artaxerxes within the defences of the town. Artaxerxes had the 100 citizens transfixed with javelins, and when 500 more came out as supplicants to seek his mercy, Artaxerxes consigned them to the same fate. Sidon was then burnt to the ground, either by Artaxerxes or by the Sidonian citizens. Forty thousand people died in the conflagration.[64] Artaxerxes sold the ruins at a high price to speculators, who calculated on reimbursing themselves by the treasures which they hoped to dig out from among the ashes.[65] Tennes was later put to death by Artaxerxes.[66] Artaxerxes later sent Jews who supported the revolt to Hyrcania the south coast of the Caspian Sea.[67][68]</p><div class="gradientback"></div></div><div class="content"><h3>Second conquest of Egypt</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/b/be/NectaneboII-StatueHead_MuseumOfFineArtsBoston.png/220px-NectaneboII-StatueHead_MuseumOfFineArtsBoston.png" width="220" height="345"><p>


				Head of Nectanebo II



				<br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/9/99/Darius_II_cartouche_at_Hibis_d1.jpg/235px-Darius_II_cartouche_at_Hibis_d1.jpg" width="235" height="352"><br>


				Egyptian Cartouche of Darius I at the Temple of Hibis


				</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/9/99/Darius_II_cartouche_at_Hibis_d1.jpg/235px-Darius_II_cartouche_at_Hibis_d1.jpg" width="235" height="352"><br><p>
					The reduction of Sidon was followed closely by the invasion of Egypt. In 343&nbsp;BC, Artaxerxes, in addition to his 330,000 Persians, had now a force of 14,000 Greeks furnished by the Greek cities of Asia Minor: 4,000 under Mentor, consisting of the troops which he had brought to the aid of Tennes from Egypt; 3,000 sent by Argos; and 1000 from Thebes. He divided these troops into three bodies, and placed at the head of each a Persian and a Greek. The Greek commanders were Lacrates of Thebes, Mentor of Rhodes and Nicostratus of Argos while the Persians were led by Rhossaces, Aristazanes, and Bagoas, the chief of the eunuchs. Nectanebo II resisted with an army of 100,000 of whom 20,000 were Greek mercenaries. Nectanebo II occupied the Nile and its various branches with his large navy.</p><p>The character of the country, intersected by numerous canals and full of strongly fortified towns, was in his favour and Nectanebo II might have been expected to offer a prolonged, if not even a successful, resistance. However, he lacked good generals, and, over-confident in his own powers of command, he was out-manoeuvred by the Greek mercenary generals and his forces were eventually defeated by the combined Persian armies at the Battle of Pelusium (343 BC).[64] After his defeat, Nectanebo hastily fled to Memphis, leaving the fortified towns to be defended by their garrisons. These garrisons consisted of partly Greek and partly Egyptian troops; between whom jealousies and suspicions were easily sown by the Persian leaders. As a result, the Persians were able to rapidly reduce numerous towns across Lower Egypt and were advancing upon Memphis when Nectanebo decided to quit the country and flee southwards to Ethiopia.[64] The Persian army completely routed the Egyptians and occupied the Lower Delta of the Nile. Following Nectanebo fleeing to Ethiopia, all of Egypt submitted to Artaxerxes. The Jews in Egypt were sent either to Babylon or to the south coast of the Caspian Sea, the same location that the Jews of Phoenicia had earlier been sent.</p><p>After this victory over the Egyptians, Artaxerxes had the city walls destroyed, started a reign of terror, and set about looting all the temples. Persia gained a significant amount of wealth from this looting. Artaxerxes also raised high taxes and attempted to weaken Egypt enough that it could never revolt against Persia. For the 10&nbsp;years that Persia controlled Egypt, believers in the native religion were persecuted and sacred books were stolen.[69] Before he returned to Persia, he appointed Pherendares as satrap of Egypt. With the wealth gained from his reconquering Egypt, Artaxerxes was able to amply reward his mercenaries. He then returned to his capital having successfully completed his invasion of Egypt.</p><p>After his success in Egypt, Artaxerxes returned to Persia and spent the next few years effectively quelling insurrections in various parts of the Empire so that a few years after his conquest of Egypt, the Persian Empire was firmly under his control. Egypt remained a part of the Persian Empire until Alexander the Great's conquest of Egypt.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/6/63/Achaemenid_Empire.gif/350px-Achaemenid_Empire.gif" width="350" height="267"><p>


				Persian Empire timeline including important events and territorial evolution.


				</p><p>
					After the conquest of Egypt, there were no more revolts or rebellions against Artaxerxes. Mentor and Bagoas, the two generals who had most distinguished themselves in the Egyptian campaign, were advanced to posts of the highest importance. Mentor, who was governor of the entire Asiatic seaboard, was successful in reducing to subjection many of the chiefs who during the recent troubles had rebelled against Persian rule. In the course of a few years Mentor and his forces were able to bring the whole Asian Mediterranean coast into complete submission and dependence.</p><div class="gradientback"></div></div><div class="content"><p>Bagoas went back to the Persian capital with Artaxerxes, where he took a leading role in the internal administration of the Empire and maintained tranquility throughout the rest of the Empire. During the last six years of the reign of Artaxerxes III, the Persian Empire was governed by a vigorous and successful government.[64]</p><p>The Persian forces in Ionia and Lycia regained control of the Aegean and the Mediterranean Sea and took over much of Athens' former island empire. In response, Isocrates of Athens started giving speeches calling for a 'crusade against the barbarians' but there was not enough strength left in any of the Greek city-states to answer his call.[70]</p><p>Although there weren't any rebellions in the Persian Empire itself, the growing power and territory of Philip II of Macedon in Macedon (against which Demosthenes was in vain warning the Athenians) attracted the attention of Artaxerxes. In response, he ordered that Persian influence was to be used to check and constrain the rising power and influence of the Macedonian kingdom. In 340&nbsp;BC, a Persian force was dispatched to assist the Thracian prince, Cersobleptes, to maintain his independence. Sufficient effective aid was given to the city of Perinthus that the numerous and well-appointed army with which Philip had commenced his siege of the city was compelled to give up the attempt.[64] By the last year of Artaxerxes' rule, Philip II already had plans in place for an invasion of the Persian Empire, which would crown his career, but the Greeks would not unite with him.[71]</p><p>In 338&nbsp;BC Artaxerxes was poisoned by Bagoas with the assistance of a physician.[72]</p><h3>Fall of the empire</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/c/c3/Battle_of_Issus_mosaic_-_Museo_Archeologico_Nazionale_-_Naples_BW.jpg/220px-Battle_of_Issus_mosaic_-_Museo_Archeologico_Nazionale_-_Naples_BW.jpg" width="220" height="132"><p>


				The Battle of Issus, between Alexander the Great on horseback to the left, and Darius III in the chariot to the right, represented in a Pompeii mosaic dated 1st century BC – Naples National Archaeological Museum.



				<br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/8/8b/Alexander%E2%80%99s_first_victory_over_Darius%2C_the_Persian_king.jpg/220px-Alexander%E2%80%99s_first_victory_over_Darius%2C_the_Persian_king.jpg" width="220" height="148"><br>


				Alexander's first victory over Darius, the Persian king depicted in medieval European style in the 15th century romance The History of Alexander's Battles


				</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/8/8b/Alexander%E2%80%99s_first_victory_over_Darius%2C_the_Persian_king.jpg/220px-Alexander%E2%80%99s_first_victory_over_Darius%2C_the_Persian_king.jpg" width="220" height="148"><br><p>
					Artaxerxes III was succeeded by Artaxerxes IV Arses, who before he could act was also poisoned by Bagoas. Bagoas is further said to have killed not only all Arses' children, but many of the other princes of the land. Bagoas then placed Darius III, a nephew of Artaxerxes IV, on the throne. Darius III, previously Satrap of Armenia, personally forced Bagoas to swallow poison. In 334 BC, when Darius was just succeeding in subduing Egypt again, Alexander and his battle-hardened troops invaded Asia Minor.</p><p>Alexander the Great (Alexander III of Macedon) defeated the Persian armies at Granicus (334 BC), followed by Issus (333 BC), and lastly at Gaugamela (331 BC). Afterwards, he marched on Susa and Persepolis which surrendered in early 330 BC. From Persepolis, Alexander headed north to Pasargadae where he visited the tomb of Cyrus, the burial of the man whom he had heard of from the Cyropedia.</p><p>In the ensuing chaos created by Alexander's invasion of Persia, Cyrus's tomb was broken into and most of its luxuries were looted. When Alexander reached the tomb, he was horrified by the manner in which it had been treated, and questioned the Magi, putting them on trial.[73][74] By some accounts, Alexander's decision to put the Magi on trial was more an attempt to undermine their influence and display his own power than a show of concern for Cyrus's tomb.[75] Regardless, Alexander the Great ordered Aristobulus to improve the tomb's condition and restore its interior, showing respect for Cyrus.[73] From there he headed to Ecbatana, where Darius III had sought refuge.</p><p>Darius III was taken prisoner by Bessus, his Bactrian satrap and kinsman. As Alexander approached, Bessus had his men murder Darius III and then declared himself Darius' successor, as Artaxerxes V, before retreating into Central Asia leaving Darius' body in the road to delay Alexander, who brought it to Persepolis for an honorable funeral. Bessus would then create a coalition of his forces, in order to create an army to defend against Alexander. Before Bessus could fully unite with his confederates at the eastern part of the empire,[76] Alexander, fearing the danger of Bessus gaining control, found him, put him on trial in a Persian court under his control, and ordered his execution in a cruel and barbarous manner.[77]</p><p>Alexander generally kept the original Achaemenid administrative structure, leading some scholars to dub him as the last of the Achaemenids[78] Upon Alexander's death in 323 BC, his empire was divided among his generals, the Diadochi, resulting in a number of smaller states. The largest of these, which held sway over the Iranian plateau, was Seleucid Empire, ruled by Alexander's general Seleucus I Nicator. Native Iranian rule would be restored by the Parthians of northeastern Iran over the course of the 2nd century BC.</p><h3>Descendants in later Iranian dynasties</h3><p>Istakhr, one of the vassal kingdoms of the Parthian Empire, would be overthrown by Papak, a priest of the temple there. Papak's son, Ardašir I, who named himself in remembrance of Artaxerxes II, would revolt against the Parthians, eventually defeating them and establishing the Sassanid Empire or as it is known the second Persian Empire.</p><p>The Achaemenid line would be carried on through the Kingdom of Pontus, based in the Pontus region of northern Asia Minor. This Pontic Kingdom, a state of Persian origin,[79][80][81][82] may even have been directly related to Darius the Great and the Achaemenid dynasty.[82] It was founded by Mithridates I in 281 BC and lasted until its conquest by the Roman Republic in 63 BC. The kingdom grew to its largest extent under Mithridates VI the Great, who conquered Colchis, Cappadocia, Bithynia, the Greek colonies of the Tauric Chersonesos and for a brief time the Roman province of Asia. Thus, this Persian dynasty managed to survive and prosper in the Hellenistic world while the main Persian Empire had fallen.</p><p>Both the later dynasties of the Parthians and Sasanians would on occasion claim Achaemenid descent. Recently there has been some corroboration for the Parthian claim to Achaemenid ancestry via the possibility of an inherited disease (neurofibromatosis) demonstrated by the physical descriptions of rulers and from evidence of familial disease on ancient coinage.[83]</p><h3>Causes of decline</h3><p>Part of the cause of the Empire's decline had been the heavy tax burden put upon the state, which eventually led to economic decline.[84][85] An estimate of the tribute imposed on the subject nations was up to U.S. $180M per year. This does not include the material goods and supplies that were supplied as taxes.[86] After the high overhead of government - the military, the bureaucracy, whatever the satraps could safely dip into the coffers for themselves - this money went into the royal treasury. According to Diodorus, at Persepolis, Alexander III found some 180,000 Attic talents of silver besides the additional treasure the Macedonians were carrying that already had been seized in Damascus by Parmenion.[87][better&nbsp;source&nbsp;needed] This amounted to U.S. $2.7B. On top of this, Darius III had taken 8,000 talents with him on his flight to the north.[86][better&nbsp;source&nbsp;needed] Alexander put this static hoard back into the economy, and upon his death some 130,000 talents had been spent on the building of cities, dockyards, temples, and the payment of the troops, besides the ordinary government expenses.[88][better&nbsp;source&nbsp;needed] Additionally, one of the satraps, Harpalus, had made off to Greece with some 6,000 talents, which Athens used to rebuild its economy after seizing it during the struggles with the Corinthian League.[89][better&nbsp;source&nbsp;needed] Due to the flood of money from Alexander's hoard entering Greece, however, a disruption in the economy occurred, in agriculture, banking, rents, the great increase in mercenary soldiers that cash allowed the wealthy, and an increase in piracy.[90][better&nbsp;source&nbsp;needed]</p><div class="gradientback"></div></div><div class="content"><p>Another factor contributing to the decline of the Empire after Xerxes was its failure to ever mold the many subject nations into a whole; the creation of a national identity was never attempted.[91] This lack of cohesion eventually affected the efficiency of the military.[92]</p><h2>Government</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/0/04/Darius_I_the_Great%27s_inscription.jpg/220px-Darius_I_the_Great%27s_inscription.jpg" width="220" height="165"><p>


				The Behistun Inscription tells the story of Darius the Great's conquests, with the names of twenty-three satrapys subject to him.



				<br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/9/94/Behistun_DB1_1-15.jpg/220px-Behistun_DB1_1-15.jpg" width="220" height="73"><br>


				Behistun Inscription, column 1 (DB I 1–15)



				<br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/a/a6/Cylinder_Seal%2C_Achaemenid%2C_modern_impression_05.jpg/220px-Cylinder_Seal%2C_Achaemenid%2C_modern_impression_05.jpg" width="220" height="131"><br>


				Modern impression of Achaemenid cylinder seal. The use of cylinder seals appears to have been restricted to officials of the royal administration during this period.[93]


				</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/9/94/Behistun_DB1_1-15.jpg/220px-Behistun_DB1_1-15.jpg" width="220" height="73"><br><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/a/a6/Cylinder_Seal%2C_Achaemenid%2C_modern_impression_05.jpg/220px-Cylinder_Seal%2C_Achaemenid%2C_modern_impression_05.jpg" width="220" height="131"><br><p>
					Cyrus the Great founded the empire as a multi-state empire, governed by four capital states; Pasargadae, Babylon, Susa and Ekbatana. The Achaemenids allowed a certain amount of regional autonomy in the form of the satrapy system. A satrapy was an administrative unit, usually organized on a geographical basis. A 'satrap' (governor) was the governor who administered the region, a 'general' supervised military recruitment and ensured order, and a 'state secretary' kept the official records. The general and the state secretary reported directly to the satrap as well as the central government. At differing times, there were between 20 and 30 satrapies.[94]</p><p>Cyrus the Great created an organized army including the Immortals unit, consisting of 10,000 highly trained soldiers[95] Cyrus also formed an innovative postal system throughout the empire, based on several relay stations called Chapar Khaneh.[96]</p><p>The Persian daric was the first gold coin which, along with a similar silver coin, the siglos, (From Ancient Greek s?????, Hebrew ?????? (shékel)) introduced the bimetallic monetary standard of the Achaemenid Persian Empire which has continued till today.[97] This was accomplished by Darius the Great, who reinforced the empire and expanded Persepolis as a ceremonial capital;[98] he revolutionized the economy by placing it on the silver and gold coinage and introducing a regulated and sustainable tax system that was precisely tailored to each satrapy, based on their supposed productivity and their economic potential. For instance, Babylon was assessed for the highest amount and for a startling mixture of commodities – 1000 silver talents, four months supply of food for the army. India was clearly already fabled for its gold; Egypt was known for the wealth of its crops; it was to be the granary of the Persian Empire (as later of Rome's) and was required to provide 120,000 measures of grain in addition to 700 talents of silver. This was exclusively a tax levied on subject peoples.[99] Other accomplishments of Darius' reign included codification of the data, a universal legal system, and construction of a new capital at Persepolis.</p><p>Under the Achaemenids, the trade was extensive and there was an efficient infrastructure that facilitated the exchange of commodities in the far reaches of the empire. Tariffs on trade were one of the empire's main sources of revenue, along with agriculture and tribute.[99][100]</p><p>The satrapies were linked by a 2,500-kilometer highway, the most impressive stretch being the Royal Road from Susa to Sardis, built by command of Darius I. The relays of mounted couriers could reach the remotest of areas in fifteen days. Herodotus observes that there is nothing in the world that travels faster than these Persian couriers. Neither snow, nor rain, nor heat, nor gloom of night stays these courageous couriers from the swift completion of their appointed rounds.[101] Despite the relative local independence afforded by the satrapy system, royal inspectors, the eyes and ears of the king, toured the empire and reported on local conditions.</p><p>The practice of slavery in Achaemenid Persia was generally banned, although there is evidence that conquered and/or rebellious armies were sold into captivity.[102] The kings of Achaemenid Persia, especially the founder Cyrus the Great, occasionally declined to adopt slavery, as evidenced by the freeing of the Jews at Babylon, and the construction of Persepolis by paid workers.</p><h2>Military</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/2/29/Persepolis_Apadana_noerdliche_Treppe_Detail.jpg/220px-Persepolis_Apadana_noerdliche_Treppe_Detail.jpg" width="220" height="337"><p>


				Median (left) and Persian (right) soldiers


				</p><p>
					Despite its humble origins in Persis, the empire reached an enormous size under the leadership of Cyrus the Great. Cyrus created a multi-state empire where he allowed regional rulers, called the 'satrap' to rule as his proxy over a certain designated area of his empire called the satrapy. The basic rule of governance was based upon loyalty and obedience of each satrapy to the central power, or the king, and compliance with tax laws.[25] Due to the ethnocultural diversity of the subject nations under the rule of Persia, its enormous geographic size, and the constant struggle for power by regional competitors,[15] the creation of a professional army was necessary for both maintenance of the peace, and also to enforce the authority of the king in cases of rebellion and foreign threat.[13][95] Cyrus managed to create a strong land army, using it to advance in his campaigns in Babylonia, Lydia, and Asia Minor, which after his death was used by his son Cambyses II, in Egypt against Psamtik III. Cyrus would die battling a local Iranian insurgency in the empire, before he could have a chance to develop a naval force.[103] That task however would fall to Darius the Great, who would officially give Persians their own royal navy to allow them to engage their enemies on multiple seas of this vast empire, from the Black Sea and the Aegean Sea, to the Persian Gulf, Ionian Sea and the Mediterranean Sea.</p><div class="gradientback"></div></div><div class="content"><h3>Military composition</h3><p>The empire's great armies were, like the empire itself, very diverse, having:[note 1] Persians,[105] Macedonians,[40] European Thracians, Paeonians, Medes, Achaean Greeks, Cissians, Hyrcanians,[106] Assyrians, Chaldeans,[107] Bactrians, Sacae,[108] Arians, Parthians, Caucasian Albanians,[109] Chorasmians, Sogdians, Gandarians, Dadicae,[110] Caspians, Sarangae, Pactyes,[111] Utians, Mycians, Phoenicians along with the Syrians of Palestine (likely Judeans), Egyptians,[112] Cyprians,[113] Cilicians, Pamphylians, Lycians, Dorians of Asia, Carians, Ionians, Aegean islanders, Aeolians, Greeks from Pontus, Paricanians,[114] Arabians, Ethiopians of Africa,[115] Ethiopians of Baluchistan,[116] Libyans,[117] Paphlagonians, Ligyes, Matieni, Mariandyni, Cappadocians,[118] Phrygians, Armenians,[119] Lydians, Mysians,[120] Asian Thracians,[121] Lasonii, Milyae,[122] Moschi, Tibareni, Macrones, Mossynoeci,[123] Mares, Colchians, Alarodians, Saspirians,[124] Red Sea islanders,[125] Sagartians,[126] Indians,[127] Eordi, Bottiaei, Chalcidians, Brygians, Pierians, Perrhaebi, Enienes, Dolopes, and Magnesians.</p><h3>Infantry</h3><p>The Achaemenid infantry consisted of three groups: the Immortals, the Sparabara, and the Takabara, though in the later years of the Achaemenid Empire, the Cardaces, were introduced.</p><p>The Immortals were described by Herodotus as being heavy infantry, led by Hydarnes, that were kept constantly at a strength of exactly 10,000 men. He claimed that the unit's name stemmed from the custom that every killed, seriously wounded, or sick member was immediately replaced with a new one, maintaining the numbers and cohesion of the unit.[128] They had wicker shields, short spears, swords or large daggers, bow and arrow. Underneath their robes they wore scale armour coats. The spear counterbalances of the common soldiery were of silver; to differentiate commanding ranks, the officers' spear butt-spikes were golden.[129] Surviving Achaemenid coloured glazed bricks and carved reliefs represent the Immortals as wearing elaborate robes, hoop earrings and gold jewelry, though these garments and accessories were most likely worn only for ceremonial occasions.[130] The Sparabara unit were usually the first to engage in hand-to-hand combat with the enemy. Although not much is known about them today, it is believed that they were the backbone of the Persian army who formed a shield wall and used their two-metre-long spears to protect more vulnerable troops such as archers from the enemy. The Sparabara were taken from the full members of Persian society, they were<br>
							

											 
										
				<br><img alt="Page semi-protected" src="http://upload.wikimedia.org/wikipedia/commons/thumb/f/fc/Padlock-silver.svg/20px-Padlock-silver.svg.png" width="20" height="20">

							</p><br><br><img alt="Page semi-protected" src="http://upload.wikimedia.org/wikipedia/commons/thumb/f/fc/Padlock-silver.svg/20px-Padlock-silver.svg.png" width="20" height="20"><h1 lang="en">Scythians</h1><p> From Wikipedia, the free encyclopedia</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/a/ad/Scythia-Parthia_100_BC.png/240px-Scythia-Parthia_100_BC.png" width="240" height="153"><p>


				The approximate extent of Eastern Iranian languages and people in Middle Iranian times in the 1st century BC is shown in orange



				<br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/c/ce/%D0%A4%D1%80%D0%B0%D0%B3%D0%BC%D0%B5%D0%BD%D1%82%D1%8B_%D0%9F%D0%B5%D0%BA%D1%82%D0%BE%D1%80%D0%B0%D0%BB%D0%B8.jpg/240px-%D0%A4%D1%80%D0%B0%D0%B3%D0%BC%D0%B5%D0%BD%D1%82%D1%8B_%D0%9F%D0%B5%D0%BA%D1%82%D0%BE%D1%80%D0%B0%D0%BB%D0%B8.jpg" width="240" height="180"><br>


				Gold Scythian pectoral, or neckpiece, from a royal kurgan in Tolstaya Mogila, Pokrov, Ukraine, dated to the second half of the 4th century BC. The central lower tier shows three horses, each being torn apart by two griffins.



				<br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/4/4e/Scythians_shooting_with_bows_Kertch_antique_Panticapeum_Ukrainia_4th_century_BCE.jpg/240px-Scythians_shooting_with_bows_Kertch_antique_Panticapeum_Ukrainia_4th_century_BCE.jpg" width="240" height="181"><br>


				Scythians shooting with the Scythian bow, Kerch (ancient Panticapeum), Crimea, 4th century BC



				<br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/6/60/Gold_scythian_belt_title_from_Mingachevir%2C_Azerbaijan.JPG/240px-Gold_scythian_belt_title_from_Mingachevir%2C_Azerbaijan.JPG" width="240" height="230"><br>


				Gold Scythian belt title, Mingachevir (ancient Scythian kingdom), Azerbaijan, 7th century BC.


				 
				</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/c/ce/%D0%A4%D1%80%D0%B0%D0%B3%D0%BC%D0%B5%D0%BD%D1%82%D1%8B_%D0%9F%D0%B5%D0%BA%D1%82%D0%BE%D1%80%D0%B0%D0%BB%D0%B8.jpg/240px-%D0%A4%D1%80%D0%B0%D0%B3%D0%BC%D0%B5%D0%BD%D1%82%D1%8B_%D0%9F%D0%B5%D0%BA%D1%82%D0%BE%D1%80%D0%B0%D0%BB%D0%B8.jpg" width="240" height="180"><br><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/4/4e/Scythians_shooting_with_bows_Kertch_antique_Panticapeum_Ukrainia_4th_century_BCE.jpg/240px-Scythians_shooting_with_bows_Kertch_antique_Panticapeum_Ukrainia_4th_century_BCE.jpg" width="240" height="181"><br><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/6/60/Gold_scythian_belt_title_from_Mingachevir%2C_Azerbaijan.JPG/240px-Gold_scythian_belt_title_from_Mingachevir%2C_Azerbaijan.JPG" width="240" height="230"><br><p>
					The Scythians (/'s??i.?n/ or /'s?ði.?n/; from Greek S?????, S?????), also known as Scyth, Saka, Sakae, Sacae, Sai, Iskuzai, or Askuzai, were a large group of Iranian[1][2][3][4] Eurasian nomads who were mentioned by nearby literate peoples as inhabiting large areas in the central Eurasian steppes from about the 9th century BC until about the 1st century BC.[5] The Scythian languages belonged to the Eastern branch of the Iranian languages.[6][7]</p><p>Ancient Greek historians spoke of Scythians who lived north of the Black Sea and the Caucasus Mountains. Persians used the term Saka (Old Persian: Saka; New Persian: ????; Greek: S??a?; Armenian: ??????????; Latin: Sacae, Sanskrit: ?? Saka), for approximately the same people who lived further east. Although the ancients did not clearly distinguish the two terms, modern scholars usually use Saka to refer to Iranian-speaking tribes who inhabited the central steppe and the Tarim Basin.[8][9] The Chinese used the term Sai (Chinese: ?; Old Chinese: *s??k), for Sakas who had moved into the Tarim Basin. Assyrian sources speak of Iskuzai or Askuzai south of the Caucasus who were probably Scythians.</p><div class="gradientback"></div></div><div class="content"><p>The relationships between the peoples living in these widely separated regions remains unclear. The term Scythian is used by modern scholars in an archaeological context for finds perceived to display attributes of the Scytho-Siberian culture, usually without implying an ethnic or linguistic connotation.[10] The term Scythic may also be used in a similar way,[11] to describe a special phase that followed the widespread diffusion of mounted nomadism, characterized by the presence of special weapons, horse gear, and animal art in the form of metal plaques.[12] Their westernmost territories during the Iron Age were known to classical Greek sources as Scythia.</p><p>The Scythians were among the earliest peoples to master mounted warfare.[1] In the 8th century BC they possibly raided Zhou China.[13] Soon after they expanded westwards and dislodged the Cimmerians from power on the Pontic Steppe.[14] At their peak, Scythians came to dominate the entire steppe zone,[15][16] stretching from the Carpathian Mountains in the west to central China (Ordos culture) and the south Siberia (Tagar culture) in the east,[10][17] creating what has been referred to as the first Central Asian nomadic empire.[14][18]</p><p>Based in what is modern-day Ukraine, Southern European Russia, and Crimea, the western Scythians were ruled by a wealthy class known as the Royal Scyths. The Scythians established and controlled a vast trade network connecting Greece, Persia, India and China, perhaps contributing to the contemporary flourishing of those civilizations.[19] Settled metalworkers made portable decorative objects for the Scythians. These objects survive mainly in metal, forming a distinctive Scythian art.[20] In the 7th century BC the Scythians crossed the Caucasus and frequently raided the Middle East along with the Cimmerians, playing an important role in the political developments of the region.[14] Around 650–630 BC, Scythians briefly dominated the Medes of the western Iranian Plateau,[21][22] stretching their power all the way to the borders of Egypt.[1] After losing control over Media the Scythians continued intervening in Middle Eastern affairs, playing a leading role in the destruction of the Assyrian Empire in the Sack of Nineveh in 612 BC. The Scythians subsequently engaged in frequent conflicts with the Achaemenid Empire. The western Scythians suffered a major defeat against Macedonia in the 4th century BC,[1] and were subsequently gradually conquered by the Sarmatians, a related Iranian people from Central Asia.[23] The Eastern Scythians of the Asian Steppe (Saka) were attacked by the Yuezhi, Wusun and Xiongnu in the 2nd century BC, prompting many of them to migrate into South Asia,[24][25] where they became known as Indo-Scythians.[26] At some point, perhaps as late as the 3rd century AD after the demise of the Han dynasty and the Xiongnu, Eastern Scythians crossed the Pamir Mountains and settled in the western Tarim Basin, where the Scythian Khotanese and Tumshuqese languages are attested in Brahmi scripture from the 10th and 11th centuries AD.[25][27] In Eastern Europe, by the early Medieval Ages, the Scythians and their closely related Sarmatians were eventually assimilated and absorbed (e.g. Slavicisation) by the Proto-Slavic population of the region.[28][29][30][31]</p><p>Scythians kept herds of horses, cattle, and sheep, lived in tent-covered wagons, and fought with bows and arrows on horseback. They developed a rich culture characterized by opulent tombs, fine metalwork, and a brilliant art style.[7]</p><h2>Contents</h2><h2>Names</h2><p>Sulimirski views the Histories of Herodotus as the most important literary source relating to ancient Scyths.[32] Herodotus provides a depiction that can be related to the results of archaeological research, but apparently knew little of the eastern part of Scythia. He did say that the ancient Persians called all the Scyths S??a? (Sacae, Herodotus 7.64). Their principal tribe, the Royal Scyths, ruled the vast lands occupied by the nation as a whole (Herodotus 4.20), calling themselves S????t?? (Scoloti, Herodotus 4.6). Oswald Szemerényi devotes a thorough discussion to the etymologies of ancient ethnic words for the Scythians in his work Four old Iranian ethnic names: Scythian – Skudra – Sogdian – Saka. In it, the names of Herodotus and the names of his title, except Saka, as well as many other words for Scythian, such as Assyrian Aškuz and Greek Skuthes, descend from *skeud-, an ancient Indo-European root meaning propel, shoot (cf. English shoot).[33] *skud- is the zero-grade; that is, a variant in which the -e- is not present. The restored Scythian name is *Skuda (archer), which among the Pontic or Royal Scythians became *Skula, in which the d has been regularly replaced by an l.</p><p>Saka, on the other hand, Szemerényi relates to an Iranian verbal root, sak-, go, roam, and hypothesizes that the Achaemenids used nomad to refer to the northern tribes, rather than their endonym. The name does appear somewhat further east than the Achaemenid Empire, as the Chinese knew the Asian Scythians as Sai (Chinese character: ?, Old Sinitic *s?k). Whether they adopted the Achaemenid name, or Saka came to be an endonym, it is not clear. The modern region of Sistan in eastern Iran and southern Afghanistan takes its name from the classical Sakastan (land of the Sakas).[34][35][36]</p><p>Sakastan was not the only province of Scythian origin on the eastern margin of the Persian Empire. According to Szemerényi, Sogdiana was named from the Skuda form. Starting from the names of the province given in Old Persian inscriptions, Sugda and Suguda, and the knowledge derived from Middle Sogdian that Old Persian -gd- applied to Sogdian was pronounced as voiced fricatives, -?d-, Szemerényi arrives at *Su?da as an Old Sogdian endonym.[37] Applying sound changes apparent in other Sogdian words and inherent in Indo-European he traces the development of *Su?da from Skuda, archer, as follows: Skuda &gt; *Sukuda by anaptyxis &gt; *Sukuda &gt; *Sukda (syncope) &gt; *Su?da (assimilation).[38]</p><h2>Origins</h2><h3>Literary evidence</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/b/bb/Roman_Empire_125.png/220px-Roman_Empire_125.png" width="220" height="183"><p>


				Map of the Roman Empire under Hadrian (ruled AD 117–138), showing the location of the Scythae Basilaei ("Royal Scyths") along the north shore of the Black Sea


				</p><p>
					The Scythians first appeared in the historical record in the 8th century BC.[39] Herodotus reported three contradictory versions as to the origins of the Scythians, but placed greatest faith in this version:[40]</p><p>There is also another different story, now to be related, in which I am more inclined to put faith than in any other. It is that the wandering Scythians once dwelt in Asia, and there warred with the Massagetae, but with ill success; they therefore quitted their homes, crossed the Araxes, and entered the land of Cimmeria.</p><p>Accounts by Herodotus of Scythian origins has been discounted recently; although his accounts of Scythian raiding activities contemporary to his writings have been deemed more reliable.[41] Moreover, the term Scythian, like Cimmerian, was used to refer to a variety of groups from the Black Sea to southern Siberia and central Asia. They were not a specific people, but rather variety of peoples referred to at variety of times in history, and in several places, none of which was their original homeland.[42] The New Testament includes a single reference to Scythians in Colossians 3:11, immediately after mentioning barbarians, possibly as an extreme example of a barbarian.[43]</p><h3>Archaeology</h3><div class="gradientback"></div></div><div class="content"><p>Modern interpretation of historical, archaeological and anthropological evidence has proposed two broad hypotheses.[44] The first, formerly more espoused by Soviet and then Russian researchers, roughly followed Herodotus' (third) account, holding that the Scythians were an Eastern Iranian group who arrived from Inner Asia, i.e. from the area of Turkestan and western Siberia. [44][45]</p><p>The second hypothesis, according to Ghirshman and others, proposes that the Scythian cultural complex emerged from local groups of the Timber Grave (or Srubna) culture at the Black Sea coast,[44] although this is also associated with the Cimmerians. According to Dolukhanov this proposal is supported by anthropological evidence which has found that Scythian skulls are similar to preceding findings from the Timber Grave culture, and distinct from those of the Central Asian Sacae.[46] Yet, according to Mallory the archaeological evidence is poor, and the Andronovo culture and at least the eastern outliers of the Timber-grave culture may be identified as Indo-Iranian.[44]</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/en/thumb/8/8f/ScythianGroups.png/220px-ScythianGroups.png" width="220" height="163"><p>


				Scythian and related archaeological groups in circum- Pontic region, c. 7th to 3rd centuries BC


				</p><p>
					Others have further stressed that Scythian was a very broad term used by both ancient and modern scholars to describe a whole host of otherwise unrelated peoples sharing only certain similarities in lifestyle (nomadism), cultural practices and language. The 1st millennium BC ushered a period of unprecedented cultural and economic connectivity amongst disparate and wide-ranging communities. A mobile, broadly similar lifestyle would have facilitated contacts amongst disparate ethnic groupings along the expansive Eurasian steppe from the Danube to Manchuria, leading to many cultural similarities. From the viewpoint of Greek and Persian ancient observers, they were all lumped together under the etic category Scythians.</p><h2>Genetics</h2><h3>MtDna and y DNA studies</h3><p>Numerous ancient mitochondrial DNA samples have now been recovered from Bronze and Iron Age communities in the Eurasian steppe and Siberian forest zone, the putative 'ancestors' of the historical Scythians. Compared to Y-DNA, mtDNA is easier to extract and amplify from ancient specimens due to numerous copies of mtDNA per cell.</p><p>The earliest studies could only analyze segments of mtDNA, thus providing only broad correlations of affinity to modern 'West Eurasian' or 'East Eurasian' populations. For example, a 2002 study, the mitochondrial DNA of Saka period male and female skeletal remains from a double inhumation kurgan at the Beral site in Kazakhstan was analysed. The two individuals were found to be not closely related. The HV1 mitochondrial sequence of the male was similar to the Anderson sequence which is most frequent in European populations. On the other hand, the HV1 sequence of the female suggested a greater likelihood of Asian origins.[47]</p><p>More recent studies have been able to type for specific mtDNA lineages. For example, a 2004 study studied the HV1 sequence obtained from a male Scytho-Siberian at the Kizil site in the Altai Republic. It belonged to the N1a maternal lineage, a geographically west Eurasian lineage.[48] Another study by the same team, again from two Scytho-Siberian skeletons found in the Altai Republic, were phenotypically males of mixed Euro-Mongoloid origin. One of the individuals was found to carry the F2a maternal lineage, and the other the D lineage, both of which are characteristic of East Eurasian populations.[49]</p><p>These early studies have been elaborated by an increasing number of studies by Russian scholars. Conclusions which might be drawn thus far, from an mtDNA perspective, are (i) an early, Bronze Age mixture of both west and east Eurasian lineages, with western lineages being found far to the East, but not vice versa; (ii) an apparent reversal by Iron Age times, with increasing presence of East Eurasian lineages in the western steppe; (iii) the possible role of migrations from the sedentary south: the Balkano-Danubian and Iranian regions toward the steppe.[50][51][52]</p><p>Ancient Y-DNA data was finally provided by Keyser et al in 2009. They studied the haplotypes and haplogroups of 26 ancient human specimens from the Krasnoyarsk area in Siberia dated from between the middle of the 2nd millennium BC and the 4th century AD (Scythian and Sarmatian timeframe). Nearly all subjects belong to haplogroup R-M17. The authors suggest that their data shows that between Bronze and Iron Ages the constellation of populations known variously as Scythians, Andronovians, etc. were blue- (or green-) eyed, fair-skinned and light-haired people who might have played a role in the early development of the Tarim Basin civilization. Moreover, this study found that they were genetically more closely related to modern populations of eastern Europe than those of central and southern Asia.[53] The ubiquity and utter dominance of R1a Y-DNA lineage contrasts markedly with the diversity seen in the mtDNA profiles.</p><p>However, this comparison was made on the basis of STRs. Since the 2009 study by Keyser et al, population and geographic specific SNPs have been discovered which can accurately distinguish between European R1a (M458, Z280) and South Asian R1a (Z93)[54] Re-analyzing ancient Scytho-Siberian samples for these more specific subclades will further elucidate if the Eurasian steppe populations have an ultimate Eastern European or EurAsian origin, or perhaps, both. This, in turn, might also depend on which population is studied, i.e. Herodotus' European classical' Scythians, the Central Asian Sakae or un-named nomadic groups in the far east (Altai region) who also bore a 'Scythian cultural tradition.</p><p>In a study conducted in 2014 by VV Ilyinskyon on bone fragments from 10 Alanic burials on the Don River, DNA could be abstracted from a total of 7. 4 of them turned out as belonging to yDNA Haplogroup G2 and 6 of them had mtDNA I.[55]</p><p>In 2015 the Institute of Archaeology in Moscow conducted researches on various Sarmatian-Alan and Saltovo-Mayaki culture Kurgan burials. In these analyses, the two Alan samples from 4th to 6th century AD turned out with yDNAs G2a-P15 and R1a-z94, while from the three Sarmatian samples from 2nd to 3rd century AD two turned out both with yDNA J1-M267 and one with R1a.[56] And the three Saltovo-Mayaki samples from 8th to 9th century AD turned out with yDNAs G, J2a-M410 and R1a-z94 respectively.[57]</p><h3>Autosomal studies</h3><p>In the recent two years new aDNA tests were made on various ancient samples across Eurasia, among them two from Scythian burials. This time the modern techniques of SNPs (in comparison to STRs in earlier tests) were in use. The Iron Age Scythian samples from the Volga region and European Steppes appear neither closely related to Eastern Europeans nor South- and Central Asians. Based on the results on professional as well amateur aDNA calculators both samples appear similar like a link between the Iranic speaking people of South-Central Asia as well people of the northern regions of West Asia on one side and Eastern Europeans on the other. This also fits fine with their geographic origin.[58][59][60]</p><p>Ancient genome-wide analysis on samples from the southern Ural region, East Kazakhstan and Tuva, shows that Iron Age Scythians were a mix of Yamnaya people from the Russian Steppe and East Asian populations, similar to the Han and the Nganasan (Samoyedic people from northern Siberia). The East Asian admixture is pervasive across diverse present-day people from Siberia and Central Asia. The Eneolithic Yamnaya and the other Bronze Age kurgan groups from Pontic–Caspian steppe had a brunet pigmentation. Contemporary populations linked to western Iron Age Scythians can be found among diverse ethnic groups in the Caucasus, Russia and Central Asia (spread across many Iranian and other Indo-European speaking groups), whereas populations with genetic similarities to eastern Scythian groups are found almost exclusively among Turkic language speakers, particularly from the Kipchak branch of Turkic languages. These results are consistent with gene flow across the steppe territory between Europe and East Asia.[58][61][62]</p><div class="gradientback"></div></div><div class="content"><h2>History</h2><h3>Classical Antiquity (600 BC to AD 300)</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/d/d5/Avar%C3%A1rok.JPG/180px-Avar%C3%A1rok.JPG" width="180" height="240"><p>


				Scythian defence line 339 BC reconstruction in Polgár, Hungary


				</p><p>
					Herodotus provides the first detailed description of the Scythians. He classes the Cimmerians as a distinct autochthonous tribe, expelled by the Scythians from the northern Black Sea coast (Hist. 4.11–12). Herodotus also states (4.6) that the Scythians consisted of the Auchatae, Catiaroi, Traspians, and Paralatae or Royal Scythians.</p><p>For Herodotus, the Scythians were outlandish barbarians living north of the Black Sea in what are now Moldova, Ukraine and Crimea.</p><p>In 512 BC, when King Darius the Great of Persia attacked the Scythians, he allegedly penetrated into their land after crossing the Danube. Herodotus relates that the nomadic Scythians frustrated the Persian army by letting it march through the entire country without an engagement.[63] According to Herodotus, Darius in this manner came as far as the Volga River.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/f/f2/KulObaTreasure.jpg/220px-KulObaTreasure.jpg" width="220" height="204"><p>


				Treasure of Kul-Oba, near Kerch


				</p><p>
					During the 5th to 3rd centuries BC, the Scythians evidently prospered. When Herodotus wrote his Histories in the 5th century BC, Greeks distinguished Scythia Minor, in present-day Romania and Bulgaria, from a Greater Scythia that extended eastwards for a 20-day ride from the Danube River, across the steppes of today's East Ukraine to the lower Don basin. The Don, then known as Tanaïs, has served as a major trading route ever since. The Scythians apparently obtained their wealth from their control over the slave trade from the north to Greece through the Greek Black Sea colonial ports of Olbia, Chersonesos, Cimmerian Bosporus, and Gorgippia. They also grew grain, and shipped wheat, flocks, and cheese to Greece.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/0/03/Scythian_Warriors.jpg/320px-Scythian_Warriors.jpg" width="320" height="123"><p>


				Scythian warriors, drawn after figures on an electrum cup from the Kul-Oba kurgan burial near Kerch, Crimea. The warrior on the right strings his bow, bracing it behind his knee; note the typical pointed hood, long jacket with fur or fleece trimming at the edges, decorated trousers, and short boots tied at the ankle. Scythians apparently wore their hair long and loose, and all adult men apparently bearded. The gorytos appears clearly on the left hip of the bare-headed spearman. The shield of the central figure may be made of plain leather over a wooden or wicker base. (Hermitage Museum, St Petersburg)


				</p><p>
					Strabo (c. 63 BC – AD 24) reports that King Ateas united under his power the Scythian tribes living between the Maeotian marshes and the Danube. His westward expansion brought him into conflict with Philip II of Macedon (reigned 359 to 336 BC), who took military action against the Scythians in 339 BC. Ateas died in battle, and his empire disintegrated. In the aftermath of this defeat, the Celts seem to have displaced the Scythians from the Balkans; while in south Russia, a kindred tribe, the Sarmatians, gradually overwhelmed them. In 329 BC Philip's son, Alexander the Great, came into conflict with the Scythians at the Battle of Jaxartes. A Scythian army sought to take revenge against the Macedonians for the death of Ateas, as they pushed the borders of their empire north and east, and to take advantage of a revolt by the local Sogdian satrap. However, the Scythian army was defeated by Alexander at the Battle of Jaxartes. Alexander did not intend to subdue the nomads: he wanted to go to the south, where a far more serious crisis demanded his attention. He could do so now without loss of face; and in order to make the outcome acceptable to the Saccae, he released the Scythian prisoners of war without ransom in order to broker a peace agreement. This policy was successful, and the Scythians no longer harassed Alexander's empire. By the time of Strabo's account (the first decades AD), the Crimean Scythians had created a new kingdom extending from the lower Dnieper to the Crimea. The kings Skilurus and Palakus waged wars with Mithridates the Great (reigned 120–63 BC) for control of the Crimean littoral, including Chersonesos Taurica and the Cimmerian Bosporus. Their capital city, Scythian Neapolis, stood on the outskirts of modern Simferopol. The Goths destroyed it later, in the mid-3rd century AD.</p><h3>Sakas of the Eastern Steppe</h3><p> Main article: Saka</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/en/thumb/0/06/ScythianC14AsiaEuropeFig6SketchEn_3dGraph.gif/260px-ScythianC14AsiaEuropeFig6SketchEn_3dGraph.gif" width="260" height="295"><div class="gradientback"></div></div><div class="content"><p>


				Timeline of Scythian kurgans in Asia and Europe.


				</p><p>
					Modern scholars usually use the term Saka to refer to Iranian-speaking tribes who inhabited the Eastern Steppe and the Tarim Basin.[8][9] Ancient Persian inscriptions also used Saka to refer to western Scythians to the north of the Black Sea – the Saka paradraya or Saka beyond the sea.[64][65]</p><p>In the Achaemenid-era Old Persian inscriptions found at Persepolis, dated to the reign of Darius I (r. 522-486 BC), the Saka are said to have lived just beyond the borders of Sogdiana.[66][67] The term Saka para Sugdam or Saka beyond Sugda (Sogdiana) was used by Darius to describe the people who formed the limits of his empire at the opposite end to Kush (the Ethiopians) in the west, i.e. at the eastern edge of his empire.[64][68] An inscription dated to the reign of Xerxes I (r. 486-465 BC) has them coupled with the Dahae people of Central Asia.[66] Two Saka tribes named in the Behistun Inscription, Saka tigraxauda (Saka with pointy hats/caps) and the Saka haumavarga (haoma-drinking saka), may be located to the east of the Caspian Sea.[64][69][70] Some argued that the Saka haumavarga may be the Saka para Sugdam, therefore Saka haumavarga would be located further east than the Saka tigraxauda. Some argued for the Pamirs or Xinjiang as their location, although Jaxartes is considered to be their more likely location given that the name says beyond Sogdiana rather than Bactria.[64]</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/e/ed/Behistun.Inscript.Skunkha.jpg/150px-Behistun.Inscript.Skunkha.jpg" width="150" height="320"><p>


				Skunkha, king of the Saka tigraxauda ("pointed-cap-wearing Sakae"). Detail of Behistun Inscription.


				</p><p>
					Cyrus the Great of the Persian Achaemenid Empire fought the Saka whose women were said to fight alongside their men.[71] According to Herodotus, Cyrus the Great also confronted the Massagetae, a people thought to be related to the Saka,[72] while campaigning to the east of the Caspian Sea and was killed in the battle in 530 BC.[73] Darius the Great also waged wars against the eastern Sakas, who fought him with three armies led by three kings according to Polyaenus.[74] In 520–519 BC, Darius I defeated the Saka tigraxauda tribe and captured their king Skunkha (depicted as wearing a pointed hat in the Behistun inscription).[8] The territories of Saka were absorbed into the Achaemenid Empire as part of Chorasmia that included much of Amu Darya (Oxus) and Syr Darya (Jaxartes),[75] and the Saka then supplied the Persian army with large number of mounted bowmen in the Achaemenid wars.[65]</p><p>In the Chinese Book of Han, the valleys of the Ili River and Chu River were called the land of the Sai, i.e. the Saka. The exact date of their arrival in this region of Central Asia is unclear, perhaps it was just before the reign of Darius I.[76] Around 30 Saka tombs in the form of kurgans (burial mounds) have also been found in the Tian Shan area dated to between 550–250 BC. Indications of Saka presence have also been found in the Tarim Basin region, possibly as early as the 7th century BC.[77] Some modern scholars thought that the sacking of the Western Zhou capital Haojing in 770 BC might have been connected to a Scythian raid from the Altai before their westward expansion.[78]</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/5/56/Issyk_Golden_Cataphract_Warrior.jpg/200px-Issyk_Golden_Cataphract_Warrior.jpg" width="200" height="531"><p>


				A cataphract-style parade armour of a Saka royal, also known as "The Golden Warrior", from the Issyk kurgan, an historic burial near ex-capital city of Almaty, Kazakhstan


				</p><p>
					However, as a consequence of the fight for supremacy between the Xiongnu and other groups, the Saka were pushed towards Bactria, and later on southward to northwest India and eastward to the oasis city-states of western Tarim Basin region of Xinjiang in Northwest China.[79][80]</p><p>Accounts of the migration of the Sakas are given in Chinese texts such as Sima Qian's Shiji. The Indo-European Yuezhi, who originally lived between Dunhuang and the Qilian Mountains of Gansu, China, were assaulted and forced to flee from the Hexi Corridor of Gansu by the Mongolic forces of the Xiongnu ruler Modu Chanyu, who conquered the area in 177-176 BC.[81][82][83] In turn the Yuezhi were responsible for attacking and pushing the Sai (i.e. Saka) southwest into Sogdiana, where in the mid 2nd century BC the latter crossed the Syr Darya into Hellenistic Greco-Bactrian Kingdom, but also into the Fergana Valley where they settled in Dayuan.[84][85] The ancient Greco-Roman geographer Strabo claims that the four tribes of the Asii, who took down the Bactrians in the Greek and Roman account, came from land north of Syr Darya where the Ili and Chu valleys are located.[76] The Saka then migrated down to the northwest area of the Indian subcontinent where they became known as Indo-Scythians, as well as eastward to the settlements of the Tarim Basin in present-day China such as Khotan and Tumshaq.</p><h3>Khotan and kingdoms of the Tarim Basin</h3><div class="gradientback"></div></div><div class="content"><p> Main article: Kingdom of Khotan</p><p>The Saka migrated from Bactria where they eventually settled in some of the oasis city-states of the Tarim Basin that at times fell under the influence of the Chinese Han dynasty (202 BC - 220 AD).[76] These states in the Tarim Basin include Khotan, Kashgar, Shache (??, probably named after the Saka inhabitants), Yanqi (??, Karasahr) and Qiuci (??, Kucha).[86][87]</p><p>The official administrative language of Khotan and nearby Shanshan was Gandhari Prakrit in the Kharosthi script.[88] There are however indications that Sakas were linked to the ruling elite – 3rd-century documents from Shanshan record the title of the king of Khotan as hinajha (i.e. generalissimo), an Iranian-based word equivalent to the Sanskrit title senapati, yet nearly identical to the Khotanese Saka hinaysa attested in later documents.[88] The regnal periods were also given in Khotanese as k?u?a, implies an established connection between the Iranian inhabitants and the royal power, according to the late Professor of Iranian Studies Ronald E. Emmerick (d. 2001).[88] He contended that Khotanese-Saka-language royal rescripts of Khotan dated to the 10th century makes it likely that the ruler of Khotan was a speaker of Iranian.[88] Furthermore, he argued that the oldest form of the name of Khotan, hvatana, may be linked semantically with the name Saka.[89]</p><p>During China's Tang dynasty (618-907 AD), the region once again came under Chinese suzerainty with the campaigns of conquest by Emperor Taizong of Tang (r. 626-649).[90] From the late 8th to 9th centuries, the region changed hands between the Chinese Tang Empire and the rival Tibetan Empire.[91][92] The kingdom existed until it was conquered by the Muslim Turkic peoples of the Kara-Khanid Khanate, which led to both the Turkification and Islamization of the region.[93][94]</p><h3>Indo-Scythians</h3><p> Main article: Indo-Scythians</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/1/1f/AzesIITriratna.jpg/260px-AzesIITriratna.jpg" width="260" height="128"><p>


				Silver coin of Indo-Scythian King Azes II (ruled c. 35–12 BC). Buddhist triratna symbol in the left field on the reverse.


				</p><p>
					After the Saka migrated into northwest area of the Indian subcontinent, the region became known as land of the Saka (i.e. Drangiana, of modern Afghanistan and Pakistan).[66] This is attested in a contemporary Kharosthi inscription found on the Mathura lion capital belonging to the Saka kingdom of the Indo-Scythians (200 BC - 400 AD) in northern India,[95] roughly the same time the Chinese record that the Saka had invaded and settled the country of Jibin ?? (i.e. Kashmir, of modern-day India and Pakistan).[96] In the Persian language of contemporary Iran the territory of Drangiana was called Sakastana, in Armenian as Sakastan, with similar equivalents in Pahlavi, Greek, Sogdian, Syriac, Arabic, and the Middle Persian tongue used in Turfan, Xinjiang, China.[95]</p><p>For more information on Indo-Scythians and other central and southern Asian nomadic groups, see Indo-Scythians.</p><h3>Late Antiquity (AD 300 to 600)</h3><p>In Late Antiquity, the notion of a Scythian ethnicity grew more vague and outsiders might dub any people inhabiting the Pontic-Caspian steppe as Scythians, regardless of their language. Thus, Priscus, a Byzantine emissary to Attila, repeatedly referred to the latter's followers as Scythians. But Eunapius, Claudius Cladianus and Olympiodorus usually mean Goths when they write Scythians.[citation needed]</p><p>The Goths had displaced the Sarmatians in the 2nd century from most areas near the Roman frontier, and by early medieval times, the Early Slavs (Proto-Slavs) marginalized Eastern Iranian dialects in Eastern Europe as they assimilated and absorbed the Iranian ethnic groups in the region.[28][29][30][31] The Turkic migration assimilated the Saka linguistically in Central Asia.[citation needed]</p><h2>Archaeology</h2><p>Archaeological remains of the Scythians include kurgan tombs (ranging from simple exemplars to elaborate Royal kurgans containing the Scythian triad of weapons, horse-harness, and Scythian-style wild-animal art), gold, silk, and animal sacrifices, in places also with suspected human sacrifices.[97][98] Mummification techniques and permafrost have aided in the relative preservation of some remains. Scythian archaeology also examines the remains of North Pontic Scythian cities and fortifications.[99]</p><p>The spectacular Scythian grave-goods from Arzhan, and others in Tuva have been dated from about 900 BC onward. One grave find on the lower Volga gave a similar date, and one of the Steblev graves from the East European end of the Scythian area was dated to the late 8th century BC.[100]</p><p>Archaeologists can distinguish three periods of ancient Scythian archaeological remains:</p><p>From the 8th to the 2nd centuries BC, archaeology records a split into two distinct settlement areas: the older in the Sayan-Altai area in Central Asia, and the younger in the North Pontic area in Eastern Europe.[101]</p><h3>Kurgans</h3><p> Main article: Kurgan</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/en/thumb/e/e0/Throne_arm.jpg/220px-Throne_arm.jpg" width="220" height="175"><p>


				An arm from the throne of a Scythian king, 7th century BC. Found at the Kerkemess kurgan, Krasnodar Krai in 1905. On exhibit at the Hermitage Museum.


				</p><p>
					These large burial mounds (some over 20 metres high) provide the most valuable archaeological remains associated with the Scythians. They dot the Eurasian steppe belt, from Mongolia to Balkans, through Ukrainian and south Russian steppes, extending in great chains for many kilometers along ridges and watersheds. From them archaeologists have learned much about Scythian life and art.[102] Some Scythian tombs reveal traces of Greek, Chinese, and Indian craftsmanship, suggesting a process of Hellenization, Sinification, and other local influences among the Scythians.[103]</p><p>The Ukrainian term for such a burial mound, kurhán (Ukrainian: ??????) as well as the Russian term kurgán, derives from a Turkic word for castle.[104]</p><p>Some Scythian-Sarmatian cultures may have given rise to Greek stories of Amazons. Graves of armed females have been found in southern Ukraine and Russia. David Anthony notes, About 20% of Scythian-Sarmatian warrior graves on the lower Don and lower Volga contained females dressed for battle as if they were men, a style that may have inspired the Greek tales about the Amazons.[105]</p><div class="gradientback"></div></div><div class="content"><p>Excavation at kurgan Sengileevskoe-2 found gold bowls with coatings indicating a strong opium beverage was used while cannabis was burning nearby. The gold bowls depicted scenes showing clothing and weapons.[106]</p><h3>Pazyryk culture</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/2/2f/PazyrikHorseman.JPG/220px-PazyrikHorseman.JPG" width="220" height="293"><p>


				A Pazyryk horseman in a felt painting from a burial around 300 BC. The Pazyryks appear to be closely related to the Scythians.[107]



				</p><p>
					 Main article: Pazyryk culture</p><p>Some of the first Bronze Age Scythian burials documented by modern archaeologists include the kurgans at Pazyryk in the Ulagan (Red) district of the Altai Republic, south of Novosibirsk in the Altai Mountains of southern Siberia (near Mongolia). Archaeologists have extrapolated the Pazyryk culture from these finds: five large burial mounds and several smaller ones between 1925 and 1949, one opened in 1947 by Russian archaeologist Sergei Rudenko. The burial mounds concealed chambers of larch-logs covered over with large cairns of boulders and stones.[108]</p><p>The Pazyryk culture flourished between the 7th and 3rd century BC in the area associated with the Sacae.</p><p>Ordinary Pazyryk graves contain only common utensils, but in one, among other treasures, archaeologists found the famous Pazyryk Carpet, the oldest surviving wool-pile oriental rug. Another striking find, a 3-metre-high four-wheel funerary chariot, survived well-preserved from the 5th to 4th century BC.[109]</p><p>Although some scholars sought to connect the Pazyryk nomads with indigenous ethnic groups of the Altaic, Rudenko summed up the cultural context in the following observation:[110]</p><p>All that is known to us at the present time about the culture of the population of the High Altai, who have left behind them the large cairns, permits us to refer them to the Scythian period, and the Pazyryk group in particular to the 5th century BC. This is supported by radiocarbon dating.</p><h3>Bilsk excavations</h3><p>Recent digs[citation needed] (see:Gelonus) in a village Bilsk near Poltava (Ukraine) have uncovered a vast city, with the largest area of any city in the world at that time (Bilsk settlement). It has been tentatively identified by a team of archaeologists led by Boris Shramko as the site of Gelonus, the purported capital of Scythia. The city's commanding ramparts and vast area of 40 square kilometers exceed even the outlandish size reported by Herodotus. Its location at the northern edge of the Ukrainian steppe would have allowed strategic control of the north-south trade-route. Judging by the finds dated to the 5th and 4th centuries BC, craft workshops and Greek pottery abounded.</p><h3>Tillia Tepe treasure</h3><p> Main article: Tillia Tepe</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/1/13/MenWithDragons.jpg/220px-MenWithDragons.jpg" width="220" height="167"><p>


				"Kings with dragons", Tillia Tepe



				<br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/9/9e/TilliaTepeCrown2.jpg/220px-TilliaTepeCrown2.jpg" width="220" height="187"><br>


				Royal crown, Tillia Tepe


				</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/9/9e/TilliaTepeCrown2.jpg/220px-TilliaTepeCrown2.jpg" width="220" height="187"><br><p>
					A site found in 1968 in Tillia Tepe (literally the golden hill) in northern Afghanistan (former Bactria) near Shebergan consisted of the graves of five women and one man with extremely rich jewelry, dated to around the 1st century BC, and probably related to that of Scythian tribes normally living slightly to the north. Altogether the graves yielded several thousands of pieces of fine jewelry, usually made from combinations of gold, turquoise and lapis-lazuli.</p><p>A high degree of cultural syncretism pervades the findings, however. Hellenistic cultural and artistic influences appear in many of the forms and human depictions (from amorini to rings with the depiction of Athena and her name inscribed in Greek), attributable to the existence of the Seleucid empire and Greco-Bactrian kingdom in the same area until around 140 BC, and the continued existence of the Indo-Greek kingdom in the northwestern Indian sub-continent until the beginning of our era. This testifies to the richness of cultural influences in the area of Bactria at that time.</p><h2>Culture and society</h2><h3>Tribal divisions</h3><p>Scythians lived in confederated tribes, a political form of voluntary association which regulated pastures and organized a common defence against encroaching neighbors for the pastoral tribes of mostly equestrian herdsmen. While the productivity of domesticated animal-breeding greatly exceeded that of the settled agricultural societies, the pastoral economy also needed supplemental agricultural produce, and stable nomadic confederations developed either symbiotic or forced alliances with sedentary peoples – in exchange for animal produce and military protection.</p><p>Herodotus relates that three main tribes of the Scythians descended from three brothers, Lipoxais, Arpoxais, and Colaxais:[111]</p><div class="gradientback"></div></div><div class="content"><p>In their reign a plough, a yoke, an axe, and a bowl, all made of gold, fell from heaven upon the Scythian territory. The oldest of the brothers wished to take them away, but as he drew near the gold began to burn. The second brother approached them, but with the like result. The third and youngest then approached, upon which the fire went out, and he was enabled to carry away the golden gifts. The two eldest then made the youngest king, and henceforth the golden gifts were watched by the king with the greatest care, and annually approached with magnificent sacrifices.[112]</p><p>Herodotus also mentions a royal tribe or clan, an elite which dominated the other Scythians:</p><p>Then on the other side of the Gerros we have those parts which are called the Royal lands and those Scythians who are the bravest and most numerous and who esteem the other Scythians their slaves.[113]</p><p>The elder brothers then, acknowledging the significance of this thing, delivered the whole of the kingly power to the youngest. From Lixopais, they say, are descended those Scythians who are called the race of the Auchatai; from the middle brother Arpoxais those who are called Catiaroi and Traspians, and from the youngest of them the Royal tribe, who are called Paralatai: and the whole together are called, they say, Scolotoi, after the name of their king; but the Hellenes gave them the name of Scythians. Thus the Scythians say they were produced; and from the time of their origin, that is to say from the first king Targitaos, to the passing over of Dareios [the Persian Emperor Darius I] against them [512 BC], they say that there is a period of a thousand years and no more.[114]</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/b/b4/ScytianBowl.JPG/220px-ScytianBowl.JPG" width="220" height="147"><p>


				Scythian bowl, 5th century BC found at Castelu, Romania. In display at Constanta Museum of National History.


				</p><p>
					The rich burials of Scythian kings in tumuli (often known by the Turkic name kurgan) is evidence for the existence of a powerful elite. While an elite clan is named in some classical sources[which?] as the Royal Dahae, the Dahae proper are generally regarded as an extinct Indo-European people, who occupied what is now Turkmenistan, and were distinct from the Scythians.</p><p>Although scholars have traditionally treated the three tribes as geographically distinct, Georges Dumézil interpreted the divine gifts as the symbols of social occupations, illustrating his trifunctional vision of early Indo-European societies: the plough and yoke symbolised the farmers, the axe – the warriors, the bowl – the priests.[115] According to Dumézil, the fruitless attempts of Arpoxais and Lipoxais, in contrast to the success of Colaxais, may explain why the highest strata was not that of farmers or magicians, but rather that of warriors.[116]</p><h3>Warfare</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/0/08/TillyaTepeSheath2.jpg/260px-TillyaTepeSheath2.jpg" width="260" height="97"><p>


				Sheath for knives


				</p><p>
					A warlike people, the Scythians were particularly known for their equestrian skills, and their early use of composite bows shot from horseback. With great mobility, the Scythians could absorb the attacks of more cumbersome footsoldiers and cavalry, just retreating into the steppes. Such tactics wore down their enemies, making them easier to defeat. The Scythians were notoriously aggressive warriors. They fought to live and lived to fight and drank the blood of their enemies and used the scalps as napkins.[107][117] Ruled by small numbers of closely allied élites, Scythians had a reputation for their archers, and many gained employment as mercenaries. Scythian élites had kurgan tombs: high barrows heaped over chamber-tombs of larch-wood – a deciduous conifer that may have had special significance as a tree of life-renewal, for it stands bare in winter. Burials at Pazyryk in the Altay Mountains have included some spectacularly preserved Scythians of the Pazyryk culture – including the Ice Maiden of the 5th century BC.</p><p>The Ziwiye hoard, a treasure of gold and silver metalwork and ivory found near the town of Sakiz south of Lake Urmia and dated to between 680 and 625 BC, includes objects with Scythian animal style features. One silver dish from this find bears some inscriptions, as yet undeciphered and so possibly representing a form of Scythian writing.</p><p>Scythians also had a reputation for the use of barbed and poisoned arrows of several types, for a nomadic life centered on horses – fed from horse-blood according to Herodotus – and for skill in guerrilla warfare.</p><h3>Clothing</h3><p>According to Herodotus, Scythian costume consisted of padded and quilted leather trousers tucked into boots, and open tunics. They rode with no stirrups or saddles, just saddle-cloths. Herodotus reports that Scythians used cannabis, both to weave their clothing and to cleanse themselves in its smoke (Hist. 4.73–75); archaeology has confirmed the use of cannabis in funeral rituals.</p><p>Scythian women dressed in much the same fashion as men. A Pazyryk burial, discovered in the 1990s, contained the skeletons of a man and a woman, each with weapons, arrowheads, and an axe. Herodotus mentioned that Sakas had high caps and&nbsp;... wore trousers. Clothing was sewn from plain-weave wool, hemp cloth, silk fabrics, felt, leather and hides.</p><p>Pazyryk findings give the most number of almost fully preserved garments and clothing worn by the Scythian/Saka peoples. Ancient Persian bas-relief – Apadana or Behistun inscription, ancient Greek pottery, archaeological findings from Ukraine, Russia, Kazakhstan, China et al. give visual representations of these garments.</p><p>Herodotus says Sakas had high caps tapering to a point and stiffly upright. Asian Saka headgear is clearly visible on the Persepolis Apadana staircase bas-relief – high pointed hat with flaps over ears and the nape of the neck.[118] From China to the Danube delta, men seemed to have worn a variety of soft headgear – either conical like the one described by Herodotus, or rounder, more like a Phrygian cap.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/e/e5/6._Pectorale_burial_mound_Arzhan_%28VIII._-_VII._B._C.%29_Tuva.JPG/220px-6._Pectorale_burial_mound_Arzhan_%28VIII._-_VII._B._C.%29_Tuva.JPG" width="220" height="165"><p>


				Pectoral from burial mound in Arzhan


				</p><div class="gradientback"></div></div><div class="content"><p>
					Women wore a variety of different headdresses, some conical in shape others more like flattened cylinders, also adorned with metal (golden) plaques.</p><p>Based on the Pazyryk findings (can be seen also in the south Siberian, Uralic and Kazakhstan rock drawings) some caps were topped with zoomorphic wooden sculptures firmly attached to a cap and forming an integral part of the headgear, similar to the surviving nomad helmets from northern China. Men and warrior women wore tunics, often embroidered, adorned with felt applique work, or metal (golden) plaques.</p><p>Persepolis Apadana again serves a good starting point to observe tunics of the Sakas. They appear to be a sewn, long sleeve garment that extended to the knees and belted with a belt while owner's weapons were fastened to the belt (sword or dagger, gorytos, battleax, whetstone etc.). Based on numerous archeological findings in Ukraine, southern Russian and Kazakhstan men and warrior women wore long sleeve tunics that were always belted, often with richly ornamented belts. The Kazakhstan Saka (e.g. Issyk Golden Man/Maiden) wore shorter tunics and more close fitting tunics than the Pontic steppe Scythians. Some Pazyryk culture Saka wore short belted tunic with a lapel on a right side, upright collar, 'puffed' sleeves narrowing at a wrist and bound in narrow cuffs of a color different from the rest of the tunic.</p><p>Scythian women wore long, loose robes, ornamented with metal plaques (gold). Women wore shawls, often richly decorated with metal (golden) plaques.</p><p>Men and women wore coats, e.g. Pazyryk Saka had many varieties, from fur to felt. They could have worn a riding coat that later was known as a Median robe or Kantus. Long sleeved, and open, it seems that on the Persepolis Apadana Skudrian delegation is perhaps shown wearing such coat. The Pazyryk felt tapestry shows a rider wearing a billowing cloak.</p><p>Men and women wore long trousers, often adorned with metal plaques and often embroidered or adorned with felt appliqués; trousers could have been wider or tight fitting depending on the area. Materials used depended on the wealth, climate and necessity.</p><p>Men and women warriors wore variations of long and shorter boots, wool-leather-felt gaiter-boots and moccasin-like shoes. They were either of a laced or simple slip on type. Women wore also soft shoes with metal (gold) plaques.</p><p>Men and women wore belts. Warrior belts were made of leather, often with gold or other metal adornments and had many attached leather thongs for fastening of the owner's gorytos, sword, whet stone, whip etc. Belts were fastened with metal or horn belt-hooks, leather thongs and metal (often golden) or horn belt-plates.</p><h3>Art</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/1/11/HorseAttackedByTigerOrdos4th-1stBCE.JPG/220px-HorseAttackedByTigerOrdos4th-1stBCE.JPG" width="220" height="151"><p>


				Bronze Ordos culture plaque, 4th century BC; a horse attacked by a tiger



				</p><p>
					 Main article: Scythian art</p><p>Scythian contacts with craftsmen in Greek colonies along the northern shores of the Black Sea resulted in the famous Scythian gold adornments that feature among the most glamorous artifacts of world museums. Ethnographically extremely useful as well, the gold depicts Scythian men as bearded, long-haired Caucasoids. Greco-Scythian works depicting Scythians within a much more Hellenic style date from a later period, when Scythians had already adopted elements of Greek culture, and the most elaborate royal pieces are assumed to have been made by Greek goldsmiths for this lucrative market. Other metalwork pieces from across the whole Eurasian steppe use an animal style, showing animals, often in combat and often with their legs folded beneath them. This origins of this style remain debated, but it probably both received and gave influences in the art of the neighbouring settled peoples, and acted as a fast route for transmission of motifs across the width of Eurasia.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/d/d3/Placca_pantera%2C_da_regione_di_krasnodar%2C_kurgan_chertomlyk%2C_oro_a_sbalzo_e_cesellato%2C_fine_VII_sec_ac..JPG/280px-Placca_pantera%2C_da_regione_di_krasnodar%2C_kurgan_chertomlyk%2C_oro_a_sbalzo_e_cesellato%2C_fine_VII_sec_ac..JPG" width="280" height="134"><p>


				Gold plaque with panther, probably for a shield or breast-plate, 13 in/33 cm long, end 7th-century BC


				</p><p>
					Surviving Scythian objects are mostly small portable pieces of metalwork: elaborate personal jewelry, weapon-ornaments and horse-trappings. But finds from sites with permafrost show rich and brightly coloured textiles, leatherwork and woodwork, not to mention tattooing. The western royal pieces executed Central-Asian animal motifs with Greek realism: winged gryphons attacking horses, battling stags, deer, and eagles, combined with everyday motifs like milking ewes.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/5/57/ChineseJadePlaques.JPG/220px-ChineseJadePlaques.JPG" width="220" height="214"><p>


				Chinese jade and steatite plaques, in the Scythian-style animal art of the steppes. 4th to 3rd centuries BC. British Museum.


				</p><p>
					In 2000, the touring exhibition 'Scythian Gold' introduced the North American public to the objects made for Scythian nomads by Greek craftsmen north of the Black Sea, and buried with their Scythian owners under burial mounds on the flat plains of present-day Ukraine. In 2001, the discovery of an undisturbed royal Scythian burial-barrow illustrated Scythian animal-style gold that lacks the direct influence of Greek styles. Forty-four pounds of gold weighed down the royal couple in this burial, discovered near Kyzyl, capital of the Siberian republic of Tuva.</p><p>Ancient influences from Central Asia became identifiable in China following contacts of metropolitan China with nomadic western and northwestern border territories from the 8th century BC. The Chinese adopted the Scythian-style animal art of the steppes (descriptions of animals locked in combat), particularly the rectangular belt-plaques made of gold or bronze, and created their own versions in jade and steatite.[119]</p><div class="gradientback"></div></div><div class="content"><p>Following their expulsion by the Yuezhi, some Scythians may also have migrated to the area of Yunnan in southern China. Scythian warriors could also have served as mercenaries for the various kingdoms of ancient China. Excavations of the prehistoric art of the Dian civilization of Yunnan have revealed hunting scenes of Caucasoid horsemen in Central Asian clothing.[120]</p><p>Scythian influences have been identified as far as Korea and Japan. Various Korean artifacts, such as the royal crowns of the kingdom of Silla, are said to be of Scythian design.[121] Similar crowns, brought through contacts with the continent, can also be found in Kofun era Japan.[122]</p><h3>Religion</h3><p> Main article: Scythian religion</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/2/2d/Alba_Iulia_National_Museum_of_the_Union_2011_-_Offering_pot_from_a_Scythian_Grave.JPG/170px-Alba_Iulia_National_Museum_of_the_Union_2011_-_Offering_pot_from_a_Scythian_Grave.JPG" width="170" height="227"><p>


				Offering pot from a Scythian grave from Alba Iulia, Romania, 6th century BC. In display at National Museum of the Union, Alba Iulia


				</p><p>
					The religious beliefs of the Scythians was a type of Pre-Zoroastrian Iranian religion and differed from the post-Zoroastrian Iranian thoughts.[123] Foremost in the Scythian pantheon stood Tabiti, who was later replaced by Atar, the fire-pantheon of Iranian tribes, and Agni, the fire deity of Indo-Aryans.[123] The Scythian belief was a more archaic stage than the Zoroastrian and Hindu systems. The use of cannabis to induce trance and divination by soothsayers was a characteristic of the Scythian belief system.[123]</p><h2>Language</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/0/0d/Khotanese_animal_zodiac_BLI6_OR11252_1R2_1.jpg/190px-Khotanese_animal_zodiac_BLI6_OR11252_1R2_1.jpg" width="190" height="244"><p>


				A document from Khotan written in Khotanese Saka, part of the Eastern Iranian branch of the Indo-European languages, listing the animals of the Chinese zodiac in the cycle of predictions for people born in that year; ink on paper, early 9th century



				</p><p>
					 Main article: Scythian languages</p><p>The Scythian group of languages in the early period are essentially unattested, and their internal divergence is difficult to judge. They belonged to the Eastern Iranian family of languages. Whether all the peoples included in the Scytho-Siberian archaeological cult<br>
							

											 
										

							</p><br><h1 lang="en">Greece</h1><p> From Wikipedia, the free encyclopedia</p><p>Greece (Greek: ????da, &nbsp;Elláda [e'laða]), officially the Hellenic Republic (Greek: ???????? ??µ???at?a, Ellinikí Dimokratía [elini'ci ðimokra'ti.a]), historically also known as Hellas (Ancient&nbsp;Greek: ?????, Hellás [he'las], modern pronunciation Ellás),[8][9][10][11] is a country in southeastern Europe, with a population of approximately 11 million as of 2015. Athens is the nation's capital and largest city, followed by Thessaloniki.</p><p>Greece is strategically located at the crossroads of Europe, Asia, and Africa. Situated on the southern tip of the Balkan peninsula, it shares land borders with Albania to the northwest, the Republic of Macedonia and Bulgaria to the north, and Turkey to the northeast. Greece consists of nine geographic regions: Macedonia, Central Greece, the Peloponnese, Thessaly, Epirus, the Aegean Islands (including the Dodecanese and Cyclades), Thrace, Crete, and the Ionian Islands. The Aegean Sea lies to the east of the mainland, the Ionian Sea to the west, the Cretan Sea and the Mediterranean Sea to the south. Greece has the longest coastline on the Mediterranean Basin and the 11th longest coastline in the world at 13,676&nbsp;km (8,498&nbsp;mi) in length, featuring a large number of islands, of which 227 are inhabited. Eighty percent of Greece is mountainous, with Mount Olympus being the highest peak at 2,918 metres (9,573&nbsp;ft).</p><p>Greece is considered the cradle of Western civilization, being the birthplace of democracy, Western philosophy, the Olympic Games, Western literature, historiography, political science, major scientific and mathematical principles, and Western drama.[12] From the eighth century BC, the Greeks were organised into various independent city-states, known as polis, which spanned the entire Mediterranean region and the Black Sea. Philip of Macedon united most of the Greek mainland in the fourth century BC, with his son Alexander the Great rapidly conquering much of the ancient world, spreading Greek culture and science from the eastern Mediterranean to the Indus River. Greece was annexed by Rome in the second century BC, becoming an integral part of the Roman Empire and its successor, the Byzantine Empire, wherein the Greek language and culture were dominant. The Greek Orthodox Church also shaped modern Greek identity and transmitted Greek traditions to the wider Orthodox World.[13] Falling under Ottoman dominion in the mid-15th century, the modern nation state of Greece emerged in 1830 following a war of independence. Greece's rich historical legacy is reflected by its 18 UNESCO World Heritage Sites, among the most in Europe and the world.[14]</p><p>Greece is a democratic and developed country with an advanced high-income economy, a high quality of life, and a very high standard of living. A founding member of the United Nations, Greece was the tenth member to join the European Communities (precursor to the European Union) and has been part of the Eurozone since 2001. It is also a member of numerous other international institutions, including the Council of Europe, the North Atlantic Treaty Organization (NATO), the Organisation for Economic Co-operation and Development (OECD), the World Trade Organization (WTO), the Organization for Security and Co-operation in Europe (OSCE), and the Organisation internationale de la Francophonie (OIF). Greece's unique cultural heritage, large tourism industry, prominent shipping sector and geostrategic importance[a] classify it as a middle power. It is the largest economy in the Balkans, where it is an important regional investor.</p><h2>Contents</h2><div class="gradientback"></div></div><div class="content"><h2>Etymology</h2><p> Main article: Name of Greece</p><p>The names for the nation of Greece and the Greek people differ from the names used in other languages, locations and cultures. Although the Greeks call the country Hellas or Ellada (Greek: ????? or ????da) and its official name is the Hellenic Republic, in English it is referred to as Greece, which comes from the Latin term Graecia as used by the Romans, which literally means the land of the Greeks, and derives from the Greek name G?a????.</p><h2>History</h2><p> Main article: History of Greece</p><h3>Ancient and Classical periods</h3><p> Main articles: Ancient Greece and Classical Greece</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/f/f3/Stiersprungfresko_02.jpg/260px-Stiersprungfresko_02.jpg" width="260" height="143"><p>


				Fresco displaying the Minoan ritual of "bull leaping", found in Knossos (Heraklion Archaeological Museum, Crete)


				</p><p>
					The earliest evidence of the presence of human ancestors in the southern Balkans, dated to 270,000 BC, is to be found in the Petralona cave, in the Greek province of Macedonia.[24] All three stages of the stone age (Paleolithic, Mesolithic, and Neolithic) are represented in Greece, for example in the Franchthi Cave.[25] Neolithic settlements in Greece, dating from the 7th millennium BC,[24] are the oldest in Europe by several centuries, as Greece lies on the route via which farming spread from the Near East to Europe.[26]</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/f/f7/Greek_Colonization_Archaic_Period.png/300px-Greek_Colonization_Archaic_Period.png" width="300" height="170"><p>


				Greek territories and colonies during the Archaic period (750–550 BC)



				<br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/d/da/The_Parthenon_in_Athens.jpg/240px-The_Parthenon_in_Athens.jpg" width="240" height="169"><br>


				The Parthenon on the Acropolis of Athens is one of the best known symbols of classical Greece.


				</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/d/da/The_Parthenon_in_Athens.jpg/240px-The_Parthenon_in_Athens.jpg" width="240" height="169"><br><p>
					Greece is home to the first advanced civilizations in Europe and is considered the birthplace of Western civilization,[27][28][29][30] beginning with the Cycladic civilization on the islands of the Aegean Sea at around 3200 BC,[31] the Minoan civilization in Crete (2700–1500 BC),[30][32] and then the Mycenaean civilization on the mainland (1900–1100 BC).[32] These civilizations possessed writing, the Minoans writing in an undeciphered script known as Linear A, and the Mycenaeans in Linear B, an early form of Greek. The Mycenaeans gradually absorbed the Minoans, but collapsed violently around 1200 BC, during a time of regional upheaval known as the Bronze Age collapse.[33] This ushered in a period known as the Greek Dark Ages, from which written records are absent.</p><p>The end of the Dark Ages is traditionally dated to 776 BC, the year of the first Olympic Games.[34] The Iliad and the Odyssey, the foundational texts of Western literature, are believed to have been composed by Homer in the 7th or 8th centuries BC.[35][36] With the end of the Dark Ages, there emerged various kingdoms and city-states across the Greek peninsula, which spread to the shores of the Black Sea, Southern Italy (Magna Graecia) and Asia Minor. These states and their colonies reached great levels of prosperity that resulted in an unprecedented cultural boom, that of classical Greece, expressed in architecture, drama, science, mathematics and philosophy. In 508 BC, Cleisthenes instituted the world's first democratic system of government in Athens.[37][38]</p><p>By 500 BC, the Persian Empire controlled the Greek city states in Asia Minor and Macedonia.[39] Attempts by some of the Greek city-states of Asia Minor to overthrow Persian rule failed, and Persia invaded the states of mainland Greece in 492 BC, but was forced to withdraw after a defeat at the Battle of Marathon in 490 BC. A second invasion by the Persians followed in 480 BC. Following decisive Greek victories in 480 and 479 BC at Salamis, Plataea, and Mycale, the Persians were forced to withdraw for a second time, marking their eventual withdrawal from all of their European territories. Led by Athens and Sparta, the Greek victories in the Greco-Persian Wars are considered a pivotal moment in world history,[40] as the 50 years of peace that followed are known as the Golden Age of Athens, the seminal period of ancient Greek development that laid many of the foundations of Western civilization.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/5/59/Alexander_and_Bucephalus_-_Battle_of_Issus_mosaic_-_Museo_Archeologico_Nazionale_-_Naples_BW.jpg/200px-Alexander_and_Bucephalus_-_Battle_of_Issus_mosaic_-_Museo_Archeologico_Nazionale_-_Naples_BW.jpg" width="200" height="142"><p>


				Alexander the Great on his horse Bucephalus, whose conquests led to the Hellenistic Age.


				</p><p>
					Lack of political unity within Greece resulted in frequent conflict between Greek states. The most devastating intra-Greek war was the Peloponnesian War (431–404 BC), won by Sparta and marking the demise of the Athenian Empire as the leading power in ancient Greece. Both Athens and Sparta were later overshadowed by Thebes and eventually Macedon, with the latter uniting the Greek world in the League of Corinth (also known as the Hellenic League or Greek League) under the guidance of Phillip II, who was elected leader of the first unified Greek state in history.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/7/78/Pella_House_atrium.jpg/170px-Pella_House_atrium.jpg" width="170" height="128"><div class="gradientback"></div></div><div class="content"><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/4/40/MacedonEmpire.jpg/245px-MacedonEmpire.jpg" width="245" height="117"><p>Following the assassination of Phillip II, his son Alexander III (The Great) assumed the leadership of the League of Corinth and launched an invasion of the Persian Empire with the combined forces of all Greek states in 334 BC. Undefeated in battle, Alexander had conquered the Persian Empire in its entirety by 330 BC. By the time of his death in 323 BC, he had created one of the largest empires in history, stretching from Greece to India. His empire split into several kingdoms upon his death, the most famous of which were the Seleucid Empire, Ptolemaic Egypt, the Greco-Bactrian Kingdom, and the Indo-Greek Kingdom. Many Greeks migrated to Alexandria, Antioch, Seleucia, and the many other new Hellenistic cities in Asia and Africa.[41] Although the political unity of Alexander's empire could not be maintained, it resulted in the Hellenistic civilization and spread the Greek language and Greek culture in the territories conquered by Alexander.[42] Greek science, technology, and mathematics are generally considered to have reached their peak during the Hellenistic period.[43]</p><h3>Hellenistic and Roman periods (323 BC&nbsp;– 4th century AD)</h3><p> Main articles: Hellenistic Greece and Roman Greece</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/7/7b/0142_-_Archaeological_Museum%2C_Athens_-_Antikythera_mechanism_-_Photo_by_Giovanni_Dall%27Orto%2C_Nov_11_2009.jpg/200px-0142_-_Archaeological_Museum%2C_Athens_-_Antikythera_mechanism_-_Photo_by_Giovanni_Dall%27Orto%2C_Nov_11_2009.jpg" width="200" height="176"><p>


				The Antikythera mechanism (c. 100 BC) is considered to be the first known mechanical analog computer (National Archaeological Museum, Athens).


				</p><p>
					After a period of confusion following Alexander's death, the Antigonid dynasty, descended from one of Alexander's generals, established its control over Macedon and most of the Greek city-states by 276 BC.[44] From about 200 BC the Roman Republic became increasingly involved in Greek affairs and engaged in a series of wars with Macedon.[45] Macedon's defeat at the Battle of Pydna in 168 BC signalled the end of Antigonid power in Greece.[46] In 146 BC, Macedonia was annexed as a province by Rome, and the rest of Greece became a Roman protectorate.[45][47]</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/8/8f/Odeon_of_Herodes_Atticus%2C_built_in_161_AD_on_the_south_slope_of_the_Acropolis_of_Athens_in_memory_of_his_wife_Annia_Regilla%2C_Athens%2C_Greece_%2814006718245%29.jpg/220px-Odeon_of_Herodes_Atticus%2C_built_in_161_AD_on_the_south_slope_of_the_Acropolis_of_Athens_in_memory_of_his_wife_Annia_Regilla%2C_Athens%2C_Greece_%2814006718245%29.jpg" width="220" height="146"><p>


				The Odeon of Herodes Atticus in Athens


				</p><p>
					The process was completed in 27 BC when the Roman Emperor Augustus annexed the rest of Greece and constituted it as the senatorial province of Achaea.[47] Despite their military superiority, the Romans admired and became heavily influenced by the achievements of Greek culture, hence Horace's famous statement: Graecia capta ferum victorem cepit (Greece, although captured, took its wild conqueror captive).[48] The epics of Homer inspired the Aeneid of Virgil, and authors such as Seneca the younger wrote using Greek styles. Roman heroes such as Scipio Africanus, tended to study philosophy and regarded Greek culture and science as an example to be followed. Similarly, most Roman emperors maintained an admiration for things Greek in nature. The Roman Emperor Nero visited Greece in AD 66, and performed at the Ancient Olympic Games, despite the rules against non-Greek participation. Hadrian was also particularly fond of the Greeks; before he became emperor, he served as an eponymous archon of Athens.</p><p>Greek-speaking communities of the Hellenized East were instrumental in the spread of early Christianity in the 2nd and 3rd centuries,[49] and Christianity's early leaders and writers (notably St Paul) were mostly Greek-speaking, though generally not from Greece itself.[50] The New Testament was written in Greek, and some of its sections (Corinthians, Thessalonians, Philippians, Revelation of St. John of Patmos) attest to the importance of churches in Greece in early Christianity. Nevertheless, much of Greece clung tenaciously to paganism, and ancient Greek religious practices were still in vogue in the late 4th century AD,[51] when they were outlawed by the Roman emperor Theodosius I in 391–392.[52] The last recorded Olympic games were held in 393,[53] and many temples were destroyed or damaged in the century that followed.[54] In Athens and rural areas, paganism is attested well into the sixth century AD[54] and even later.[55] The closure of the Neoplatonic Academy of Athens by the emperor Justinian in 529 is considered by many to mark the end of antiquity, although there is evidence that the Academy continued its activities for some time after that.[54] Some remote areas such as the southeastern Peloponnese remained pagan until well into the 10th century AD.[56]</p><h3>Medieval period (4th century&nbsp;– 1453)</h3><p> Main articles: Byzantine Greece and Frankokratia</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/a/a7/Map_Byzantine_Empire_1025-en.svg/300px-Map_Byzantine_Empire_1025-en.svg.png" width="300" height="169"><p>


				The Byzantine (Eastern Roman) Empire after the death of Basil II in 1025



				<br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/6/60/Agia_Sofia_front_July_2006.jpg/200px-Agia_Sofia_front_July_2006.jpg" width="200" height="150"><br>


				The Byzantine church of Hagia Sophia, Thessaloniki (8th century), an UNESCO's World Heritage Site.


				</p><div class="gradientback"></div></div><div class="content"><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/6/60/Agia_Sofia_front_July_2006.jpg/200px-Agia_Sofia_front_July_2006.jpg" width="200" height="150"><br><p>
					The Roman Empire in the east, following the fall of the Empire in the west in the 5th century, is conventionally known as the Byzantine Empire (but was simply called Roman Empire in its own time) and lasted until 1453. With its capital in Constantinople, its language and literary culture was Greek and its religion was predominantly Eastern Orthodox Christian.[57]</p><p>From the 4th century, the Empire's Balkan territories, including Greece, suffered from the dislocation of the Barbarian Invasions. The raids and devastation of the Goths and Huns in the 4th and 5th centuries and the Slavic invasion of Greece in the 7th century resulted in a dramatic collapse in imperial authority in the Greek peninsula.[58] Following the Slavic invasion, the imperial government retained formal control of only the islands and coastal areas, particularly the densely populated walled cities such as Athens, Corinth and Thessalonica, while some mountainous areas in the interior held out on their own and continued to recognize imperial authority.[58] Outside of these areas, a limited amount of Slavic settlement is generally thought to have occurred, although on a much smaller scale than previously thought.[59][60]</p><p>The Byzantine recovery of lost provinces began toward the end of the 8th century and most of the Greek peninsula came under imperial control again, in stages, during the 9th century.[61][62] This process was facilitated by a large influx of Greeks from Sicily and Asia Minor to the Greek peninsula, while at the same time many Slavs were captured and re-settled in Asia Minor and the few that remained were assimilated.[59] During the 11th and 12th centuries the return of stability resulted in the Greek peninsula benefiting from strong economic growth&nbsp;– much stronger than that of the Anatolian territories of the Empire.[61]</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/a/a6/Maltan_knights_castle_in_rh.jpg/280px-Maltan_knights_castle_in_rh.jpg" width="280" height="80"><p>


				The Palace of the Grand Master of the Knights of Rhodes, administrative centre of the Knights Hospitaller


				</p><p>
					Following the Fourth Crusade and the fall of Constantinople to the Latins in 1204 mainland Greece was split between the Greek Despotate of Epirus (a Byzantine successor state) and French rule[63] (known as the Frankokratia), while some islands came under Venetian rule.[64] The re-establishment of the Byzantine imperial capital in Constantinople in 1261 was accompanied by the empire's recovery of much of the Greek peninsula, although the Frankish Principality of Achaea in the Peloponnese and the rival Greek Despotate of Epirus in the north both remained important regional powers into the 14th century, while the islands remained largely under Genoese and Venetian control.[63]</p><p>In the 14th century, much of the Greek peninsula was lost by the Byzantine Empire at first to the Serbs and then to the Ottomans.[65] By the beginning of the 15th century, the Ottoman advance meant that Byzantine territory in Greece was limited mainly to its then-largest city, Thessaloniki, and the Peloponnese (Despotate of the Morea).[65] After the fall of Constantinople to the Ottomans in 1453, the Morea was the last remnant of the Byzantine Empire to hold out against the Ottomans. However, this, too, fell to the Ottomans in 1460, completing the Ottoman conquest of mainland Greece.[66] With the Turkish conquest, many Byzantine Greek scholars, who up until then were largely responsible for preserving Classical Greek knowledge, fled to the West, taking with them a large body of literature and thereby significantly contributing to the Renaissance.[67]</p><h3>Early modern period: Venetian possessions and Ottoman rule (15th century&nbsp;– 1821)</h3><p> Main articles: Ottoman Greece and Stato da Màr</p><p> Further information: Phanariotes and Ecumenical Patriarchate of Constantinople</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/0/0a/Angelokastro_%28Corfu%29.jpg/200px-Angelokastro_%28Corfu%29.jpg" width="200" height="150"><p>


				The Byzantine castle of Angelokastro successfully repulsed the Ottomans during the First Great Siege of Corfu in 1537, the siege of 1571, and the Second Great Siege of Corfu in 1716, causing them to abandon their plans to conquer Corfu.[68]


				</p><p>
					While most of mainland Greece and the Aegean islands was under Ottoman control by the end of the 15th century, Cyprus and Crete remained Venetian territory and did not fall to the Ottomans until 1571 and 1670 respectively. The only part of the Greek-speaking world that escaped long-term Ottoman rule was the Ionian Islands, which remained Venetian until their capture by the First French Republic in 1797, then passed to the United Kingdom in 1809 until their unification with Greece in 1864.[69]</p><p>While some Greeks in the Ionian Islands and Constantinople lived in prosperity, and Greeks of Constantinople (Phanariotes) achieved positions of power within the Ottoman administration,[70] much of the population of mainland Greece suffered the economic consequences of the Ottoman conquest. Heavy taxes were enforced, and in later years the Ottoman Empire enacted a policy of creation of hereditary estates, effectively turning the rural Greek populations into serfs.[71]</p><p>The Greek Orthodox Church and the Ecumenical Patriarchate of Constantinople were considered by the Ottoman governments as the ruling authorities of the entire Orthodox Christian population of the Ottoman Empire, whether ethnically Greek or not. Although the Ottoman state did not force non-Muslims to convert to Islam, Christians faced several types of discrimination intended to highlight their inferior status in the Ottoman Empire. Discrimination against Christians, particularly when combined with harsh treatment by local Ottoman authorities, led to conversions to Islam, if only superficially. In the 19th century, many crypto-Christians returned to their old religious allegiance.[72]</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/e/e0/Battle_of_Lepanto_1571.jpg/260px-Battle_of_Lepanto_1571.jpg" width="260" height="139"><p>


				The Battle of Lepanto in 1571 prevented the Ottomans from expanding further


				</p><p>
					The nature of Ottoman administration of Greece varied, though it was invariably arbitrary and often harsh.[72] Some cities had governors appointed by the Sultan, while others (like Athens) were self-governed municipalities. Mountains regions in the interior and many islands remained effectively autonomous from the central Ottoman state for many centuries.[73][page&nbsp;needed]</p><div class="gradientback"></div></div><div class="content"><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/4/49/White_Tower_in_Thessaloniki.jpg/180px-White_Tower_in_Thessaloniki.jpg" width="180" height="255"><p>


				The White Tower of Thessaloniki, one of the best-known Ottoman structures remaining in Greece.


				</p><p>
					When military conflicts broke out between the Ottoman Empire and enemies, Greeks usually took arms against the empire, with few exceptions. Prior to the Greek Revolution of 1821, there had been a number of wars which saw Greeks fight against the Ottomans, such as the Greek participation in the Battle of Lepanto in 1571, the Epirus peasants' revolts of 1600–1601, the Morean War of 1684–1699, and the Russian-instigated Orlov Revolt in 1770, which aimed at breaking up the Ottoman Empire in favor of Russian interests.[73][page&nbsp;needed] These uprisings were put down by the Ottomans with great bloodshed.[74][75] On the other side, many Greeks were conscripted as Ottoman citizens to serve in the Ottoman army (and especially the Ottoman navy), while the Ecumenical Patriarchate of Constantinople, responsible for the Orthodox, remained in general loyal to the empire.</p><p>The 16th and 17th centuries are regarded as something of a dark age in Greek history, with the prospect of overthrowing Ottoman rule appearing remote with only the Ionian islands remaining free of Turkish domination. Corfu withstood three major sieges in 1537, 1571 and 1716 all of which resulted in the repulsion of the Ottomans. However, in the 18th century, there arose through shipping a wealthy and dispersed Greek merchant class. These merchants came to dominate trade within the Ottoman Empire, establishing communities throughout the Mediterranean, the Balkans, and Western Europe. Though the Ottoman conquest had cut Greece off from significant European intellectual movements such as the Reformation and the Enlightenment, these ideas together with the ideals of the French Revolution and romantic nationalism began to penetrate the Greek world via the mercantile diaspora.[76] In the late 18th century, Rigas Feraios, the first revolutionary to envision an independent Greek state, published a series of documents relating to Greek independence, including but not limited to a national anthem and the first detailed map of Greece, in Vienna, and was murdered by Ottoman agents in 1798.[77][78]</p><h3>Modern period</h3><p> Main article: History of modern Greece</p><p> Main article: Greek War of Independence</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/0/0e/The_sortie_of_Messologhi_by_Theodore_Vryzakis.jpg/240px-The_sortie_of_Messologhi_by_Theodore_Vryzakis.jpg" width="240" height="335"><p>


				The sortie (exodus) of Messolonghi, during the Greek War of Independence (1821–1830), by Theodoros Vryzakis.


				</p><p>
					In the late eighteenth century, an increase in secular learning during the Modern Greek Enlightenment led to the revival among Greeks of the diaspora of the notion of a Greek nation tracing its existence to ancient Greece, distinct from the other Orthodox peoples, and having a right to political autonomy. One of the organizations formed in this intellectual milieu was the Filiki Eteria, a secret organization formed by merchants in Odessa in 1814.[79] Appropriating a long-standing tradition of Orthodox messianic prophecy aspiring to the resurrection of the eastern Roman empire and creating the impression they had the backing of Tsarist Russia, they managed amidst a crisis of Ottoman trade, from 1815 onwards, to engage traditional strata of the Greek Orthodox world in their liberal nationalist cause.[80] The Filiki Eteria planned to launch revolution in the Peloponnese, the Danubian Principalities and Constantinople. The first of these revolts began on 6 March 1821 in the Danubian Principalities under the leadership of Alexandros Ypsilantis, but it was soon put down by the Ottomans. The events in the north spurred the Greeks of the Peloponnese into action and on 17 March 1821 the Maniots declared war on the Ottomans.[81]</p><p>By the end of the month, the Peloponnese was in open revolt against the Ottomans and by October 1821 the Greeks under Theodoros Kolokotronis had captured Tripolitsa. The Peloponnesian revolt was quickly followed by revolts in Crete, Macedonia and Central Greece, which would soon be suppressed. Meanwhile, the makeshift Greek navy was achieving success against the Ottoman navy in the Aegean Sea and prevented Ottoman reinforcements from arriving by sea. In 1822 and 1824 the Turks and Egyptians ravaged the islands, including Chios and Psara, committing wholesale massacres of the population.[81] This had the effect of galvanizing public opinion in western Europe in favor of the Greek rebels.[73][page&nbsp;needed]</p><p>Tensions soon developed among different Greek factions, leading to two consecutive civil wars. Meanwhile, the Ottoman Sultan negotiated with Mehmet Ali of Egypt, who agreed to send his son Ibrahim Pasha to Greece with an army to suppress the revolt in return for territorial gain. Ibrahim landed in the Peloponnese in February 1825 and had immediate success: by the end of 1825, most of the Peloponnese was under Egyptian control, and the city of Missolonghi—put under siege by the Turks since April 1825—fell in April 1826. Although Ibrahim was defeated in Mani, he had succeeded in suppressing most of the revolt in the Peloponnese and Athens had been retaken.</p><p>After years of negotiation, three Great Powers, Russia, the United Kingdom, and France, decided to intervene in the conflict and each nation sent a navy to Greece. Following news that combined Ottoman–Egyptian fleets were going to attack the Greek island of Hydra, the allied fleet intercepted the Ottoman–Egyptian fleet at Navarino. After a week-long standoff, a battle began which resulted in the destruction of the Ottoman–Egyptian fleet. A French expeditionary force was dispatched to supervise the evacuation of the Egyptian army from the Peloponnese, while the Greeks proceeded to the captured part of Central Greece by 1828. As a result of years of negotiation, the nascent Greek state was finally recognized under the London Protocol in 1830.</p><p> Main article: Kingdom of Greece</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/3/35/Peter_von_Hess_-_The_Entry_of_King_Othon_of_Greece_in_Athens_-_WGA11387.jpg/300px-Peter_von_Hess_-_The_Entry_of_King_Othon_of_Greece_in_Athens_-_WGA11387.jpg" width="300" height="180"><div class="gradientback"></div></div><div class="content"><p>


				The Entry of King Otto in Athens, Peter von Hess, 1839.


				</p><p>
					In 1827, Ioannis Kapodistrias, from Corfu, was chosen by the Third National Assembly at Troezen as the first governor of the First Hellenic Republic. Kapodistrias established a series of state, economic and military institutions. Soon tensions appeared between him and local interests. Following his assassination in 1831 and the subsequent conference a year later, the Great Powers of Britain, France and Russia installed Bavarian Prince Otto von Wittelsbach as monarch.[82] One of his first actions was to transfer the capital from Nafplio to Athens. In 1843 an uprising forced the king to grant a constitution and a representative assembly.</p><p>Due to his authoritarian rule, he was eventually dethroned in 1862 and a year later replaced by Prince Wilhelm (William) of Denmark, who took the name George I and brought with him the Ionian Islands as a coronation gift from Britain. In 1877 Charilaos Trikoupis, who is credited with significant improvement of the country's infrastructure, curbed the power of the monarchy to interfere in the assembly by issuing the rule of vote of confidence to any potential prime minister.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/1/18/King_George_of_Hellenes.jpg/160px-King_George_of_Hellenes.jpg" width="160" height="217"><p>


				George I was King from 1863 to 1913


				</p><p>
					Corruption and Trikoupis' increased spending to create necessary infrastructure like the Corinth Canal overtaxed the weak Greek economy, forcing the declaration of public insolvency in 1893 and to accept the imposition of an International Financial Control authority to pay off the country's debtors. Another political issue in 19th-century Greece was uniquely Greek: the language question. The Greek people spoke a form of Greek called Demotic. Many of the educated elite saw this as a peasant dialect and were determined to restore the glories of Ancient Greek.</p><p>Government documents and newspapers were consequently published in Katharevousa (purified) Greek, a form which few ordinary Greeks could read. Liberals favoured recognising Demotic as the national language, but conservatives and the Orthodox Church resisted all such efforts, to the extent that, when the New Testament was translated into Demotic in 1901, riots erupted in Athens and the government fell (the Evangeliaka). This issue would continue to plague Greek politics until the 1970s.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/6/6c/Greekhistory.GIF/300px-Greekhistory.GIF" width="300" height="216"><p>


				The territorial evolution of Kingdom of Greece until 1947.


				</p><p>
					All Greeks were united, however, in their determination to liberate the Greek-speaking provinces of the Ottoman Empire, regardless of the dialect they spoke. Especially in Crete, a prolonged revolt in 1866–1869 had raised nationalist fervour. When war broke out between Russia and the Ottomans in 1877, Greek popular sentiment rallied to Russia's side, but Greece was too poor, and too concerned about British intervention, to officially enter the war. Nevertheless, in 1881, Thessaly and small parts of Epirus were ceded to Greece as part of the Treaty of Berlin, while frustrating Greek hopes of receiving Crete.</p><p>Greeks in Crete continued to stage regular revolts, and in 1897, the Greek government under Theodoros Deligiannis, bowing to popular pressure, declared war on the Ottomans. In the ensuing Greco-Turkish War of 1897, the badly trained and equipped Greek army was defeated by the Ottomans. Through the intervention of the Great Powers, however, Greece lost only a little territory along the border to Turkey, while Crete was established as an autonomous state under Prince George of Greece. With state coffers empty, fiscal policy came under International Financial Control. In the next decade, Greek efforts were focused on the Macedonian Struggle, a state-sponsored guerilla campaign against pro-Bulgarian rebel gangs in Ottoman-ruled Macedonia, which ended inconclusively with the Young Turk Revolution in 1908.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/f/fd/Greek_Parade_Paris_1919.jpg/250px-Greek_Parade_Paris_1919.jpg" width="250" height="179"><p>


				Greek military formation in the World War I Victory Parade in Arc de Triomphe, Paris, July 1919.



				<br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/5/59/Greece_in_the_Treaty_of_S%C3%A8vres.jpg/250px-Greece_in_the_Treaty_of_S%C3%A8vres.jpg" width="250" height="178"><br>


				Map of Greater Greece after the Treaty of Sèvres, when the Megali Idea seemed close to fulfillment, featuring Eleftherios Venizelos.


				</p><div class="gradientback"></div></div><div class="content"><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/5/59/Greece_in_the_Treaty_of_S%C3%A8vres.jpg/250px-Greece_in_the_Treaty_of_S%C3%A8vres.jpg" width="250" height="178"><br><p>
					Amidst general dissatisfaction with the state of the nation, a group of military officers organized a coup in August 1909 and shortly thereafter called to power Cretan politician Eleftherios Venizelos. After winning two elections and becoming Prime Minister, Venizelos initiated wide-ranging fiscal, social, and constitutional reforms, reorganized the military, made Greece a member of the Balkan League, and led the country through the Balkan Wars. By 1913, Greece's territory and population had almost doubled, annexing Crete, Epirus, and Macedonia. In the following years, the struggle between King Constantine I and charismatic Venizelos over the country's foreign policy on the eve of World War I dominated the country's political scene, and divided the country into two opposing groups. During parts of World War I, Greece had two governments; a royalist pro-German government in Athens and a Venizelist pro-Entente one in Thessaloniki. The two governments were united in 1917, when Greece officially entered the war on the side of the Entente.</p><p>In the aftermath of World War I, Greece attempted further expansion into Asia Minor, a region with a large native Greek population at the time, but was defeated in the Greco-Turkish War of 1919–1922, contributing to a massive flight of Asia Minor Greeks.[83][84] These events overlapped, with both happening during the Greek genocide (1914–1922),[85][86][87][88] a period during which, according to various sources,[89] Ottoman and Turkish officials contributed to the death of several hundred thousand Asia Minor Greeks. The resultant Greek exodus from Asia Minor was made permanent, and expanded, in an official Population exchange between Greece and Turkey. The exchange was part of the terms of the Treaty of Lausanne which ended the war.[90]</p><p>The following era was marked by instability, as over 1.5 million propertyless Greek refugees from Turkey had to be integrated into Greek society. Cappadocian Greeks, Pontian Greeks, and non-Greek followers of Greek Orthodoxy were all subject to the exchange as well. Some of the refugees could not speak the language, and were from what had been unfamiliar environments to mainland Greeks, such as in the case of the Cappadocians and non-Greeks. The refugees also made a dramatic post-war population boost, as the amount of refugees was more than a quarter of Greece's prior population.[91]</p><p>Following the catastrophic events in Asia Minor, the monarchy was abolished via a referendum in 1924 and the Second Hellenic Republic was declared. In 1935, a royalist general-turned-politician Georgios Kondylis took power after a coup d'état and abolished the republic, holding a rigged referendum, after which King George II returned to Greece and was restored to the throne.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/5/58/Greek_Army_during_Primavera_Offensive_Klisura_March_1941.JPG/200px-Greek_Army_during_Primavera_Offensive_Klisura_March_1941.JPG" width="200" height="139"><p>


				Greek troops during the Italian Spring Offensive (1941) in the Greco-Italian War. Greece's victory against Fascist Italy, gave the Allies their first victory over Axis forces on land in World War II.


				</p><p>
					An agreement between Prime Minister Ioannis Metaxas and the head of state George II followed in 1936, which installed Metaxas as the head of a dictatorial regime known as the 4th of August Regime, inaugurating a period of authoritarian rule that would last, with short breaks, until 1974.[92] Although a dictatorship, Greece remained on good terms with Britain and was not allied with the Axis.</p><p>On 28 October 1940, Fascist Italy demanded the surrender of Greece, but the Greek administration refused, and, in the following Greco-Italian War, Greece repelled Italian forces into Albania, giving the Allies their first victory over Axis forces on land. The Greek struggle and victory against the Italians received exuberant praise at the time.[93][94] Most prominent is the quote attributed to Winston Churchill: Hence we will not say that Greeks fight like heroes, but we will say that heroes fight like Greeks.[93] French general Charles de Gaulle was among those who praised the fierceness of the Greek resistance. In an official notice released to coincide with the Greek national celebration of the Day of Independence, De Gaulle expressed his admiration for the Greek resistance:</p><p>In the name of the captured yet still alive French people, France wants to send her greetings to the Greek people who are fighting for their freedom. The 25 March 1941 finds Greece in the peak of their heroic struggle and in the top of their glory. Since the Battle of Salamis, Greece had not achieved the greatness and the glory which today holds.[94]</p><p>The country would eventually fall to urgently dispatched German forces during the Battle of Greece, despite the fierce Greek resistance, particularly in the Battle of the Metaxas Line. Adolf Hitler himself recognised the bravery and the courage of the Greek army, stating in his address to the Reichstag on 11 December 1941, that: Historical justice obliges me to state that of the enemies who took up positions against us, the Greek soldier particularly fought with the highest courage. He capitulated only when further resistance had become impossible and useless.[95]</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/5/51/%CE%91%CE%BD%CF%84%CE%AC%CF%81%CF%84%CE%B5%CF%82_%CF%84%CE%BF%CF%85_%CE%95%CE%91%CE%9C-%CE%95%CE%9B%CE%91%CE%A3.jpg/200px-%CE%91%CE%BD%CF%84%CE%AC%CF%81%CF%84%CE%B5%CF%82_%CF%84%CE%BF%CF%85_%CE%95%CE%91%CE%9C-%CE%95%CE%9B%CE%91%CE%A3.jpg" width="200" height="153"><p>


				Guerillas of EAM-ELAS resistance organization


				</p><p>
					The Nazis proceeded to administer Athens and Thessaloniki, while other regions of the country were given to Nazi Germany's partners, Fascist Italy and Bulgaria. The occupation brought about terrible hardships for the Greek civilian population. Over 100,000 civilians died of starvation during the winter of 1941–1942, tens of thousands more died because of reprisals by Nazis and collaborators, the country's economy was ruined, and the great majority of Greek Jews were deported and murdered in Nazi concentration camps.[96][97] The Greek Resistance, one of the most effective resistance movements in Europe, fought vehemently against the Nazis and their collaborators. The German occupiers committed numerous atrocities, mass executions, and wholesale slaughter of civilians and destruction of towns and villages in reprisals. In the course of the concerted anti-guerilla campaign, hundreds of villages were systematically torched and almost 1,000,000 Greeks left homeless.[97] In total, the Germans executed some 21,000 Greeks, the Bulgarians 40,000, and the Italians 9,000.[98]</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/7/75/%CE%91%CE%B8%CE%B7%CE%BD%CE%B1%CE%AF%CE%BF%CE%B9_%CE%B3%CE%B9%CE%BF%CF%81%CF%84%CE%AC%CE%B6%CE%BF%CF%85%CE%BD_%CF%84%CE%B7%CE%BD_%CE%B1%CF%80%CE%B5%CE%BB%CE%B5%CF%85%CE%B8%CE%AD%CF%81%CF%89%CF%83%CE%B7_%CF%84%CE%B7%CF%82_%CF%80%CF%8C%CE%BB%CE%B7%CF%82_%CF%84%CE%BF%CF%85%CF%82%2C_%CE%9F%CE%BA%CF%84%CF%8E%CE%B2%CF%81%CE%B9%CE%BF%CF%82_1944.jpg/180px-%CE%91%CE%B8%CE%B7%CE%BD%CE%B1%CE%AF%CE%BF%CE%B9_%CE%B3%CE%B9%CE%BF%CF%81%CF%84%CE%AC%CE%B6%CE%BF%CF%85%CE%BD_%CF%84%CE%B7%CE%BD_%CE%B1%CF%80%CE%B5%CE%BB%CE%B5%CF%85%CE%B8%CE%AD%CF%81%CF%89%CF%83%CE%B7_%CF%84%CE%B7%CF%82_%CF%80%CF%8C%CE%BB%CE%B7%CF%82_%CF%84%CE%BF%CF%85%CF%82%2C_%CE%9F%CE%BA%CF%84%CF%8E%CE%B2%CF%81%CE%B9%CE%BF%CF%82_1944.jpg" width="180" height="188"><p>


				People in Athens celebrate the liberation from the Axis powers, October 1944. Postwar Greece will experience a civil war and political polarization.


				</p><div class="gradientback"></div></div><div class="content"><p>
					After liberation and the Allies' win over Axis, Greece annexed the Dodecanese islands. Soon the country experienced a polarising civil war between communist and anticommunist forces until 1949, which led to economic devastation and severe social tensions between rightists and largely communist leftists for the next thirty years.[99] The next twenty years were characterized by marginalisation of the left in the political and social spheres and by rapid economic growth, propelled in part by the Marshall Plan.</p><p>Greece's highest development visibility during the twentieth century, is also seen by its HDI component-numeracy, which increased rapidly during this period, respectively even though low levels of human capital level persisted even sometime after Ottoman rule ended.[100]</p><p>King Constantine II's dismissal of George Papandreou's centrist government in July 1965 prompted a prolonged period of political turbulence which culminated in a coup d'état on 21 April 1967 by the Regime of the Colonels. The brutal suppression of the Athens Polytechnic uprising on 17 November 1973 is claimed to have sent shockwaves through the regime, and a counter-coup overthrew Georgios Papadopoulos to establish brigadier Dimitrios Ioannidis as leader. On 20 July 1974, as Turkey invaded the island of Cyprus, the regime collapsed.</p><p> Main article: Third Hellenic Republic</p><p>The former prime minister Konstantinos Karamanlis was invited back from Paris where he had lived in self-exile since 1963, marking the beginning of the Metapolitefsi era. The first multiparty elections since 1964 were held on the first anniversary of the Polytechnic uprising. A democratic and republican constitution was promulgated on 11 June 1975 following a referendum which chose to not restore the monarchy.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/en/thumb/e/e7/Accession_of_Greece_to_the_European_Union.png/200px-Accession_of_Greece_to_the_European_Union.png" width="200" height="148"><p>


				Signing at Zappeion of the documents for the accession of Greece to the European Communities in 1979.


				</p><p>
					Meanwhile, Andreas Papandreou, George Papandreou's son, founded the Panhellenic Socialist Movement (PASOK) in response to Karamanlis's conservative New Democracy party, with the two political formations dominating in government over the next four decades. Greece rejoined NATO in 1980.[b][101] Greece became the tenth member of the European Communities (subsequently subsumed by the European Union) on 1 January 1981, ushering in a period of sustained growth. Widespread investments in industrial enterprises and heavy infrastructure, as well as funds from the European Union and growing revenues from tourism, shipping, and a fast-growing service sector raised the country's standard of living to unprecedented levels. Traditionally strained relations with neighbouring Turkey improved when successive earthquakes hit both nations in 1999, leading to the lifting of the Greek veto against Turkey's bid for EU membership.</p><p>The country adopted the euro in 2001 and successfully hosted the 2004 Summer Olympic Games in Athens.[102] More recently, Greece has suffered greatly from the late-2000s recession and has been central to the related European sovereign debt crisis. Due to the adoption of the euro, when Greece experienced financial crisis, it could no longer devalue its currency to regain competitiveness. Youth unemployment was especially high during the 2000s.[103] The Greek government-debt crisis, subsequent austerity policies, and resultant protests have agitated domestic politics and have regularly threatened European and global financial markets since the crisis began in 2010.</p><h2>Geography and climate</h2><p> Main article: Geography of Greece</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/4/45/%CE%9D%CE%B1%CF%85%CE%AC%CE%B3%CE%B9%CE%BF_%CE%96%CE%B1%CE%BA%CF%8D%CE%BD%CE%B8%CE%BF%CF%85.jpg/180px-%CE%9D%CE%B1%CF%85%CE%AC%CE%B3%CE%B9%CE%BF_%CE%96%CE%B1%CE%BA%CF%8D%CE%BD%CE%B8%CE%BF%CF%85.jpg" width="180" height="240"><p>


				Navagio (shipwreck) bay, Zakynthos island


				</p><p>
					Located in Southern Europe,[104] Greece is a transcontinental country that consists of a mountainous, peninsular mainland jutting out into the sea at the southern end of the Balkans, ending at the Peloponnese peninsula (separated from the mainland by the canal of the Isthmus of Corinth) and strategically located at the crossroads of Europe, Asia, and Africa.[105][106][107] Due to its highly indented coastline and numerous islands, Greece has the 11th longest coastline in the world with 13,676&nbsp;km (8,498&nbsp;mi);[108] its land boundary is 1,160&nbsp;km (721&nbsp;mi). The country lies approximately between latitudes 34° and 42° N, and longitudes 19° and 30° E, with the extreme points being:[109]</p><p>Eighty percent of Greece consists of mountains or hills, making the country one of the most mountainous in Europe. Mount Olympus, the mythical abode of the Greek Gods, culminates at Mytikas peak 2,918 metres (9,573&nbsp;ft),[110] the highest in the country. Western Greece contains a number of lakes and wetlands and is dominated by the Pindus mountain range. The Pindus, a continuation of the Dinaric Alps, reaches a maximum elevation of 2,637&nbsp;m (8,652&nbsp;ft) at Mt. Smolikas (the second-highest in Greece) and historically has been a significant barrier to east-west travel.</p><p>The Pindus range continues through the central Peloponnese, crosses the islands of Kythera and Antikythera and finds its way into southwestern Aegean, in the island of Crete where it eventually ends. The islands of the Aegean are peaks of underwater mountains that once constituted an extension of the mainland. Pindus is characterized by its high, steep peaks, often dissected by numerous canyons and a variety of other karstic landscapes. The spectacular Vikos Gorge, part of the Vikos-Aoos National Park in the Pindus range, is listed by the Guinness book of World Records as the deepest gorge in the world.[111] Another notable formation are the Meteora rock pillars, atop which have been built medieval Greek Orthodox monasteries.</p><p>Northeastern Greece features another high-altitude mountain range, the Rhodope range, spreading across the region of East Macedonia and Thrace; this area is covered with vast, thick, ancient forests, including the famous Dadia forest in the Evros regional unit, in the far northeast of the country.</p><p>Extensive plains are primarily located in the regions of Thessaly, Central Macedonia and Thrace. They constitute key economic regions as they are among the few arable places in the country. Rare marine species such as the pinniped seals and the loggerhead sea turtle live in the seas surrounding mainland Greece, while its dense forests are home to the endangered brown bear, the Eurasian lynx, the roe deer and the wild goat.</p><h3>Islands</h3><p> Main article: List of islands of Greece</p><div class="gradientback"></div></div><div class="content"><p>Greece features a vast number of islands, between 1,200 and 6,000, depending on the definition,[112] 227 of which are inhabited. Crete is the largest and most populous island; Euboea, separated from the mainland by the 60m-wide Euripus Strait, is the second largest, followed by Lesbos and Rhodes.</p><p>The Greek islands are traditionally grouped into the following clusters: The Argo-Saronic Islands in the Saronic gulf near Athens, the Cyclades, a large but dense collection occupying the central part of the Aegean Sea, the North Aegean islands, a loose grouping off the west coast of Turkey, the Dodecanese, another loose collection in the southeast between Crete and Turkey, the Sporades, a small tight group off the coast of northeast Euboea, and the Ionian Islands, located to the west of the mainland in the Ionian Sea.</p><h3>Climate</h3><p> Further information: Climate of Greece</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/1/17/Mytikas.jpg/220px-Mytikas.jpg" width="220" height="165"><p>


				A view of Mount Olympus, the highest mountain in Greece and mythical abode of the Gods of Olympus


				</p><p>
					The climate of Greece is primarily Mediterranean, featuring mild, wet winters and hot, dry summers. This climate occurs at all coastal locations, including Athens, the Cyclades, the Dodecanese, Crete, the Peloponnese, the Ionian Islands and parts of the Central Continental Greece region. The Pindus mountain range strongly affects the climate of the country, as areas to the west of the range are considerably wetter on average (due to greater exposure to south-westerly systems bringing in moisture) than the areas lying to the east of the range (due to a rain shadow effect).</p><p>The mountainous areas of Northwestern Greece (parts of Epirus, Central Greece, Thessaly, Western Macedonia) as well as in the mountainous central parts of Peloponnese&nbsp;– including parts of the regional units of Achaea, Arcadia and Laconia&nbsp;– feature an Alpine climate with heavy snowfalls. The inland parts of northern Greece, in Central Macedonia and East Macedonia and Thrace feature a temperate climate with cold, damp winters and hot, dry summers with frequent thunderstorms. Snowfalls occur every year in the mountains and northern areas, and brief snowfalls are not unknown even in low-lying southern areas, such as Athens.</p><h3>Ecology</h3><p>Phytogeographically, Greece belongs to the Boreal Kingdom and is shared between the East Mediterranean province of the Mediterranean Region and the Illyrian province of the Circumboreal Region. According to the World Wide Fund for Nature and the European Environment Agency, the territory of Greece can be subdivided into six ecoregions: the Illyrian deciduous forests, Pindus Mountains mixed forests, Balkan mixed forests, Rhodope montane mixed forests, Aegean and Western Turkey sclerophyllous and mixed forests and Crete Mediterranean forests.</p><h2>Politics</h2><p> Main article: Politics of Greece</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/1/11/Hellenic_Parliament_from_high_above.jpg/260px-Hellenic_Parliament_from_high_above.jpg" width="260" height="174"><p>


				The building of the Hellenic Parliament in central Athens.



				<br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/0/00/Kapodistrias2.jpg/160px-Kapodistrias2.jpg" width="160" height="236"><br>


				Count Ioannis Kapodistrias, first governor and founder of the modern Greek State


				</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/0/00/Kapodistrias2.jpg/160px-Kapodistrias2.jpg" width="160" height="236"><br><p>
					Greece is a unitary parliamentary republic.[113] The nominal head of state is the President of the Republic, who is elected by the Parliament for a five-year term.[113] The current Constitution was drawn up and adopted by the Fifth Revisionary Parliament of the Hellenes and entered into force in 1975 after the fall of the military junta of 1967–1974. It has been revised three times since, in 1986, 2001 and 2008. The Constitution, which consists of 120 articles, provides for a separation of powers into executive, legislative, and judicial branches, and grants extensive specific guarantees (further reinforced in 2001) of civil liberties and social rights.[114][115] Women's suffrage was guaranteed with an amendment to the 1952 Constitution.</p><p>According to the Constitution, executive power is exercised by the President of the Republic and the Government.[113] From the Constitutional amendment of 1986 the President's duties were curtailed to a significant extent, and they are now largely ceremonial; most political power thus lies in the hands of the Prime Minister.[116] The position of Prime Minister, Greece's head of gove<br>
							

											 
										

							</p><br><h1 lang="en">Coat of arms of Greece</h1><p> From Wikipedia, the free encyclopedia</p><p>The coat of arms of Greece displays a white cross on a blue escutcheon, which is surrounded by two laurel branches.</p><p>The constitution does not specify a tincture for the branches, implying proper (i.e. green). The Greek government normally uses a design in which the laurel branches are monochrome blue. A version with golden laurel leaves is displayed by the military and on the presidential standard.</p><h2>Contents</h2><h2>History</h2><h3>1832–1863: Wittelsbach dynasty</h3><p>The first Greek coat of arms was introduced during the reign of the Bavarian King Otto. Based on that of the Kingdom of Bavaria, and supported by two crowned lions rampant and surmounted by the royal crown. The escutcheon of pretence was the coat of arms of Bavaria, as a symbol of the House of Wittelsbach.</p><div class="gradientback"></div></div><div class="content"><p>This emblem was discarded upon the king's exile in 1862.</p><h3>1924–1935: Second Hellenic Republic</h3><p>When Greece became a republic in 1924, all external ornamentation was discarded.</p><h3>1864-1924 and 1935–1973: Glücksburg dynasty</h3><p>After Otto's fall, the young Prince William of Denmark was in 1864 chosen as king, and the new achievement for the coat of arms bore a strong resemblance to that of the Danish Royal Family. The escutcheon remained the same, but the dynastic arms of the Schleswig-Holstein-Sonderburg-Glücksburg family became the new escutcheon of pretence. The shield remained surmounded by the royal crown. Two new male figures were introduced as new supporters, alluding to the legendary Heracles.[1] The Order of the Redeemer was also added. The motto of the dynasty, i.e. ?s??? µ?? ? ???p? t?? ?a?? (People's love, my strength), was also introduced.</p><p>This achievement remains in use by the current pretender Greek Royal Family.</p><h3>1975–present</h3><p>In 1973, the then-ruling military junta abolished the monarchy. 7 June 1975, the current arms was introduced. This is a restoration of the traditional arms, yet with laurel leaves being the sole external ornamentation. The government uses a stylised design by the artist Kostas Grammatopoulos.</p><h3>List</h3><h3>Historical, non-heraldic emblems</h3><p>The first Greek national emblem was provided for by the Constitution of Epidauros of 1 January 1822 and was established by decree on 15 March of the same year. It was the shape of a blue and white circular cockade.</p><p>Since it was first established the emblem has undergone many changes in shape and in design, mainly due to changes of regime. The original Greek national emblem depicted the goddess Athena and the owl. At the time of Ioannis Kapodistrias, the first Prime Minister of modern Greece, the phoenix, the symbol of rebirth, was added.</p><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Coat_of_arms_of_Greece&amp;oldid=784018414"					
								Categories:  Hidden categories:</p><br><h1 lang="en">Hymn to Liberty</h1><p> From Wikipedia, the free encyclopedia</p><p>The Hymn to Liberty or Hymn to Freedom[1] (Greek: ?µ??? e?? t?? ??e??e??a?, Ýmnos is tin Eleftherían pronounced&nbsp;['im.nos is tin elef'?eri.an], also Greek: ?µ??? p??? t?? ??e??e??a?[3][4][5] Ýmnos pros tin Eleftherían pronounced&nbsp;['im.nos pros tin elef'?eri.an]) is a poem written by Dionýsios Solomós in 1823 that consists of 158 stanzas, which is used as the national anthem of Greece and Cyprus. It was set to music by Nikolaos Mantzaros, and is the longest national anthem in the world by length of text.[6] In 1865, the first three stanzas (and later the first two) officially became the national anthem of Greece and, from 1966, also that of the Republic of Cyprus.</p><h2>Contents</h2><h2>History</h2><p>Dionysios Solomos wrote the anthem in 1823 in Zakynthos and one year later was printed in Messolonghi. The hymn was set to music in 1865 by the Corfiot operatic composer Nikolaos Mantzaros, who composed two choral versions, a long one for the whole poem and a short one for the first two stanzas; the latter is the one adopted as the National Anthem of Greece. The Greek anthem was adopted as the anthem of the Republic of Cyprus by order of the Council of Ministers in 1966.[7]</p><h2>Lyrics</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/a/a9/Lytras_-_Execution_of_Gregory_V.jpg/180px-Lytras_-_Execution_of_Gregory_V.jpg" width="180" height="145"><p>


				Execution of Patriarch Gregory V of Constantinople by Nikiforos Lytras



				<br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/6/67/Panagiotis_Kefalas_by_Hess.jpg/180px-Panagiotis_Kefalas_by_Hess.jpg" width="180" height="222"><br>


				Siege of Tripolitsa by Peter von Hess


				</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/6/67/Panagiotis_Kefalas_by_Hess.jpg/180px-Panagiotis_Kefalas_by_Hess.jpg" width="180" height="222"><br><p>
					Inspired by the Greek War of Independence, Solomos wrote the hymn to honour the struggle of Greeks for independence after centuries of Ottoman rule.</p><p>The poet recounts the misery of the Greeks under the Ottomans and their hope for freedom. He describes different events of the War, such as the execution of Patriarch Gregory V of Constantinople, the reaction of the Great Powers, extensively the Siege of Tripolitsa and the Christian character of the struggle.</p><h3>Greek original</h3><h3>English translations</h3><h2>Uses</h2><p>An adapted version was used during the short-lived Cretan State as the Cretan Anthem. The Hymn to Liberty has been the Greek Royal Anthem since 1864.</p><p>The Constitution of Cyprus (1960) does not proclaim a national anthem. The two communities later agreed, in official circumstances, that a piece of classical music should be played in lieu of the anthem.[citation needed] However, after rejecting the amended Constitution proposed by Makarios in 1963, the Turkish representation broke away from the government of the Republic of Cyprus; there followed a period of intercommunal violence. The Council of Ministers subsequently decided to adopt the Hymn to Liberty as the official anthem of Cyprus on 16 November 1966.[2]</p><div class="gradientback"></div></div><div class="content"><p>This anthem has been performed at every closing ceremony of the Olympic Games, to pay tribute to Greece as the birthplace of the Olympic Games. The version commonly played by military bands was composed by Lieutenant Colonel Margaritis Kastellis (1907–1979), former director of the Greek Music Corps.[9]</p><h2>References and notes</h2><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Hymn_to_Liberty&amp;oldid=782276791"					
								Categories:  Hidden categories:</p><br><h1 lang="en">Greece (disambiguation)</h1><p> From Wikipedia, the free encyclopedia</p><p>Greece may refer to:</p><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Greece_(disambiguation)&amp;oldid=779771977"					
								Categories:  Hidden categories:</p><br><h1 lang="en">Greek Orthodox Church</h1><p> From Wikipedia, the free encyclopedia</p><p> This article is about all Orthodox jurisdictions of Greek cultural heritage. For the Orthodox Church in Greece, see Church of Greece.</p><p>The name Greek Orthodox Church (Greek: ?????????d??? ?????s?a, Ellinorthódoxi Ekklisía, IPA:&nbsp;[elinor'?oðoksi ekli'sia]), or Greek Orthodoxy, is a term referring to the body of several Churches[5][6][7] within the larger communion of Eastern Orthodox Christianity, whose liturgy is or was traditionally conducted in Koine Greek,[8] the original language of the New Testament,[9][10] and whose history, traditions, and theology are rooted in the early Church Fathers and the culture of the Byzantine Empire. Greek Orthodox Christianity has also traditionally placed heavy emphasis and awarded high prestige to traditions of Christian monasticism and asceticism, with origins in Early Christianity in the Near East and in Byzantine Anatolia. Today, the most important centres of Christian Orthodox monasticism are Saint Catherine's Monastery in the Sinai Peninsula (Egypt), Meteora at Thessaly in Greece, Mount Athos in Greek Macedonia, Mar Saba in the Bethlehem Governorate of the West Bank, and the Monastery of Saint John the Theologian on the island of Patmos in Greece.</p><p>Historically, the term Greek Orthodox has also been used to describe all Eastern Orthodox Churches in general, since Greek in Greek Orthodox can refer to the heritage of the Byzantine Empire.[11][12][13] During the first eight centuries of Christian history, most major intellectual, cultural, and social developments in the Christian Church took place within the Empire or in the sphere of its influence,[13][14][15] where the Greek language was widely spoken and used for most theological writings. Over time, most parts of the liturgy, traditions, and practices of the church of Constantinople were adopted by all, and still provide the basic patterns of contemporary Orthodoxy.[16][17][18] Thus, the Eastern Church came to be called Greek Orthodox in the same way that the Western Church is called Roman Catholic. However, the appellation Greek was abandoned by the Slavic and other Eastern Orthodox churches in connection with their peoples' national awakenings, from as early as the 10th century A.D.[a] Thus, today it is generally only those churches that are most closely tied to Greek or Byzantine culture that are called Greek Orthodox.</p><h2>Contents</h2><h2>Overview</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/7/7f/Tinos_panagia_evangelistria_200707_04.jpg/220px-Tinos_panagia_evangelistria_200707_04.jpg" width="220" height="147"><p>


				Our Lady of Tinos


				</p><p>
					The Greek Orthodox churches are descended from churches which the Apostles founded in the Balkans and the Middle East during the first century A.D.,[b] and they maintain many traditions practiced in the ancient Church.[28] Orthodox Churches, unlike the Catholic Church, have no Bishopric head, such as a Pope, and hold the belief that Christ is the head of the Church. However, they are each governed by a committee of Bishops, called the Holy Synod, with one central Bishop holding the honorary title of first among equals.</p><p>Greek Orthodox Churches are united in communion with each other, as well as with the other Eastern Orthodox Churches (such as the Russian Orthodox Church). The Eastern Orthodox hold a common doctrine and a common form of worship, and they see themselves not as separate Churches but as administrative units of one single Church. They are notable for their extensive tradition of iconography (: Byzantine art), for their veneration of the Mother of God and the Saints, and for their use of the Divine Liturgy on Sundays, which is a standardized worship service dating back to the fourth century A.D. in its current form. The most commonly used Divine Liturgy of the Orthodox Church was written by Saint John Chrysostom (347–407 A.D.). Others, are attributed to St. Basil the Great, St. James, the Brother of God and St. Gregory the Dialogist</p><p>The current territory of the Greek Orthodox Churches more or less covers the areas in the Balkans, Anatolia, and the Eastern Mediterranean that used to be a part of the Byzantine Empire. The majority of Greek Orthodox Christians live within Greece and elsewhere in the southern Balkans (especially in Albania), but also in Lebanon, Cyprus, Anatolia, European Turkey, and the South Caucasus. In addition, due to the large Greek diaspora, there are many Greek Orthodox Christians who live in North America and Australia. Orthodox Christians in Finland, who compose about 1% of the population, are also under the jurisdiction of a Greek Orthodox Church (the Ecumenical Patriarchate).</p><p>There are also many Greek Orthodox Christians, with origins dating back to the Byzantine and Ottoman periods, who are of Arabic-speaking or mixed Greek and Arabic-speaking ancestry and live in southern Turkey, Israel, Palestine, Iraq, Syria, Lebanon, Jordan, and Egypt. They attend churches which conduct their services in Arabic, the common language of most Greek Orthodox believers in the Levant, while at the same time maintaining elements of the Byzantine Greek cultural tradition.</p><p>Ethnic Greeks in Russia and Greeks in Ukraine, as well as Pontic Greeks and Caucasus Greeks from the former Russian Transcaucasus, often consider themselves both Greek Orthodox and Russian Orthodox, which is consistent with the Orthodox faith (since Orthodoxy is the same across ethnic boundaries). Thus, they may attend services held in Old Russian and Old Church Slavonic, without this in any way undermining their Orthodox faith or distinct Greek ethnic identity. Over the centuries, these Pontic Greek-speaking Greek Orthodox communities have mixed through intermarriage in varying degrees with ethnic Russians and other Orthodox Christians from mainly Southern Russia, where most of them settled between the Middle Ages and early 19th century.</p><div class="gradientback"></div></div><div class="content"><h2>Churches</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/4/48/Orthodox_cross_procession_Corfu_Easter_2014.jpg/200px-Orthodox_cross_procession_Corfu_Easter_2014.jpg" width="200" height="134"><p>


				A religious procession in Corfu



				<br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/3/33/Agios_Stephanos_Kirche_%28Lesbos%29_03.jpg/200px-Agios_Stephanos_Kirche_%28Lesbos%29_03.jpg" width="200" height="132"><br>


				Saint Therapon (Mytilene)


				</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/3/33/Agios_Stephanos_Kirche_%28Lesbos%29_03.jpg/200px-Agios_Stephanos_Kirche_%28Lesbos%29_03.jpg" width="200" height="132"><br><p>
					The churches where the Greek Orthodox term is applicable are:</p><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Greek_Orthodox_Church&amp;oldid=783198527"					
								Categories:  Hidden categories:</p><br><h1 lang="en">Unitary state</h1><p> From Wikipedia, the free encyclopedia</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/4/46/Map_of_unitary_and_federal_states.svg/370px-Map_of_unitary_and_federal_states.svg.png" width="370" height="190"><p>


				&nbsp;&nbsp;Unitary states
				&nbsp;&nbsp;Federations




				<br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/d/da/The_pathway_of_regional_integration_or_separation.png/330px-The_pathway_of_regional_integration_or_separation.png" width="330" height="91"><br>


				The pathway of regional integration or separation


				 
				</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/d/da/The_pathway_of_regional_integration_or_separation.png/330px-The_pathway_of_regional_integration_or_separation.png" width="330" height="91"><br><p>
					A unitary state is a state governed as a single power in which the central government is ultimately supreme and any administrative divisions (sub-national units) exercise only the powers that the central government chooses to delegate. The majority of states in the world have a unitary system of government. Of the 192 UN member states, 165 are governed as unitary states.</p><p>In a unitary state, sub-national units are created and abolished (an example being the 22 mainland regions of France being merged into 13), and their powers may be broadened and narrowed, by the central government. Although political power may be delegated through devolution to local governments by statute, the central government remains supreme; it may abrogate the acts of devolved governments or curtail their powers.</p><p>The United Kingdom of Great Britain and Northern Ireland is an example of a unitary state. Scotland, Wales and Northern Ireland have a degree of autonomous devolved power, but such power is delegated by the Parliament of the United Kingdom, which may enact laws unilaterally altering or abolishing devolution (England does not have any devolved power).[1] Many unitary states have no areas possessing a degree of autonomy. In such countries, sub-national regions cannot decide their own laws. Examples are the Republic of Ireland and the Kingdom of Norway.[2] In federal states, the sub-national governments share powers with the central government as equal actors through a written constitution, to which the consent of both is required to make amendments. This means that the sub-national units have a right of existence and powers that cannot be unilaterally changed by the central government.</p><p>Unitary states are contrasted with federations. An example of a federation is the United States of America. Under the U.S. Constitution, powers are shared between the federal government and the states. Its Article V states that the approval of three-quarters of the states, in either their legislatures or state ratifying conventions, must be attained for an amendment to take effect, giving the states a strong degree of protection from domination by the centre.[3]</p><h2>Contents</h2><h2>List of unitary states</h2><p>Italics: States with limited recognition</p><h3>Unitary republics</h3><h3>Unitary monarchies</h3><h3>5 largest unitary states by nominal GDP</h3><h3>5 largest unitary states by population</h3><h3>5 largest unitary states by area</h3><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Unitary_state&amp;oldid=781394099"					
								Categories:  Hidden categories:</p><br><br><img alt="Page protected with pending changes level 1" src="http://upload.wikimedia.org/wikipedia/en/thumb/2/28/Padlock-silver-light.svg/20px-Padlock-silver-light.svg.png" width="20" height="20"><h1 lang="en">Republic</h1><p> From Wikipedia, the free encyclopedia</p><br><img src="http:/w/extensions/FlaggedRevs/frontend/modules/img/doc-magnify.png" alt="Changes must be reviewed before being displayed on this page." title="Changes must be reviewed before being displayed on this page."><div class="gradientback"></div></div><div class="content"><br><img src="http:/w/extensions/FlaggedRevs/frontend/modules/img/arrow-down.png" style="display: none;" alt="show/hide details"><p> This article is about the form of government. For the political ideology, see Republicanism. For other uses, see Republic (disambiguation).</p><p>A republic (Latin: res publica) is a form of government in which the country is considered a public matter – not the private concern or property of the rulers – and where offices of state are elected or appointed, rather than inherited. It is a government where the head of state is not a monarch.[1][2][3]</p><p>In American English, the definition of a republic can also refer specifically to a government in which elected individuals represent the citizen body, known elsewhere as a representative democracy (a democratic republic),[4] and exercise power according to the rule of law (a constitutional republic).[5][6][2]</p><p>As of 2017[update], 159 of the world's 206 sovereign states use the word republic as part of their official names; not all of these are republics in the sense of having elected governments, nor do all nations with elected governments use the word republic in their names.</p><p>Both modern and ancient republics vary widely in their ideology, composition, and practicality. In the classical and medieval period of Europe, many states were fashioned on the Roman Republic, which referred to the governance of the city of Rome, between it having kings and emperors. The Italian medieval and Renaissance political tradition, today referred to as civic humanism, is sometimes considered to derive directly from Roman republicans such as Sallust and Tacitus. However, Greek-influenced Roman authors, such as Polybius[7] and Cicero, sometimes also used the term as a translation for the Greek politeia which could mean regime generally, but could also be applied to certain specific types of regime that did not exactly correspond to that of the Roman Republic. Republics were not equated with classical democracies such as Athens, but had a democratic aspect.</p><p>Republics became more common in the Western world starting in the late 18th century, eventually displacing absolute monarchy as the most common form of government in Europe. In modern republics, the executive is legitimized both by a constitution and by popular suffrage. In his work, The Spirit of the Laws, Montesquieu classified both democracies, where all the people have a share in rule, and aristocracies, where only some of the people rule, as republican forms of government.[8]</p><p>Most often a republic is a single sovereign state, but there are also sub-sovereign state entities that are referred to as republics, or that have governments that are described as 'republican' in nature. For instance, Article IV of the United States Constitution guarantee[s] to every State in this Union a Republican form of Government.[9] In contrast, the Soviet Union was constitutionally described as a federal multinational state, composed of 15 republics, two of which – Ukraine and Belarus – had their own seats at the United Nations.</p><h2>Contents</h2><h2>Etymology</h2><p>The term originates as the Latin translation of Greek word politeia. Cicero, among other Latin writers, translated politeia as res publica and it was in turn translated by Renaissance scholars as republic (or similar terms in various western European languages).[citation needed]</p><p>The term politeia can be translated as form of government, polity, or regime, and is therefore not always a word for a specific type of regime as the modern word republic is. (One of Plato's major works on political science was titled Politeia and in English it is thus known as The Republic. However, apart from the title, in modern translations of The Republic, alternative translations of politeia are also used.[10]) However, in Book III of his Politics (1279a), Aristotle was apparently the first classical writer to state that the term politeia can be used to refer more specifically to one type of politeia: When the citizens at large govern for the public good, it is called by the name common to all governments (to koinon onoma pason ton politeion), government (politeia). And also amongst classical Latin, the term republic can be used in a general way to refer to any regime, or in a specific way to refer to governments which work for the public good.[citation needed]</p><p>In medieval Northern Italy, a number of city states had commune or signoria based governments. In the late Middle Ages, writers, such as Giovanni Villani, began writing about the nature of these states and the differences from other types of regime. They used terms such as libertas populi, a free people, to describe the states. The terminology changed in the 15th century as the renewed interest in the writings of Ancient Rome caused writers to prefer using classical terminology. To describe non-monarchical states writers, most importantly Leonardo Bruni, adopted the Latin phrase res publica.[11]</p><p>While Bruni and Machiavelli used the term to describe the states of Northern Italy, which were not monarchies, the term res publica has a set of interrelated meanings in the original Latin. The term can quite literally be translated as public matter.[12] It was most often used by Roman writers to refer to the state and government, even during the period of the Roman Empire.[13]</p><p>In subsequent centuries, the English word commonwealth came to be used as a translation of res publica, and its use in English was comparable to how the Romans used the term res publica.[14] Notably, during The Protectorate of Oliver Cromwell the word commonwealth was the most common term to call the new monarchless state, but the word republic was also in common use.[15] Likewise, in Polish, the term was translated as rzeczpospolita, although the translation is now only used with respect to Poland.</p><p>Presently, the term republic commonly means a system of government which derives its power from the people rather than from another basis, such as heredity or divine right.[citation needed]</p><h2>History</h2><p>While the philosophical terminology developed in classical Greece and Rome, as already noted by Aristotle there was already a long history of city states with a wide variety of constitutions, not only in Greece but also in the Middle East. After the classical period, during the Middle Ages, many free cities developed again, such as Venice.</p><h3>Classical republics</h3><p> Main article: Classical republic</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/c/c9/Republica_Romana.svg/200px-Republica_Romana.svg.png" width="200" height="130"><p>


				A map of the Roman Republic


				</p><p>
					The modern type of republic itself is different from any type of state found in the classical world.[16][17] Nevertheless, there are a number of states of the classical era that are today still called republics. This includes ancient Athens, Sparta and the Roman Republic. While the structure and governance of these states was very different from that of any modern republic, there is debate about the extent to which classical, medieval, and modern republics form a historical continuum. J. G. A. Pocock has argued that a distinct republican tradition stretches from the classical world to the present.[12][18] Other scholars disagree.[12] Paul Rahe, for instance, argues that the classical republics had a form of government with few links to those in any modern country.[19]</p>
				<div class="gradientback"></div></div><div class="content">
				<p>Elam (/'i?l?m/) was an ancient Pre-Iranian civilization centered in the far West and Southwest of what is now modern-day Iran, stretching from the lowlands of what is now Khuzestan and Ilam Province as well as a small part of southern Iraq. The modern name Elam stems from the Sumerian transliteration elam(a), along with the later Akkadian elamtu, and the Elamite haltamti. Elamite states were among the leading political forces of the Ancient Near East.[1] In classical literature, Elam was also known as Susiana, which is a name derived from its capital, Susa.[2]</p><p>Elam was part of the early urbanization during the Chalcolithic period (Copper Age). The emergence of written records from around 3000 BC also parallels Sumerian history, where slightly earlier records have been found.[3][4] In the Old Elamite period (Middle Bronze Age), Elam consisted of kingdoms on the Iranian plateau, centered in Anshan, and from the mid-2nd millennium BC, it was centered in Susa in the Khuzestan lowlands.[5] Its culture played a crucial role during the Persian Achaemenid dynasty that succeeded Elam, when the Elamite language remained among those in official use. Elamite is generally accepted to be a language isolate unrelated to the much later arriving Persian and Iranic languages. In accordance with geographical and archaeological matches, some historians argue that the Elamites comprise a large portion of the ancestors of the modern day Lurs,[6][7] whose language, Luri, split from Middle Persian.</p><h2>Contents</h2><h2>Etymology</h2><p>The Elamites called their country Haltamti,[8] Sumerian ELAM, Akkadian Elamû, female Elamitu resident of Susiana, Elamite.[9]</p><p>The Elamite civilization was primarily centered in the province of what is modern-day Khuzestan and Ilam in prehistoric times. The modern provincial name Khuzestan is derived from the Persian name for Susa: Old Persian Hujiya Elam (Old Persian: ????????????),[8] in Middle Persian Huz Susiana, which gave modern Persian Xuz, compounded with -stån place (cf. Sistan Saka-land).</p><h2>Geography</h2><p>In geographical terms, Susiana basically represents the Iranian province of Khuzestan around the river Karun. In ancient times, several names were used to describe this area. The great ancient geographer Ptolemy was the earliest to call the area Susiana, referring to the country around Susa.</p><p>Another ancient geographer, Strabo, viewed Elam and Susiana as two different geographical regions. He referred to Elam (land of the Elymaei) as primarily the highland area of Khuzestan.[10]</p><p>Disagreements over the location also exist in the Jewish historical sources says Daniel T. Potts. Some ancient sources draw a distinction between Elam as the highland area of Khuzestan, and Susiana as the lowland area. Yet in other ancient sources 'Elam' and 'Susiana' seem equivalent.[10]</p><p>The uncertainty in this area extends also to modern scholarship. Since the discovery of ancient Anshan, and the realization of its great importance in Elamite history, the definitions were changed again. Some modern scholars[11] argued that the centre of Elam lay at Anshan and in the highlands around it, and not at Susa in lowland Khuzistan.</p><p>Potts disagrees suggesting that the term 'Elam' was primarily constructed by the Mesopotamians to describe the area in general terms, without referring specifically either to the lowlanders or the highlanders,</p><p>Elam is not an Iranian term and has no relationship to the conception which the peoples of highland Iran had of themselves. They were Anshanites, Marhashians, Shimashkians, Zabshalians, Sherihumians, Awanites, etc. That Anshan played a leading role in the political affairs of the various highland groups inhabiting southwestern Iran is clear. But to argue that Anshan is coterminous with Elam is to misunderstand the artificiality and indeed the alienness of Elam as a construct imposed from without on the peoples of the southwestern highlands of the Zagros mountain range, the coast of Fars and the alluvial plain drained by the Karun-Karkheh river system.[12]</p><h2>History</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/8/84/Pre-Achaemenid_Era.gif/350px-Pre-Achaemenid_Era.gif" width="350" height="267"><p>


				Timeline of Elam.


				</p><p>
					Knowledge of Elamite history remains largely fragmentary, reconstruction being based on mainly Mesopotamian (Sumerian, Akkadian, Assyrian and Babylonian) sources. The history of Elam is conventionally divided into three periods, spanning more than two millennia. The period before the first Elamite period is known as the proto-Elamite period:</p><h3>Proto-Elamite</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/1/12/Elam_Map.jpg" width="300" height="250"><p>Proto-Elamite civilization grew up east of the Tigris and Euphrates alluvial plains; it was a combination of the lowlands and the immediate highland areas to the north and east. At least three proto-Elamite states merged to form Elam: Anshan (modern Khuzestan Province), Awan (modern Lorestan Province) and Shimashki (modern Kerman). References to Awan are generally older than those to Anshan, and some scholars suggest that both states encompassed the same territory, in different eras (see Hanson, Encyclopædia Iranica). To this core Shushiana (modern Khuzestan) was periodically annexed and broken off. In addition, some Proto-Elamite sites are found well outside this area, spread out on the Iranian plateau; such as Warakshe, Sialk (now a suburb of the modern city of Kashan) and Jiroft[13] in Kerman Province. The state of Elam was formed from these lesser states as a response to invasion from Sumer during the Old Elamite period. Elamite strength was based on an ability to hold these various areas together under a coordinated government that permitted the maximum interchange of the natural resources unique to each region. Traditionally, this was done through a federated governmental structure.</p><div class="gradientback"></div></div><div class="content"><p>The Proto-Elamite city of Susa was founded around 4000 BC in the watershed of the river Karun. It is considered to be the site of Proto-Elamite cultural formation. During its early history, it fluctuated between submission to Mesopotamian and Elamite power. The earliest levels (22—17 in the excavations conducted by Le Brun, 1978) exhibit pottery that has no equivalent in Mesopotamia, but for the succeeding period, the excavated material allows identification with the culture of Sumer of the Uruk period. Proto-Elamite influence from the Mesopotamia in Susa becomes visible from about 3200 BC, and texts in the still undeciphered Proto-Elamite writing system continue to be present until about 2700 BC. The Proto-Elamite period ends with the establishment of the Awan dynasty. The earliest known historical figure connected with Elam is the king Enmebaragesi of Kish (c. 2650 BC?), who subdued it, according to the Sumerian king list. Elamite history can only be traced from records dating to beginning of the Akkadian Empire (2335-2154 BC) onwards.</p><p>The Proto-Elamite states in Jiroft and Zabol (not universally accepted), present a special case because of their great antiquity. Archaeologists have suggested that a close relationship between the Jiroft civilisation and the Elamite civilisation is evidenced by striking similarities in art and culture, as well as by Elamite language writings found in Jiroft—possibly extending the Elamite presence to as early as 7000 BC.[citation needed]</p><p>In ancient Luristan, bronze-making tradition goes back to the mid–3rd millennium B.C, and has many Elamite connections. Bronze objects from several cemeteries in the region date to the Early Dynastic Period (Mesopotamia) I, and to Ur-III period c. 2900–2000 B.C. These excavations include Kalleh Nisar, Bani Surmah, Chigha Sabz, Kamtarlan, Sardant, and Gulal-i Galbi.[14]</p><h3>Old Elamite period</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/e/e7/Tchogha_Zanbil.jpg/220px-Tchogha_Zanbil.jpg" width="220" height="56"><p>


				The current Chogha Zanbil ziggurat site, showing the vicinity of the main structure as well



				<br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/c/c4/Untash_Napirisha_stele_Louvre_Sb12.jpg/220px-Untash_Napirisha_stele_Louvre_Sb12.jpg" width="220" height="335"><br>


				Relief resembles a fish tailed woman holding snakes



				<br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/4/4a/Woman_spinning-Sb_2834-IMG_0921-black.jpg/220px-Woman_spinning-Sb_2834-IMG_0921-black.jpg" width="220" height="220"><br>


				Relief of a woman being fanned by an attendant while she holds what may be a spinning device before a table with a bowl containing a whole fish



				<br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/5/5c/Goatfishes_Louvre_Sb19.jpg/220px-Goatfishes_Louvre_Sb19.jpg" width="220" height="146"><br>


				An ornate design on this limestone ritual vat from the Middle Elamite period depicts creatures with the heads of goats and the tails of fish



				<br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/7/7a/Susa-destruction.jpg/220px-Susa-destruction.jpg" width="220" height="253"><br>


				Ashurbanipal's campaign against Susa is triumphantly recorded in this relief showing the sack of Susa in 647 BC. Here, flames rise from the city as Assyrian soldiers topple it with pickaxes and crowbars and carry off the spoils.



				<br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/3/36/Elam_cool.jpg/220px-Elam_cool.jpg" width="220" height="383"><br>


				Silver cup with linear-Elamite inscription on it. Late 3rd millennium BC. National Museum of Iran.


				</p><div class="gradientback"></div></div><div class="content"><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/c/c4/Untash_Napirisha_stele_Louvre_Sb12.jpg/220px-Untash_Napirisha_stele_Louvre_Sb12.jpg" width="220" height="335"><br><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/4/4a/Woman_spinning-Sb_2834-IMG_0921-black.jpg/220px-Woman_spinning-Sb_2834-IMG_0921-black.jpg" width="220" height="220"><br><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/5/5c/Goatfishes_Louvre_Sb19.jpg/220px-Goatfishes_Louvre_Sb19.jpg" width="220" height="146"><br><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/7/7a/Susa-destruction.jpg/220px-Susa-destruction.jpg" width="220" height="253"><br><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/3/36/Elam_cool.jpg/220px-Elam_cool.jpg" width="220" height="383"><br><p>
					The Old Elamite period began around 2700 BC. Historical records mention the conquest of Elam by Enmebaragesi the Sumerian king of Kish in Mesopotamia. Three dynasties ruled during this period. We know of twelve kings of each of the first two dynasties, those of Awan (or Avan; c. 2400 – c. 2100) and Simashki (c. 2100 – c. 1970), from a list from Susa dating to the Old Babylonian period. Two Elamite dynasties said to have exercised brief control over parts of Sumer in very early times include Awan and Hamazi; and likewise, several of the stronger Sumerian rulers, such as Eannatum of Lagash and Lugal-anne-mundu of Adab, are recorded as temporarily dominating Elam.</p><p>The Avan dynasty was partly contemporary with that of the Mesopotamian emperor Sargon of Akkad, who not only defeated the Awan king Luhi-ishan and subjected Susa, but attempted to make the East Semitic Akkadian the official language there. From this time, Mesopotamian sources concerning Elam become more frequent, since the Mesopotamians had developed an interest in resources (such as wood, stone, and metal) from the Iranian plateau, and military expeditions to the area became more common. With the collapse of Akkad under Sargon's great great-grandson, Shar-kali-sharri, Elam declared independence under the last Avan king, Kutik-Inshushinak (c. 2240 – c. 2220), and threw off the Akkadian language, promoting in its place the brief Linear Elamite script. Kutik-Inshushinnak conquered Susa and Anshan, and seems to have achieved some sort of political unity. Following his reign, the Awan dynasty collapsed as Elam was temporarily overrun by the Guti, another pre-Iranic people from what is now north west Iran who also spoke a language isolate.</p><p>About a century later, the Sumerian king Shulgi of the Neo-Sumerian Empire retook the city of Susa and the surrounding region. During the first part of the rule of the Simashki dynasty, Elam was under intermittent attack from the Sumerians of Mesopotamia and also Gutians from northwestern Iran, alternating with periods of peace and diplomatic approaches. The Elamite state of Simashki at this time also extended into northern Iran, and possibly even as far as the Caspian Sea. Shu-Sin of Ur gave one of his daughters in marriage to a prince of Anshan. But the power of the Sumerians was waning; Ibbi-Sin in the 21st century did not manage to penetrate far into Elam, and in 2004 BC, the Elamites, allied with the people of Susa and led by king Kindattu, the sixth king of Simashki, managed to sack Ur and lead Ibbi-Sin into captivity, ending the third dynasty of Ur. The Akkadian kings of Isin, successor state to Ur, managed to drive the Elamites out of Ur, rebuild the city, and to return the statue of Nanna that the Elamites had plundered.</p><p>The succeeding dynasty, the Eparti (c. 1970 – c. 1770), also called of the sukkalmahs after the title borne by its members, was roughly contemporary with the Old Assyrian Empire, and Old Babylonian period in Mesopotamia, being younger by approximately sixty years than the Akkadian speaking Old Assyrian Empire in Upper Mesopotamia, and almost seventy-five years older than the Old Babylonian Empire. This period is confusing and difficult to reconstruct. It was apparently founded by Eparti I. During this time, Susa was under Elamite control, but Akkadian speaking Mesopotamian states such as Larsa and Isin continually tried to retake the city. Around 1850 BC Kudur-mabuk, apparently king of another Akkadian state to the north of Larsa, managed to install his son, Warad-Sin, on the throne of Larsa, and Warad-Sin's brother, Rim-Sin, succeeded him and conquered much of southern Mesopotamia for Larsa.</p><p>Notable Eparti dynasty rulers in Elam during this time include Sirukdukh (c. 1850), who entered various military coalitions to contain the power of the south Mesopotamian states; Siwe-Palar-Khuppak, who for some time was the most powerful person in the area, respectfully addressed as Father by Mesopotamian kings such as Zimrilim of Mari, Shamshi-Adad I of Assyria, and even Hammurabi of Babylon; and Kudur-Nahhunte, who plundered the temples of southern Mesopotamia, the north being under the control of the Old Assyrian Empire. But Elamite influence in southern Mesopotamia did not last. Around 1760 BC, Hammurabi drove out the Elamites, overthrew Rim-Sin of Larsa, and established a short lived Babylonian Empire in Mesopotamia. Little is known about the latter part of this dynasty, since sources again become sparse with the Kassite rule of Babylon (from c. 1595).</p><h3>Middle Elamite period</h3><p>The Middle Elamite period began with the rise of the Anshanite dynasties around 1500 BC. Their rule was characterized by an Elamisation of Susa, and the kings took the title king of Anshan and Susa. While the first of these dynasties, the Kidinuids continued to use the Akkadian language frequently in their inscriptions, the succeeding Igihalkids and Shutrukids used Elamite with increasing regularity. Likewise, Elamite language and culture grew in importance in Susiana. The Kidinuids (c. 1500 – 1400) are a group of five rulers of uncertain affiliation. They are identified by their use of the older title, king of Susa and of Anshan, and by calling themselves servant of Kirwashir, an Elamite deity, thereby introducing the pantheon of the highlands to Susiana.</p><p>Of the Igehalkids (c. 1400 – 1210), ten rulers are known, and there were possibly more. Some of them married Kassite princesses. The Kassites were also a Language Isolate speaking people from the Zagros Mountains who had taken Babylonia shortly after its sacking by the Hittite Empire in 1595 BC. The Kassite king of Babylon Kurigalzu II who had been installed on the throne by Ashur-uballit I of the Middle Assyrian Empire (1366–1020 BC), temporarily occupied Elam around 1320 BC, and later (c. 1230) another Kassite king, Kashtiliash IV, fought Elam unsuccessfully. Kassite-Babylonian power waned, as they became dominated by the northern Mesopotamian Middle Assyrian Empire. Kiddin-Khutran of Elam repulsed the Kassites by defeating Enlil-nadin-shumi in 1224 BC and Adad-shuma-iddina around 1222–1217. Under the Igehalkids, Akkadian inscriptions were rare, and Elamite highland gods became firmly established in Susa.</p><p>Under the Shutrukids (c. 1210 – 1100), the Elamite empire reached the height of its power. Shutruk-Nakhkhunte and his three sons, Kutir-Nakhkhunte II, Shilhak-In-Shushinak, and Khutelutush-In-Shushinak were capable of frequent military campaigns into Kassite Babylonia (which was also being ravaged by the empire of Assyria during this period), and at the same time were exhibiting vigorous construction activity—building and restoring luxurious temples in Susa and across their Empire. Shutruk-Nakhkhunte raided Babylonia, carrying home to Susa trophies like the statues of Marduk and Manishtushu, the Manishtushu Obelisk, the Stele of Hammurabi and the stele of Naram-Sin. In 1158 BC, after much of Babylonia had been annexed by Ashur-Dan I of Assyria and Shutruk-Nakhkhunte, the Elamites defeated the Kassites permanently, killing the Kassite king of Babylon, Zababa-shuma-iddin, and replacing him with his eldest son, Kutir-Nakhkhunte, who held it no more than three years before being ejected by the native Akkadian speaking Babylonians. The Elamites then briefly came into conflict with Assyria, managing to take the Assyrian city of Arrapha (modern Kirkuk) before being ultimately defeated and having a treaty forced upon them by Ashur-Dan I.</p><p>Kutir-Nakhkhunte's son Khutelutush-In-Shushinak was probably of an incestuous relation of Kutir-Nakhkhunte's with his own daughter, Nakhkhunte-utu.[citation needed] He was defeated by Nebuchadnezzar I of Babylon, who sacked Susa and returned the statue of Marduk, but who was then himself defeated by the Assyrian king Ashur-resh-ishi I. He fled to Anshan, but later returned to Susa, and his brother Shilhana-Hamru-Lagamar may have succeeded him as last king of the Shutrukid dynasty. Following Khutelutush-In-Shushinak, the power of the Elamite empire began to wane seriously, for after the death of this ruler, Elam disappears into obscurity for more than three centuries.</p><h3>Neo-Elamite period</h3><p>Very little is known of this period. Anshan was still at least partially Elamite. There appear to have been unsuccessful alliances of Elamites, Babylonians, Chaldeans and other peoples against the powerful Neo Assyrian Empire (911-605 BC); the Babylonian king Mar-biti-apla-ushur (984–979) was of Elamite origin, and Elamites are recorded to have fought unsuccessfully with the Babylonian king Marduk-balassu-iqbi against the Assyrian forces under Shamshi-Adad V (823–811).</p><div class="gradientback"></div></div><div class="content"><p>The later Neo-Elamite period is characterized by a significant migration of Indo-European speaking Iranians to the Iranian plateau. Assyrian sources beginning around 800 BC distinguish the powerful Medes, i.e. the actual Medes, Persians, (Parthians, Sagartians, Margians, Bactrians, Sogdians etc.). Among these pressuring tribes were the Parsu, first recorded in 844 BC as living on the southeastern shore of Lake Urmiah, but who by the end of this period would cause the Elamites' original home, the Iranian Plateau, to be renamed Persia proper. These newly arrived Iranian peoples were also conquered by Assyria, and largely regarded as vassals of the Neo-Assyrian Empire until the late 7th century.</p><p>More details are known from the late 8th century BC, when the Elamites were allied with the Chaldean chieftain Merodach-baladan to defend the cause of Babylonian independence from Assyria. Khumbanigash (743–717) supported Merodach-baladan against Sargon II, apparently without success; while his successor, Shutruk-Nakhkhunte II (716–699), was routed by Sargon's troops during an expedition in 710, and another Elamite defeat by Sargon's troops is recorded for 708. The Assyrian dominion over Babylon was underlined by Sargon's son Sennacherib, who defeated the Elamites, Chaldeans and Babylonians and dethroned Merodach-baladan for a second time, installing his own son Ashur-nadin-shumi on the Babylonian throne in 700.</p><p>Shutruk-Nakhkhunte II, the last Elamite to claim the old title king of Anshan and Susa, was murdered by his brother Khallushu, who managed to briefly capture the Assyrian governor of Babylonia Ashur-nadin-shumi and the city of Babylon in 694 BC. Sennacherib soon responded by invading and ravaging Elam. Khallushu was in turn assassinated by Kutir-Nakhkhunte, who succeeded him but soon abdicated in favor of Khumma-Menanu III (692–689). Khumma-Menanu recruited a new army to help the Babylonians and Chaldeans against the Assyrians at the battle of Halule in 691. Both sides claimed the victory in their annals, but Babylon was destroyed by Sennacherib only two years later, and its Elamite allies defeated in the process.</p><p>The reigns of Khumma-Khaldash I (688–681) and Khumma-Khaldash II (680–675) saw a deterioration of Elamite-Babylonian relations, and both of them raided Sippar. At the beginning of Esarhaddon's reign in Assyria (681–669), Nabu-zer-kitti-lišir, an ethnically Elamite governor in the south of Babylonia, revolted and besieged Ur, but was routed by the Assyrians and fled to Elam where the king of Elam, fearing Assyrian repercussions, took him prisoner and put him to the sword (ABC 1 Col.3:39–42).</p><p>Urtaku (674–664) for some time wisely maintained good relations with the Assyrian king Ashurbanipal (668–627), who sent wheat to Susiana during a famine. But these friendly relations were only temporary, and Urtaku was killed in battle during a failed Elamite attack on Assyria.</p><p>His successor Tempti-Khumma-In-Shushinak (664–653) attacked Assyria, but was defeated and killed by Ashurbanipal following the battle of the Ulaï in 653 BC; and Susa itself was sacked and occupied by the Assyrians. In this same year the Assyrian vassal Median state to the north fell to the invading Scythians and Cimmerians under Madius, and displacing another Assyrian vassal people, the Parsu (Persians) to Anshan which their king Teispes captured that same year, turning it for the first time into an Indo-Iranian kingdom under Assyrian dominance that would a century later become the nucleus of the Achaemenid dynasty. The Assyrians successfully subjugated and drove the Scythians and Cimmerians from their Iranian colonies, and the Persians, Medes and Parthians remained vassals of Assyria.</p><p>During a brief respite provided by the civil war between Ashurbanipal and his own brother Shamash-shum-ukin whom their father Esarhaddon had installed as the vassal king of Babylon, the Elamites both gave support to Shamash-shum-ukin, and indulged in fighting among themselves, so weakening the Elamite kingdom that in 646 BC Ashurbanipal devastated Susiana with ease, and sacked Susa. A succession of brief reigns continued in Elam from 651 to 640, each of them ended either due to usurpation, or because of capture of their king by the Assyrians. In this manner, the last Elamite king, Khumma-Khaldash III, was captured in 640 BC by Ashurbanipal, who annexed and destroyed the country.[15]</p><p>In a tablet unearthed in 1854 by Henry Austin Layard, Ashurbanipal boasts of the destruction he had wrought:</p><p>The devastation was a little less complete than Ashurbanipal boasted, and a weak and fragmented Elamite rule was resurrected soon after with Shuttir-Nakhkhunte, son of Humban-umena III (not to be confused with Shuttir-Nakhkhunte, son of Indada, a petty king in the first half of the 6th century). Elamite royalty in the final century preceding the Achaemenids was fragmented among different small kingdoms, the united Elamite nation having been destroyed and colonised by the Assyrians. The three kings at the close of the 7th century (Shuttir-Nakhkhunte, Khallutush-In-Shushinak and Atta-Khumma-In-Shushinak) still called themselves king of Anzan and of Susa or enlarger of the kingdom of Anzan and of Susa, at a time when the Achaemenid Persians were already ruling Anshan under Assyrian dominance.</p><p>The various Assyrian Empires, which had been the dominant force in the Near East, Asia Minor, the Caucasus, North Africa, Arabian peninsula and East Mediterranean for much of the period from the first half of the 14th century BC, began to unravel after the death of Ashurbanipal in 627 BC, descending into a series of bitter internal civil wars which also spread to Babylonia. The Iranian Medes, Parthians, Persians and Sagartians who had been largely subject to Assyria since their arrival in the region around 1000 BC, quietly took full advantage of the anarchy in Assyria, and in 616 BC freed themselves from Assyrian rule.</p><p>The Medians took control of Elam during this period. Cyaxares the king of the Medes, Persians, Parthians and Sagartians entered into an alliance with a coalition of fellow former vassals of Assyria; Nabopolassar of Babylon and Chaldea, and also the Scythians and Cimmerians against Sin-shar-ishkun of Assyria, who was faced with unremitting civil war in Assyria itself. This alliance then attacked a disunited and war weakened Assyria, and between 616 BC and 599 BC at the very latest, had conquered its vast empire which stretched from the Caucasus Mountains to Egypt, Libya and the Arabian Peninsula, and from Cyprus and Ephesus to Persia and the Caspian Sea.</p><p>The major cities in Assyria itself were gradually taken; Arrapha (modern Kirkuk and Kalhu (modern Nimrud) in 616, Ashur, Dur-Sharrukin and Arbela (modern Erbil) in 613, Nineveh falling in 612, Harran in 608 BC, Carchemish in 605 BC, and finally Dur-Katlimmu by 599 BC. Elam, already largely destroyed and subjugated by Assyria, thus became easy prey for the Median dominated Iranian peoples, and was incorporated into the Median Empire (612-546 BC) and then the succeeding Achaemenid Empire (546-332 BC), with Assyria suffering the same fate. (see Achaemenid Assyria, Athura).[17]</p><p>The prophet Ezekiel describes the status of their power in the 12th year of the Hebrew Babylonian Captivity in 587 BC:</p><p>Their successors Khumma-Menanu and Shilhak-In-Shushinak II bore the simple title king, and the final king Tempti-Khumma-In-Shushinak used no honorific at all. In 540 BC, Achaemenid rule began in Susa.</p><h2>Religion</h2><p> Main article: Matriarchal religion</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/d/d9/Two_horned_elam.jpg/170px-Two_horned_elam.jpg" width="170" height="325"><div class="gradientback"></div></div><div class="content"><p>


				A "two-horned" figure wrestling with serpent goddesses. The Elamite artifact was discovered by Iran's border police in the possession of historical heritage traffickers, en route to Turkey, and was confiscated. Style is determined to be from "Jiroft".[citation needed]


				</p><p>
					The Elamites practised polytheism. Knowledge about their religion is scant, but, according to Cambridge Ancient History, at one time they had a pantheon headed by the goddess Kiririsha/Pinikir.[19] Other deities included In-shushinak and Jabru, lord of the underworld. According to Cambridge Ancient History, this predominance of a supreme goddess is probably a reflexion from the practice of matriarchy which at all times characterized Elamite civilization to a greater or lesser degree.[19]</p><h2>Language</h2><p> Main articles: Elamite language and Origin of the name Khuzestan</p><p>Elamite is traditionally thought to be a language isolate, and completely unrelated to the neighbouring Semitic, Sumerian (also an isolate), and the later Indo-European Iranian languages that came to dominate the region. It was written in a cuneiform adapted from the Semitic Akkadian script of Assyria and Babylonia, although the very earliest documents were written in the quite different Linear Elamite script. In 2006, two even older inscriptions in a similar script were discovered at Jiroft to the east of Elam, leading archaeologists to speculate that Linear Elamite had originally spread from further east to Susa. It seems to have developed from an even earlier writing known as proto-Elamite, but scholars are not unanimous on whether or not this script was used to write Elamite or another language, as it has not yet been deciphered. Several stages of the language are attested; the earliest date back to the third millennium BC, the latest to the Achaemenid Empire.</p><p>The Elamite language may have survived as late as the early Islamic period (roughly contemporary with the early medieval period in Europe). Among other Islamic medieval historians, Ibn al-Nadim, for instance, wrote that The Iranian languages are Fahlavi (Pahlavi), Dari (not to be confused with Dari Persian in modern Afghanistan), Khuzi, Persian and Suryani (Assyrian), and Ibn Moqaffa noted that Khuzi was the unofficial language of the royalty of Persia, Khuz being the corrupted name for Elam.</p><h3>Suggested relations to other language families</h3><p>A minority of scholars have proposed that the Elamite language could be related to the Munda Language of India, some to Mon–Khmer of Cambodia and some to the modern Dravidian languages of India and Sri Lanka such as Tamil and Malayalam,[20] in contrast to the majority who denote it as a language isolate.[21] David McAlpine believes Elamite may be related to the living Dravidian languages. This hypothesis is considered under the rubric of Elamo-Dravidian languages.</p><h2>Legacy</h2><p>The Assyrians had utterly destroyed the Elamite nation, but new polities emerged in the area after Assyrian power faded. Among the nations that benefited from the decline of the Assyrians were the Iranian tribes, whose presence around Lake Urmia to the north of Elam is attested from the 9th century BC in Assyrian texts. Some time after that region fell to Madius the Scythian (653 BC), Teispes son of Achaemenes conquered Elamite Anshan in the mid 7th century BC, forming a nucleus that would expand into the Persian Empire. They were largely regarded as vassals of the Assyrians, and the Medes, Mannaeans and Persians paid tribute to Assyria from the 10th century BC until the death of Ashurbanipal in 627 BC. After his death the Medes played a major role in the destruction of the weakened Assyrian Empire in 612 BC.</p><p>The rise of the Achaemenids in the 6th century BC brought an end to the existence of Elam as an independent political power but not as a cultural entity (Encyclopædia Iranica, Columbia University). Indigenous Elamite traditions, such as the use of the title king of Anshan by Cyrus the Great; the Elamite robe worn by Cambyses I of Anshan and seen on the famous winged genii at Pasargadae; some glyptic styles; the use of Elamite as the first of three official languages of the empire used in thousands of administrative texts found at Darius’ city of Persepolis; the continued worship of Elamite deities; and the persistence of Elamite religious personnel and cults supported by the crown, formed an essential part of the newly emerging Achaemenid culture in Persian Iran. The Elamites thus became the conduit by which achievements of the Mesopotamian civilizations were introduced to the tribes of the Iranian plateau.</p><p>Conversely, remnants of Elamite had absorbed Iranian influences in both structure and vocabulary by 500 BC,[22] suggesting a form of cultural continuity or fusion connecting the Elamite and the Persian periods.[23]</p><p>The name of Elam survived into the Hellenistic period and beyond. In its Greek form, Elymais, it emerges as designating a semi-independent state under Parthian suzerainty during the 2nd century BC to the early 3rd century AD. In Acts 2:8-9 in the New Testament, the language of the Elamites is one of the languages heard at the Pentecost. From 410 onwards Elam (Beth Huzaye) was the senior metropolitan province of the Church of the East, surviving into the 14th century.</p><p>Coordinates: 29°54'N 52°24'E? / ?29.900°N 52.400°E? / 29.900; 52.400</p><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Elam&amp;oldid=783307645"					
								Categories:  Hidden categories:</p><br><h1 lang="en">Qumis, Iran</h1><p> From Wikipedia, the free encyclopedia</p><p>Saddarvazeh (New Persian: ????????) or Hecatompylos (Ancient&nbsp;Greek: ??at?µp????) was an ancient city of uncertain location which was the capital of the Parthian Arsacid dynasty by 200 BCE. The Greek name Hekatompylos means one hundred gates and the Persian term has the same meaning. The title was commonly used for cities which had more than the traditional four gates. It may be understood better as the Many Gated. Most scholars locate it at Sahr -e Qumis, in the Qumis region in west Khurasan, Iran.[1]</p><p>Alexander the Great stopped here in the summer of 330 BCE and it became part of the Seleucid Empire after his death. The Parni tribe took the city around 238 BCE and made it one of the first capitals of their Parthian Empire. It was mentioned as the royal city of the Parthians by a number of classical writers including Strabo, Pliny, and Ptolemy, although the Parthians seemed to have used a number of cities as their capital at different periods.</p><p>It is estimated to have had an area of 28&nbsp;km2 (11&nbsp;sq&nbsp;mi) at its peak, which would indicate a population in the tens of thousands[citation needed].</p><p>Qumis was destroyed by an earthquake in 856 AD, and it was probably abandoned afterwards. The site of this ancient city is now called Šahr-e Qumis (Persian: ??? ??????), between Semnan and Damqan in the Semnan Province.</p><h2>Contents</h2><div class="gradientback"></div></div><div class="content"><h2>Modern development</h2><p>In 2011 plans for an International Project of Tourism &amp; Recreational City were published, using the name of Hecatompylos. The project envisions using an area of 250 hectares (620 acres) close to the city of Damghan, which would place the resort at about 30&nbsp;km (19&nbsp;mi) northeast of the historic site. [2]</p><h2>Citations</h2><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Qumis,_Iran&amp;oldid=771279123"					
								Categories:  Hidden categories:</p><br><h1 lang="en">Nisa, Turkmenistan</h1><p> From Wikipedia, the free encyclopedia</p><p>Nisa (also Parthaunisa) was an ancient city, located near modern-day Bagir village, 18&nbsp;km southwest of Ashgabat, Turkmenistan. Nisa is described by some as the first seat of central government of the Parthians. It is traditionally assumed to be founded by Arsaces I (reigned c. 250 BC–211 BC), and was reputedly the royal necropolis of the Parthian kings, although it has not been established that the fortress at Nisa was either a royal residence or a mausoleum.</p><h2>Contents</h2><h2>Excavations</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/3/36/Nisa-Overview-2015.JPG/400px-Nisa-Overview-2015.JPG" width="400" height="159"><p>


				Nisa seen from its western end


				</p><p>
					Excavations at Nisa have revealed substantial buildings, mausoleums and shrines, many inscribed documents, and a looted treasury. Many Hellenistic art works have been uncovered, as well as a large number of ivory rhytons, the outer rims (coins) decorated with Iranian subjects or classical mythological scenes.</p><p>Nisa was later renamed Mithradatkirt (fortress of Mithradates) by Mithridates I of Parthia (reigned c. 171 BC–138 BC).</p><p>Nisa was totally destroyed by an earthquake, which occurred during the first decade BC.</p><p>The fortress at Nisa was declared a World Heritage Site by UNESCO in 2007.[1](See List of World Heritage Sites in Turkmenistan)</p><h2>Selected bibliography</h2><p>Sorted by year then author:[2]</p><p>1982
				MASSON M.E., PUGACHENKOVA G.A., The Parthians rhytons of Nisa, Monografie di Mesopotamia (Introduction by A. Invernizzi), Firenze, Le Lettere.</p><p>1990
				INVERNIZZI A., KOSHELENKO G.A., «Soviet-Italian Excavations in Old Nisa (Season 1990)&nbsp;», Mesopotamia, XXV, pp.&nbsp;47–50.</p><p>1996
				GABUTTI A., «The Italian Excavation in Old Nisa: the Northern Corner of the Round Hall Complex», Mesopotamia XXXI, pp.&nbsp;161–177
				INVERNIZZI A., «Archaeological research in Old Nisa 1990-1994», in La Persia e l’Asia Centrale da Alessandro al X secolo, Atti dei Convegni Lincei, 127, Roma, pp.&nbsp;237–249.</p><p>1998
				INVERNIZZI A., «New Archaeological Research in Old Nisa, 1990-1991», in The Art and Archaeology of Ancient Persia. New Light on the Parthian and Sasanian Empire, ed. V. Sarkhosh Curtis, R. Hillenbrand, J.M. Rogers, London-New York, 8-13.
				INVERNIZZI A., «Old Nisa and the Art of the Steppes», Bulletin of the Asia Institute, 10, 33-38.
				INVERNIZZI A., «Parthian Nisa. New Lines of Research», in J. Wiesehöfer (ed.), Das Partherreich und seine Zeugnisse, Beiträge des internationalen Colloquiums - Eutin, 1996, (Historia Einzelschriften, 122), Stuttgart, 45-59.</p><p>2000
				INVERNIZZI A., «The Square House at Old Nisa», Parthica 2, pp.&nbsp;13–53</p><p>2001
				INVERNIZZI A., «Arsacid Dynastic Art», Parthica 3, pp.&nbsp;133–157.
				INVERNIZZI A., «Arsacid Palaces», in The Royal Palace Institution in the 1st Millennium BC (Ed. I. Nielsen), Athens, pp.&nbsp;295–312.
				LIPPOLIS C., book review of V.N. PILIPKO, Staraja Nisa. Zdanie s Kvadratnym Zalom, Moskva, 1996, su Parthica, 3, 2001, pp.&nbsp;221–234.</p><p>2002
				KOSHELENKO G, LAPCHIN A., «Ricerche nel complesso del Tempio Rotondo a Nisa Vecchia», Parthica 4, pp.&nbsp;9–45.</p><p>2003
				LIPPOLIS C., «Novije Issledovanija Staroj Nisji», Kulturnye Ziennosti 2000-2001, Ashkhabad.
				LIPPOLIS C., «Nisa-Mithradatkert: the building to the north of the Round Hall. Preliminary Report of the 2000-2001 excavations campaign», Central Asia Cultural Values, vol. I, n. 2, June 2003, p.&nbsp;1-17.
				LIPPOLIS C., book review of PILIPKO V.N., Staraja Nisa – Osnovnye itogi arheologicheskogo izuchenija v sovetskij period, su Parthica 5, 2003, p.&nbsp;3-13.</p><p>2004
				INVERNIZZI A., «The culture of Nisa, between steppe and empire», After Alexander-Central Asia before Islam. Themes in the history and archaeology of Western Central Asia, British Academy Conference, 23–25 June 2004.
				INVERNIZZI A., «Thoughts on Parthian Nisa», in Parthica 6, pp.&nbsp;133–143.</p><p>2005
				INVERNIZZI A., «Representations of Gods in Parthian Nisa», Parthica 7 (2005), pp.&nbsp;71–80.</p><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Nisa,_Turkmenistan&amp;oldid=778675361"					
								Categories:  Hidden categories:</p><br><h1 lang="en">Parthian language</h1><p> From Wikipedia, the free encyclopedia</p><p>The Parthian language, also known as Arsacid Pahlavi and Pahlawanig, is a now-extinct ancient Northwestern Iranian language spoken in Parthia, a region of northeastern ancient Iran. Parthian was the language of state of the Arsacid Parthian Empire (248 BC – 224 AD), as well as of its eponymous branches of the Arsacid dynasty of Armenia, Arsacid dynasty of Iberia, and the Arsacid dynasty of Caucasian Albania.</p><p>This language had a huge impact on Armenian, a large part of whose vocabulary was formed primarily from borrowings from Parthian. Many ancient Parthian words preserved and now can be seen only in Armenian.</p><div class="gradientback"></div></div><div class="content"><h2>Contents</h2><h2>Classification</h2><p>Parthian was a Western Middle Iranian language. Language contact made it share some features of the Eastern Iranian language group, the influence of which is attested primarily in loanwords. Some traces of Eastern influence survive in Parthian loanwords in Armenian.[2]</p><p>Taxonomically, Parthian belongs to the Northwestern Iranian language group while Middle Persian belongs to the Southwestern Iranian language group.</p><h2>Written Parthian</h2><p> Main article: Pahlavi scripts</p><p>The Parthian language was rendered using the Pahlavi writing system, which had two essential characteristics: First, its script derived from Aramaic,[3] the script (and language) of the Achaemenid chancellery (i.e. Imperial Aramaic). Second, it had a high incidence of Aramaic words, rendered as ideograms or logograms, that is, they were written Aramaic words but understood as Parthian ones (See Arsacid Pahlavi for details).</p><p>The Parthian language was the language of the old Satrapy of Parthia and was used in the Arsacids courts. The main sources for Parthian are the few remaining inscriptions from Nisa and Hecatompolis, Manichaean texts, Sasanian multi-lingual inscriptions, and remains of Parthian literature in the succeeding Middle Persian. Among these, the Manichaean texts, composed shortly after the demise of the Parthian power, play an important role for reconstructing the Parthian language.[4] These Manichaean manuscripts contain no ideograms.</p><h2>Attestations</h2><p>Attestations of the Parthian language include:[5]</p><h2>Extinction</h2><p>In 224 AD, Ardashir I, the local ruler of Pars, deposed and replaced Artabanus IV, the last Parthian Emperor, and founded the fourth Iranian dynasty, and the second Persian dynasty, the Sassanian Empire. Parthian was then succeeded by Middle Persian, which when written is known as Sasanian Pahlavi. Parthian did not die out immediately, but remains attested in a few bi-lingual inscriptions from the Sasanian era.</p><h3>Notes</h3><h3>General references</h3><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Parthian_language&amp;oldid=783674896"					
								Categories:  Hidden categories:</p><br><h1 lang="en">Ctesiphon</h1><p> From Wikipedia, the free encyclopedia</p><p>Ctesiphon (/'t?s?f?n/ TESIFON; Greek: ?t?s?f??; from Parthian/Middle Persian: tyspwn or tysfwn[1]) was an ancient city located on the eastern bank of Tigris, and about 35 kilometres (22&nbsp;mi) southeast of present-day Baghdad. It became the capital of the Parthian Empire in about 58 BC, and remained the capital of the Sasanian Empire until the Muslim conquest of Persia in 651.</p><p>Ctesiphon developed into a rich commercial metropolis, merging with the surrounding cities along both shores of the river, including the Hellenistic city of Seleucia. Ctesiphon and its environs were therefore sometimes referred to as the cities (Aramaic: Mahuza, Arabic: ?????????, al-Mada'in). In the late sixth and early seventh century, it was one of the largest cities in the world.[2]</p><p>During the Roman–Persian Wars, Ctesiphon fell four times to the Romans, and later once during Sasanian rule. It was also the site of the Battle of Ctesiphon (363). After the Muslim invasion the city fell into decay and was depopulated by the end of the 8th century. The most conspicuous structure remaining today is the great archway of Ctesiphon.[3]</p><h2>Contents</h2><h2>Names</h2><p>The Latin name Ctesiphon derives from Ancient Greek Ktesiphôn (?t?s?f??) is ostensibly a Greek toponym based on a personal name, although it may be a Hellenized form of a local name, reconstructed as Tisfon or Tisbon.[4] In Iranian-language texts of the Sasanian era, it is spelled as tyspwn, which can be read as Tisfon, Tesifon, etc. in Manichaean Parthian, in Middle Persian and in Christian Sogdian (in Syriac alphabet) languages. The New Persian form is Tisfun (??????).</p><p>Texts from the Assyrian Church of the East's synods referred to the city as Q?espon (Syriac: ????????) or some times Ma?ôze (Syriac: ????¨??) when referring to the metropolis of Seleucia-Ctesiphon.</p><p>In modern Arabic, the name is usually ?aysafun (??????) or Qa?aysfun (???????) or as al-Mada'in (??????? The Cities, referring to Greater Ctesiphon). According to Yaqut [...], quoting ?amza, the original form was ?usfun or Tusfun, which was arabicized as ?aysafun.[5] The Armenian name of the city was Tizbon (??????). Ctesiphon is first mentioned in the Book of Ezra[6] of the Old Testament as Kasfia/Casphia (a derivative of the ethnic name, Cas, and a cognate of Caspian and Qazvin).</p><h2>Location</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/6/63/Ctesiphon-ruin_1864.jpg/220px-Ctesiphon-ruin_1864.jpg" width="220" height="137"><p>


				Taq Kasra or Ctesiphon palace ruin, with the arch in the centre, 1864


				</p><p>
					Ctesiphon is located approximately at Al-Mada'in, 32&nbsp;km (20&nbsp;mi) southeast of the modern city of Baghdad, Iraq, along the river Tigris. Ctesiphon measured 30 square kilometers, more than twice the surface of 13.7-square-kilometer fourth-century Imperial Rome.</p><p>The archway of Chosroes (Taq Kasra) was once a part of the royal palace in Ctesiphon and is estimated to date between the 3rd and 6th centuries AD.[7] It is located in what is now the Iraqi town of Salman Pak.</p><h2>History</h2><h3>Parthian period</h3><div class="gradientback"></div></div><div class="content"><p>Ctesiphon was founded in the late 120s BC. It was built on the site of a military camp established across from Seleucia by Mithridates I of Parthia. The reign of Gotarzes I saw Ctesiphon reach a peak as a political and commercial center. The city became the Empire's capital circa 58&nbsp;BC during the reign of Orodes II. Gradually, the city merged with the old Hellenistic capital of Seleucia and other nearby settlements to form a cosmopolitan metropolis.[8]</p><p>The reason for this westward relocation of the capital could have been in part due to the proximity of the previous capitals (Mithradatkirt, and Hecatompylos at Hyrcania) to the Scythian incursions.[8]</p><p>Strabo abundantly describes the foundation of Ctesiphon:</p><p>In ancient times Babylon was the metropolis of Assyria; but now Seleucia is the metropolis, I mean the Seleucia on the Tigris, as it is called. Nearby is situated a village called Ctesiphon, a large village. This village the kings of the Parthians were wont to make their winter residence, thus sparing the Seleucians, in order that the Seleucians might not be oppressed by having the Scythian folk or soldiery quartered amongst them. Because of the Parthian power, therefore, Ctesiphon is a city rather than a village; its size is such that it lodges a great number of people, and it has been equipped with buildings by the Parthians themselves; and it has been provided by the Parthians with wares for sale and with the arts that are pleasing to the Parthians; for the Parthian kings are accustomed to spend the winter there because of the salubrity of the air, but they summer at Ecbatana and in Hyrcania because of the prevalence of their ancient renown.[9]</p><p>Because of its importance, Ctesiphon was a major military objective for the leaders of the Roman Empire in their eastern wars. The city was captured by Rome five times in its history – three times in the 2nd century alone. The emperor Trajan captured Ctesiphon in 116, but his successor, Hadrian, decided to willingly return Ctesiphon in 117 as part of a peace settlement. The Roman general Avidius Cassius captured Ctesiphon in 164 during another Parthian war, but abandoned it when peace was concluded. In 197, the emperor Septimius Severus sacked Ctesiphon and carried off thousands of its inhabitants, whom he sold into slavery.</p><h3>Sasanian period</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/0/01/Southwestern_part_of_the_Sasanian_Empire.jpg/300px-Southwestern_part_of_the_Sasanian_Empire.jpg" width="300" height="175"><p>


				Map of Sasanian Mesopotamia and its surroundings.


				</p><p>
					By 226, Ctesiphon was in the hands of the Sasanian Empire, who also made it their capital and had laid an end to the Parthian dynasty of Iran. Ctesiphon was greatly enlarged and flourished during their rule, thus turning into a metropolis, which was known by in Arabic as al-Mada'in, and in Aramaic as Mahoze.[10] The oldest inhabited places of Ctesiphon were on its eastern side, which in Arabic sources is called the Old City, where the residence of the Sasanians, known as the White Palace, was located. The southern side of Ctesiphon was known as Aspanbar, which was known by its prominent halls, riches, games, stables, and baths.[10]</p><p>The western side was known as Veh-Ardashir (meaning the good city of Ardashir in Middle Persian), known as Mahoza by the Jews, Kokhe by the Christians, and Behrasir by the Arabs. Veh-Ardashir was populated by many wealthy Jews, and was the seat of the church of the Nestorian patriarch. To the south of Veh-Ardashir was Valashabad.[10] Ctesiphon had several other districts which were named Hanbu Shapur, Darzanidan, Veh Jondiu-Khosrow, Nawinabad and Kardakadh.[10]</p><p>Severus Alexander advanced towards Ctesiphon in 233, but as corroborated by Herodian, his armies suffered a humiliating defeat against Ardashir I.[11] In 283, emperor Carus sacked the city uncontested during a period of civil upheaval. In 295, emperor Galerius was defeated outside the city. However, he returned a year later with a vengeance and won a victory which ended in the fifth and final capture of the city by the Romans in 299. He returned it to the Persian king Narses in exchange for Armenia and western Mesopotamia. In c.325 and again in 410, the city, or the Greek colony directly across the river, was the site of church councils for the Church of the East.[citation needed]</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/c/cf/Babylon%26Seleuicia1%28Peutinger_Map%29.png/220px-Babylon%26Seleuicia1%28Peutinger_Map%29.png" width="220" height="80"><p>


				4th century Ctesiphon (Peutinger Map)


				</p><p>
					
				After the conquest of Antioch in 541, Khosrau I built a new city near Ctesiphon for the inhabitants he captured. He called this new city Weh Antiok Khusrau, or literally, better than Antioch Khosrau built this.[12] Local inhabitants of the area called the new city Rumagan, meaning town of the Romans and Arabs called the city al-Rumiyya. Along with Weh Antiok, Khosrau built a number of fortified cities.[13] Khosrau I deported 292,000 citizens, slaves, and conquered people to the new city of Ctesiphon in 542.[14]</p><p>In 590, a member of the House of Mihran, Bahram Chobin repelled the newly ascended Sasanian ruler Khosrau II from Iraq, and conquered the region. One year later, Khosrau II, with aid from the Byzantine Empire, reconquered his domains. During his reign, some of the great fame of al-Mada'in decreased, due to the popularity of Khosrau's new winter residence, Dastagerd.[15] In 627, the Byzantine Emperor Heraclius surrounded the city, the capital of the Sassanid Empire, leaving it after the Persians accepted his peace terms. In 628, a deadly plague hit Ctesiphon, al-Mada'in and the rest of the western part of the Sasanian Empire, which even killed Khosrau's son and successor, Kavadh II.[15]</p><p>In 629, Ctesiphon was briefly under the control of Mihranid usurper Shahrbaraz, but the latter was shortly assassinated by the supporters of Khosrau II's daughter Borandukht. Ctesiphon then continued to be involved in constant fighting between two factions of the Sasanian Empire, the Pahlav (Parthian) faction under the House of Ispahbudhan and the Parsig (Persian) faction under Piruz Khosrow.</p><h3>Downfall of the Sasanians and the Islamic conquests</h3><p>In 636, the Muslim Arabs, who had since 633 invaded the territories of the Sasanian Empire, defeated them during a great battle known as the Battle of al-Qadisiyyah. The Arabs then attacked Ctesiphon, and seized some parts of it.[10]</p><p>The Muslim military officer Khalid ibn 'Urfuta quickly seized Valashabad and made a peace treaty with the inhabitants of Weh Antiok Khusrau and Veh-Ardashir. The terms of the treaty were that the inhabitants of Weh Antiok Khusrau were allowed to leave if they wanted to, but if they did not, they were forced to acknowledge Muslim authority, and also pay tribute (jizya). When the Muslim military officer Sa`d ibn Abi Waqqas arrived at Ctesiphon, it was completely desolated, due to flight of the Sasanian royal family, nobles, and troops. However, the Muslims had managed to take some of troops captive, and many riches were seized from the Sasanian treasury and were given to the Muslim troops.[10] Furthermore, the throne hall in Taq Kasra was briefly used as a mosque.[16]</p><p>Still, as political and economic fortune had passed elsewhere, the city went into a rapid decline, especially after the founding of the Abbasid capital at Baghdad in the 8th century, and soon became a ghost town. Caliph Al-Mansur took much of the required material for the construction of Baghdad from the ruins of Ctesiphon. He also attempted to demolish the palace and reuse its bricks for his own palace, but he desisted only when the undertaking proved too vast.[17]</p><div class="gradientback"></div></div><div class="content"><p>It is believed to be the basis for the city of Isbanir in One Thousand and One Nights.</p><h3>Modern era</h3><p>The ruins of Ctesiphon were the site of a major battle of World War I in November 1915. The Ottoman Empire defeated troops of Britain attempting to capture Baghdad, and drove them back some 40 miles (64&nbsp;km) before trapping the British force and compelling it to surrender.</p><h2>Population and religion</h2><p>During the Sasanian period, the population of Ctesiphon was heavily mixed, it included Arameans, Persians, Greeks, and Assyrians. Several religions were also practiced in the metropolis, which included Christianity, Judaism, and Zoroastrianism. The population also included Manicheans, who continued to be mentioned in Ctesiphon during Umayyad rule.[10] Much of the population fled from Ctesiphon after the Arab capture of the metropolis. However, a portion of Persians remained there, and some important figures of these people are known to have provided Ali with presents, which he, however, refused to take. After the Battle of Siffin, the Persian population of Ctesiphon disappeared.[10]</p><h2>Archaeology</h2><p>A German Oriental Society and University of Pennsylvania team led by Oscar Reuther excavated at Ctesiphon in 1928–29 and 1931–32, mainly at Qasr bint al-Qadi on the western part of the site.[18][19][20][21]</p><p>In the late 1960s and early 1970s, an Italian team from the University of Turin directed by Antonio Invernizzi and Giorgio Gullini&nbsp;(it) worked at the site, mainly doing restoration at the palace of Khosrau II.[22][23][24][25][26][27] In 2013 the Iraqi government contracted to restore the Arch of Ctesiphon as a tourist attraction.[28]</p><h2>Notes</h2><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Ctesiphon&amp;oldid=783985832"					
								Categories:  Hidden categories:</p><br><h1 lang="en">Rey, Iran</h1><p> From Wikipedia, the free encyclopedia</p><p>Rey or Ray [Pronunciation: ra] (Persian: ??? ????, Shahr-e-Ray, City of Ray), also known as Rhages (/'re?d??z/; Greek: ???a?, or Europos (????p??) Rhagai; Latin: Rhagae or Rhaganae) and formerly as Arsacia, is the capital of Rey County in Tehran Province of Iran, and the oldest existing city in the province.</p><p>Ray today has been absorbed into the Greater Tehran metropolitan area. Ray is connected via the Tehran Metro to the rest of Tehran and has many industries and factories in operation. Limited excavations of what was not bulldozed began in 1997 in collaboration with the Iranian Cultural Heritage and Tourism Organization (ICHTO), the Department of Archaeological Sciences of the University of Bradford and the Department of Archaeology of the University of Tehran.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/9/92/Rey%2C_Iran_map.JPG/350px-Rey%2C_Iran_map.JPG" width="350" height="238"><p>


				Rey map



				<br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/8/84/Rey_in_Tehran_map_%28black%29.JPG/350px-Rey_in_Tehran_map_%28black%29.JPG" width="350" height="225"><br>


				Rey in Tehran map (black). Rey is 20th district of municipal Tehran.


				</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/8/84/Rey_in_Tehran_map_%28black%29.JPG/350px-Rey_in_Tehran_map_%28black%29.JPG" width="350" height="225"><br><p>
					Note on spelling: According to the Iranian Chamber Society, the correct spelling of the city in both English and Persian is Ray, though variations in spelling also exist.[1] The city university also uses the spelling Ray (Azad University, Shahr-e-Ray),[2] as does the Encyclopædia Iranica published by Columbia University.[3]</p><h2>Contents</h2><h2>History</h2><p>A settlement began here c 6,000 BCE as part of the Central Plateau Culture. The settlement was used as a capital by the Arsacids called Rhaga. In Classical Greco-Roman geography it was called Rhagae (Greek: ???a?). It is mentioned several times in the Apocrypha.[4] Its name dates back to the pre-Median period. Some historians attribute its building to ancient mythological monarchs, and some others believe that Ray was the seat of a dynasty of Zoroastrian leader.</p><p>During the Seleucid period, Alexander the Great's general Seleucus I Nicator renamed the city as Europos, honouring his home city in Macedonia. Rey is also shown on the 4th century Peutinger Map.</p><p>Ray is richer than many other ancient cities in the number of its historical monuments, among which one might refer to the 3000-year-old Gebri castle, the 5000-year-old Cheshmeh Ali hill, the 1000-year-old Bibi Shahr Banoo tomb and Shah Abbasi caravanserai. It has been home to pillars of science like Rhazes.</p><p>Rey was one of the capital cities of the Seljuq Empire in the 11th century. In the 13th century after the Mongol conquest the town was severely damaged and it gradually lost its importance in the presence of nearby Tehran.</p><p>There is also a shrine there, dedicated to commemorate Princess Shahr Banu, eldest daughter of the last ruler of the Sassanid Empire. She gave birth to Ali Zayn al Abidin, the fourth holy Imam of the Shia faith. This was through her marriage to Husayn ibn Ali, the grandson of Muhammad, the prophet of Islam. A nearby mountain is also named after her. However, some sources attribute the shrine to the goddess of water and fertility, Anahita, claiming it was renamed in Islamic times to protect it from any possible harm after the conversion of Iranians to Islam.</p><div class="gradientback"></div></div><div class="content"><p>In the middle of the 19th century Ray was described as place of ruins, the only settlement being around the shrine of Abdol Azim.[5] Being the only important pilgrimage site in vicinity to the royal court in the new capital Tehran brought more people to visit the shrine and a major restoration was sponsored by the court.[6] Thus Ray was the first place in Iran to be connected to the capital by a railroad in 1888.</p><h2>Main sights</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/f/f3/Rey_map_by_Ker_Porter.jpg/220px-Rey_map_by_Ker_Porter.jpg" width="220" height="173"><p>


				1818 map by Robert Ker Porter



				<br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/4/43/Borj-toghrul.jpg/150px-Borj-toghrul.jpg" width="150" height="188"><br>


				Tughrul Tower, a 12th-century monument commemorating the Seljuq monarch Tugrul Beg, is one of the historical structures still standing today.


				 


				<br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/a/a9/Rey_panorama_small.jpg/700px-Rey_panorama_small.jpg" width="700" height="94"><br>


				View from Rashkan hill to Ray and Bibi-shahr-bano mountain



				</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/4/43/Borj-toghrul.jpg/150px-Borj-toghrul.jpg" width="150" height="188"><br><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/a/a9/Rey_panorama_small.jpg/700px-Rey_panorama_small.jpg" width="700" height="94"><br><h2>Notable people</h2><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Rey,_Iran&amp;oldid=772599227"					
								Categories:  Hidden categories:</p><br><h1 lang="en">Feudalism</h1><p>
					 From Wikipedia, the free encyclopedia</p><p> This article is about the classic, or medieval, Western European form of feudalism. For feudalism as practiced in other societies, as well as that of the Europeans, see Examples of feudalism.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/2/27/Rolandfealty.jpg/220px-Rolandfealty.jpg" width="220" height="244"><p>


				Roland pledges his fealty to Charlemagne; from a manuscript of a chanson de geste, c. 14th century (?)



				<br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/9/94/Slovakia_Oravsky_Podzamok.jpg/230px-Slovakia_Oravsky_Podzamok.jpg" width="230" height="173"><br>


				Castle – a traditional symbol of a feudal society (Orava Castle in Slovakia).


				 
				</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/9/94/Slovakia_Oravsky_Podzamok.jpg/230px-Slovakia_Oravsky_Podzamok.jpg" width="230" height="173"><br><p>
					Feudalism was a combination of legal and military customs in medieval Europe that flourished between the 9th and 15th centuries. Broadly defined, it was a way of structuring society around relationships derived from the holding of land in exchange for service or labour.</p><p>Although derived from the Latin word feodum or feudum (fief),[1] then in use, the term feudalism and the system it describes were not conceived of as a formal political system by the people living in the Middle Ages.[2] In its classic definition, by François-Louis Ganshof (1944),[3] feudalism describes a set of reciprocal legal and military obligations among the warrior nobility, revolving around the three key concepts of lords, vassals and fiefs.[3]</p><p>A broader definition of feudalism, as described by Marc Bloch (1939), includes not only the obligations of the warrior nobility but also those of all three estates of the realm: the nobility, the clergy, and the peasantry bound by manorialism; this is sometimes referred to as a feudal society. Since the publication of Elizabeth A. R. Brown's The Tyranny of a Construct (1974) and Susan Reynolds's Fiefs and Vassals (1994), there has been ongoing inconclusive discussion among medieval historians as to whether feudalism is a useful construct for understanding medieval society.[4][5][6][7][8]</p><h2>Contents</h2><h2>Definition</h2><p>There is no commonly accepted modern definition of feudalism, at least among scholars.[4][7] The adjective feudal was coined in the 17th century, and the noun feudalism, often used in a political and propaganda context, was not coined until the 19th century,[4] from the French féodalité (feudality), itself an 18th-century creation.</p><div class="gradientback"></div></div><div class="content"><p>In a classic definition by François-Louis Ganshof (1944),[3] feudalism describes a set of reciprocal legal and military obligations among the warrior nobility, revolving around the three key concepts of lords, vassals and fiefs,[3] though Ganshof himself noted that his treatment related only to the narrow, technical, legal sense of the word.</p><p>A broader definition, as described in Marc Bloch's Feudal Society (1939),[9] includes not only the obligations of the warrior nobility but those of all three estates of the realm: the nobility, the clergy, and those living by their labour, most directly the peasantry bound by manorialism; this order is often referred to as feudal society, echoing Bloch's usage.</p><p>Since the publication of Elizabeth A. R. Brown's The Tyranny of a Construct (1974)[5] and Susan Reynolds's Fiefs and Vassals (1994),[6] there has been ongoing inconclusive discussion among medieval historians as to whether feudalism is a useful construct for understanding medieval society.[4][7][10]</p><p>Outside a European context, the concept of feudalism is often used only by analogy (called semi-feudal), most often in discussions of feudal Japan under the shoguns, and sometimes medieval and Gondarine Ethiopia.[11] However, some have taken the feudalism analogy further, seeing feudalism (or traces of it) in places as diverse as Spring and Autumn period in China, ancient Egypt, the Parthian empire, the Indian subcontinent and the Antebellum and Jim Crow American South.[11]</p><p>The term feudalism has also been applied—often inappropriately or pejoratively—to non-Western societies where institutions and attitudes similar to those of medieval Europe are perceived to prevail.[12] Some historians and political theorists believe that the term feudalism has been deprived of specific meaning by the many ways it has been used, leading them to reject it as a useful concept for understanding society.[4][5]</p><h2>Etymology</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/f/f0/Codex_Manesse_Reinmar_von_Zweter.jpg/220px-Codex_Manesse_Reinmar_von_Zweter.jpg" width="220" height="330"><p>


				Herr Reinmar von Zweter, a 13th-century Minnesinger, was depicted with his noble arms in Codex Manesse.


				</p><p>
					The term féodal was used in 17th-century French legal treatises (1614)[13][14] and translated into English legal treatises as an adjective, such as feodal government.</p><p>In the 18th century, Adam Smith, seeking to describe economic systems, effectively coined the forms feudal government and feudal system in his book Wealth of Nations (1776).[15] In the 19th century the adjective feudal evolved into a noun: feudalism.[15] The term feudalism is recent, first appearing in French in 1823, Italian in 1827, English in 1839, and in German in the second half of the 19th century.[15]</p><p>The term feudal or feodal is derived from the medieval Latin word feodum. The etymology of feodum is complex with multiple theories, some suggesting a Germanic origin (the most widely held view) and others suggesting an Arabic origin. Initially in medieval Latin European documents, a land grant in exchange for service was called a beneficium (Latin).[16] Later, the term feudum, or feodum, began to replace beneficium in the documents.[16] The first attested instance of this is from 984, although more primitive forms were seen up to one-hundred years earlier.[16] The origin of the feudum and why it replaced beneficium has not been well established, but there are multiple theories, described below.[16]</p><p>The most widely held theory is put forth by Marc Bloch.[16][17][18] Bloch said it is related to the Frankish term *fehu-ôd, in which *fehu means cattle and -ôd means goods, implying a moveable object of value.[17][18] Bloch explains that by the beginning of the 10th century it was common to value land in monetary terms but to pay for it with moveable objects of equivalent value, such as arms, clothing horses or food. This was known as feos, a term that took on the general meaning of paying for something in lieu of money. This meaning was then applied to land itself, in which land was used to pay for fealty, such as to a vassal. Thus the old word feos meaning movable property changed little by little to feus meaning the exact opposite: landed property.[17][18] This Germanic origin theory was also shared by William Stubbs in the 19th century.[16][19]</p><p>Another theory was put forward by Archibald R. Lewis.[16] Lewis said the origin of 'fief' is not feudum (or feodum), but rather foderum, the earliest attested use being in Astronomus's Vita Hludovici (840).[20] In that text is a passage about Louis the Pious that says annona militaris quas vulgo foderum vocant, which can be translated as Louis forbade that military provender (which they popularly call fodder) be furnished..[16]</p><p>Another theory by Alauddin Samarrai suggests an Arabic origin, from fuyu (the plural of fay, which literally means the returned, and was used especially for 'land that has been conquered from enemies that did not fight').[16][21] Samarrai's theory is that early forms of 'fief' include feo, feu, feuz, feuum and others, the plurality of forms strongly suggesting origins from a loanword. Indeed, the first use of these terms is in Languedoc, one of the least Germanic areas of Europe and bordering Muslim Spain. Further, the earliest use of feuum (as a replacement for beneficium) can be dated to 899, the same year a Muslim base at Fraxinetum (La Garde-Freinet) in Provence was established. It is possible, Samarrai says, that French scribes, writing in Latin, attempted to transliterate the Arabic word fuyu (the plural of fay), which was being used by the Muslim invaders and occupiers at the time, resulting in a plurality of forms – feo, feu, feuz, feuum and others – from which eventually feudum derived. Samarrai, however, also advises to handle this theory with care, as Medieval and Early Modern Muslim scribes often used etymologically fanciful roots in order to claim the most outlandish things to be of Arabian or Muslim origin.[21]</p><h2>History</h2><p>Feudalism, in its various forms, usually emerged as a result of the decentralization of an empire: especially in the Carolingian empires, which lacked the bureaucratic infrastructure[clarification needed] necessary to support cavalry without the ability to allocate land to these mounted troops. Mounted soldiers began to secure a system of hereditary rule over their allocated land and their power over the territory came to encompass the social, political, judicial, and economic spheres.[22]</p><p>These acquired powers significantly diminished unitary power in these empires. Only when the infrastructure existed to maintain unitary power—as with the European monarchies—did Feudalism begin to yield to this new power structure and eventually disappear.[22]</p><h3>Classic feudalism</h3><p>The classic François-Louis Ganshof version of feudalism[4][3] describes a set of reciprocal legal and military obligations among the warrior nobility, revolving around the three key concepts of lords, vassals and fiefs. A lord was in broad terms a noble who held land, a vassal was a person who was granted possession of the land by the lord, and the land was known as a fief. In exchange for the use of the fief and the protection of the lord, the vassal would provide some sort of service to the lord. There were many varieties of feudal land tenure, consisting of military and non-military service. The obligations and corresponding rights between lord and vassal concerning the fief form the basis of the feudal relationship.[3]</p><div class="gradientback"></div></div><div class="content"><h3>Vassalage</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/7/74/Hommage_du_comt%C3%A9_de_Clermont-en-Beauvaisis.png/220px-Hommage_du_comt%C3%A9_de_Clermont-en-Beauvaisis.png" width="220" height="256"><p>


				Homage of Clermont-en-Beauvaisis


				</p><p>
					Before a lord could grant land (a fief) to someone, he had to make that person a vassal. This was done at a formal and symbolic ceremony called a commendation ceremony, which was composed of the two-part act of homage and oath of fealty. During homage, the lord and vassal entered into a contract in which the vassal promised to fight for the lord at his command, whilst the lord agreed to protect the vassal from external forces. Fealty comes from the Latin fidelitas and denotes the fidelity owed by a vassal to his feudal lord. Fealty also refers to an oath that more explicitly reinforces the commitments of the vassal made during homage. Such an oath follows homage.[23]</p><p>Once the commendation ceremony was complete, the lord and vassal were in a feudal relationship with agreed obligations to one another. The vassal's principal obligation to the lord was to aid, or military service. Using whatever equipment the vassal could obtain by virtue of the revenues from the fief, the vassal was responsible to answer calls to military service on behalf of the lord. This security of military help was the primary reason the lord entered into the feudal relationship. In addition, the vassal could have other obligations to his lord, such as attendance at his court, whether manorial, baronial, both termed court baron, or at the king's court.[24]</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/9/90/Map_France_1477-en.svg/220px-Map_France_1477-en.svg.png" width="220" height="237"><p>


				France in the late 15th century: a mosaic of feudal territories


				</p><p>
					It could also involve the vassal providing counsel, so that if the lord faced a major decision he would summon all his vassals and hold a council. At the level of the manor this might be a fairly mundane matter of agricultural policy, but also included sentencing by the lord for criminal offences, including capital punishment in some cases. Concerning the king's feudal court, such deliberation could include the question of declaring war. These are examples; depending on the period of time and location in Europe, feudal customs and practices varied; see examples of feudalism.</p><h3>The Feudal Revolution in France</h3><p>In its origin, the feudal grant of land had been seen in terms of a personal bond between lord and vassal, but with time and the transformation of fiefs into hereditary holdings, the nature of the system came to be seen as a form of politics of land (an expression used by the historian Marc Bloch). The 11th century in France saw what has been called by historians a feudal revolution or mutation and a fragmentation of powers (Bloch) that was unlike the development of feudalism in England or Italy or Germany in the same period or later:[25] counties and duchies began to break down into smaller holdings as castellans and lesser seigneurs took control of local lands, and (as comital families had done before them) lesser lords usurped/privatized a wide range of prerogatives and rights of the state, most importantly the highly profitable rights of justice, but also travel dues, market dues, fees for using woodlands, obligations to use the lord's mill, etc.[26] (what Georges Duby called collectively the seigneurie banale[27]). Power in this period became more personal.[28]</p><p>This fragmentation of powers was not however systematic throughout France, and in certain counties (such as Flanders, Normandy, Anjou, Toulouse), counts were able to maintain control of their lands into the 12th century or later.[29] Thus, in some regions (like Normandy and Flanders), the vassal/feudal system was an effective tool for ducal and comital control, linking vassals to their lords; but in other regions, the system led to significant confusion, all the more so as vassals could and frequently did pledge themselves to two or more lords. In response to this, the idea of a liege lord was developed (where the obligations to one lord are regarded as superior) in the 12th century.[30]</p><h3>End of European feudalism</h3><p> Further information: Abolition of feudalism in France</p><p>Feudalism itself decayed and effectively disappeared in most of Western Europe by about 1500,[31][32] partly since the military power of kings shifted from armies consisting of the nobility to professional fighters (effectively reducing the nobility's power), but also because the Black Death reduced the nobility's hold on the lower classes. The system lingered on in parts of Central and Eastern Europe as late as the 1850s. Russia finally abolished serfdom in 1861.[33][34]</p><p>However, even when the original feudal relationships had disappeared, there were many institutional remnants of feudalism left in place. Historian Georges Lefebvre explains how at an early stage of the French Revolution, on just one night of August 4, 1789, France abolished the long-lasting remnants of the feudal order. It announced, The National Assembly abolishes the feudal system entirely. Lefebvre explains:</p><p>Without debate the Assembly enthusiastically adopted equality of taxation and redemption of all manorial rights except for those involving personal servitude — which were to be abolished without indemnification. Other proposals followed with the same success: the equality of legal punishment, admission of all to public office, abolition of venality in office, conversion of the tithe into payments subject to redemption, freedom of worship, prohibition of plural holding of benefices.... Privileges of provinces and towns were offered as a last sacrifice.[35]</p><p>Originally the peasants were supposed to pay for the release of seigneurial dues; these dues affected more than a fourth of the farmland in France and provided most of the income of the large landowners.[36] The majority refused to pay and in 1793 the obligation was cancelled. Thus the peasants got their land free, and also no longer paid the tithe to the church.[37]</p><h2>Feudal society</h2><div class="gradientback"></div></div><div class="content"><p> Main article: Manorialism</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/6/61/Reeve_and_Serfs.jpg/220px-Reeve_and_Serfs.jpg" width="220" height="127"><p>


				Depiction of socage on the royal demesne in feudal England, c. 1310


				</p><p>
					The phrase feudal society as defined by Marc Bloch[9] offers a wider definition than Ganshof's and includes within the feudal structure not only the warrior aristocracy bound by vassalage, but also the peasantry bound by manorialism, and the estates of the Church. Thus the feudal order embraces society from top to bottom, though the powerful and well-differentiated social group of the urban classes came to occupy a distinct position to some extent outside the classical feudal hierarchy.</p><h2>Historiography</h2><p>The idea of feudalism was unknown and the system it describes was not conceived of as a formal political system by the people living in the Medieval Period. This section describes the history of the idea of feudalism, how the concept originated among scholars and thinkers, how it changed over time, and modern debates about its use.</p><h3>Evolution of the concept</h3><p>The concept of a feudal state or period, in the sense of either a regime or a period dominated by lords who possess financial or social power and prestige, became widely held in the middle of the 18th century, as a result of works such as Montesquieu's De L'Esprit des Lois (1748; published in English as The Spirit of the Laws), and Henri de Boulainvilliers’s Histoire des anciens Parlements de France (1737; published in English as An Historical Account of the Ancient Parliaments of France or States-General of the Kingdom, 1739).[15] In the 18th century, writers of the Enlightenment wrote about feudalism to denigrate the antiquated system of the Ancien Régime, or French monarchy. This was the Age of Enlightenment when writers valued reason and the Middle Ages were viewed as the Dark Ages. Enlightenment authors generally mocked and ridiculed anything from the Dark Ages including feudalism, projecting its negative characteristics on the current French monarchy as a means of political gain.[38] For them feudalism meant seigneurial privileges and prerogatives. When the French Constituent Assembly abolished the feudal regime in August 1789 this is what was meant.</p><p>Adam Smith used the term feudal system to describe a social and economic system defined by inherited social ranks, each of which possessed inherent social and economic privileges and obligations. In such a system wealth derived from agriculture, which was arranged not according to market forces but on the basis of customary labour services owed by serfs to landowning nobles.[39]</p><h3>Marx</h3><p>Karl Marx also used the term in the 19th century in his analysis of society's economic and political development, describing feudalism (or more usually feudal society or the feudal mode of production) as the order coming before capitalism. For Marx, what defined feudalism was the power of the ruling class (the aristocracy) in their control of arable land, leading to a class society based upon the exploitation of the peasants who farm these lands, typically under serfdom and principally by means of labour, produce and money rents.[40] Marx thus defined feudalism primarily by its economic characteristics.</p><p>He also took it as a paradigm for understanding the power-relationships between capitalists and wage-labourers in his own time: ‘in pre-capitalist systems it was obvious that most people did not control their own destiny — under feudalism, for instance, serfs had to work for their lords. Capitalism seems different because people are in theory free to work for themselves or for others as they choose. Yet most workers have as little control over their lives as feudal serfs’.[41] Some later Marxist theorists (e.g. Eric Wolf) have applied this label to include non-European societies, grouping feudalism together with Imperial Chinese and pre-Columbian Incan societies as 'tributary'.</p><h3>Later studies</h3><p>In the late 19th and early 20th centuries, John Horace Round and Frederic William Maitland, both historians of medieval Britain, arrived at different conclusions as to the character of English society before the Norman Conquest in 1066. Round argued that the Normans had brought feudalism with them to England, while Maitland contended that its fundamentals were already in place in Britain before 1066. The debate continues today, but a consensus viewpoint is that England before the Conquest had commendation (which embodied some of the personal elements in feudalism) while William the Conqueror introduced a modified and stricter northern French feudalism to England incorporating (1086) oaths of loyalty to the king by all who held by feudal tenure, even the vassals of his principal vassals (Holding by feudal tenure meant that vassals must provide the quota of knights required by the king or a money payment in substitution).</p><p>In the 20th century, two outstanding historians offered still more widely differing perspectives. The French historian Marc Bloch, arguably the most influential 20th-century medieval historian.,[40] approached feudalism not so much from a legal and military point of view but from a sociological one, presenting in Feudal Society (1939; English 1961) a feudal order not limited solely to the nobility. It is his radical notion that peasants were part of the feudal relationship that sets Bloch apart from his peers: while the vassal performed military service in exchange for the fief, the peasant performed physical labour in return for protection – both are a form of feudal relationship. According to Bloch, other elements of society can be seen in feudal terms; all the aspects of life were centered on lordship, and so we can speak usefully of a feudal church structure, a feudal courtly (and anti-courtly) literature, and a feudal economy.[40]</p><p>In contradistinction to Bloch, the Belgian historian François-Louis Ganshof defined feudalism from a narrow legal and military perspective, arguing that feudal relationships existed only within the medieval nobility itself. Ganshof articulated this concept in Qu'est-ce que la féodalité? (What is feudalism?, 1944; translated in English as Feudalism). His classic definition of feudalism is widely accepted today among medieval scholars,[40] though questioned both by those who view the concept in wider terms and by those who find insufficient uniformity in noble exchanges to support such a model.</p><p>Although he was never formally a student in the circle of scholars around Marc Bloch and Lucien Febvre that came to be known as the Annales School, Georges Duby was an exponent of the Annaliste tradition. In a published version of his 1952 doctoral thesis entitled La société aux XIe et XIIe siècles dans la région mâconnaise (Society in the 11th and 12th centuries in the Mâconnais region), and working from the extensive documentary sources surviving from the Burgundian monastery of Cluny, as well as the dioceses of Mâcon and Dijon, Duby excavated the complex social and economic relationships among the individuals and institutions of the Mâconnais region and charted a profound shift in the social structures of medieval society around the year 1000. He argued that in early 11th century, governing institutions—particularly comital courts established under the Carolingian monarchy—that had represented public justice and order in Burgundy during the 9th and 10th centuries receded and gave way to a new feudal order wherein independent aristocratic knights wielded power over peasant communities through strong-arm tactics and threats of violence.</p><h3>Challenges to the feudal model</h3><p>In 1974, U.S. historian Elizabeth A. R. Brown[5] rejected the label feudalism as an anachronism that imparts a false sense of uniformity to the concept. Having noted the current use of many, often contradictory, definitions of feudalism, she argued that the word is only a construct with no basis in medieval reality, an invention of modern historians read back tyrannically into the historical record. Supporters of Brown have suggested that the term should be expunged from history textbooks and lectures on medieval history entirely.[40] In Fiefs and Vassals: The Medieval Evidence Reinterpreted (1994),[6] Susan Reynolds expanded upon Brown's original thesis. Although some contemporaries questioned Reynolds's methodology, other historians have supported it and her argument.[40] Reynolds argues:</p><div class="gradientback"></div></div><div class="content"><p>The term feudal has also been applied to non-Western societies in which institutions and attitudes similar to those of medieval Europe are perceived to have prevailed (See Examples of feudalism). Japan has been extensively studied in this regard.[43] Friday notes that in the 21st century historians of Japan rarely invoke feudalism; instead of looking at similarities, specialists attempting comparative analysis concentrate on fundamental differences.[44] Ultimately, critics say, the many ways the term feudalism has been used have deprived it of specific meaning, leading some historians and political theorists to reject it as a useful concept for understanding society.[40]</p><p>Richard Abels notes that Western Civilization and World Civilization textbooks now shy away from the term 'feudalism'.[45]</p><p>Military:</p><p>Non-European:</p><h3>Historiographical works</h3><h3>End of feudalism</h3><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Feudalism&amp;oldid=782785487"					
								Categories:  Hidden categories:</p><br><h1 lang="en">Artabanus V of Parthia</h1><p> From Wikipedia, the free encyclopedia</p><p>Artabanus V of Parthia, also known as Ardavan V (Parthian: ????????????????), ruled the Parthian Empire from c. 208 to 224. He was the younger son of Vologases V, who died in 208.</p><h2>Contents</h2><h2>Civil war and war with the Romans</h2><p>In 208, Artabanus rebelled against his brother Vologases VI, and soon gained the upper hand, although Vologases VI maintained himself in a part of Babylonia until about 228.[1]</p><p>The Roman emperor Caracalla, wishing to make use of this civil war for a conquest of the East in imitation of his hero, Alexander the Great, attacked the Parthians in 216. He crossed the Tigris, destroyed the towns and spoiled the tombs of Arbela, but when Artabanus advanced at the head of an army, he retired to Carrhae. There Caracalla was murdered by Martialis on April 8, 217. Caracalla's successor, the Praetorian Prefect of the Guard Macrinus, was defeated at Nisibis and concluded a peace with Artabanus, in which he gave up all the Roman conquests, restored the booty, and paid a heavy contribution to the Parthians.[2]</p><p>In Susa a stela was found showing the king and the satrap Khwasak. The stela dates to 215 and demonstrated that the city was at that time part of the Parthian empire. There are indications that it was before independent.</p><h2>Struggle for supremacy in Iran</h2><p>At about this time, Ardashir had begun his conquests in Persis and Carmania. This expansion came to the attention of the Arsacid Great King, Artabanus V, who ordered his vassal, the ruler of Khuzestan, to confront Ardashir.[3] It was Ardashir, however, who emerged victorious in that battle. In 224, Artabanus himself invaded Fars to confront the rebelling Ardashir. The latter won the first battle, but with heavy losses on both sides. In the second battle, the Parthians suffered a greater loss, and Ardashir was again deemed the victor. Their armies clashed once again in a final battle at Hormozgan, near the modern city of Bandar Abbas. At this encounter, the Parthian army was completely defeated, and Artabanus was killed.[4] This ended the 400-year rule of the Arsacid Dynasty.</p><h2>Sources</h2><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Artabanus_V_of_Parthia&amp;oldid=780631061"					
								Categories:  Hidden categories:</p><br><h1 lang="en">Aramaic language</h1><p> From Wikipedia, the free encyclopedia</p><p> This article is about the Semitic language now spoken by smaller numbers of people in scattered locations. For the Semitic language spoken in Ethiopia, see Amharic.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/4/46/Aramaic_alphabet.jpg/260px-Aramaic_alphabet.jpg" width="260" height="107"><p>


				Syriac-Aramaic alphabet


				</p><p>
					Aramaic[2] (????????? Aramaya, Syriac: ??????, Arabic ??????) is a Middle Eastern language or group of languages belonging to the Semitic subfamily of the Afroasiatic language family. More specifically, it is part of the Northwest Semitic group, which also includes the Canaanite languages such as Hebrew and Phoenician. The Aramaic alphabet was widely adopted for other languages and is ancestral to the Hebrew, Syriac and Arabic alphabets.</p><p>During its approximately 3100 years of written history,[3] Aramaic has served variously as a language of administration of empires and as a language of divine worship, as well as the spoken tongue of a number of Semitic peoples from the Near East.</p><p>It rose to prominence when it became the lingua franca of the Neo-Assyrian Empire (911–605 BC), and then the succeeding Neo-Babylonian Empire (605–539 BC), Achaemenid Empire (539–323 BC), Parthian Empire (247 BC–224 AD), and the Sasanian Empire (224–651), and of the states of post-imperial Assyria (Assur, Adiabene, Osroene, Beth Nuhadra, Beth Garmai and Hatra); the Aramean state of Palmyra, and the day-to-day language of Yehud Medinata and of Roman Judaea (539 BC – 70 AD). It was the language of Jesus and John the Baptist,[4][5][6] who spoke a Western Aramaic language during his public ministry,[4][5] as well as the language of large sections of the biblical books of Daniel and Ezra, and also the main language of the Talmud.</p><div class="gradientback"></div></div><div class="content"><p>At its height it was spoken all over what is today Iraq, Syria, south east and south central Turkey, north west Iran, Lebanon, Israel, Jordan, Palestinian territories, Kuwait and parts of Eastern Arabia and Northern Arabia, but in its more widely spoken Eastern Aramaic and Mandaic forms is today largely restricted to northern Iraq, north east Syria, north west Iran and south east Turkey, whilst the severely endangered Western Aramaic is spoken by small communities in north western Syria and Israel.</p><p>Aramaic was also the original language of the Bahrani people of Eastern Arabia,[7] and of the Mandaeans and their gnostic religion, Mandaeism, as well as the language of the once widespread but now extinct religion of Manichaeism.</p><p>The major Aramaic dialect Syriac is the liturgical language of Syriac Christianity, in particular the Assyrian Church of the East, the Chaldean Catholic Church, the Saint Thomas Christian Churches in India,[8] the Syriac Orthodox Church, the Assyrian Pentecostal Church, Assyrian Evangelical Church, Ancient Church of the East, Syriac Catholic Church, Melkite Church and the Maronite Church.[9]</p><p>Aramaic's long history and diverse and widespread use has led to the development of many divergent varieties, which are sometimes considered dialects, though they have become distinct enough over time that they are now sometimes considered as separate languages. Therefore, there is not one singular, static Aramaic language; each time and place rather has had its own variation. Aramaic is retained as a liturgical language by certain Eastern Christian churches, in the form of Syriac, whether or not those communities once spoke it or another form of Aramaic as their vernacular, but have since shifted to another language as their primary community language.</p><p>Neo-Aramaic languages are still spoken today as a first language by many communities of Syriac Christians, Jews, and Mandaeans of Western Asia,[10] most numerously by Assyrian Christians with numbers of fluent speakers among Assyrian people ranging from approximately 575,000 to 1,000,000, with the main languages being Assyrian Neo-Aramaic (235,000 speakers), Chaldean Neo-Aramaic (216,000 speakers) and Surayt/Turoyo (112,000 to 450,000 speakers), together with a number of smaller closely related languages with no more than 5,000 to 10,000 speakers between them. They have retained use of the once dominant lingua franca despite subsequent language shifts experienced throughout the Middle East. The Aramaic languages are now considered endangered.[11]</p><h2>Contents</h2><h2>Etymology</h2><p>Aram is used as a proper name of several people in the Torah (Hebrew Bible) including descendants of Shem (Genesis 10:22), Nahor (Genesis 22:21), and Jacob (1 Chronicles 7:34).[12]</p><p>Ancient Aram, bordering northern Israel and now called Syria, is considered the linguistic epicenter of Aramaic, the language of the Arameans who settled the area during the Bronze Age circa 3500 BC. The language is often mistakenly considered to have originated within Assyria (Iraq). In fact, Arameans carried their language and writing into Mesopotamia by voluntary migration, by forced exile of conquering armies, and by nomadic Chaldean invasions of Babylonia during the period from 1200 to 1000 BC.[13]</p><p>Interestingly, the Christian New Testament, for which the constituent texts are largely written in Koine Greek, translates the word Hebrew as Aramaic.[12] The Hellenized Jewish community of Alexandria instead translated Aramaic to the Syrian tongue.</p><h2>Geographic distribution</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/7/7e/Syriac_inscription_at_Syro-Malabar_Catholic_Major_Archbishop%27s_House_Ernakulam.jpg/220px-Syriac_inscription_at_Syro-Malabar_Catholic_Major_Archbishop%27s_House_Ernakulam.jpg" width="220" height="161"><p>


				Syriac inscription at the Syro-Malabar Catholic Church's Major Archbishop's House in South India.


				</p><p>
					During the Neo-Assyrian and Neo-Babylonian Empires, Arameans, the native speakers of Aramaic, began to settle in greater numbers, at first in Babylonia, and later in Assyria (Upper Mesopotamia, modern-day northern Iraq, northeast Syria, northwest Iran, and south eastern Turkey (what was Armenia at the time).[14] The influx eventually resulted in the Neo-Assyrian Empire (911-605 BC) adopting an Akkadian-influenced Imperial Aramaic as the lingua franca of its empire.[15] This policy was continued by the short-lived Neo-Babylonian Empire and Medes, and all three empires became operationally bilingual in written sources, with Aramaic used alongside Akkadian. The Achaemenid Empire (539-323 BC) continued this tradition, and the extensive influence of these empires led to Aramaic gradually becoming the lingua franca of most of western Asia, the Arabian Peninsula, Anatolia, the Caucasus, and Egypt.[14] Aramaic was also the lingua franca of the Parthian Empire.[16][17] Aramaic writing has been found as far north as Hadrian's Wall in Roman Britain, in the form of inscriptions in Aramaic made by Assyrian and Aramean soldiers serving in the Roman legions in Northern England during the second century.[18]</p><p>The successor state of the Parthians and thus the new neighboring archrival of the Roman-Byzantine Empire, the Sasanian Empire, continued with the usage of Aramaic as the lingua franca.[16][19] From the late 7th to the 14th century, Aramaic was gradually replaced as the lingua franca of the Middle East by Arabic. However, Aramaic remains a spoken, literary, and liturgical language for local Christians and also some Jews. It is spoken by the Assyrians of Iraq, northeastern Syria, southeastern Turkey and northwest Iran, with diaspora communities in Armenia, Georgia, Azerbaijan and southern Russia. The Mandaeans also continue to use Mandaic Aramaic as a liturgical language, although most now speak Arabic as their first language. There are still also a small number of first-language speakers of Western Aramaic varieties in isolated villages in western Syria.</p><p>The turbulence of the last two centuries (particularly the Assyrian genocide) has seen speakers of first-language and literary Aramaic dispersed throughout the world. However, there are a number of sizable Assyrian towns in northern Iraq such as Alqosh, Bakhdida, Bartella, Tesqopa, and Tel Keppe, and numerous small villages, where Aramaic is still the main spoken language, and many large cities in this region also have Assyrian Aramaic-speaking communities, particularly Mosul, Erbil, Kirkuk, Dohuk, and al-Hasakah. Aramaic is also experiencing a revival among Maronites in Israel in Jish.[20]</p><h3>Aramaic languages and dialects</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/8/8e/YeshuaDSS.gif/220px-YeshuaDSS.gif" width="220" height="81"><p>


				"Jesus" in Jewish Aramaic.


				</p><p>
					Aramaic is often spoken of as a single language, but is in reality a group of related languages.[citation needed] Some Aramaic languages differ more from each other than the Romance languages do among themselves. Its long history, extensive literature, and use by different religious communities are all factors in the diversification of the language. Some Aramaic dialects are mutually intelligible, whereas others are not, not unlike the situation with modern varieties of Arabic. Some Aramaic languages are known under different names; for example, Syriac is particularly used to describe the Eastern Aramaic variety used in Christian ethnic communities in Iraq, southeastern Turkey, northeastern Syria, and northwestern Iran, and Saint Thomas Christians in India. Most dialects can be described as either Eastern or Western, the dividing line being roughly the Euphrates, or slightly west of it. It is also helpful to draw a distinction between those Aramaic languages that are modern living languages (often called Neo-Aramaic), those that are still in use as literary languages, and those that are extinct and are only of interest to scholars. Although there are some exceptions to this rule, this classification gives Modern, Middle, and Old periods, alongside Eastern and Western areas, to distinguish between the various languages and dialects that are Aramaic.</p><div class="gradientback"></div></div><div class="content"><h2>Writing system</h2><p> Main article: Aramaic alphabet</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/1/15/Amen_in_East_Syriac_Aramaic_language.svg/150px-Amen_in_East_Syriac_Aramaic_language.svg.png" width="150" height="125"><p>


				Amen in East Syriac Aramaic



				<br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/5/5b/Syriac_Sert%C3%A2_book_script.jpg/220px-Syriac_Sert%C3%A2_book_script.jpg" width="220" height="166"><br>


				11th century book in Syriac Serto


				</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/5/5b/Syriac_Sert%C3%A2_book_script.jpg/220px-Syriac_Sert%C3%A2_book_script.jpg" width="220" height="166"><br><p>
					The earliest Aramaic alphabet was based on the Phoenician alphabet. In time, Aramaic developed its distinctive square style. The ancient Israelites and other peoples of Canaan adopted this alphabet for writing their own languages. Thus, it is better known as the Hebrew alphabet today. This is the writing system used in Biblical Aramaic and other Jewish writing in Aramaic. The other main writing system used for Aramaic was developed by Christian communities: a cursive form known as the Syriac alphabet. A highly modified form of the Aramaic alphabet, the Mandaic alphabet, is used by the Mandaeans.</p><p>In addition to these writing systems, certain derivatives of the Aramaic alphabet were used in ancient times by particular groups: the Nabataean alphabet in Petra and the Palmyrene alphabet in Palmyra. In modern times, Turoyo (see below) has sometimes been written in a Latin script.</p><h2>History</h2><p>The history of Aramaic is broken down into three broad periods:</p><p>This classification is based on that used by Klaus Beyer.</p><h2>Old Aramaic</h2><p> Main article: Old Aramaic language</p><p>The term Old Aramaic is used to describe the varieties of the language from its first known use until the point roughly marked by the rise of the Sasanian Empire (224 AD), dominating the influential, eastern dialect region. As such, the term covers over thirteen centuries of the development of Aramaic. This vast time span includes all Aramaic that is now effectively extinct.</p><p>The central phase in the development of Old Aramaic was its official use by the Achaemenid Empire (500–330 BC). The period before this, dubbed Ancient Aramaic, saw the development of the language from being spoken in Aramaean city-states to become a major means of communication in diplomacy and trade throughout Mesopotamia, the Levant and Egypt. After the fall of the Achaemenid Empire, local vernaculars became increasingly prominent, fanning the divergence of an Aramaic dialect continuum and the development of differing written standards.</p><h3>Ancient Aramaic</h3><p>Ancient Aramaic refers to the earliest known period of the language, from its origin until it becomes the lingua franca of the Fertile Crescent. It was the language of the Aramean city-states of Damascus, Hamath and Arpad.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/2/26/Bar-rakib.jpg/220px-Bar-rakib.jpg" width="220" height="183"><p>


				Silver ingot of Bar-Rakib, son of Panammuwa II,[21] King of Sam'al.


				</p><p>
					There are inscriptions that evidence the earliest use of the language, dating from the 10th century BC. These inscriptions are mostly diplomatic documents between Aramaean city-states. The alphabet of Aramaic at this early period seems to be based on the Phoenician alphabet, and there is a unity in the written language. It seems that, in time, a more refined alphabet, suited to the needs of the language, began to develop from this in the eastern regions of Aram. Due to increasing Aramean migration eastward, the Western periphery of Assyria became bilingual in Akkadian and Aramean at least as early as the mid-9th century BC. As the Neo-Assyrian Empire conquered Aramean lands west of the Euphrates, Tiglath-Pileser III made Aramaic the Empire's second official language, and it eventually supplanted Akkadian completely.</p><p>From 700 BC, the language began to spread in all directions, but lost much of its unity. Different dialects emerged in Assyria, Babylonia, the Levant and Egypt. Around 600 BC, Adon, a Canaanite king, used Aramaic to write to an Egyptian Pharaoh.[22]</p><p>Chaldee or Chaldean Aramaic used to be common terms for the Aramaic of the Chaldean dynasty of Babylonia. It was used to describe Biblical Aramaic, which was, however, written in a later style. It is not to be confused with the modern language Chaldean Neo-Aramaic.</p><h3>Imperial Aramaic</h3><p>Around 500 BC, following the Achaemenid conquest of Mesopotamia under Darius I, Aramaic (as had been used in that region) was adopted by the conquerors as the vehicle for written communication between the different regions of the vast empire with its different peoples and languages. The use of a single official language, which modern scholarship has dubbed Official Aramaic or Imperial Aramaic, can be assumed to have greatly contributed to the astonishing success of the Achaemenids in holding their far-flung empire together for as long as they did.[23] In 1955, Richard Frye questioned the classification of Imperial Aramaic as an official language, noting that no surviving edict expressly and unambiguously accorded that status to any particular language.[24] Frye reclassifies Imperial Aramaic as the lingua franca of the Achaemenid territories, suggesting then that the Achaemenid-era use of Aramaic was more pervasive than generally thought.</p><div class="gradientback"></div></div><div class="content"><p>Imperial Aramaic was highly standardised; its orthography was based more on historical roots than any spoken dialect, and the inevitable influence of Persian gave the language a new clarity and robust flexibility. For centuries after the fall of the Achaemenid Empire (in 331 BC), Imperial Aramaic&nbsp;– or near enough for it to be recognisable&nbsp;– would remain an influence on the various native Iranian languages. Aramaic script and&nbsp;– as ideograms&nbsp;– Aramaic vocabulary would survive as the essential characteristics of the Pahlavi scripts.[25]</p><p>One of the largest collections of Imperial Aramaic texts is that of the Persepolis fortification tablets, which number about five hundred.[26] Many of the extant documents witnessing to this form of Aramaic come from Egypt, and Elephantine in particular (see Elephantine papyri). Of them, the best known is the Story of Ahikar, a book of instructive aphorisms quite similar in style to the biblical Book of Proverbs. Achaemenid Aramaic is sufficiently uniform that it is often difficult to know where any particular example of the language was written. Only careful examination reveals the occasional loan word from a local language.</p><p>A group of thirty Aramaic documents from Bactria have been discovered, and an analysis was published in November 2006. The texts, which were rendered on leather, reflect the use of Aramaic in the 4th century BC Achaemenid administration of Bactria and Sogdia.[27]</p><h3>Post-Achaemenid Aramaic</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/2/29/Alexander_Aramaic_coin.jpg/220px-Alexander_Aramaic_coin.jpg" width="220" height="109"><p>


				Coin of Alexander the Great bearing an Aramaic language inscription



				<br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/1/10/AsokaKandahar.jpg/220px-AsokaKandahar.jpg" width="220" height="231"><br>


				Bilingual inscription (Greek and Aramaic) by the Indian king Ashoka, 3rd century BC at Kandahar, Afghanistan



				<br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/b/b9/Targum.jpg/220px-Targum.jpg" width="220" height="256"><br>


				11th century Hebrew Bible with Targum


				</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/1/10/AsokaKandahar.jpg/220px-AsokaKandahar.jpg" width="220" height="231"><br><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/b/b9/Targum.jpg/220px-Targum.jpg" width="220" height="256"><br><p>
					The conquest by Alexander the Great did not destroy the unity of Aramaic language and literature immediately. Aramaic that bears a relatively close resemblance to that of the 5th century BC can be found right up to the early 2nd century BC. The Seleucids imposed Greek in the administration of Syria and Mesopotamia from the start of their rule. In the 3rd century BC, Greek overtook Aramaic as the common[clarification needed] language in Egypt and Syria. However, a post-Achaemenid Aramaic continued to flourish from Judaea, Assyria, Mesopotamia, through the Syrian Desert and into northern Arabia and Parthia.</p><p>Biblical Aramaic is the Aramaic found in four discrete sections of the Hebrew Bible:</p><p>Biblical Aramaic is a somewhat hybrid dialect. It is theorized that some Biblical Aramaic material originated in both Babylonia and Judaea before the fall of the Achaemenid dynasty. According to historical criticism, defiant Jewish propaganda shaped Aramaic Daniel during Seleucid rule. These stories might have existed as oral traditions at their earliest stage. This might be one factor that led to differing collections of Daniel in the Greek Septuagint and the Masoretic Text, which presents a lightly Hebrew-influenced Aramaic.</p><p>Under the category of post-Achaemenid is Hasmonaean Aramaic, the official language of Hasmonaean Judaea (142–37 BC). It influenced the Biblical Aramaic of the Qumran texts, and was the main language of non-biblical theological texts of that community. The major Targums, translations of the Hebrew Bible into Aramaic, were originally composed in Hasmonaean. Hasmonaean also appears in quotations in the Mishnah and Tosefta, although smoothed into its later context. It is written quite differently from Achaemenid Aramaic; there is an emphasis on writing as words are pronounced rather than using etymological forms.</p><p>Babylonian Targumic is the later post-Achaemenid dialect found in the Targum Onqelos and Targum Jonathan, the official targums. The original, Hasmonaean targums had reached Babylon sometime in the 2nd or 3rd century AD. They were then reworked according to the contemporary dialect of Babylon to create the language of the standard targums. This combination formed the basis of Babylonian Jewish literature for centuries to follow.</p><p>Galilean Targumic is similar to Babylonian Targumic. It is the mixing of literary Hasmonaean with the dialect of Galilee. The Hasmonaean targums reached Galilee in the 2nd century AD, and were reworked into this Galilean dialect for local use. The Galilean Targum was not considered an authoritative work by other communities, and documentary evidence shows that its text was amended. From the 11th century AD onwards, once the Babylonian Targum had become normative, the Galilean version became heavily influenced by it.</p><p>Babylonian Documentary Aramaic is a dialect in use from the 3rd century AD onwards. It is the dialect of Babylonian private documents, and, from the 12th century, all Jewish private documents are in Aramaic. It is based on Hasmonaean with very few changes. This was perhaps because many of the documents in BDA are legal documents, the language in them had to be sensible throughout the Jewish community from the start, and Hasmonaean was the old standard.</p><p>Nabataean Aramaic is the language of the Arameo-Arab kingdom of Petra. The kingdom (c. 200 BC–106 AD) covered the east bank of the Jordan River, the Sinai Peninsula and northern Arabia. Perhaps because of the importance of the caravan trade, the Nabataeans began to use Aramaic in preference to Old North Arabic. The dialect is based on Achaemenid with a little influence from Arabic: l is often turned into n, and there are a few Arabic loanwords. Some Nabataean Aramaic inscriptions exist from the early days of the kingdom, but most are from the first four centuries AD The language is written in a cursive script that is the precursor to the modern Arabic alphabet. The number of Arabic loanwords increases through the centuries, until, in the 4th century, Nabataean merges seamlessly with Arabic.</p><div class="gradientback"></div></div><div class="content"><p>Palmyrene Aramaic is the dialect that was in use in the Syriac city state of Palmyra in the Syrian Desert from 44 BC to 274 AD. It was written in a rounded script, which later gave way to cursive Estrangela. Like Nabataean, Palmyrene was influenced by Arabic, but to a much lesser degree.</p><p>Arsacid Aramaic, that in use during the Parthian Empire (247 BC – 224 AD), represents a continuation of Achaemenid Aramaic, widely spoken throughout the west of the empire. Aramaic continued as the scribal basis for Pahlavi as it developed for the needs of Parthian: using an Aramaic-derived script and incorporating many heterograms, or Aramaic words meant to be read as Parthian ones. The Parthians saw themselves as a continuation of Achaemenid rule, and so Arsacid Aramaic, more than any other post-Achaemenid dialect, continued the tradition of the chancery of Darius I. Over time, however, it came under the influence of contemporary, spoken Aramaic and Persian. After the establishment of the Persian-speaking Sasanian Empire, Arsacid Pahlavi and Aramaic were influential on Sasanian language use.[28]</p><h3>Late Old Eastern Aramaic</h3><p> Main article: Eastern Aramaic languages</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/a/ad/Mandaic.jpg/220px-Mandaic.jpg" width="220" height="228"><p>


				Mandaic magical "demon trap"


				</p><p>
					The dialects mentioned in the last section were all descended from Achaemenid Imperial Aramaic. However, the diverse regional dialects of Late Ancient Aramaic continued alongside these, often as simple, spoken languages. Early evidence for these spoken dialects is known only through their influence on words and names in a more standard dialect. However, these regional dialects became written languages in the 2nd century BC. These dialects reflect a stream of Aramaic that is not dependent on Imperial Aramaic, and shows a clear division between the regions of Mesopotamia, Babylon and the east, and Judah, Syria, and the west.</p><p>In the East, the dialects of Palmyrene and Arsacid Aramaic merged with the regional languages to create languages with a foot in Imperial and a foot in regional Aramaic. The written form of Mandaic, the language of the Mandaean religion, was descended from the Arsacid chancery script.[29]</p><p>In the kingdom of Osroene, centred on Edessa and founded in 132 BC, the regional dialect became the official language: Old Syriac. On the upper reaches of the Tigris, East Mesopotamian Aramaic flourished, with evidence from Hatra, Assur and the Tur Abdin. Tatian, the author of the gospel harmony the Diatessaron came from Assyria, and perhaps wrote his work (172 AD) in East Mesopotamian rather than Syriac or Greek. In Babylonia, the regional dialect was used by the Jewish community, Jewish Old Babylonian (from c. 70 AD). This everyday language increasingly came under the influence of Biblical Aramaic and Babylonian Targumic.</p><h3>Late Old Western Aramaic</h3><p> Main article: Western Aramaic languages</p><p>The western regional dialects of Aramaic followed a similar course to those of the east. They are quite distinct from the eastern dialects and Imperial Aramaic. Aramaic came to coexist with Canaanite dialects, eventually completely displacing Phoenician in the first century BC and Hebrew around the turn of the fourth century AD.</p><p>The form of Late Old Western Aramaic used by the Jewish community is best attested, and is usually referred to as Jewish Old Palestinian. Its oldest form is Old East Jordanian, which probably comes from the region of Caesarea Philippi. This is the dialect of the oldest manuscript of the Book of Enoch (c. 170 BC). The next distinct phase of the language is called Old Judaean into the second century AD. Old Judean literature can be found in various inscriptions and personal letters, preserved quotations in the Talmud and receipts from Qumran. Josephus' first, non-extant edition of his The Jewish War was written in Old Judean.</p><p>The Old East Jordanian dialect continued to be used into the first century AD by pagan communities living to the east of the Jordan. Their dialect is often then called Pagan Old Palestinian, and it was written in a cursive script somewhat similar to that used for Old Syriac. A Christian Old Palestinian dialect may have arisen from the pagan one, and this dialect may be behind some of the Western Aramaic tendencies found in the otherwise eastern Old Syriac gospels (see Peshitta).</p><p> Further information: language of Jesus</p><p>It is generally believed by Christian scholars that in the first century, Jews in Judea primarily spoke Aramaic with a decreasing number using Hebrew as their first language. Many learned Hebrew as a liturgical language. Additionally, Koine Greek was the lingua franca of the Middle East in trade, among the Hellenized classes (much like French in the 18th,19th and 20th centuries in Europe), and in the Roman administration. Latin, the language of the Roman army and higher levels of administration, had almost no impact on the linguistic landscape.</p><p>In addition to the formal, literary dialects of Aramaic based on Hasmonean and Babylonian, there were a number of colloquial Aramaic dialects. Seven Western Aramaic varieties were spoken in the vicinity of Judea in Jesus' time. They were probably distinctive yet mutually intelligible. Old Judean was the prominent dialect of Jerusalem and Judaea. The region of Ein Gedi was the Southeast Judaean dialect. Samaria had its distinctive Samaritan Aramaic, where the consonants he, heth and ‘ayin all became pronounced as aleph. Galilean Aramaic, the dialect of Jesus' home region, is only known from a few place names, the influences on Galilean Targumic, some rabbinic literature and a few private letters. It seems to have a number of distinctive features: diphthongs are never simplified into monophthongs. East of the Jordan, the various dialects of East Jordanian were spoken. In the region of Damascus and the Anti-Lebanon Mountains, Damascene Aramaic was spoken (deduced mostly from Modern Western Aramaic). Finally, as far north as Aleppo, the western dialect of Orontes Aramaic was spoken.</p><p>The three languages influenced one another, especially Hebrew and Aramaic. Hebrew words entered Jewish Aramaic (mostly technical religious words but also everyday words like ?? ?e? wood). Conversely, Aramaic words entered Hebrew (not only Aramaic words like mammôn wealth but Aramaic ways of using words like making Hebrew ???? ra’ûi, seen mean worthy in the sense of seemly, which is a calque of Aramaic ?zî meaning seen and worthy).</p><p>The Greek of the New Testament often preserves non-Greek semiticisms, including transliterations of Semitic words:</p><p>The 2004 film The Passion of the Christ used Aramaic for much of its dialogue, specially reconstructed by a scholar, William Fulco, S.J. Where the appropriate words (in first century Aramaic) were no longer known, he used the Aramaic of Daniel, fourth-century Syriac and Hebrew as the basis for his work.[citation needed]</p><h2>Middle Aramaic</h2><div class="gradientback"></div></div><div class="content"><p>The 3rd century AD is taken as the threshold between Old and Middle Aramaic. During that century, the nature of the various Aramaic languages and dialects begins to change. The descendants of Imperial Aramaic ceased to be living languages, and the eastern and western regional languages began to form vital, new literatures. Unlike many of the dialects of Old Aramaic, much is known about the vocabulary and grammar of Middle Aramaic.</p><h3>Eastern Middle Aramaic</h3><p>Only two of the Old Eastern Aramaic languages continued into this period. In the north of the region, Old Syriac moved into Middle Syriac. In the south, Jewish Old Babylonian became Jewish Middle Babylonian. The post-Achaemenid, Arsacid dialect became the background of the new Mandaic language.</p><p> Main article: Syriac language</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/a/a1/Estrangela.jpg/220px-Estrangela.jpg" width="220" height="367"><p>


				9th century Syriac Estrangela manuscript of John Chrysostom's Homily on the Gospel of John


				 
				</p><p>
					Syriac (also Middle Syriac) is the classical, literary, liturgical and often spoken language of Syriac Christianity to this day, particularly the Assyrian Church of the East, Chaldean Catholic Church, Ancient Church of the East, Syriac Orthodox Church and Saint Thomas Christians. It originated in fifth century BC Achaemenid Assyria, but its golden age was the fourth to sixth centuries. This period began with the translation of the Bible into the language: the Peshitta and the masterful prose and poetry of Ephrem the Syrian. Middle Syriac became the language of those opposed to the Byzantine leadership of the Church of the East. Missionary activity by Assyrian and Nestorian Christians led to the spread of Syriac from Mesopotamia and Persia, into Central Asia, India and China.</p><p> Main article: Jewish Babylonian Aramaic</p><p>Jewish Middle Babylonian is the language employed by Jewish writers in Babylonia between the fourth and the eleventh century. It is most commonly identified with the language of the Babylonian Talmud (which was completed in the seventh century) and of post-Talmudic Geonic literature, which are the most important cultural products of Babylonian Judaism. The most important epigraphic sources for the dialect are the hundreds of incantation bowls written in Jewish Babylonian Aramaic.</p><p> Main article: Mandaic language</p><p>The Mandaic language, spoken by the Mandaeans of Iraq, is a sister dialect to Jewish Babylonian Aramaic, though it is both linguistically and culturally distinct. Classical Mandaic is the language in which the Mandaean's gnostic religious literature was composed. It is characterized by a highly phonetic orthography.</p><h3>Western Middle Aramaic</h3><p>The dialects of Old Western Aramaic continued with Jewish Middle Palestinian (in Hebrew square script), Samaritan Aramaic (in the old Hebrew script) and Christian Palestinian (in cursive Syriac script). Of these three, only Jewish Middle Palestinian continued as a written language.[clarification needed]</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/9/96/Kennicott_Bible_fol_42v.jpg/220px-Kennicott_Bible_fol_42v.jpg" width="220" height="298"><p>


				Hebrew (left) and Aramaic (right) in parallel in a 1299 Hebrew Bible held by the Bodleian Library



				</p><p>
					 Main article: Jewish Palestinian Aramaic</p><p>In 135, after the Bar Kokhba revolt, many Jewish leaders, expelled from Jerusalem, moved to Galilee. The Galilean dialect thus rose from obscurity to become the standard among Jews in the west. This dialect was spoken not only in Galilee, but also in the surrounding parts. It is the linguistic setting for the Jerusalem Talmud (completed in the 5th century), Palestinian targumim (Jewish Aramaic versions of scripture), and midrashim (biblical commentaries and teaching). The standard vowel pointing for the Hebrew Bible, the Tiberian system (7th century), was developed by speakers of the Galilean dialect of Jewish Middle Palestinian. Classical Hebrew vocalisation, therefore, in representing the Hebrew of this period, probably reflects the contemporary pronunciation of this Aramaic dialect.</p><p>Middle Judaean, the descendant of Old Judaean, is no longer the dominant dialect, and was used only in southern Judaea (the variant Engedi dialect continued throughout this period). Likewise, Middle East Jordanian continues as a minor dialect from Old East Jordanian. The inscriptions in the synagogue at Dura-Europos are either in Middle East Jordanian or Middle Judaean.</p><p> Main article: Samaritan Aramaic language</p><p>The Samaritan Aramaic is earliest attested by the documentary tradition of the Samaritans that can be dated back to the fourth century. Its modern pronunciation is based on the form used in the tenth century.</p><div class="gradientback"></div></div><div class="content"><p>Sometimes referred to as Melkite Aramaic, it is the language of Western-Aramaic-speaking Christians. It is evidenced from the 5th-6th century, but probably existed two centuries earlier. The language itself comes from Old Christian Palestinian Aramaic, but its writing conventions were based on early Middle Syriac, and it was heavily influenced by Greek. For example, the name Jesus, although ???? Yešua’ in Jewish Aramaic, and Išo in Syriac, is written Yesûs (a transliteration of the Greek form) in Christian Palestinian.[citation needed]</p><h2>Modern Aramaic</h2><p> Main article: Neo-Aramaic languages</p><p>As the Western Aramaic languages of the Levant and Lebanon have become nearly extinct in non-liturgical usage, the most prolific speakers of Aramaic dialects today are predominantly ethnic Assyrian Eastern Neo-Aramaic speakers, the most numerous being the Northeast Neo-Aramaic speakers of Mesopotamia. This includes speakers of Assyrian Neo-Aramaic (235,000 speakers), Chaldean Neo-Aramaic (216,000 speakers), and Turoyo (Surayt) (112,000 to 450,000 speakers). Having largely lived in remote areas as insulated communities for over a millennium, the remaining modern speakers of Aramaic dialects, such as the Assyrians, and the Arameans, escaped the linguistic pressures experienced by others during the large-scale language shifts that saw the proliferation of other tongues among those who previously did not speak them, most recently the Arabization of the Middle East and North Africa by Arabs beginning with the early Muslim conquests of the seventh century.[30][31]</p><p>Another Western Aramaic language, Neo-Mandaean, is spoken by the Mandaeans of Iraq and Iran. They number some 50,000-75,000 people, but it is believed the Mandaic language may now be spoken fluently by as few as 6000 people, with other Mandaeans having varying degrees of knowledge.[32]</p><h3>Modern Eastern Aramaic</h3><p> Main articles: Northeastern Neo-Aramaic and Neo-Mandaic</p><p>Modern Eastern Aramaic exists in a wide variety of dialects and languages. There is significant difference between the Aramaic spoken by Jews, Christians, and Mandaeans.</p><p>The Christian varieties are often called Modern Syriac (or Neo-Syriac, particularly when referring to their literature), being deeply influenced by the literary and liturgical language of Middle Syriac. However, they also have roots in numerous, previously unwritten, local Aramaic varieties, and are not purely the direct descendants of the language of Ephrem the Syrian. The varieties are not all mutually intelligible. The principal Christian varieties are Assyrian Neo-Aramaic and Chaldean Neo-Aramaic, both used by the ethnic Assyrians of Iraq, southeast Turkey, Iran, and northeast Syria.</p><p>The Judeo-Aramaic languages are now mostly spoken in Israel, and most are facing extinction. The Jewish varieties that have come from communities that once lived between Lake Urmia and Mosul are not all mutually intelligible. In some places, for example Urmia, Assyrian Christians and Jews speak mutually unintelligible varieties of Modern Eastern Aramaic in the same place. In others, the Nineveh plains around Mosul for example, the varieties of these two ethnic communities are similar enough to allow conversation.</p><p>Modern Central Neo-Aramaic, being in between Western Neo-Aramaic and Eastern Neo-Aramaic) is generally represented by Turoyo, the language of the Assyrians of Tur Abdin. A related language, Mlahsô, has recently become extinct.</p><p>Mandaeans living in the Khuzestan Province of Iran and scattered throughout Iraq, speak Modern Mandaic. It is quite distinct from any other Aramaic variety.</p><h3>Modern Central Aramaic</h3><p> Main article: Central Neo-Aramaic</p><p>Central Neo-Aramaic consists of Turoyo and the recently extinct Mlahsô.</p><h3>Modern Western Aramaic</h3><p> Main article: Western Neo-Aramaic</p><p>Very little remains of Western Aramaic. It is still spoken in the villages of Ma'loula, al-Sarkha (Bakhah), and Jubb'adin on Syria's side of the Anti-Lebanon Mountains, as well as by some people who migrated from these villages, to Damascus and other larger towns of Syria. All these speakers of Modern Western Aramaic are fluent in Arabic, which has now become the main language in these villages. Jewish Palestinian Aramaic and Samaritan Aramaic are preserved in liturgical and literary usage.</p><h2>Phonology</h2><p>Each dialect of Aramaic has its own distinctive pronunciation, and it would not be feasible here to go into all these properties. Aramaic has a phonological palette of 25 to 40 distinct phonemes. Some modern Aramaic pronunciations lack the series of emphatic consonants, and some have borrowed from the inventories of surrounding languages, particularly Arabic, Azerbaijani, Kurdish, Persian and Turkish.</p><h3>Vowels</h3><p>As with most Semitic languages, Aramaic can be thought of as having three basic sets of vowels:</p><p>These vowel groups are relatively stable, but the exact articulation of any individual is most dependent on its consonantal setting.</p><p>The open vowel is an open near-front unrounded vowel (short a, somewhat like the first vowel in the English batter, [a]). It usually has a back counterpart (long a, like the a in father, [?], or even tending to the vowel in caught, [?]), and a front counterpart (short e, like the vowel in head, [?]). There is much correspondence between these vowels between dialects. There is some evidence that Middle Babylonian dialects did not distinguish between the short a and short e. In West Syriac dialects, and possibly Middle Galilean, the long a became the o sound. The open e and back a are often indicated in writing by the use of the letters ? alaph (a glottal stop) or ? he (like the English h).</p><p>The close front vowel is the long i (like the vowel in need, [i]). It has a slightly more open counterpart, the long e, as in the final vowel of café ([e]). Both of these have shorter counterparts, which tend to be pronounced slightly more open. Thus, the short close e corresponds with the open e in some dialects. The close front vowels usually use the consonant ? y as a mater lectionis.</p><p>The close back vowel is the long u (like the vowel in school, [u]). It has a more open counterpart, the long o, like the vowel in low ([o]). There are shorter, and thus more open, counterparts to each of these, with the short close o sometimes corresponding with the long open a. The close back vowels often use the consonant ? w to indicate their quality.</p><p>Two basic diphthongs exist: an open vowel followed by ? y (ay), and an open vowel followed by ? w (aw). These were originally full diphthongs, but many dialects have converted them to e and o respectively.</p><p>The so-called emphatic consonants (see the next section) cause all vowels to become mid-centralised.</p><h3>Consonants</h3><p>The various alphabets used for writing Aramaic languages have twenty-two letters (all of which are consonants). Some of these letters, though, can stand for two or three different sounds (usually a stop and a fricative at the same point of articulation). Aramaic classically uses a series of lightly contrasted plosives and fricatives:</p><div class="gradientback"></div></div><div class="content"><p>Each member of a certain pair is written with the same letter of the alphabet in most writing systems (that is, p and f are written with the same letter), and are near allophones.</p><p>A distinguishing feature of Aramaic phonology (and that of Semitic languages in general) is the presence of emphatic consonants. These are consonants that are pronounced with the root of the tongue retracted, with varying degrees of pharyngealization and velarization. Using their alphabetic names, these emphatics are:</p><p>Ancient Aramaic may have had a larger series of emphatics, and some Neo-Aramaic languages definitely do. Not all dialects of Aramaic give these consonants their historic values.</p><p>Overlapping with the set of emphatics are the guttural consonants. They include ? ?ê? and ? ?Ayn from the emphatic set, and add ? 'Alap¯ (a glottal stop) and ? Hê (as the English h).</p><p>Aramaic classically has a set of four sibilants (ancient Aramaic may have had six):</p><p>In addition to these sets, Aramaic has the nasal consonants ? m and ? n, and the approximants ? r (usually an alveolar trill), ? l, ? y and ? w.</p><h3>Historical sound changes</h3><p>Six broad features of sound change can be seen as dialect differentials:</p><h2>Grammar</h2><p>As with other Semitic languages, Aramaic morphology (the way words are formed) is based on the consonantal root. The root generally consists of two or three consonants and has a basic meaning, for example, ???? k-t-b has the meaning of 'writing'. This is then modified by the addition of vowels and other consonants to create different nuances of the basic meaning:</p><h3>Nouns and adjectives</h3><p>Aramaic nouns and adjectives are inflected to show gender, number and state.</p><p>Aramaic has two grammatical genders: masculine and feminine. The feminine absolute singular is often marked by the ending ?- -â.</p><p>Nouns can be either singular or plural, but an additional dual number exists for nouns that usually come in pairs. The dual number gradually disappeared from Aramaic over time and has little influence in Middle and Modern Aramaic.</p><p>Aramaic nouns and adjectives can exist in one of three states. To a certain extent, these states correspond to the role of articles and cases in the Indo-European languages:</p><li>The absolute state is the basic form of a noun. In early forms of Aramaic, the absolute state expresses indefiniteness, comparable to the English indefinite article a(n) (for example, ???? k?a?â, a handwriting), and can be used in most syntactic roles. However, by the Middle Aramaic period, its use for nouns (but not adjectives) had been widely replaced by the emphatic state.</li><li>The construct state is a form of the noun used to make possessive constructions (for example, ???? ????? k?a?at malk?â, the handwriting of the queen). In the masculine singular the form of the construct is often the same as the absolute, but it may undergo vowel reduction in longer words. The feminine construct and masculine construct plural are marked by suffixes. Unlike a genitive case, which marks the possessor, the construct state is marked on the possessed. This is mainly due to Aramaic word order: possessed[const.] possessor[abs./emph.] are treated as a speech unit, with the first unit (possessed) employing the construct state to link it to the following word. In Middle Aramaic, the use of the construct state for all but stock phrases (like ?? ??? bar našâ, son of man) begins to disappear.</li><li>The emphatic or determined state is an extended form of the noun that functions similarly to the definite article. It is marked with a suffix (for example, ????? k?a?tâ, the handwriting). Although its original grammatical function seems to have been to mark definiteness, it is used already in Imperial Aramaic to mark all important nouns, even if they should be considered technically indefinite. This practice developed to the extent that the absolute state became extraordinarily rare in later varieties of Aramaic.</li><p>Whereas other Northwest Semitic languages, like Hebrew, have the absolute and construct states, the emphatic/determined state is a unique feature to Aramaic. Case endings, as in Ugaritic, probably existed in a very early stage of the language, and glimpses of them can be seen in a few compound proper names. However, as most of those cases were expressed by short final vowels, they were never written, and the few characteristic long vowels of the masculine plural accusative and genitive are not clearly evidenced in inscriptions. Often, the direct object is marked by a prefixed -? l- (the preposition to) if it is definite.</p><p>Adjectives agree with their nouns in number and gender but agree in state only if used attributively. Predicative adjectives are in the absolute state regardless of the state of their noun (a copula may or may not be written). Thus, an attributive adjective to an emphatic noun, as in the phrase the good king, is written also in the emphatic state ???? ??? malkâ ?a?â—king[emph.] good[emph.]. In comparison, the predicative adjective, as in the phrase the king is good, is written in the absolute state ???? ?? malkâ ?a? — king[emph.] good[abs.].</p><p>The final ?- -â in a number of these suffixes is written with the letter aleph. However, some Jewish Aramaic texts employ the letter he for the feminine absolute singular. Likewise, some Jewish Aramaic texts employ the Hebrew masculine absolute singular suffix ??- -îm instead of ??- -în. The masculine determined plural suffix, ??- -ayyâ, has an alternative version, -ê. The alternative is sometimes called the gentilic plural for its prominent use in ethnonyms (?????? y?hû?ayê, 'the Jews', for example). This alternative plural is written with the letter aleph, and came to be the only plural for nouns and adjectives of this type in Syriac and some other varieties of Aramaic. The masculine construct plural, -ê, is written with yodh. In Syriac and some other variants this ending is diphthongized to -ai.</p><p>Possessive phrases in Aramaic can either be made with the construct state or by linking two nouns with the relative particle -[?[? d[î]-. As the use of the construct state almost disappears from the Middle Aramaic period on, the latter method became the main way of making possessive phrases.</p><p>For example, the various forms of possessive phrases (for the handwriting of the queen) are:</p><li>???? ????? k?a?a? malk?â – the oldest construction, also known as ?????? s?mî?û?&nbsp;: the possessed object (???? k?abâ, handwriting) is in the construct state (???? k?a?a?); the possessor (???? malkâ, queen) is in the emphatic state (????? malk?â)</li><li>????? ?????? k?a?tâ d(î)-malk?â – both words are in the emphatic state and the relative particle -[?[? d[î]- is used to mark the relationship</li><li>????? ?????? k?a?tah d(î)-malk?â – both words are in the emphatic state, and the relative particle is used, but the possessed is given an anticipatory, pronominal ending (????? k?a?ta-h, handwriting-her; literally, her writing, that (of) the queen).</li><p>In Modern Aramaic, the last form is by far the most common. In Biblical Aramaic, the last form is virtually absent.</p><h3>Verbs</h3><p>The Aramaic verb has gradually evolved in time and place, varying between varieties of the language. Verb forms are marked for person (first, second or third), number (singular or plural), gender (masculine or feminine), tense (perfect or imperfect), mood (indicative, imperative, jussive or infinitive) and voice (active, reflexive or passive). Aramaic also employs a system of conjugations, or verbal stems, to mark intensive and extensive developments in the lexical meaning of verbs.</p><p>Aramaic has two proper tenses: perfect and imperfect. These were originally aspectual, but developed into something more like a preterite and future. The perfect is unmarked, while the imperfect uses various preformatives that vary according to person, number and gender. In both tenses the third-person singular masculine is the unmarked form from which others are derived by addition of afformatives (and preformatives in the imperfect). In the chart below (on the root ???? K-T-B, meaning to write), the first form given is the usual form in Imperial Aramaic, while the second is Classical Syriac.</p><div class="gradientback"></div></div><div class="content"><p>Like other Semitic languages, Aramaic employs a number of derived verb stems, to extend the lexical coverage of verbs. The basic form of the verb is called the ground stem, or G-stem. Following the tradition of mediaeval Arabic grammarians, it is more often called the P?‘al ??? (also written Pe‘al), using the form of the Semitic root ???? P-‘-L, meaning to do. This stem carries the basic lexical meaning of the verb.</p><p>By doubling of the second radical, or root letter, the D-stem or ??? Pa‘‘el is formed. This is often an intensive development of the basic lexical meaning. For example, q??al means he killed, whereas qa??el means he slew. The precise relationship in meaning between the two stems differs for every verb.</p><p>A preformative, which can be -? ha-, -? a- or -? ša-, creates the C-stem or variously the Hap¯‘el, Ap¯‘el or Šap¯‘el (also spelt ???? Haph‘el, ???? Aph‘el and ???? Shaph‘el). This is often an extensive or causative development of the basic lexical meaning. For example, ??? ??‘â means he went astray, whereas ???? a?‘î means he deceived. The Šap¯‘el ???? is the least common variant of the C-stem. Because this variant is standard in Akkadian, it is possible that its use in Aramaic represents loanwords from that language. The difference between the variants ???? Hap¯‘el and ???? Ap¯‘el appears to be the gradual dropping of the initial ? h sound in later Old Aramaic. This is noted by the respelling of the older he preformative with ? aleph.</p><p>These three conjugations are supplemented with three further derived stems, produced by the preformative -?? hi?- or -?? e?-. The loss of the initial ? h sound occurs similarly to that in the form above. These three derived stems are the Gt-stem, ????? Hi?p?‘el or ????? E?p?‘el (also written Hithpe‘el or Ethpe‘el), the Dt-stem, ?????? Hi?pa‘‘al or ?????? E?pa‘‘al (also written Hithpa‘‘al or Ethpa‘‘al), and the Ct-stem, ?????? Hi?hap¯‘al, ?????? Ettap¯‘al, ?????? Hištap¯‘al or ?????? Eštap¯‘al (also written Hithhaph‘al, Ettaph‘al, Hishtaph‘al or Eshtaph‘al). Their meaning is usually reflexive, but later became passive. However, as with other stems, actual meaning differs from verb to verb.</p><p>Not all verbs utilise all of these conjugations, and, in some, the G-stem is not used. In the chart below (on the root ???? K-T-B, meaning to write), the first form given is the usual form in Imperial Aramaic, while the second is Classical Syriac.</p><p>Aramaic also has two proper tenses: the perfect and the imperfect. In Imperial Aramaic, the participle began to be used for a historical present. Perhaps under influence from other languages, Middle Aramaic developed a system of composite tenses (combinations of forms of the verb with pronouns or an auxiliary verb), allowing for narrative that is more vivid. The syntax of Aramaic (the way sentences are put together) usually follows the order verb–subject–object (VSO). Imperial (Persian) Aramaic, however, tended to follow a S-O-V pattern (similar to Akkadian), which was the result of Persian syntactic influence.</p><h2>Word processors</h2><p>The World's first Aramaic language word processing software was developed in 1986–1987 in Kuwait by information technology professional Sunil Sivanand (1953– ), who is now Managing Director and Chief Technology Architect at Acette. Sunil Sivanand did most of the character generation and programming work on a first generation, twin disk drive IBM Personal Computer. The project was sponsored by Daniel Benjamin, who was a patron of a group of individuals working worldwide to preserve and revive the Aramaic language.</p><h2>Notes</h2><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Aramaic_language&amp;oldid=783240892"					
								Categories:  Hidden categories:</p><br><br><img alt="Page semi-protected" src="http://upload.wikimedia.org/wikipedia/commons/thumb/f/fc/Padlock-silver.svg/20px-Padlock-silver.svg.png" width="20" height="20"><h1 lang="en">Zoroastrianism</h1><p> From Wikipedia, the free encyclopedia</p><p>Zoroastrianism,[n 1] or more natively Mazdayasna,[1] is one of the world's oldest extant religions, combining a cosmogonic dualism and eschatological monotheism in a manner unique [...] among the major religions of the world.[2] Ascribed to the teachings of the Iranian prophet Zoroaster (or Zarathustra),[3] it exalts a deity of wisdom, Ahura Mazda (Wise Lord), as its Supreme Being.[4] Major features of Zoroastrianism, such as messianism, heaven and hell, and free will have, some believe, influenced other religious systems, including Second Temple Judaism, Gnosticism, Christianity, and Islam.[5] With possible roots dating back to the second millennium BCE, Zoroastrianism enters recorded history in the 5th-century BCE,[4] and along with a Mithraic Median prototype and a Zurvanist Sassanid successor it served as the state religion of the pre-Islamic Iranian empires from around 600 BCE to 650 CE. Zoroastrianism was suppressed from the 7th century onwards following the Muslim conquest of Persia of 633-654.[6] Recent estimates place the current number of Zoroastrians at around 2.6 million, with most living in India and in Iran.[7][8][better&nbsp;source&nbsp;needed][n 2] Besides the Zoroastrian diaspora, the older Mithraic faith Yazdânism is still practised amongst Kurds.[n 3]</p><p>The religious philosophy of Zoroaster divided the early Iranian gods of Proto-Indo-Iranian tradition.[9] The most important texts of the religion are those of the Avesta,[10] the Zoroastrians' holy book. In Zoroastrianism, the creator Ahura Mazda, through the Spenta Mainyu (Good Spirit, Bounteous Immortals)[11] is an all-good father of Asha (Truth, order, justice),[12][13] in opposition to Druj (falsehood, deceit)[14][15] and no evil originates from him.[16] He and his works are evident to humanity through the six primary Amesha Spentas[17] and the host of other Yazatas, through whom worship of Mazda is ultimately directed. Spenta Mainyu adjoined unto truth[18] oppose the Spirit's opposite,[19][20] Angra Mainyu and its forces born of Ak?m Manah (“evil thinking”).[21]</p><p>Zoroastrianism has no major theological divisions, though it is not uniform; modern-era influences having a significant impact on individual and local beliefs, practices, values and vocabulary, sometimes merging with tradition and in other cases displacing it.[22] In Zoroastrianism, the purpose in life is to be among those who renew the world...to make the world progress towards perfection. Its basic maxims include:</p><p>The most important texts of the religion are those of the Avesta, which includes the writings of Zoroaster known as the Gathas, enigmatic poems that define the religion's precepts, and the Yasna, the scripture. The full name by which Zoroaster addressed the deity is: Ahura, The Lord Creator, and Mazda, Supremely Wise. He proclaimed that there is only one God, the singularly creative and sustaining force of the Universe. He also stated that human beings are given a right of choice, and because of cause and effect are also responsible for the consequences of their choices. Zoroaster's teachings focused on responsibility, and did not introduce a devil per se. The contesting force to Ahura Mazda was called Angra Mainyu, or angry spirit. Post-Zoroastrian scripture introduced the concept of Ahriman, the Devil, which was effectively a personification of Angra Mainyu.[23]</p><h2>Contents</h2><h2>Terminology</h2><p>The name Zoroaster is a Greek rendering of the name Zarathustra. He is known as Zartosht and Zardosht in Persian and Zaratosht in Gujarati. The Zoroastrian name of the religion is Mazdayasna, which combines Mazda- with the Avestan language word yasna, meaning worship, devotion. In English, an adherent of the faith is commonly called a Zoroastrian or a Zarathustrian. An older expression still used today is Behdin, meaning The best Religion | Beh &lt; Middle Persian Weh (good) + Din &lt; Middle Persian den &lt; Avestan Daena. In Zoroastrian liturgy the term is used as a title for an individual who has been formally inducted into the religion in a Navjote ceremony.</p><div class="gradientback"></div></div><div class="content"><p>The term Mazdaism /'mæzd?.?z?m/ is a typical 19th century construct, taking Mazda- from the name Ahura Mazda and adding the suffix -ism to suggest a belief system. The March 2001 draft edition of the Oxford English Dictionary also records an alternate form, Mazdeism, perhaps derived from the French Mazdéisme, which first appeared in 1871. In older English sources, the terms Gheber and Gueber (both deriving from Persian for infidel, compare giaour) were used to refer to Zoroastrians; however, these terms are considered offensive and have fallen out of use.</p><p>Zoroastrian philosophy is identified as having been known to Italian Renaissance Europe through an image of Zoroaster in Raphael's School of Athens by Giorgio Vasari in 1550. The first surviving reference to Zoroaster in English scholarship is attributed to Thomas Browne (1605–1682), who briefly refers to the prophet in his 1643 Religio Medici,[24] followed by the Oxford English Dictionary's record of the 1743 (Warburton, Pope's Essay). The Oxford English Dictionary records use of the term Zoroastrianism in 1874 in Archibald Sayce's Principles of Comparative Philology.[1]</p><h2>Overview</h2><h3>Theology</h3><p>Zoroastrians believe that there is one universal, transcendent, supreme god, Ahura Mazda, or the Wise Lord. (Ahura means Being and Mazda means Mind in Avestan language).[25] Zoroaster keeps the two attributes separate as two different concepts in most of the Gathas and also consciously uses a masculine word for one concept and a feminine for the other, as if to distract from an anthropomorphism of his divinity. Zoroaster claimed that Ahura Mazda is almighty, though not omnipotent.</p><p>Other scholars assert that since Zoroastrianism's divinity covers both being and mind as immanent entities, it is better described as a belief in an immanent self-creating universe with consciousness as its special attribute, thereby putting Zoroastranism in the pantheistic fold where it can be easily traced to its shared origin with Indian Brahmanism.[26][27] In any case, Ahura Mazda's creation—evident is widely agreed as asha, truth and order—is the antithesis of chaos, which is evident as druj, falsehood and disorder. The resulting conflict involves the entire universe, including humanity, which has an active role to play in the conflict.[28]</p><p>In Zoroastrian tradition, the chaotic is represented by Angra Mainyu (also referred to as Ahriman), the Destructive Principle, while the benevolent is represented through Ahura Mazda's Spenta Mainyu, the instrument or Bounteous Principle of the act of creation. It is through Spenta Mainyu that transcendental Ahura Mazda is immanent in humankind, and through which the Creator interacts with the world. According to Zoroastrian cosmology, in articulating the Ahuna Vairya formula, Ahura Mazda made His ultimate triumph evident to Angra Mainyu. As expressions and aspects of Creation, Ahura Mazda emanated the Amesha Spentas (Bounteous Immortals), that are each the hypostasis and representative of one aspect of that Creation. These Amesha Spenta are in turn assisted by a league of lesser principles, the Yazatas, each Worthy of Worship and each again a hypostasis of a moral or physical aspect of creation.</p><p>Zoroastrian theology includes a duty to protect nature. This has led some to proclaim it as the world's first ecological religion. Scholars have argued that, since the protections are part of a ritual, they stem from theology rather than ecology. Others have responded that, since the scripture calls for the protection of water, earth, fire, air, as once of its strongest precepts, it is, in effect, an ecological religion: It is not surprising that Mazdaism (another term for Zoroastrianism) is called the ?rst ecological religion. The reverence for Yazatas (divine spirits) emphasizes the preservation of nature (Avesta: Yasnas 1.19, 3.4, 16.9; Yashts 6.3–4, 10.13). [29]</p><h3>Practices</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/2/26/Dinastia_tang%2C_shanxi%2C_straniero_dal_volto_velato%2C_600-750_ca.JPG/250px-Dinastia_tang%2C_shanxi%2C_straniero_dal_volto_velato%2C_600-750_ca.JPG" width="250" height="353"><p>


				An 8th-century Tang dynasty Chinese clay figurine of a Sogdian man (an Eastern Iranian person) wearing a distinctive cap and face veil, possibly a camel rider or even a Zoroastrian priest engaging in a ritual at a fire temple, since face veils were used to avoid contaminating the holy fire with breath or saliva; Museum of Oriental Art (Turin), Italy.[30]


				</p><p>
					The religion states that active participation in life through good deeds is necessary to ensure happiness and to keep chaos at bay. This active participation is a central element in Zoroaster's concept of free will, and Zoroastrianism rejects all forms of monasticism. Ahura Mazda will ultimately prevail over the evil Angra Mainyu or Ahriman, at which point the universe will undergo a cosmic renovation and time will end. In the final renovation, all of creation—even the souls of the dead that were initially banished to darkness—will be reunited in Ahura Mazda, returning to life in the undead form. At the end of time, a savior-figure (a Saoshyant) will bring about a final renovation of the world (frashokereti), in which the dead will be revived.[28]</p><p>In Zoroastrian tradition, life is a temporary state in which a mortal is expected to actively participate in the continuing battle between truth and falsehood. Prior to being born, the urvan (soul) of an individual is still united with its fravashi (guardian spirit), which has existed since Mazda created the universe. During life, the fravashi acts as a guardian and protector. On the fourth day after death, the soul is reunited with its fravashi, in which the experiences of life in the material world are collected for the continuing battle in the spiritual world. For the most part, Zoroastrianism does not have a notion of reincarnation, at least not until the final renovation of the world. Followers of Ilm-e-Kshnoom in India believe in reincarnation and practice vegetarianism, two principles unknown to Orthodox Zoroastrianism,[31] although Zoroaster was himself a vegetarian.[32]</p><p>In Zoroastrianism, water (apo, aban) and fire (atar, azar) are agents of ritual purity, and the associated purification ceremonies are considered the basis of ritual life. In Zoroastrian cosmogony, water and fire are respectively the second and last primordial elements to have been created, and scripture considers fire to have its origin in the waters. Both water and fire are considered life-sustaining, and both water and fire are represented within the precinct of a fire temple. Zoroastrians usually pray in the presence of some form of fire (which can be considered evident in any source of light), and the culminating rite of the principle act of worship constitutes a strengthening of the waters. Fire is considered a medium through which spiritual insight and wisdom is gained, and water is considered the source of that wisdom.</p><p>A corpse is considered a host for decay, i.e., of druj. Consequently, scripture enjoins the safe disposal of the dead in a manner such that a corpse does not pollute the good creation. These injunctions are the doctrinal basis of the fast-fading traditional practice of ritual exposure, most commonly identified with the so-called Towers of Silence for which there is no standard technical term in either scripture or tradition. Ritual exposure is only practiced by Zoroastrian communities of the Indian subcontinent, in locations where it is not illegal and diclofenac poisoning has not led to the virtual extinction of scavenger birds. Other Zoroastrian communities either cremate their dead, or bury them in graves that are cased with lime mortar.</p><div class="gradientback"></div></div><div class="content"><p>While the Parsees in India have traditionally been opposed to proselytizing, probably for historical reasons, and even considered it a crime for which the culprit may face expulsion,[33] Iranian Zoroastrians have never been opposed to conversion, and the practice has been endorsed by the Council of Mobeds of Tehran. While the Iranian authorities do not permit proselytizing within Iran, Iranian Zoroastrians in exile have actively encouraged missionary activities, with The Zarathushtrian Assembly in Los Angeles and the International Zoroastrian Centre in Paris as two prominent centres. As in many other faiths, Zoroastrians are encouraged to marry others of the same faith, but this is not a requirement.</p><h2>History</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/5/53/BactrianZoroastrian.jpg/250px-BactrianZoroastrian.jpg" width="250" height="338"><p>


				Painted clay and alabaster head of a Zoroastrian priest wearing a distinctive Bactrian-style headdress, Takhti-Sangin, Tajikistan, Greco-Bactrian kingdom, 3rd–2nd century BC


				</p><h3>Classical antiquity</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/4/4c/Farvahar001.JPG/220px-Farvahar001.JPG" width="220" height="165"><br><p>
					The roots of Zoroastrianism are thought to have emerged from a common prehistoric Indo-Iranian religious system dating back to the early 2nd millennium BCE.[34] The prophet Zoroaster himself, though traditionally dated to the 6th century BC, is thought by many modern historians to have been a reformer of the polytheistic Iranian religion who lived in the 10th century BC.[35] Zoroastrianism as a religion was not firmly established until several centuries later. Zoroastrianism enters recorded history in the mid-5th century BCE. Herodotus' The Histories (completed c. 440&nbsp;BCE) includes a description of Greater Iranian society with what may be recognizably Zoroastrian features, including exposure of the dead.</p><p>The Histories is a primary source of information on the early period of the Achaemenid era (648–330&nbsp;BCE), in particular with respect to the role of the Magi. According to Herodotus i.101, the Magi were the sixth tribe of the Medians (until the unification of the Persian empire under Cyrus the Great, all Iranians were referred to as Mede or Mada by the peoples of the Ancient World), who appear to have been the priestly caste of the Mesopotamian-influenced branch of Zoroastrianism today known as Zurvanism, and who wielded considerable influence at the courts of the Median emperors.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/5/56/Map_of_the_Achaemenid_Empire.jpg/250px-Map_of_the_Achaemenid_Empire.jpg" width="250" height="121"><p>


				The Zoroastrian Achaemenid Empire at its greatest extent was the largest ancient empire in recorded history at 8.0 million km2 (480 BCE).[36]


				</p><p>
					Following the unification of the Median and Persian empires in 550 BCE, Cyrus the Great and, later, his son Cambyses II curtailed the powers of the Magi after they had attempted to sow dissent following their loss of influence. In 522 BCE, the Magi revolted and set up a rival claimant to the throne. The usurper, pretending to be Cyrus' younger son Smerdis, took power shortly thereafter.[37] Owing to the despotic rule of Cambyses and his long absence in Egypt, the whole people, Persians, Medes and all the other nations acknowledged the usurper, especially as he granted a remission of taxes for three years (Herodotus iii. 68).</p><p>Darius I and later Achaemenid emperors acknowledged their devotion to Ahura Mazda in inscriptions, as attested to several times in the Behistun inscription, and appear to have continued the model of coexistence with other religions. Whether Darius was a follower of Zoroaster has not been conclusively established, since devotion to Ahura Mazda was (at the time) not necessarily an indication of an adherence to Zoroaster's teaching. A number of the Zoroastrian texts that today are part of the greater compendium of the Avesta have been attributed to that period. This calendar attributed to the Achaemenid period is still in use today. Additionally, the divinities, or yazatas, are present-day Zoroastrian angels (Dhalla, 1938).</p><p>According to later Zoroastrian legend (Denkard and the Book of Arda Viraf), many sacred texts were lost when Alexander the Great's troops invaded Persepolis and subsequently destroyed the royal library there. Diodorus Siculus's Bibliotheca historica, which was completed circa 60 BCE, appears to substantiate this Zoroastrian legend (Diod. 17.72.2–17.72.6). According to one archaeological examination, the ruins of the palace of Xerxes bear traces of having been burned (Stolze, 1882). Whether a vast collection of (semi-)religious texts written on parchment in gold ink, as suggested by the Denkard, actually existed remains a matter of speculation, but is unlikely. Given that many of the Denkards statements-as-fact have since been refuted by scholars, the tale of the library is widely accepted to be fictional (Kellens, 2002).</p><p>Alexander's conquests largely displaced Zoroastrianism with Hellenistic beliefs,[35] though the religion continued to be practiced many centuries following the demise of the Achaemenids in mainland Persia and the core regions of the former Achaemenid Empire, most notably Anatolia, Mesopotamia, and the Caucasus. In the Cappadocian kingdom, whose territory was formerly an Achaemenid possession, Persian colonists, cut off from their co-religionists in Iran proper, continued to practice the faith [Zoroastrianism] of their forefathers; and there Strabo, observing in the first century B.C., records (XV.3.15) that these fire kindlers possessed many holy places of the Persian Gods, as well as fire temples.[38] Strabo furthermore relates, were noteworthy enclosures; and in their midst there is an altar, on which there is a large quantity of ashes and where the magi keep the fire ever burning.[38] It was not until the end of the Parthian period (247 b.c.–a.d. 224) that Zoroastrianism would receive renewed interest.[35]</p><div class="gradientback"></div></div><div class="content"><h3>Late antiquity</h3><p>As late as the Parthian period, a form of Zoroastrianism was without a doubt the dominant religion in the Armenian lands.[39] The Sassanids aggressively promoted the Zurvanite form of Zoroastrianism, often building fire temples in captured territories to promote the religion. During the period of their centuries long suzerainty over the Caucasus, the Sassanids made attempts to promote Zoroastrianism there with considerable successes, and it was prominent in the pre-Christian Caucasus (especially modern-day Azerbaijan).</p><p>Due to its ties to the Christian Roman Empire, Persia's arch-rival since Parthian times, the Sassanids were suspicious of Roman Christianity, and, after the reign of Constantine the Great, sometimes persecuted it.[40] The Sassanid authority clashed with their Armenian subjects in the Battle of Avarayr (a.d. 451), making them officially break with the Roman Church. But the Sassanids tolerated or even sometimes favored the Christianity of the Church of the East. The acceptance of Christianity in Georgia (Caucasian Iberia) saw the Zoroastrian religion there slowly but surely decline,[41] but as late the 5th century a.d.it was still widely practised as something like a second established religion.[42][43]</p><h3>Decline in the Middle Ages</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/f/f6/Hamza_Burns_Zarthust%E2%80%99s_Chest_and_Shatters_the_Urn_with_his_Ashes.jpg/220px-Hamza_Burns_Zarthust%E2%80%99s_Chest_and_Shatters_the_Urn_with_his_Ashes.jpg" width="220" height="281"><p>


				A scene from the Hamzanama where Hamza ibn ‘Abd al-Muttalib Burns Zarthust’s Chest and Shatters the Urn with his Ashes


				</p><p>
					Most of the Sassanid Empire was overthrown by the Arabs over the course of 16 years in the 7th century. Although the administration of the state was rapidly Islamicized and subsumed under the Umayyad Caliphate, in the beginning there was little serious pressure exerted on newly subjected people to adopt Islam.[44] Because of their sheer numbers, the conquered Zoroastrians had to be treated as dhimmis (despite doubts of the validity of this identification that persisted down the centuries),[45] which made them eligible for protection. Islamic jurists took the stance that only Muslims could be perfectly moral, but unbelievers might as well be left to their iniquities, so long as these did not vex their overlords.[45] In the main, once the conquest was over and local terms were agreed on, the Arab governors protected the local populations in exchange for tribute.[45]</p><p>The Arabs adopted the Sassanid tax-system, both the land-tax levied on land owners and the poll-tax levied on individuals,[45] called jizya, a tax levied on non-Muslims (i.e., the dhimmis). In time, this poll-tax came to be used as a means to humble the non-Muslims, and a number of laws and restrictions evolved to emphasize their inferior status. Under the early orthodox caliphs, as long as the non-Muslims paid their taxes and adhered to the dhimmi laws, administrators were enjoined to leave non-Muslims in their religion and their land. (Caliph Abu Bakr, qtd. in Boyce 1979, p.&nbsp;146).</p><p>Under Abbasid rule, Muslim Iranians (who by then were in the majority) increasingly found ways to taunt Zoroastrians, and distressing them became a popular sport. For example, in the 9th century, a deeply venerated cypress tree in Khorasan (which Parthian-era legend supposed had been planted by Zoroaster himself) was felled for the construction of a palace in Baghdad, 2,000 miles (3,200&nbsp;km) away. In the 10th century, on the day that a Tower of Silence had been completed at much trouble and expense, a Muslim official contrived to get up onto it, and to call the adhan (the Muslim call to prayer) from its walls. This was made a pretext to annex the building.[46] Another popular means to distress Zoroastrians was to maltreat dogs, as these animals are sacred in Zoroastrianism. Such baiting, which was to continue down the centuries, was indulged in by all; not only by high officials, but by the general uneducated population as well.</p><p>Ultimately, Muslim scholars like Al-Biruni found little records left of the belief of, for instance, the Khawarizmians, because figures like Qutayba ibn Muslim “extinguished and ruined in every possible way all those who knew how to write and read the Khawarizmi writing, who knew the history of the country and who studied their sciences.” As a result, “these things are involved in so much obscurity that it is impossible to obtain an accurate knowledge of the history of the country since the time of Islam...”[47]</p><p>Though subject to a new leadership and harassment, the Zoroastrians were able to continue in their former ways. But there was a slow but steady social and economic pressure to convert.[48][49] The nobility and city-dwellers were the first to convert, with Islam more slowly being accepted among the peasantry and landed gentry.[50] Power and worldly-advantage now lay with followers of Islam, and although the official policy was one of aloof contempt, there were individual Muslims eager to proselytize and ready to use all sorts of means to do so.[49]</p><p>Two decrees in particular encouraged the transition to a preponderantly Islamic society.[citation needed] The first edict, adapted from an Arsacid and Sassanid one (but in those to the advantage of Zoroastrians), was that only a Muslim could own Muslim slaves or indentured servants. Thus, a bonded individual owned by a Zoroastrian could automatically become a freeman by converting to Islam. The other edict was that if one male member of a Zoroastrian family converted to Islam, he instantly inherited all its property.</p><p>In time, a tradition evolved by which Islam was made to appear as a partly Iranian religion. One example of this was a legend that Husayn, son of the fourth caliph Ali and grandson of Islam's prophet Muhammad, had married a captive Sassanid princess named Shahrbanu. This wholly fictitious figure[51] was said to have borne Husayn a son, the historical fourth Shi'a imam, who claimed that the caliphate rightly belonged to him and his descendants, and that the Umayyads had wrongfully wrested it from him. The alleged descent from the Sassanid house counterbalanced the Arab nationalism of the Umayyads, and the Iranian national association with a Zoroastrian past was disarmed. Thus, according to scholar Mary Boyce, it was no longer the Zoroastrians alone who stood for patriotism and loyalty to the past.[51] The damning indictment that becoming Muslim was Un-Iranian only remained an idiom in Zoroastrian texts.[51]</p><p>With Iranian (especially Persian) support, the Abbasids overthrew the Umayyads in 750, and in the subsequent caliphate government—that nominally lasted until 1258—Muslim Iranians received marked favor in the new government, both in Iran and at the capital in Baghdad. This mitigated the antagonism between Arabs and Iranians, but sharpened the distinction between Muslims and non-Muslims. The Abbasids zealously persecuted heretics, and although this was directed mainly at Muslim sectarians, it also created a harsher climate for non-Muslims.[52] Although the Abbasids were deadly foes of Zoroastrianism, the brand of Islam they propagated throughout Iran became in turn ever more Zoroastrianized, making it easier for Iranians to embrace Islam.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/c/c3/USSHER%281865%29_p012_BAKU%2C_FIRE_TEMPLE.jpg/235px-USSHER%281865%29_p012_BAKU%2C_FIRE_TEMPLE.jpg" width="235" height="170"><div class="gradientback"></div></div><div class="content"><p>


				The fire temple of Baku, c. 1860


				</p><p>
					Despite economic and social incentives to convert, Zoroastrianism remained strong in some regions, particularly in those furthest away from the Caliphate capital at Baghdad. In Bukhara (in present-day Uzbekistan), resistance to Islam required the 9th-century Arab commander Qutaiba to convert his province four times. The first three times the citizens reverted to their old religion. Finally, the governor made their religion difficult for them in every way, turned the local fire temple into a mosque, and encouraged the local population to attend Friday prayers by paying each attendee two dirhams.[49] The cities where Arab governors resided were particularly vulnerable to such pressures, and in these cases the Zoroastrians were left with no choice but to either conform or migrate to regions that had a more amicable administration.[49]</p><p>The 9th century came to define the great number of Zoroastrian texts that were composed or re-written during the 8th to 10th centuries (excluding copying and lesser amendments, which continue for some time thereafter). All of these works are in the Middle Persian dialect of that period (free of Arabic words), and written in the difficult Pahlavi script (hence the adoption of the term Pahlavi as the name of the variant of the language, and of the genre, of those Zoroastrian books). If read aloud, these books would still have been intelligible to the laity. Many of these texts are responses to the tribulations of the time, and all of them include exhortations to stand fast in their religious beliefs. Some, such as the Denkard, are doctrinal defenses of the religion, while others are explanations of theological aspects (such as the Bundahishn's) or practical aspects (e.g., explanation of rituals) of it. About sixty such works are known to have existed, of which some are known only from references to them in other works.[citation needed]</p><p>In Khorasan in the northeastern Iran, a 10th-century Iranian nobleman brought together four Zoroastrian priests to transcribe a Sassanid-era Middle Persian work titled Book of the Lord (Khwaday Namag) from Pahlavi script into Arabic script. This transcription, which remained in Middle Persian prose (an Arabic version, by al-Muqaffa, also exists), was completed in 957 and subsequently became the basis for Firdausi's Book of Kings. It became enormously popular among both Zoroastrians and Muslims, and also served to propagate the Sassanid justification for overthrowing the Arsacids (i.e., that the Sassanids had restored the faith to its orthodox form after the Hellenistic Arsacids had allowed Zoroastrianism to become corrupt).</p><p>Among migrations were those to cities in (or on the margins of) the great salt deserts, in particular to Yazd and Kerman, which remain centers of Iranian Zoroastrianism to this day. Yazd became the seat of the Iranian high priests during Mongol Il-Khanate rule, when the best hope for survival [for a non-Muslim] was to be inconspicuous.[53] Crucial to the present-day survival of Zoroastrianism was a migration from the northeastern Iranian town of Sanjan in south-western Khorasan,[54] to Gujarat, in western India. The descendants of that group are today known as the Parsis—as the Gujaratis, from long tradition, called anyone from Iran[54]—who today represent the larger of the two groups of Zoroastrians.</p><p>The struggle between Zoroastrianism and Islam declined in the 10th and 11th centuries. Local Iranian dynasties, all vigorously Muslim,[54] had emerged as largely independent vassals of the Caliphs. In the 16th century, in one of the early letters between Iranian Zoroastrians and their co-religionists in India, the priests of Yazd lamented that no period [in human history], not even that of Alexander, had been more grievous or troublesome for the faithful than 'this millennium of the demon of Wrath'.[55]</p><h3>Modern</h3><p> Further information: Parsi, Irani (India), and Zoroastrians in Iran</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/c/cb/Sadeh.jpg/220px-Sadeh.jpg" width="220" height="165"><p>


				Sadeh in Tehran, 2011


				</p><p>
					Zoroastrianism has survived into the modern period, particularly in India, where it has been present since about the 9th century.</p><p>Today Zoroastrianism can be divided in three different sects or dominions: restorationists, progressives and traditionalists (or isolationists).[56] Traditionalists or isolationists are almost solely Parsis and accept, beside the Gathas and Avesta, also the Middle Persian works called 'Nasks of the Sassanians'. They generally do not allow conversion to the faith. Therefore, for someone to be a Zoroastrian, they must be born of Zoroastrian parents. Some traditionalists recognize the children of mixed marriages as Zoroastrians.[56][57]</p><p>From the 19th century onward, the Parsis gained a reputation for their education and widespread influence in all aspects of society. They played an instrumental role in the economic development of the region over many decades; several of the best-known business conglomerates of India are run by Parsi-Zoroastrians, including Tata, Godrej, Wadia families, and others.[citation needed]</p><p>Though the Armenians share a rich history affiliated with Zoroastrianism (that eventually declined with the advent of Christianity), reports indicate that there were Zoroastrian Armenians in Armenia until the 1920s.[58]</p><p>A comparatively minor population persisted in Central Asia, the Caucasus, and Persia, and an expatriate community has formed in the United States (some from India), and to a lesser extent in the United Kingdom, Canada and Australia. Many of these are titled restorationists, progressives or reformists. Progressives generally accept the Yashts and the Visperad texts of the Avesta as obligatory, along with the Gathas.[56] Restorationists refer only to the compositions of Zoroaster, and thus only consider the Gathas, the other texts only having value as far as they elaborate on some Gathic point and do not contradict the Gathic teaching.[56]</p><p>At the request of the government of Tajikistan, UNESCO declared 2003 a year to celebrate the 3000th anniversary of Zoroastrian culture, with special events throughout the world. In 2011 the Tehran Mobeds Anjuman announced that for the first time in the history of Iran and of the Zoroastrian communities worldwide, women had been ordained in Iran and North America as mobedyars, meaning women mobeds (Zoroastrian priests).[59][60]</p><h2>Relation to other religions and cultures</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/3/36/Iran-achaemenids_%28darius_the_great%29.jpg/250px-Iran-achaemenids_%28darius_the_great%29.jpg" width="250" height="151"><p>


				The Achaemenid Empire in the 5th century BCE consisted of the largest empire in history by percentage of world population.[61]


				</p><div class="gradientback"></div></div><div class="content"><p>
					Some scholars believe[62] that key concepts of Zoroastrian eschatology and demonology influenced the Abrahamic religions.[63][64] On the other hand, Zoroastrianism itself inherited ideas from other belief systems and, like other practiced religions, accommodates some degree of syncretism.[65]</p><h3>Indo-Iranian origins</h3><p>Many traits of Zoroastrianism can be traced back to the culture and beliefs of the prehistorical Indo-Iranian period, that is, to the time before the migrations that led to the Indo-Aryans and Iranics becoming distinct peoples. Zoroastrianism consequently shares elements with the historical Vedic religion that also has its origins in that era. An example is the relation of the Zoroastrian word Ahura (Ahura Mazda) and the Vedic word Asura (meaning demon or demigod). They are therefore hypothesized to have descended from a common Proto-Indo-Iranian religion.[66]</p><h3>Manichaeism</h3><p>Zoroastrianism is often compared with the Manichaeism. Nominally an Iranian religion, it has its origins in the Middle-Eastern Gnosticism. Superficially such a comparison seem apt, as both are dualistic and Manichaeism adopted many of the Yazatas for its own pantheon. Gherardo Gnoli, in The Encyclopaedia of Religion, says that we can assert that Manichaeism has its roots in the Iranian religious tradition and that its relationship to Mazdaism, or Zoroastrianism, is more or less like that of Christianity to Judaism.[67]</p><p>They are however quite different.[68] Manichaeism equated evil with matter and good with spirit, and was therefore particularly suitable as a doctrinal basis for every form of asceticism and many forms of mysticism. Zoroastrianism, on the other hand, rejects every form of asceticism, has no dualism of matter and spirit (only of good and evil), and sees the spiritual world as not very different from the natural one (the word paradise, or pairi.daeza, applies equally to both.)</p><p>Manichaeism's basic doctrine was that the world and all corporeal bodies were constructed from the substance of Satan, an idea that is fundamentally at odds with the Zoroastrian notion of a world that was created by God and that is all good, and any corruption of it is an effect of the bad. From what may be inferred from many Manichean texts and a few Zoroastrian sources[citation needed], the adherents of the two religions (or at least their respective priesthoods) despised each other intensely.</p><h3>Present-day Iran</h3><p>Many aspects of Zoroastrianism are present in the culture and mythologies of the peoples of the Greater Iran, not least because Zoroastrianism was a dominant influence on the people of the cultural continent for a thousand years. Even after the rise of Islam and the loss of direct influence, Zoroastrianism remained part of the cultural heritage of the Iranian language-speaking world, in part as festivals and customs, but also because Ferdowsi incorporated a number of the figures and stories from the Avesta in his epic Shahname, which in turn is pivotal to Iranian identity.</p><h2>Religious text</h2><h3>Avestan</h3><p> Main articles: Avesta and Avestan language</p><p>The Avesta is the religious book of Zoroastrians that contains a collection of sacred texts. The history of the Avesta is found in many Pahlavi texts. According to tradition, Ahura Mazda created the twenty-one nasks which Zoroaster brought to Vishtaspa. Here, two copies were created, one which was put in the house of archives, and the other put in the Imperial treasury. During Alexander's conquest of Persia, the Avesta was burned, and the scientific sections that the Greeks could use were dispersed among themselves.</p><p>Under the reign of King Valax of the Arsacis Dynasty, an attempt was made to restore the Avesta. During the Sassanid Empire, Ardeshir ordered Tansar, his high priest, to finish the work that King Valax had started. Shapur I sent priests to locate the scientific text portions of the Avesta that were in the possession of the Greeks. Under Shapur II, Arderbad Mahrespandand revised the canon to ensure its orthodox character, while under Khosrow I, the Avesta was translated into Pahlavi.</p><p>The compilation of these ancient texts was successfully established underneath the Mazdean priesthood and the Sassanian emperors. Only a fraction of the texts survive today. The later manuscripts all date from this millennium, the latest being from 1288, 590 years after the fall of the Sassanian Empire. The texts that remain today are the Gathas, Yasna, Visperad and the Vendidad. Along with these texts is the communal household prayer book called the Khordeh Avesta, which contains the Yashts and the Siroza. The rest of the materials from the Avesta are called Avestan fragments.[69]</p><h3>Middle Persian/Pahlavi</h3><p>Middle Persian and Pahlavi works created in the 9th and 10th century contain many religious Zoroastrian books, as most of the writers and copyists were part of the Zoroastrian clergy. The most significant and important books of this era include the Denkard, Bundahishn, Menog-i Khrad, Selections of Zadspram, Jamasp Namag, Epistles of Manucher, Rivayats, Dadestan-i-Denig, and Arda Viraf Namag. All Middle Persian texts written on Zoroastrianism during this time period are considered secondary works on the religion, and not scripture. Nonetheless, these texts have a strong influence on the religion.</p><h2>Zoroaster</h2><p> Main article: Zoroaster</p><p>Zoroastrianism was founded by Zoroaster (or Zarathustra), later deemed a prophet, in ancient Iran. The precise date of the founding of Zoroastrianism is uncertain. Zoroaster was born in either Northeast Iran or Southwest Afghanistan. He was born into a culture with a polytheistic religion, which included animal sacrifice[70] and the ritual use of intoxicants, quite similar to early forms of Hinduism in India. Zoroaster's birth and early life are little documented. What is known is recorded in the Gathas—the core of the Avesta, which contains hymns thought to be composed by Zoroaster himself. Born into the Spitama clan, he worked as a priest. He had a wife, three sons, and three daughters.</p><p>Zoroaster rejected the religion of the Bronze Age Iranians, with their many gods and oppressive class structure, in which the Karvis and Karapans (princes and priests) controlled the ordinary people. He also opposed animal sacrifices and the use of the hallucinogenic Haoma plant (possibly a species of ephedra) in rituals, but held the rooster as a symbol of light[71] and associated it with good against evil[72] because of his heraldic actions.</p><h3>Vision of Zoroaster</h3><p>According to Zoroastrian belief, when Zoroaster was 30 years old, he went into the Daiti river to draw water for a Haoma ceremony; when he emerged, he received a vision of Vohu Manah. After this, Vohu Manah took him to the other six Amesha Spentas, where he received the completion of his vision.[73] This vision radically transformed his view of the world, and he tried to teach this view to others. Zoroaster believed in one creator God, teaching that only one God was worthy of worship. Some of the deities of the old religion, the Daevas (Devas in Sanskrit), appeared to delight in war and strife. Zoroaster said these were evil spirits, workers of Angra Mainyu.</p><p>Zoroaster's ideas were not taken up quickly; he originally only had one convert: his cousin Maidhyoimanha.[74] The local religious authorities opposed his ideas, considering that their faith, power, and particularly their rituals, were threatened by Zoroaster's teaching against over-ritualising religious ceremonies. Many did not like Zoroaster's downgrading of the Daevas to evil spirits. After 12 years of little success, Zoroaster left his home.</p><div class="gradientback"></div></div><div class="content"><p>In the country of King Vishtaspa in Bactria, the king and queen heard Zoroaster debating with the religious leaders of the land and decided to accept Zoroaster's ideas as the official religion of their kingdom. Zoroaster died in his late 70s. Very little is known of the time between Zoroaster and the Achaemenian period, except that Zoroastrianism spread to Western Iran. By the time of the founding of the Achaemenid Empire, Zoroastrianism was already a well-established religion.</p><h2>Principal beliefs</h2><p>Humata, Hukhta, Huvarshta (Good Thoughts, Good Words, Good Deeds) are the basic tenets of the religion.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/7/77/Faravahar.svg/220px-Faravahar.svg.png" width="220" height="118"><p>


				Faravahar (or Ferohar), one of the primary symbols of Zoroastrianism, believed to be the depiction of a Fravashi (guardian spirit)


				</p><p>
					In Zoroastrianism, Ahura Mazda is the beginning and the end, the creator of everything that can and cannot be seen, the Eternal, the Pure and the only Truth. In the Gathas, the most sacred texts of Zoroastrianism thought to have been composed by Zoroaster himself, the prophet acknowledged devotion to no other divinity besides Ahura Mazda.</p><p>Daena (din in modern Persian) is the eternal Law, whose order was revealed to humanity through the Mathra-Spenta (Holy Words). Daena has been used to mean religion, faith, law, and even as a translation for the Hindu and Buddhist term Dharma. The latter is often interpreted as duty but can also mean social order, right conduct, or virtue. The metaphor of the path of Daena is represented in Zoroastrianism by the muslin undershirt Sudra, the Good/Holy Path, and the 72-thread Kushti girdle, the Pathfinder.</p><p>Daena should not be confused with the fundamental principle asha (Vedic rta), the equitable law of the universe, which governed the life of the ancient Indo-Iranians. For these, asha was the course of everything observable—the motion of the planets and astral bodies; the progression of the seasons; and the pattern of daily nomadic herdsman life, governed by regular metronomic events such as sunrise and sunset.</p><p>All physical creation (geti) was thus determined to run according to a master plan—inherent to Ahura Mazda—and violations of the order (druj) were violations against creation, and thus violations against Ahura Mazda. This concept of asha versus the druj should not be confused with the good-versus-evil battle evident in western religions, for although both forms of opposition express moral conflict, the asha versus druj concept is more systemic and less personal, representing, for instance, chaos (that opposes order); or uncreation, evident as natural decay (that opposes creation); or more simply the lie (that opposes truth and righteousness). Moreover, in his role as the one uncreated creator of all, Ahura Mazda is not the creator of druj, which is nothing, anti-creation, and thus (likewise) uncreated. Thus, in Zoroaster's revelation, Ahura Mazda was perceived to be the creator of only the good (Yasna 31.4), the supreme benevolent providence (Yasna 43.11), that will ultimately triumph (Yasna 48.1).</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/e/e9/Parsee_Wedding_1905.jpg/220px-Parsee_Wedding_1905.jpg" width="220" height="151"><p>


				A Parsi Wedding, 1905


				</p><p>
					In this schema of asha versus druj, mortal beings (both humans and animals) play a critical role, for they too are created. Here, in their lives, they are active participants in the conflict, and it is their duty to defend order, which would decay without counteraction. Throughout the Gathas, Zoroaster emphasizes deeds and actions, and accordingly asceticism is frowned upon in Zoroastrianism. In later Zoroastrianism, this was explained as fleeing from the experiences of life, which was the very purpose that the urvan (most commonly translated as the soul) was sent into the mortal world to collect. The avoidance of any aspect of life, which includes the avoidance of the pleasures of life, is a shirking of the responsibility and duty to oneself, one's urvan, and one's family and social obligations.</p><p>Central to Zoroastrianism is the emphasis on moral choice, to choose the responsibility and duty for which one is in the mortal world, or to give up this duty and so facilitate the work of druj. Similarly, predestination is rejected in Zoroastrian teaching. Humans bear responsibility for all situations they are in, and in the way they act toward one another. Reward, punishment, happiness, and grief all depend on how individuals live their lives.[75]</p><p>In Zoroastrianism, good transpires for those who do righteous deeds. Those who do evil have themselves to blame for their ruin. Zoroastrian morality is then to be summed up in the simple phrase, good thoughts, good words, good deeds (Humata, Hukhta, Hvarshta in Avestan), for it is through these that asha is maintained and druj is kept in check.</p><p>Through accumulation, several other beliefs were introduced to the religion that, in some instances, supersede those expressed in the Gathas. In the late 19th century, the moral and immoral forces came to be represented by Spenta Mainyu and its antithesis Angra Mainyu, the good spirit and evil spirit emanations of Ahura Mazda, respectively. Although the names are old, this opposition is a modern Western-influenced development popularized by Martin Haug in the 1880s, and was, in effect, a realignment of the precepts of Zurvanism (Zurvanite Zoroastrianism), which had postulated a third deity, Zurvan, to explain a mention of twinship (Yasna 30.3) between the moral and immoral. Although Zurvanism had died out by the 10th century, the critical question of the twin brothers mentioned in Yasna 30.3 remained, and Haug's explanation provided a convenient defence against Christian missionaries, who disparaged the Parsis for their dualism. Haug's concept was subsequently disseminated as a Parsi interpretation, thus corroborating Haug's theory, and the idea became so popular that it is now almost universally accepted as doctrine.[citation needed]</p><p>Zoroastrianism developed the abstract concepts of heaven and hell, as well as personal and final judgment, all of which are only alluded to in the Gathas. Yasna 19, which has only survived in a Sassanid era ([–650 CE] Zend commentary on the Ahuna Vairya invocation), prescribes a Path to Judgment known as the Chinvat Peretum or Chinvat bridge (cf: As-Sirat in Islam), which all souls had to cross, and judgment (over thoughts, words, and deeds performed during a lifetime) was passed as they were doing so. However, the Zoroastrian personal judgment is not final. At the end of time, when evil is finally defeated, all souls will be ultimately reunited with their Fravashi. Thus, Zoroastrianism can be said to be a universalist religion with respect to salvation.</p><p>In addition, and strongly influenced by Babylonian and Akkadian practices, the Achaemenids popularized shrines and temples, hitherto alien forms of worship. In the wake of Achaemenid expansion, shrines were constructed throughout the empire and particularly influenced the role of Mithra, Aredvi Sura Anahita, Verethregna and Tishtrya, all of which, in addition to their original (proto-)Indo-Iranian functions, now also received Perso-Babylonian functions.</p><h3>Creation of the universe</h3><p>According to the Zoroastrian story of creation, Ahura Mazda existed in light and goodness above, while Angra Mainyu existed in darkness and ignorance below. They have existed independently of each other for all time, and manifest contrary substances. Ahura Mazda first created seven abstract heavenly beings called Amesha Spentas, who support him and represent beneficent aspects, along with numerous yazads, lesser beings worthy of worship. He then created the universe itself in order to ensnare evil. Ahura Mazda created the floating, egg-shaped universe in two parts: first the spiritual (menog) and 3,000 years later, the physical (getig). Ahura Mazda then created Gayomard, the archetypical perfect man, and the first bull.[75]</p><div class="gradientback"></div></div><div class="content"><p>While Ahura Mazda created the universe and humankind, Angra Mainyu, whose instinct is to destroy, miscreated demons, evil yazads, and noxious creatures (khrafstar) such as snakes, ants, and flies. Angra Mainyu created an opposite, evil being for each good being, except for humans, which he found he could not match. Angra Mainyu invaded the universe through the base of the sky, inflicting Gayomard and the bull with suffering and death. However, the evil forces were trapped in the universe and could not retreat. The dying primordial man and bull emitted seeds. From the bull's seed grew all beneficial plants and animals of the world, and from the man's seed grew a plant whose leaves became the first human couple. Humans thus struggle in a two-fold universe trapped with evil. The evils of this physical world are not products of an inherent weakness, but are the fault of Angra Mainyu's assault on creation. This assault turned the perfectly flat, peaceful, and ever day-lit world into a mountainous, violent place that is half night.[75]</p><h3>Renovation and judgment</h3><p> Main article: Frashokereti</p><p>Zoroastrianism also includes beliefs about the renovation of the world and individual judgment (cf. general and particular judgment), including the resurrection of the dead.</p><p>Individual judgment at death is by the Bridge of Judgment, which each human must cross, facing a spiritual judgment. Humans' actions under their free will determine the outcome. One is either greeted at the bridge by a beautiful, sweet-smelling maiden or by an ugly, foul-smelling old woman. The maiden leads the dead safely across the bridge to the Amesha Spenta Good Mind, who carries the dead to paradise. The old woman leads the dead down a bridge that narrows until the departed falls off into the abyss of hell.[75]</p><p>Zoroastrian hell is reformative; punishments fit the crimes, and souls do not rest in eternal damnation. Hell contains foul smells and evil food, and souls are packed tightly together although they believe they are in total isolation.[75]</p><p>In Zoroastrian eschatology, a 3,000-year struggle between good and evil will be fought, punctuated by evil's final assault. During the final assault, the sun and moon will darken and humankind will lose its reverence for religion, family, and elders. The world will fall into winter, and Angra Mainyu's most fearsome miscreant, Azi Dahaka, will break free and terrorize the world.[75]</p><p>The final savior of the world, Saoshyant, will be born to a virgin impregnated by the seed of Zoroaster while bathing in a lake. Saoshyant will raise the dead – including those in both heaven and hell – for final judgment, returning the wicked to hell to be purged of bodily sin. Next, all will wade through a river of molten metal in which the righteous will not burn. Heavenly forces will ultimately triumph over evil, rendering it forever impotent. Saoshyant and Ahura Mazda will offer a bull as a final sacrifice for all time, and all humans will become immortal. Mountains will again flatten and valleys will rise; heaven will descend to the moon, and the earth will rise to meet them both.[75]</p><p>Humanity requires two judgments because there are as many aspects to our being: spiritual (menog) and physical (getig).[75]</p><h3>Head covering</h3><p>The Zarathushtri also practice traditional head covering ritual similar to that of Judaism. It is vital to the practice, and according to Hoshang Bhadha,[year&nbsp;needed][unreliable source?]</p><p>A Zarathustri is enjoined to cover his head at all times. It is one of the basic disciplines for a Zarathustri. If you have ever looked at the pictures of Zarathustris from the past, you will recognize them simply because they were wearing cap or turban covering their head. If you read the description of Parsees from the past... it is emphatically described that whether a child, female or male they all had their head(s) covered. It is unfortunate that our own community people laugh on us for wearing cap, which is the foundation of all our religion practices. Needless to say, today a Zarathustri wearing cap will get strange glances; he/she will evoke giggles and some people even consider them as one belonging to the Stone Age. However, such reactions are seldom seen when a Zarathustri will observe a Muslim or Jew demonstrating their practice of covering head during and out of their prayer area. It is a common sight to see a Zarathustri coming out from the Agiary with one hand over his head, not as a respect but to prepare himself/ herself to remove the cap/scarf before he/she reaches the main gate. Some people feel embarrassed to wear in public whereas some remove it to protect their hairstyle. My dear Zarathustris, wearing cap is not imposed upon us but it is a remedy to protect oneself from destructive thought process[es]...[76]</p><h2>Demographics</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/4/4f/Ateshkadeh_yazd.jpg/220px-Ateshkadeh_yazd.jpg" width="220" height="165"><p>


				The Zoroastrian Atash Behram of Yazd, Iran.



				</p><p> Further information: List of countries by Zoroastrian population and List of Zoroastrians</p><p>
					Zoroastrian communities comprise two main groups of people: those of South Asian Zoroastrian background known as Parsis (or Parsees), and those of Central Asian background. According to a survey in 2004 by the Zoroastrian Associations of North America, the number of Zoroastrians worldwide was estimated at between 124,000 and 190,000. The number is imprecise because of wildly diverging counts in Iran.[22] India's 2011 Census found 57,264 Parsi Zoroastrians.[77]</p><p>Small Zoroastrian communities may be found all over the world, with a continuing concentration in Western India, Central Iran, and Southern Pakistan. Zoroastrians of the diaspora are primarily located in Great Britain and the former British colonies, particularly Canada and Australia, as well as in the American state of California where they form part of the Iranian American community.</p><h3>In South Asia</h3><p> Main articles: Parsi and Irani (India)</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/e/e8/Parsi-navjote-sitting.jpg/170px-Parsi-navjote-sitting.jpg" width="170" height="302"><div class="gradientback"></div></div><div class="content"><p>


				Parsi Navjote ceremony (rites of admission into the Zoroastrian faith)


				</p><p>
					India is considered to be home to the largest Zoroastrian population in the world. When the Islamic armies, under the first Caliphs, invaded Persia, those locals who were unwilling to convert to Islam sought refuge, first in the mountains of Northern Iran, then the regions of Yazd and its surrounding villages. Later, in the ninth century CE, a group sought refuge in the western coastal region of India, and also scattered to other regions of the world. Following the fall of the Sassanid Empire in 651 CE, many Zoroastrians migrated. Among them were several groups who ventured to Gujarat on the western shores of the Indian subcontinent, where they finally settled. The descendants of those refugees are today known as the Parsis. The year of arrival on the subcontinent cannot be precisely established, and Parsi legend and tradition assigns various dates to the event.</p><p>In the Indian census of 2001, the Parsis numbered 69,601, representing about 0.006% of the total population of India, with a concentration in and around the city of Mumbai. Due to a low birth rate and high rate of emigration, demographic trends project that by 2020 the Parsis will number only about 23,000 or 0.002% of the total population of India. The Parsis would then cease to be called a community and will be labeled a tribe. By 2008, the birth-to-death ratio was 1:5; 200 births per year to 1,000 deaths.[78] In Pakistan, they number fewer than 1,700, mostly living in Karachi.[79]</p><h3>Iran, Iraq and Central Asia</h3><p> Main article: Zoroastrians in Iran</p><p>Iran's figures of Zoroastrians have ranged widely; the last census (1974) before the revolution of 1979 revealed 21,400 Zoroastrians.[80] Some 10,000 adherents remain in the Central Asian regions that were once considered the traditional stronghold of Zoroastrianism, i.e., Bactria ( Balkh), which is in Northern Afghanistan; Sogdiana; Margiana; and other areas close to Zoroaster's homeland. In Iran, emigration, out-marriage and low birth rates are likewise leading to a decline in the Zoroastrian population. Zoroastrian groups in Iran say their number is approximately 60,000.[81] According to the Iranian census data from 2011 the number of Zoroastrians in Iran was 25,271.[82]</p><p>Communities exist in Tehran, as well as in Yazd, Kerman and Kermanshah, where many still speak an Iranian language distinct from the usual Persian. They call their language Dari (not to be confused with the Dari of Afghanistan). Their language is also called Gavri or Behdini, literally of the Good Religion. Sometimes their language is named for the cities in which it is spoken, such as Yazdi or Kermani. Iranian Zoroastrians were historically called Gabrs, originally without a pejorative connotation but in the present-day derogatorily applied to all non-Muslims.</p><p>More recently the Zoroastrian faith has gained strength among the Kurds in Iraq, claiming up to 100,000 adherents as of 2015.[83] Zoroastrians currently seek official status for their religion in Iraqi Kurdistan.[84]</p><h3>Western world</h3><p>North America is thought to be home to 18,000–25,000 Zoroastrians of both South Asian and Iranian background. A further 3,500 live in Australia (mainly in Sydney). In recent years, the United States has become a significant destination of Zoroastrian populations, holding the second largest population of Zoroastrians after India.</p><h2>Notes</h2><h3>Citations</h3><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Zoroastrianism&amp;oldid=777850458"					
								Categories:  Hidden categories:</p><br><br><img alt="Page semi-protected" src="http://upload.wikimedia.org/wikipedia/commons/thumb/f/fc/Padlock-silver.svg/20px-Padlock-silver.svg.png" width="20" height="20"><h1 lang="en">Anno Domini</h1><p> From Wikipedia, the free encyclopedia</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/8/89/Austria_Klagenfurt_Dome_12.jpg/220px-Austria_Klagenfurt_Dome_12.jpg" width="220" height="163"><p>


				Anno Domini inscription at a cathedral in Carinthia, Austria.


				</p><p>
					The terms anno Domini[a][1][2] (AD) and before Christ[3][4][5][6] (BC) are used to label or number years in the Julian and Gregorian calendars. The term anno Domini is Medieval Latin and means in the year of the Lord,[7] but is often translated as in the year of our Lord.[8][9]</p><p>This calendar era is based on the traditionally reckoned year of the conception or birth of Jesus of Nazareth, with AD counting years from the start of this epoch, and BC denoting years before the start of the era. There is no year zero in this scheme, so the year AD&nbsp;1 immediately follows the year 1&nbsp;BC. This dating system was devised in 525 by Dionysius Exiguus of Scythia Minor, but was not widely used until after 800.[10][11]</p><p>The Gregorian calendar is the most widely used calendar in the world today. For decades, it has been the unofficial global standard, adopted in the pragmatic interests of international communication, transportation, and commercial integration, and recognized by international institutions such as the United Nations.[12]</p><p>Traditionally, English followed Latin usage by placing the AD abbreviation before the year number.[b] However, BC is placed after the year number (for example: AD&nbsp;2017, but 68&nbsp;BC), which also preserves syntactic order. The abbreviation is also widely used after the number of a century or millennium, as in fourth century AD or second millennium AD (although conservative usage formerly rejected such expressions).[14] Because BC is the English abbreviation for Before Christ, it is sometimes incorrectly concluded that AD means After Death, i.e., after the death of Jesus. However, this would mean that the approximate 33 years commonly associated with the life of Jesus would not be included in either of the BC and the AD time scales.[15]</p><p>Terminology that is viewed by some as being more neutral and inclusive of non-Christian people is to call this the Current or Common Era (abbreviated as CE), with the preceding years referred to as Before the Common or Current Era (BCE). Astronomical year numbering and ISO 8601 avoid words or abbreviations related to Christianity, but use the same numbers for AD years.</p><div class="gradientback"></div></div><div class="content"><h2>Contents</h2><h2>History</h2><p>The Anno Domini dating system was devised in 525 by Dionysius Exiguus to enumerate the years in his Easter table. His system was to replace the Diocletian era that had been used in an old Easter table because he did not wish to continue the memory of a tyrant who persecuted Christians.[16] The last year of the old table, Diocletian 247, was immediately followed by the first year of his table, AD 532. When he devised his table, Julian calendar years were identified by naming the consuls who held office that year—he himself stated that the present year was the consulship of Probus Junior, which was 525 years since the incarnation of our Lord Jesus Christ.[17] Thus Dionysius implied that Jesus' Incarnation occurred 525 years earlier, without stating the specific year during which his birth or conception occurred. However, nowhere in his exposition of his table does Dionysius relate his epoch to any other dating system, whether consulate, Olympiad, year of the world, or regnal year of Augustus; much less does he explain or justify the underlying date.[18]</p><p>Blackburn &amp; Holford-Strevens briefly present arguments for 2 BC, 1 BC, or AD 1 as the year Dionysius intended for the Nativity or Incarnation. Among the sources of confusion are:[11]</p><p>It is not known how Dionysius established the year of Jesus's birth. Two major theories are that Dionysius based his calculation on the Gospel of Luke, which states that Jesus was about thirty years old shortly after the fifteenth year of the reign of Tiberius Caesar, and hence subtracted thirty years from that date, or that Dionysius counted back 532 years (the period during which the dates of Alexandrian Easter repeat) from the first year of his new table.[19][20] It is convenient to initiate a calendar not from the very day of an event but from the beginning of a cycle which occurs in close proximity. For example, the Islamic calendar begins not from the date of the Hegira, but rather weeks later, on the first subsequent occurrence of the month of Muharram (corresponding to 16 July AD 622).</p><p>It has also been speculated by Georges Declercq[21] that Dionysius' desire to replace Diocletian years with a calendar based on the incarnation of Christ was intended to prevent people from believing the imminent end of the world. At the time, it was believed by some that the Resurrection and end of the world would occur 500 years after the birth of Jesus. The old Anno Mundi calendar theoretically commenced with the creation of the world based on information in the Old Testament. It was believed that, based on the Anno Mundi calendar, Jesus was born in the year 5500 (or 5500 years after the world was created) with the year 6000 of the Anno Mundi calendar marking the end of the world.[22][23] Anno Mundi 6000 (approximately AD 500) was thus equated with the resurrection and the end of the world[24] but this date had already passed in the time of Dionysius.</p><h3>Popularization</h3><p>The Anglo-Saxon historian the Venerable Bede, who was familiar with the work of Dionysius Exiguus, used Anno Domini dating in his Ecclesiastical History of the English People, completed in 731. In this same history, he also used another Latin term, ante vero incarnationis dominicae tempus anno sexagesimo (in fact in the 60th year before the time of the Lord's incarnation), equivalent to the English before Christ, to identify years before the first year of this era.[25] Both Dionysius and Bede regarded Anno Domini as beginning at the incarnation of Jesus, but the distinction between Incarnation and Nativity was not drawn until the late 9th century, when in some places the Incarnation epoch was identified with Christ's conception, i.e., the Annunciation on March 25 (Annunciation style).[26]</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/d/d0/Charlemagne_Agostino_Cornacchini_Vatican_2.jpg/220px-Charlemagne_Agostino_Cornacchini_Vatican_2.jpg" width="220" height="283"><p>


				Statue of Charlemagne by Agostino Cornacchini (1725), at St. Peter's Basilica, Vatican City. Charlemagne promoted the usage of the Anno Domini epoch throughout the Carolingian Empire


				</p><p>
					On the continent of Europe, Anno Domini was introduced as the era of choice of the Carolingian Renaissance by the English cleric and scholar Alcuin in the late eighth century. Its endorsement by Emperor Charlemagne and his successors popularizing the use of the epoch and spreading it throughout the Carolingian Empire ultimately lies at the core of the system's prevalence. According to the Catholic Encyclopedia, popes continued to date documents according to regnal years for some time, but usage of AD gradually became more common in Roman Catholic countries from the 11th to the 14th centuries.[27] In 1422, Portugal became the last Western European country to switch to the system begun by Dionysius.[28] Eastern Orthodox countries only began to adopt AD instead of the Byzantine calendar in 1700 when Russia did so, with others adopting it in the 19th and 20th centuries.</p><p>Although Anno Domini was in widespread use by the 9th century, the term Before Christ (or its equivalent) did not become common until much later. Bede the Venerable used the expression anno igitur ante incarnationem Dominicam (so in the year before the Incarnation of the Lord) twice. Anno an xpi nativitate (in the year before the birth of Christ) is found in 1474 in a work by a German monk.[29] In 1627, the French Jesuit theologian Denis Pétau (Dionysius Petavius in Latin), with his work De doctrina temporum, popularized the usage ante Christum (Latin for Before Christ) to mark years prior to AD.[30][31][32]</p><h3>Change of year</h3><p>When the reckoning from Jesus' incarnation began replacing the previous dating systems in western Europe, various people chose different Christian feast days to begin the year: Christmas, Annunciation, or Easter. Thus, depending on the time and place, the year number changed on different days in the year, which created slightly different styles in chronology:[33]</p><p>With these various styles, the same day could, in some cases, be dated in 1099, 1100 or 1101.</p><h2>Historical birth date of Jesus</h2><p>The date of birth of Jesus of Nazareth is not stated in the gospels or in any secular text, but most scholars assume a date of birth between 6 BC and 4 BC.[34] The historical evidence is too sketchy to allow a definitive dating,[35] but the date is estimated through two different approaches - one by analyzing references to known historical events mentioned in the Nativity accounts in the Gospels of Luke and Matthew, and the second by working backwards from the estimation of the start of the ministry of Jesus.[36][37]</p><h2>Other eras</h2><p> Further information: Calendar era</p><p>During the first six centuries of what would come to be known as the Christian era, European countries used various systems to count years. Systems in use included consular dating, imperial regnal year dating, and Creation dating.</p><div class="gradientback"></div></div><div class="content"><p>Although the last non-imperial consul, Basilius, was appointed in 541 by Emperor Justinian I, later emperors through Constans II (641–668) were appointed consuls on the first 1 January after their accession. All of these emperors, except Justinian, used imperial post-consular years for the years of their reign, along with their regnal years.[38] Long unused, this practice was not formally abolished until Novell XCIV of the law code of Leo VI did so in 888.</p><p>Another calculation had been developed by the Alexandrian monk Annianus around the year AD 400, placing the Annunciation on 25 March AD 9 (Julian)—eight to ten years after the date that Dionysius was to imply. Although this incarnation was popular during the early centuries of the Byzantine Empire, years numbered from it, an Era of Incarnation, were exclusively used and are yet used, in Ethiopia. This accounts for the seven- or eight-year discrepancy between the Gregorian and Ethiopian calendars. Byzantine chroniclers like Maximus the Confessor, George Syncellus, and Theophanes dated their years from Annianus' creation of the world. This era, called Anno Mundi, year of the world (abbreviated AM), by modern scholars, began its first year on 25 March 5492 BC. Later Byzantine chroniclers used Anno Mundi years from 1 September 5509 BC, the Byzantine Era. No single Anno Mundi epoch was dominant throughout the Christian world. Eusebius of Caesarea in his Chronicle used an era beginning with the birth of Abraham, dated in 2016 BC (AD 1 = 2017 Anno Abrahami).[39]</p><p>Spain and Portugal continued to date by the Era of the Caesars or Spanish Era, which began counting from 38 BC, well into the Middle Ages. In 1422, Portugal became the last Catholic country to adopt the Anno Domini system.[27]</p><p>The Era of Martyrs, which numbered years from the accession of Diocletian in 284, who launched the last yet most severe persecution of Christians, was used by the Church of Alexandria and is still used, officially, by the Coptic Orthodox and Coptic Catholic churches. It was also used by the Ethiopian church. Another system was to date from the crucifixion of Jesus Christ, which as early as Hippolytus and Tertullian was believed to have occurred in the consulate of the Gemini (AD 29), which appears in some medieval manuscripts.</p><h2>CE and BCE</h2><p> Main article: Common Era</p><p>Alternative names for the Anno Domini era include vulgaris aerae (found 1615 in Latin),[40] Vulgar Era (in English, as early as 1635),[41] Christian Era (in English, in 1652),[42] Common Era (in English, 1708),[43] and Current Era.[44] Since 1856,[45] the alternative abbreviations CE and BCE, (sometimes written C.E. and B.C.E.) are sometimes used in place of AD and BC.</p><p>The Common/Current Era (CE) terminology is often preferred by those who desire a term that does not explicitly make religious references.[46][47] For example, Cunningham and Starr (1998) write that B.C.E./C.E. …do not presuppose faith in Christ and hence are more appropriate for interfaith dialog than the conventional B.C./A.D.[48] Upon its foundation, the Republic of China adopted the Minguo Era, but used the Western calendar for international purposes. The translated term was ?? (xi yuán, Western Era). Later, in 1949, the People's Republic of China adopted ?? (gongyuán, Common Era) for all purposes domestic and foreign.</p><h2>No year zero / Start and end of a century</h2><p> Further information: 0 (year), Astronomical year numbering, and Millennium</p><p>In the AD year numbering system, whether applied to the Julian or Gregorian calendars, AD 1 is preceded by 1 BC. There is no year 0 between them. Because of this, most experts agree that a new century begins in a year which has 01 as the final digits (e.g., 1801, 1901, 2001). New millennia likewise are considered to have begun in 1001 and 2001. This is at odds with the much more common conception that centuries and millennia begin when the trailing digits are zeroes (1800, 1900, 2000, etc.); for example, the worldwide celebration of the new millennium took place on New Year's Eve 1999, when the year number ticked over to 2000.[10]</p><p>For computational reasons, astronomical year numbering and the ISO 8601 standard designate years so that AD 1 = year 1, 1 BC = year 0, 2 BC = year -1, etc.[c] In common usage, ancient dates are expressed in the Julian calendar, but ISO 8601 uses the Gregorian calendar and astronomers may use a variety of time scales depending on the application. Thus dates using the year 0 or negative years may require further investigation before being converted to BC or AD.</p><h2>Notes</h2><h3>Citations</h3><h3>Sources</h3><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Anno_Domini&amp;oldid=782411048"					
								Categories:  Hidden categories:</p><br><br><img alt="Page semi-protected" src="http://upload.wikimedia.org/wikipedia/commons/thumb/f/fc/Padlock-silver.svg/20px-Padlock-silver.svg.png" width="20" height="20"><h1 lang="en">Kura–Araxes culture</h1><p> From Wikipedia, the free encyclopedia</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/d/d8/%D5%87%D5%A5%D5%B6%D5%A3%D5%A1%D5%BE%D5%AB%D5%A9%D5%AB_%D5%A9%D5%A1%D5%B6%D5%A3%D6%80%D5%A1%D5%B6%D5%A8_1.JPG/350px-%D5%87%D5%A5%D5%B6%D5%A3%D5%A1%D5%BE%D5%AB%D5%A9%D5%AB_%D5%A9%D5%A1%D5%B6%D5%A3%D6%80%D5%A1%D5%B6%D5%A8_1.JPG" width="350" height="263"><p>


				Kura-Araxes pottery fragments and obsidian from the Shengavit Settlement


				</p><p>
					The Kura–Araxes culture or the early trans-Caucasian culture was a civilization that existed from 3400 BC until about 2000 BC,[1] which has traditionally been regarded as the date of its end; in some locations it may have disappeared as early as 2600 or 2700 BC.[2] The earliest evidence for this culture is found on the Ararat plain; it spread northward in Caucasus by 3000 BC (but never reaching Colchis[3]).</p><p>Altogether, the early trans-Caucasian culture enveloped a vast area approximately 1,000&nbsp;km by 500&nbsp;km,[4] and mostly encompassed, on modern-day territories, the Southern Caucasus (except western Georgia), northwestern Iran, the northeastern Caucasus, eastern Turkey, and as far as Syria.[5][6]</p><p>The name of the culture is derived from the Kura and Araxes river valleys. Kura–Araxes culture is sometimes known as Shengavitian, Karaz (Erzurum), Pulur, and Yanik Tepe (Iranian Azerbaijan, near Lake Urmia) cultures.[7] It gave rise to the later Khirbet Kerak-ware culture found in Syria and Canaan after the fall of the Akkadian Empire.</p><h2>Contents</h2><div class="gradientback"></div></div><div class="content"><h2>Early history</h2><p>Shulaveri-Shomu culture preceded the Kura–Araxes culture in the area. There were many differences between these two cultures, so the connection was not clear. Later, it was suggested that the Sioni culture of eastern Georgia possibly represented a transition from the Shulaveri to the Kura-Arax cultural complex.</p><p>At many sites, the Sioni culture layers can be seen as intermediary between Shulaver-Shomu-Tepe layers and the Kura-Araxes layers.[8] This kind of stratigraphy warrants a chronological place of the Sioni culture at around 4000 BCE.[9]</p><p>Nowadays scholars consider the Kartli area, as well as the Kakheti area (in the river Sioni region) as key to forming the earliest phase of the Kura–Araxes culture.[9] To a large extent, this appears as an indigenous culture of Caucasus that was formed over a long period, and at the same time incorporating foreign influences.</p><p>There are some indications (such as at Arslantepe) of the overlapping in time of the Kura-Araxes and Uruk cultures; such contacts may go back even to the Middle Uruk period.[10]</p><h2>Expansion</h2><p>Rather quickly, elements of Kura–Araxes culture started to proceed westward to the Erzurum plain, southwest to Cilicia, and to the southeast into the area of Lake Van, and below the Urmia basin in Iran, such as to Godin Tepe.</p><p>Finally, it proceeded into the present-day Syria (Amuq valley), and as far as Palestine.</p><p>Its territory corresponds to large parts of modern Armenia, Azerbaijan, Chechnya, Dagestan, Georgia, Ingushetia, North Ossetia, and parts of Iran and Turkey.[5][6][11]</p><p>At Sos Hoyuk, in Erzurum Province, Turkey, early forms of Kura-Araxes pottery were found in association with local ceramics as early as 3500-3300 BC. During the Early Bronze Age in 3000-2200 BC, this settlement was part of the Kura-Araxes phenomenon.[12]</p><p>At Arslantepe, Turkey, around 3000 BCE, there was widespread burning and destruction, after which Kura-Araxes pottery appeared in the area.[13]</p><h2>Settlements</h2><p>Archaeological evidence of inhabitants of the Kura–Araxes culture showed that ancient settlements were found along the Hrazdan river, as shown by drawings at a mountainous area in a cave nearby.[14] Structures in settlements have not revealed much differentiation, nor was there much difference in size or character between settlements,[3] facts that suggest they probably had a poorly developed social hierarchy for a significant stretch of their history. Some, but not all, settlements were surrounded by stone walls.[3] They built mud-brick houses, originally round, but later developing into subrectangular designs with structures of just one or two rooms, multiple rooms centered around an open space, or rectilinear designs.[3]</p><p>At some point the culture's settlements and burial grounds expanded out of lowland river valleys and into highland areas.[15] Although some scholars have suggested that this expansion demonstrates a switch from agriculture to pastoralism and that it serves as possible proof of a large-scale arrival of Indo-Europeans, facts such as that settlement in the lowlands remained more or less continuous suggest merely that the people of this culture were diversifying their economy to encompass crop and livestock agriculture.[15]</p><p>Shengavit Settlement is a prominent Kura-Araxes site in present-day Yerevan area in Armenia. It was inhabited from approximately 3200 BC cal to 2500 BC cal. Later on, in the Middle Bronze Age, it was used irregularly until 2200 BC cal. The town occupied an area of six hectares, which is large for Kura-Araxes sites.</p><h3>Kura-Araxes mounds</h3><p>In the 3rd millennium B.C., one particular group of mounds of the Kura–Araxes culture is remarkable for their wealth. This was the final stage of culture's development. These burial mounds are known as the Martqopi (or Martkopi) period mounds. Those on the left bank of the river Alazani are often 20-25 meter high and 200-300 meter in diameter. They contain especially rich artefacts, such as gold and silver jewelry.[16]</p><h2>Economy</h2><p>The economy was based on farming and livestock-raising (especially of cattle and sheep).[17] They grew grain and orchard crops, and are known to have used implements to make flour. They raised cattle, sheep, goats, dogs, and in later phases, horses.[17]</p><p>Before the Kura-Araxes period, horse bones were not found in Transcaucasia. Later, beginning about 3300 BCE, they became widespread, with signs of domestication.[18]</p><p>There is evidence of trade with Mesopotamia as well as Asia Minor.[17] It is, however, considered above all to be indigenous to the Caucasus, and its major variants characterized (according to Caucasus historian Amjad Jaimoukha) later major cultures in the region.[17]</p><h3>Metallurgy</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/4/41/Influencedurartu1.PNG/250px-Influencedurartu1.PNG" width="250" height="188"><p>


				Early expansion of the Kuro-Araxes culture (light shading) shown in relation to subsequent cultures in the area, such as Urartu (dark shading).


				</p><p>
					In the earliest phase of the Kura–Araxes culture, metal was scarce. In comparison, the preceding Leilatepe culture's metalwork tradition was far more sophisticated.[19]</p><p>The Kura–Araxes culture would later display a precocious metallurgical development, which strongly influenced surrounding regions.[20] They worked copper, arsenic, silver, gold,[3] tin, and bronze.[15]</p><p>Their metal goods were widely distributed, from the Volga, Dnieper and Don-Donets river systems in the north to Syria and Palestine in the south and Anatolia in the west.</p><h3>Goods</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/7/75/Saxs%C4%B1_k%C3%BCp%2C_T%C9%99p%C9%99yata%C4%9F%C4%B1.JPG/220px-Saxs%C4%B1_k%C3%BCp%2C_T%C9%99p%C9%99yata%C4%9F%C4%B1.JPG" width="220" height="299"><div class="gradientback"></div></div><div class="content"><p>


				Pottery


				</p><p>
					Their pottery was distinctive. The spread of their pottery along trade routes into surrounding cultures was much more impressive than any of their achievements domestically.[3] It was painted black and red, using geometric designs. Examples have been found as far south as Syria and Israel, and as far north as Dagestan and Chechnya.[21] The spread of this pottery, along with archaeological evidence of invasions, suggests that the Kura-Araxes people may have spread outward from their original homes and, most certainly, had extensive trade contacts. Jaimoukha believes that its southern expanse is attributable primarily to Mitanni and the Hurrians.[17]</p><p>They are also remarkable for the production of wheeled vehicles (wagons and carts), which were sometimes included in burial kurgans.[15]</p><h3>Viticulture</h3><p>Viticulture and wine-making were widely practised in the area from the earliest times. Viticulture even goes back to the earlier Shulaveri-Shomu culture.</p><p>The earliest evidence of domesticated grapes in the world has been found at Gadachrili Gora, near the village of Imiri, Marneuli Municipality, in southeastern Republic of Georgia; carbon-dating points to the date of about 6000 BC.[22][23]</p><p>Grape pips dating back to the V-IVth millennia B.C. were found in Shulaveri; others dating back to the IVth millennium B.C. were found in Khizanaant Gora—all in this same 'Shulaveri area' of the Republic of Georgia.[24]</p><p>A theory has been suggested by Stephen Batiuk that the Kura-Araxes folk may have spread Vitis vinifera vine and wine technology to the “Fertile Crescent”—to Mesopotamia and the Eastern Mediterranean.[25] The spread of wine-goblet form, such as represented by the Khirbet Kerak ware, is clearly associated with these peoples. The same applies to the large ceramic vessels used for grape fermentation.</p><h2>Culture</h2><p>The culture is closely linked to the approximately contemporaneous Maykop culture of Ciscaucasia. As Amjad Jaimoukha puts it,</p><p>The Kura-Araxes culture was contiguous, and had mutual influences, with the Maikop culture in the Northwest Caucasus. According to E.I. Krupnov (1969:77), there were elements of the Maikop culture in the early memorials of Chechnya and Ingushetia in the Meken and Bamut kurgans and in Lugovoe in Serzhen-Yurt. Similarities between some features and objects of the Maikop and Kura-Araxes cultures, such as large square graves, the bold-relief curvilinear ornamentation of pottery, ochre-coloured ceramics, earthen hearth props with horn projections, flint arrowheads, stone axes and copper pitchforks are indicative of a cultural unity that pervaded the Caucasus in the Neolithic Age.[26]</p><p>Inhumation practices are mixed. Flat graves are found but so are substantial kurgan burials, the latter of which may be surrounded by cromlechs. This points to a heterogeneous ethno-linguistic population (see section below).[citation needed] Late in the history of this culture, its people built kurgans of greatly varying sizes, containing widely varying amounts and types of metalwork, with larger, wealthier kurgans surrounded by smaller kurgans containing less wealth.[2] This trend suggests the eventual emergence of a marked social hierarchy.[2] Their practice of storing relatively great wealth in burial kurgans was probably a cultural influence from the more ancient civilizations of the Fertile Crescent to the south.[2]</p><p>According to Giulio Palumbi (2008), the typical red-black ware of Kura–Araxes culture originated in eastern Anatolia, and then moved on to the Caucasus area. But then these cultural influences came back to Anatolia mixed in with other cultural elements from the Caucasus.[27]</p><h2>Ethno-linguistic makeup</h2><p>Hurrian and Urartian language elements are quite probable, as are Northeast Caucasian ones. Some authors subsume Hurrians and Urartians under Northeast Caucasian as well as part of the Alarodian theory.[28] The presence of Kartvelian languages was also highly probable. Influences of Semitic languages and Indo-European languages are highly possible, though the presence of the languages on the lands of the Kura–Araxes culture is more controversial.</p><p>In the Armenian hypothesis of Indo-European origins, this culture (and perhaps that of the Maykop culture) is identified with the speakers of the Anatolian languages.[29][30][31][32][33]</p><p>The expansion of Y-DNA subclade R-Z93 (R1a1a1b2), according to Mascarenhas et al. (2015), is compatible with the archeological records of eastward expansion of West Asian populations in the 4th millennium BCE, culminating in the socalled Kura-Araxes migrations in the post-Uruk IV period.[34] According to Pamjav et al. (2012), Inner and Central Asia is an overlap zone for the R -Z280 and R -Z93 lineages, implying that an early differentiation zone of R-M198 conceivably occurred somewhere within the Eurasian Steppes or the Middle East and Caucasus region as they lie between South Asia and Eastern Europe. [35] According to Underhill et al. (2014/2015), R1a1a1, the most frequent subclade of R1a, split into R-Z282 (Europe) and R-Z93 (Asia) at circa 5,800 before present,[36] in the vicinity of Iran and Eastern Turkey. According to Underhill et al. (2014/2015), [t]his suggests the possibility that R1a lineages accompanied demic expansions initiated during the Copper, Bronze, and Iron ages.[37]</p><h2>Sources</h2><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Kura–Araxes_culture&amp;oldid=779443218"					
								Categories:  Hidden categories:</p><br><h1 lang="en">Kassites</h1><p> From Wikipedia, the free encyclopedia</p><br><img alt="Kassites is located in Iraq" src="http://upload.wikimedia.org/wikipedia/commons/thumb/8/80/Iraq_adm_location_map.svg/300px-Iraq_adm_location_map.svg.png" width="300" height="306"><div class="gradientback"></div></div><div class="content"><br><img alt="Babylon" src="http://upload.wikimedia.org/wikipedia/commons/thumb/0/0c/Red_pog.svg/8px-Red_pog.svg.png" title="Babylon" width="8" height="8"><br><img alt="Isin" src="http://upload.wikimedia.org/wikipedia/commons/thumb/0/0c/Red_pog.svg/8px-Red_pog.svg.png" title="Isin" width="8" height="8"><br><img alt="Kish" src="http://upload.wikimedia.org/wikipedia/commons/thumb/0/0c/Red_pog.svg/8px-Red_pog.svg.png" title="Kish" width="8" height="8"><br><img alt="Nippur" src="http://upload.wikimedia.org/wikipedia/commons/thumb/0/0c/Red_pog.svg/8px-Red_pog.svg.png" title="Nippur" width="8" height="8"><br><img alt="Sippar" src="http://upload.wikimedia.org/wikipedia/commons/thumb/0/0c/Red_pog.svg/8px-Red_pog.svg.png" title="Sippar" width="8" height="8"><br><img alt="Ur" src="http://upload.wikimedia.org/wikipedia/commons/thumb/0/0c/Red_pog.svg/8px-Red_pog.svg.png" title="Ur" width="8" height="8"><br><img alt="Uruk" src="http://upload.wikimedia.org/wikipedia/commons/thumb/0/0c/Red_pog.svg/8px-Red_pog.svg.png" title="Uruk" width="8" height="8"><br><img alt="Dur-Kurigalzu" src="http://upload.wikimedia.org/wikipedia/commons/thumb/0/0c/Red_pog.svg/8px-Red_pog.svg.png" title="Dur-Kurigalzu" width="8" height="8"><br><img alt="Girsu" src="http://upload.wikimedia.org/wikipedia/commons/thumb/0/0c/Red_pog.svg/8px-Red_pog.svg.png" title="Girsu" width="8" height="8"><p>The Kassites (/'kæsa?ts/) were a people of the ancient Near East, who controlled Babylonia after the fall of the Old Babylonian Empire c. 1531 BC and until c. 1155 BC (short chronology). The endonym of the Kassites was probably Galzu,[1] although they have also been referred to by the names Kaššu, Kassi, Kasi or Kashi.</p><p>They gained control of Babylonia after the Hittite sack of the city in 1595 BC (i.e. 1531 BC per the short chronology), and established a dynasty based in Dur-Kurigalzu.[2][3] The Kassites were members of a small military aristocracy but were efficient rulers and not locally unpopular,[4] and their 500-year reign laid an essential groundwork for the development of subsequent Babylonian culture.[3] The horse, which the Kassites worshipped, first came into use in Babylonia at this time.[4]</p><p>The Kassite language has not been classified.[3] What is known is that their language was not related to either the Indo-European language group, nor to Semitic or other Afro-Asiatic languages, and is most likely to have been a language isolate (a stand-alone language unrelated to any other), although some linguists have proposed a link to the Hurro-Urartian languages of Asia Minor.[5] However, several Kassite leaders bore Indo-European names, and they might have had an Indo-European elite similar to the Mitanni, who ruled over the Hurro-Urartian-speaking Hurrians of Asia Minor.[6][7]</p><h2>Contents</h2><h2>History</h2><p>The original homeland of the Kassites is not well known, but appears to have been located in the Zagros Mountains, in what is now the Lorestan Province of Iran. However the Kassites were – like the Elamites, Gutians and Manneans who preceded them – linguistically unrelated to the Iranian-speaking peoples who came to dominate the region a millennium later.[8][9] They first appeared in the annals of history in the 18th century BC when they attacked Babylonia in the 9th year of the reign of Samsu-iluna (reigned c. 1749–1712 BC), the son of Hammurabi. Samsu-iluna repelled them, as did Abi-Eshuh, but they subsequently gained control of Babylonia c. 1570 BC some 25 years after the fall of Babylon to the Hittites in c. 1595 BC, and went on to conquer the southern part of Mesopotamia, roughly corresponding to ancient Sumer and known as the Dynasty of the Sealand by c. 1460 BC. The Hittites had carried off the idol of the god Marduk, but the Kassite rulers regained possession, returned Marduk to Babylon, and made him the equal of the Kassite Shuqamuna. The circumstances of their rise to power are unknown, due to a lack of documentation from this so-called Dark Age period of widespread dislocation. No inscription or document in the Kassite language has been preserved, an absence that cannot be purely accidental, suggesting a severe regression of literacy in official circles. Babylon under Kassite rulers, who renamed the city Karanduniash, re-emerged as a political and military power in Mesopotamia. A newly built capital city Dur-Kurigalzu was named in honour of Kurigalzu I (ca. early 14th century BC).</p><p>Their success was built upon the relative political stability that the Kassite monarchs achieved. They ruled Babylonia practically without interruption for almost four hundred years— the longest rule by any dynasty in Babylonian history.</p><p>The transformation of southern Mesopotamia into a territorial state, rather than a network of allied or combative city states, made Babylonia an international power, although it was often overshadowed by its northern neighbour, Assyria and by Elam to the east. Kassite kings established trade and diplomacy with Assyria. (Puzur-Ashur III of Assyria and Burna-Buriash I signed a treaty agreeing the border between the two states in the mid 16th Century BC), Egypt, Elam, and the Hittites, and the Kassite royal house intermarried with their royal families. There were foreign merchants in Babylon and other cities, and Babylonian merchants were active from Egypt (a major source of Nubian gold) to Assyria and Anatolia. Kassite weights and seals, the packet-identifying and measuring tools of commerce, have been found in as far afield as Thebes in Greece, in southern Armenia, and even in the Uluburun shipwreck off the southern coast of today's Turkey.</p><p>A further treaty between Kurigalzu I and Ashur-bel-nisheshu of Assyria was agreed in the mid 15th century. However, Babylonia found itself under attack and domination from Assyria for much of the next few centuries after the accession of Ashur-uballit I in 1365 BC who made Assyria (along with the Hittites and Egyptians) the major power in the Near East. Babylon was sacked by the Assyrian king Ashur-uballit I (1365 BC – 1330 BC)) in the 1360s after the Kassite king in Babylon who was married to the daughter of Ashur-uballit was murdered. Ashur-uballit promptly marched into Babylonia and avenged his son-in-law, deposing the king and installing Kurigalzu II of the royal Kassite line as king there. His successor Enlil-nirari (1330 BC to 1319) also attacked Babylonia and his great grandson Adad-nirari I (1307 to 1275 BC) annexed Babylonian territory when he became king. Tukulti-Ninurta I (1244 BC -1208 BC) not content with merely dominating Babylonia went further, conquering Babylonia, deposing Kashtiliash IV and ruling there for 8 years in person from 1235 BC to 1227 BC.</p><p>The Kassite kings maintained control of their realm through a network of provinces administered by governors. Almost equal with the royal cities of Babylon and Dur-Kurigalzu, the revived city of Nippur was the most important provincial center. Nippur, the formerly great city, which had been virtually abandoned c. 1730 BC, was rebuilt in the Kassite period, with temples meticulously re-built on their old foundations. In fact, under the Kassite government, the governor of Nippur, who took the Sumerian-derived title of Guennakku, ruled as a sort of secondary and lesser king. The prestige of Nippur was enough for a series of 13th century BC Kassite kings to reassume the title 'governor of Nippur' for themselves.</p><p>Other important centers during the Kassite period were Larsa, Sippar and Susa. After the Kassite dynasty was overthrown in 1155 BC, the system of provincial administration continued and the country remained united under the succeeding rule, the Second Dynasty of Isin.</p><p>Documentation of the Kassite period depends heavily on the scattered and disarticulated tablets from Nippur, where thousands of tablets and fragments have been excavated. They include administrative and legal texts, letters, seal inscriptions, kudurrus (land grants and administrative regulations), private votive inscriptions, and even a literary text (usually identified as a fragment of a historical epic).</p><div class="gradientback"></div></div><div class="content"><p>Kassite rulers in Babylon were also scrupulous to follow existing forms of expression, and the public and private patterns of behavior and even went beyond that — as zealous neophytes do, or outsiders, who take up a superior civilization — by favoring an extremely conservative attitude, at least in palace circles. (Oppenheim 1964, p.&nbsp;62).</p><p>The Elamites conquered Babylonia in the 12th century BC, thus ending the Kassite state. The last Kassite king, Enlil-nadin-ahi, was taken to Susa and imprisoned there, where he also died.</p><p>The Kassites did briefly regain control over Babylonia with Dynasty V (1025 BC-1004 BC), however they were deposed once more, this time by an Aramean dynasty.</p><p>Kassites survived as a distinct ethnic group in the mountains of Lorestan (Luristan) long after the Kassite state collapsed. Babylonian records describe how the Assyrian king Sennacherib on his eastern campaign of 702 BC subdued the Kassites in a battle near Hulwan, Iran.</p><p>Herodotus and other ancient Greek writers sometimes referred to the region around Susa as Cissia, a variant of the Kassite name. However, it is not clear if Kassites were actually living in that region so late...</p><p>During the later Achaemenid period, the Kassites, referred to as Kossaei, lived in the mountains to the east of Media and were one of several predatory mountain tribes that regularly extracted gifts from the Achaemenid Persians, according to a citation of Nearchus by Strabo (13.3.6).</p><p>But Kassites again fought on the Persian side in the Battle of Gaugamela in 331 BC, in which the Persian Empire fell to Alexander the Great, according to Diodorus Siculus (17.59) (who called them Kossaei) and Curtius Rufus (4.12) (who called them inhabitants of the Cossaean mountains). According to Strabo's citation of Nearchus, Alexander later separately attacked the Kassites in the winter, after which they stopped their tribute-seeking raids.</p><p>Strabo also wrote that the Kossaei contributed 13,000 archers to the army of Elymais in a war against Susa and Babylon. This statement is hard to understand, as Babylon had lost importance under Seleucid rule by the time Elymais emerged around 160 BC. If Babylon is understood to mean the Seleucids, then this battle would have occurred sometime between the emergence of Elymais and Strabo's death around 25 AD. If Elymais is understood to mean Elam, then the battle probably occurred in the 6th century BC. Note that Susa was the capital of Elam and later of Elymais, so Strabo's statement implies that the Kassites intervened to support a particular group within Elam or Elymais against their own capital, which at that moment was apparently allied with or subject to Babylon or the Seleucids.</p><p>The latest evidence of Kassite culture is a reference by the 2nd century geographer Ptolemy, who described Kossaei as living in the Susa region, adjacent to the Elymeans. This could represent one of many cases where Ptolemy relied on out-of-date sources.</p><p>It is believed[by whom?] that the name of the Kassites is preserved in the name of the Kashgan River, in Lorestan.</p><h3>Kassite Dynasty of Babylon</h3><h2>Kassite Culture</h2><h3>Social life</h3><p>In spite of the fact that some of them took Babylonian names, the Kassites retained their traditional clan and tribal structure, in contrast to the smaller family unit of the Babylonians. They were proud of their affiliation with their tribal houses, rather than their own fathers, preserved their customs of fratriarchal property ownership and inheritance.[10]</p><h3>Language</h3><p> Main article: Kassite language</p><p>The Kassite language has not been classified.[3] However, several Kassite leaders bore Indo-European names, and they might have had an Indo-European elite similar to the Mitanni.[6][7] Over the centuries, however, the Kassites were absorbed into the Babylonian population. Eight among the last kings of the Kassite dynasty have Akkadian names, Kudur-Enlil's name is part Elamite and part Sumerian and Kassite princesses married into the royal family of Assyria.</p><p>Herodotus was almost certainly[citation needed] referring to Kassites when he described Asiatic Ethiopians in the Persian army that invaded Greece in 492 BC. Herodotus was presumably[citation needed] repeating an account that had used the name Cush, or something similar, to describe the Kassites; the similar name Kush was also, purely by coincidence, a name for Ethiopia. A similar confusion of Kassites with Ethiopians is evident in various ancient Greek accounts of the Trojan war hero Memnon, who was sometimes described as a Cissian and founder of Susa, and other times as Ethiopian. According to Herodotus, the Asiatic Ethiopians lived not in Cissia, but to the north, bordering on the Paricanians who in turn bordered on the Medes. The Kassites were not geographically linked to Kushites and Ethiopians, nor is there any documentation describing them as similar in appearance, and the Kassite language is regarded as a language isolate, utterly unrelated to any language of Ethiopia or Kush/Nubia,[11] although more recently a possible relationship to the Hurro-Urartian family of Asia Minor has been proposed.[12] However, the evidence for its genetic affiliation is meager due to the scarcity of extant texts.</p><p>According to the Encyclopædia Iranica:</p><p>There is not a single connected text in the Kassite language. The number of Kassite appellatives is restricted (slightly more than 60 vocables, mostly referring to colors, parts of the chariot, irrigation terms, plants, and titles). About 200 additional lexical elements can be gained by the analysis of the more numerous anthroponyms, toponyms, theonyms, and horse names used by the Kassites (see Balkan, 1954, passim; Jaritz, 1957 is to be used with caution). As is clear from this material, the Kassites spoke a language without a genetic relationship to any other known tongue</p><h3>Kudurru</h3><p>The most notable Kassite artifacts are their Kudurru steles. Used for marking boundaries and making proclamations, they were also carved with a high degree of artistic skill, they took a long time to make.</p><h2>Notes</h2><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Kassites&amp;oldid=773596129"					
								Categories:  Hidden categories:</p><br><h1 lang="en">Seleucid Empire</h1><p> From Wikipedia, the free encyclopedia</p><p>The Seleucid Empire (/s?'lju?s?d/;[6] Ancient&nbsp;Greek: ?as??e?a t?? Se?e???d??, Basileía ton Seleukidon) was a Hellenistic state ruled by the Seleucid dynasty, which existed from 312 BC to 63 BC; it was founded by Seleucus I Nicator following the division of the Macedonian empire vastly expanded by Alexander the Great.[7][8][9][10] Seleucus received Babylonia and, from there, expanded his dominions to include much of Alexander's near eastern territories. At the height of its power, it included central Anatolia, Persia, the Levant, Mesopotamia, and what is now Kuwait, Afghanistan, and parts of Pakistan and Turkmenistan.</p><p>The Seleucid Empire was a major center of Hellenistic culture that maintained the preeminence of Greek customs where a Greek political elite dominated, mostly in the urban areas.[10][11][12][13] The Greek population of the cities who formed the dominant elite were reinforced by immigration from Greece.[10][11] Seleucid expansion into Anatolia and Greece was abruptly halted after decisive defeats at the hands of the Roman army. Their attempts to defeat their old enemy Ptolemaic Egypt were frustrated by Roman demands. Having come into conflict with Chandragupta Maurya of the Maurya Empire, after several defeats, Seleucus entered into an agreement with Maurya where he ceded vast territory west of the Indus, including the Hindu Kush, modern day Afghanistan, and the Balochistan province of Pakistan and offered his daughter for marriage to the Emperor to formalize the alliance. Much of the eastern part of the empire was conquered by the Parthians under Mithridates I of Parthia in the mid-2nd century BC, yet the Seleucid kings continued to rule a rump state from Syria until the invasion by Armenian king Tigranes the Great and their ultimate overthrow by the Roman general Pompey.</p><div class="gradientback"></div></div><div class="content"><h2>Contents</h2><h2>Name</h2><p>Contemporary sources, such as a loyalist degree from Ilium, in Greek language define the Seleucid state both as an empire (arche) and as a kingdom (basileia). Similarly, Seleucid rulers were described as kings in Babylonia.[14]</p><p>Starting from the 2nd century BC, ancient writers referred to the Seleucid ruler as the King of Syria, Lord of Asia, and other designations;[15] the evidence for the Seleucid rulers representing themselves as kings of Syria is provided by the inscription of Antigonus son of Menophilus, who described himself as the admiral of Alexander, king of Syria. He refers to either Alexander Balas or Alexander II Zabinas as a ruler.[16]</p><h2>History</h2><h3>Partition of Alexander's empire</h3><p> Main article: Diadochi</p><p>Alexander, who quickly conquered the Persian Empire under its last Achaemenid dynast, Darius III, died young in 323 BC, leaving an expansive empire of partly Hellenised culture without an adult heir. The empire was put under the authority of a regent in the person of Perdiccas, and the territories were divided among Alexander's generals, who thereby became satraps, at the Partition of Babylon, all in that same year.</p><h3>Rise of Seleucus</h3><p>Alexander's generals (the Diadochi) jostled for supremacy over parts of his empire. Ptolemy, a former general and the satrap of Egypt, was the first to challenge the new system; this led to the demise of Perdiccas. Ptolemy's revolt led to a new subdivision of the empire with the Partition of Triparadisus in 320 BC. Seleucus, who had been Commander-in-Chief of the Companion cavalry (hetairoi) and appointed first or court chiliarch (which made him the senior officer in the Royal Army after the regent and commander-in-chief Perdiccas since 323 BC, though he helped to assassinate him later) received Babylonia and, from that point, continued to expand his dominions ruthlessly. Seleucus established himself in Babylon in 312 BC, the year used as the foundation date of the Seleucid Empire. He ruled not only Babylonia, but the entire enormous eastern part of Alexander's empire, as described by Appian:</p><p>Always lying in wait for the neighboring nations, strong in arms and persuasive in council, he [Seleucus] acquired Mesopotamia, Armenia, 'Seleucid' Cappadocia, Persis, Parthia, Bactria, Arabia, Tapouria, Sogdia, Arachosia, Hyrcania, and other adjacent peoples that had been subdued by Alexander, as far as the river Indus, so that the boundaries of his empire were the most extensive in Asia after that of Alexander. The whole region from Phrygia to the Indus was subject to Seleucus.[17]</p><p>Seleucus went as far as India, where, after two years of war, he reached an agreement with Chandragupta Maurya, in which he gave his daughter in marriage to Chandragupta and exchanged his eastern territories for a considerable force of 500 war elephants, which would play a decisive role at Ipsus (301 BC). Strabo, in his Geographica, wrote:</p><p>The Indians occupy [in part] some of the countries situated along the Indus, which formerly belonged to the Persians: Alexander deprived the Ariani of them, and established there settlements of his own. But Seleucus Nicator gave them to Sandrocottus (Chandragupta Maurya) in consequence of a marriage contract, and received in return five hundred elephants.[18]</p><h3>Westward expansion</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/f/f1/SeleucosCoin.jpg/220px-SeleucosCoin.jpg" width="220" height="223"><p>


				Coin of Seleucus I Nicator


				</p><p>
					Following his and Lysimachus' victory over Antigonus Monophthalmus at the decisive Battle of Ipsus in 301 BC, Seleucus took control over eastern Anatolia and northern Syria.</p><p>In the latter area, he founded a new capital at Antioch on the Orontes, a city he named after his father. An alternative capital was established at Seleucia on the Tigris, north of Babylon. Seleucus's empire reached its greatest extent following his defeat of his erstwhile ally, Lysimachus, at Corupedion in 281 BC, after which Seleucus expanded his control to encompass western Anatolia. He hoped further to take control of Lysimachus's lands in Europe – primarily Thrace and even Macedonia itself, but was assassinated by Ptolemy Ceraunus on landing in Europe.</p><p>His son and successor, Antiochus I Soter, was left with an enormous realm consisting of nearly all of the Asian portions of the Empire, but faced with Antigonus II Gonatas in Macedonia and Ptolemy II Philadelphus in Egypt, he proved unable to pick up where his father had left off in conquering the European portions of Alexander's empire.</p><h3>An overextended domain</h3><p>Nevertheless, even before Seleucus' death, it was difficult to assert control over the vast eastern domains of the Seleucids. Seleucus invaded the Punjab region of India in 305 BC, confronting Chandragupta Maurya (Sandrokottos), founder of the Maurya Empire. It is said that Chandragupta fielded an army of 600,000 men and 9,000 war elephants.[19]</p><p>Mainstream scholarship asserts that Chandragupta received vast territory, sealed in a treaty, west of the Indus, including the Hindu Kush, modern day Afghanistan, and the Balochistan province of Pakistan.[20][21] Archaeologically, concrete indications of Mauryan rule, such as the inscriptions of the Edicts of Ashoka, are known as far as Kandahar in southern Afghanistan. According to Appian:</p><p>He [Seleucus] crossed the Indus and waged war with Sandrocottus [Maurya], king of the Indians, who dwelt on the banks of that stream, until they came to an understanding with each other and contracted a marriage relationship.[22]</p><p>It is generally thought that Chandragupta married Seleucus's daughter, or a Macedonian princess, a gift from Seleucus to formalize an alliance. In a return gesture, Chandragupta sent 500 war elephants,[23][24][25][26][27] a military asset which would play a decisive role at the Battle of Ipsus in 301 BC. In addition to this treaty, Seleucus dispatched an ambassador, Megasthenes, to Chandragupta, and later Deimakos to his son Bindusara, at the Mauryan court at Pataliputra (modern Patna in Bihar state). Megasthenes wrote detailed descriptions of India and Chandragupta's reign, which have been partly preserved to us through Diodorus Siculus. Later Ptolemy II Philadelphus, the ruler of Ptolemaic Egypt and contemporary of Ashoka the Great, is also recorded by Pliny the Elder as having sent an ambassador named Dionysius to the Mauryan court.[28]</p><div class="gradientback"></div></div><div class="content"><p>Other territories lost before Seleucus' death were Gedrosia in the south-east of the Iranian plateau, and, to the north of this, Arachosia on the west bank of the Indus River.</p><p>Antiochus I (reigned 281–261 BC) and his son and successor Antiochus II Theos (reigned 261–246 BC) were faced with challenges in the west, including repeated wars with Ptolemy II and a Celtic invasion of Asia Minor—distracting attention from holding the eastern portions of the Empire together. Towards the end of Antiochus II's reign, various provinces simultaneously asserted their independence, such as Bactria and Sogdiana under Diodotus, Cappadocia under Ariarathes III, and Parthia under Andragoras. A few years later, the latter was defeated and killed by the invading Parni of Arsaces - the region would then become the core of the Parthian Empire.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/9/93/DiodotusGoldCoin.jpg/300px-DiodotusGoldCoin.jpg" width="300" height="148"><p>


				In Bactria, the satrap Diodotus asserted independence to form the Greco-Bactrian kingdom c.245 BC.


				</p><p>
					Diodotus, governor for the Bactrian territory, asserted independence in around 245 BC, although the exact date is far from certain, to form the Greco-Bactrian kingdom. This kingdom was characterized by a rich Hellenistic culture and was to continue its domination of Bactria until around 125 BC when it was overrun by the invasion of northern nomads. One of the Greco-Bactrian kings, Demetrius I of Bactria, invaded India around 180 BC to form the Greco-Indian kingdom, lasting until around AD 20.</p><p>The Seleucid satrap of Parthia, named Andragoras, first claimed independence, in a parallel to the secession of his Bactrian neighbour. Soon after, however, a Parthian tribal chief called Arsaces invaded the Parthian territory around 238 BC to form the Arsacid Dynasty, from which the Parthian Empire originated.</p><p>Antiochus II's son Seleucus II Callinicus came to the throne around 246 BC. Seleucus II was soon dramatically defeated in the Third Syrian War against Ptolemy III of Egypt and then had to fight a civil war against his own brother Antiochus Hierax. Taking advantage of this distraction, Bactria and Parthia seceded from the empire. In Asia Minor too, the Seleucid dynasty seemed to be losing control: the Gauls had fully established themselves in Galatia, semi-independent semi-Hellenized kingdoms had sprung up in Bithynia, Pontus, and Cappadocia, and the city of Pergamum in the west was asserting its independence under the Attalid Dynasty.[citation needed] The Seleucid economy started to show the first signs of weakness, as Galatians gained independence and Pergamum took control of coastal cities in Anatolia. Consequently, they managed to partially block contact with the West.[29]</p><h3>Revival (223–191 BC)</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/3/37/AntiochusIII.jpg/300px-AntiochusIII.jpg" width="300" height="142"><p>


				Silver coin of Antiochus III the Great.



				<br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/2/2c/Seleucid-Empire_200bc.jpg/300px-Seleucid-Empire_200bc.jpg" width="300" height="173"><br>


				The Seleucid Empire in 200 BC (before expansion into Anatolia and Greece).


				</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/2/2c/Seleucid-Empire_200bc.jpg/300px-Seleucid-Empire_200bc.jpg" width="300" height="173"><br><p>
					A revival would begin when Seleucus II's younger son, Antiochus III the Great, took the throne in 223 BC. Although initially unsuccessful in the Fourth Syrian War against Egypt, which led to a defeat at the Battle of Raphia (217 BC), Antiochus would prove himself to be the greatest of the Seleucid rulers after Seleucus I himself. He spent the next ten years on his anabasis through the eastern parts of his domain and restoring rebellious vassals like Parthia and Greco-Bactria to at least nominal obedience. He won the Battle of the Arius and besieged the Bactrian capital, and even emulated Alexander with an expedition into India where he met with king Sophagasenus receiving war elephants:</p><p>He (Antiochus) crossed the Caucasus and descended into India; renewed his friendship with Sophagasenus the king of the Indians; received more elephants, until he had a hundred and fifty altogether; and having once more provisioned his troops, set out again personally with his army: leaving Androsthenes of Cyzicus the duty of taking home the treasure which this king had agreed to hand over to him. Polybius 11.39</p><p>When he returned to the west in 205 BC, Antiochus found that with the death of Ptolemy IV, the situation now looked propitious for another western campaign. Antiochus and Philip V of Macedon then made a pact to divide the Ptolemaic possessions outside of Egypt, and in the Fifth Syrian War, the Seleucids ousted Ptolemy V from control of Coele-Syria. The Battle of Panium (198 BC) definitively transferred these holdings from the Ptolemies to the Seleucids. Antiochus appeared, at the least, to have restored the Seleucid Kingdom to glory.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/7/71/Asia_Minor_188_BCE.jpg/300px-Asia_Minor_188_BCE.jpg" width="300" height="168"><p>


				The reduced empire (titled: Syria, Kingdom of the Seleucids) and the expanded states of Pergamum and Rhodes, after the defeat of Antiochus III by Rome. Circa 188 BC.



				</p><p> Further information: Roman–Syrian War</p><p>
					Following the defeat of his erstwhile ally Philip by Rome in 197 BC, Antiochus saw the opportunity for expansion into Greece itself. Encouraged by the exiled Carthaginian general Hannibal, and making an alliance with the disgruntled Aetolian League, Antiochus launched an invasion across the Hellespont. With his huge army he aimed to establish the Seleucid empire as the foremost power in the Hellenic world, but these plans put the empire on a collision course with the new rising power of the Mediterranean, the Roman Republic. At the battles of Thermopylae (191 BC) and Magnesia (190 BC), Antiochus's forces suffered resounding defeats, and he was compelled to make peace and sign the Treaty of Apamea (188 BC), the main clause of which saw the Seleucids agree to pay a large indemnity, to retreat from Anatolia and to never again attempt to expand Seleucid territory west of the Taurus Mountains. The Kingdom of Pergamum and the Republic of Rhodes, Rome's allies in the war, gained the former Seleucid lands in Anatolia. Antiochus died in 187 BC on another expedition to the east, where he sought to extract money to pay the indemnity.</p><div class="gradientback"></div></div><div class="content"><h3>Roman power, Parthia and Judea</h3><p> Further information: Seleucid–Parthian wars and Maccabean Revolt</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/8/88/Seleucid_prince_Massimo_Inv1049.jpg/170px-Seleucid_prince_Massimo_Inv1049.jpg" width="170" height="434"><p>


				Statue of a prince without a crown, traditionally thought to be a Seleucid prince, maybe Attalus II of Pergamon. Bronze, Greek artwork of the Hellenistic era, 3rd-2nd centuries BC.


				</p><p>
					The reign of his son and successor Seleucus IV Philopator (187-175 BC) was largely spent in attempts to pay the large indemnity, and Seleucus was ultimately assassinated by his minister Heliodorus.</p><p>Seleucus' younger brother, Antiochus IV Epiphanes, now seized the throne. He attempted to restore Seleucid power and prestige with a successful war against the old enemy, Ptolemaic Egypt, which met with initial success as the Seleucids defeated and drove the Egyptian army back to Alexandria itself. As the king planned on how to conclude the war, he was informed that Roman commissioners, led by the Proconsul Gaius Popillius Laenas, were near and requesting a meeting with the Seleucid king. Antiochus agreed, but when they met and Antiochus held out his hand in friendship, Popilius placed in his hand the tablets on which was written the decree of the senate and told him to read it. When the king said that he would call his friends into council and consider what he ought to do, Popilius drew a circle in the sand around the king's feet with the stick he was carrying and said, Before you step out of that circle give me a reply to lay before the senate. For a few moments he hesitated, astounded at such a peremptory order, and at last replied, I will do what the senate thinks right. He then chose to withdraw rather than set the empire to war with Rome again.[30]</p><p>The latter part of his reign saw a further disintegration of the Empire despite his best efforts. Weakened economically, militarily and by loss of prestige, the Empire became vulnerable to rebels in the eastern areas of the empire, who began to further undermine the empire while the Parthians moved into the power vacuum to take over the old Persian lands. Antiochus' aggressive Hellenizing (or de-Judaizing) activities provoked a full scale armed rebellion in Judea—the Maccabean Revolt.[31] Efforts to deal with both the Parthians and the Jews as well as retain control of the provinces at the same time proved beyond the weakened empire's power. Antiochus died during a military expedition against the Parthians in 164 BC.</p><h3>Civil war and further decay</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/9/92/AntiochusIVEpiphanes.jpg/300px-AntiochusIVEpiphanes.jpg" width="300" height="146"><p>


				Coin of Antiochus IV Epiphanes.



				<br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/f/f0/AlexanderI.jpg/300px-AlexanderI.jpg" width="300" height="144"><br>


				Silver coin of Alexander Balas.



				</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/f/f0/AlexanderI.jpg/300px-AlexanderI.jpg" width="300" height="144"><br><p> Further information: Seleucid Dynastic Wars</p><p>
					After the death of Antiochus IV Epiphanes, the Seleucid Empire became increasingly unstable. Frequent civil wars made central authority tenuous at best. Epiphanes' young son, Antiochus V Eupator, was first overthrown by Seleucus IV's son, Demetrius I Soter in 161 BC. Demetrius I attempted to restore Seleucid power in Judea particularly, but was overthrown in 150 BC by Alexander Balas – an impostor who (with Egyptian backing) claimed to be the son of Epiphanes. Alexander Balas reigned until 145 BC when he was overthrown by Demetrius I's son, Demetrius II Nicator. Demetrius II proved unable to control the whole of the kingdom, however. While he ruled Babylonia and eastern Syria from Damascus, the remnants of Balas' supporters – first supporting Balas' son Antiochus VI, then the usurping general Diodotus Tryphon – held out in Antioch.</p><p>Meanwhile, the decay of the Empire's territorial possessions continued apace. By 143 BC, the Jews in the form of the Maccabees had fully established their independence. Parthian expansion continued as well. In 139 BC, Demetrius II was defeated in battle by the Parthians and was captured. By this time, the entire Iranian Plateau had been lost to Parthian control.</p><p>Demetrius Nicator's brother, Antiochus VII Sidetes, took the throne after his brother's capture. He faced the enormous task of restoring a rapidly crumbling empire, one facing threats on multiple fronts. Hard-won control of Coele-Syria was threatened by the Jewish Maccabee rebels. Once-vassal dynasties in Armenia, Cappadocia, and Pontus were threatening Syria and northern Mesopotamia; the nomadic Parthians, brilliantly led by Mithridates I of Parthia, had overrun upland Media (home of the famed Nisean horse herd); and Roman intervention was an ever-present threat. Sidetes managed to bring the Maccabees to heel and frighten the Anatolian dynasts into a temporary submission; then, in 133, he turned east with the full might of the Royal Army (supported by a body of Jews under the Maccabee prince, John Hyrcanus) to drive back the Parthians.</p><div class="gradientback"></div></div><div class="content"><p>Sidetes' campaign initially met with spectacular success, recapturing Mesopotamia, Babylonia, and Media and defeating and slaying the Parthian Satrap of Seleucia-on-Tigris in personal combat. In the winter of 130/129 BC, his army was scattered in winter quarters throughout Media and Persis when the Parthian king, Phraates II, counter-attacked. Moving to intercept the Parthians with only the troops at his immediate disposal, he was ambushed and killed. Antiochus Sidetes is sometimes called the last great Seleucid king.</p><p>After the death of Antiochus VII Sidetes, all of the recovered eastern territories were recaptured by the Parthians. The Maccabees again rebelled, civil war soon tore the empire to pieces, and the Armenians began to encroach on Syria from the north.</p><h3>Collapse (100–63 BC)</h3><p>By 100 BC, the once formidable Seleucid Empire encompassed little more than Antioch and some Syrian cities. Despite the clear collapse of their power, and the decline of their kingdom around them, nobles continued to play kingmakers on a regular basis, with occasional intervention from Ptolemaic Egypt and other outside powers. The Seleucids existed solely because no other nation wished to absorb them – seeing as they constituted a useful buffer between their other neighbours. In the wars in Anatolia between Mithridates VI of Pontus and Sulla of Rome, the Seleucids were largely left alone by both major combatants.</p><p>Mithridates' ambitious son-in-law, Tigranes the Great, king of Armenia, however, saw opportunity for expansion in the constant civil strife to the south. In 83 BC, at the invitation of one of the factions in the interminable civil wars, he invaded Syria and soon established himself as ruler of Syria, putting the Seleucid Empire virtually at an end.</p><p>Seleucid rule was not entirely over, however. Following the Roman general Lucullus' defeat of both Mithridates and Tigranes in 69 BC, a rump Seleucid kingdom was restored under Antiochus XIII. Even so, civil wars could not be prevented, as another Seleucid, Philip II, contested rule with Antiochus. After the Roman conquest of Pontus, the Romans became increasingly alarmed at the constant source of instability in Syria under the Seleucids. Once Mithridates was defeated by Pompey in 63 BC, Pompey set about the task of remaking the Hellenistic East, by creating new client kingdoms and establishing provinces. While client nations like Armenia and Judea were allowed to continue with some degree of autonomy under local kings, Pompey saw the Seleucids as too troublesome to continue; doing away with both rival Seleucid princes, he made Syria into a Roman province.</p><h2>Culture</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/4/4c/BagdatesI290-280BCEPersia.jpg/300px-BagdatesI290-280BCEPersia.jpg" width="300" height="287"><p>


				Bagadates I (Minted 290–280 BC) was the first indigenous Seleucid satrap to be appointed.[32]


				</p><p>
					The Seleucid empire's geographical span, from the Aegean Sea to what is now Afghanistan and Pakistan, created a melting pot of various peoples, such as Greeks, Armenians, Persians, Medes, Assyrians and Jews. The immense size of the empire, followed by its encompassing nature, encouraged the Seleucid rulers to implement a policy of ethnic unity—a policy initiated by Alexander.</p><p>The Hellenization of the Seleucid empire was achieved by the establishment of Greek cities throughout the empire. Historically significant towns and cities, such as Antioch, were created or renamed with more appropriate Greek names. The creation of new Greek cities and towns was aided by the fact that the Greek mainland was overpopulated and therefore made the vast Seleucid empire ripe for colonization. Colonization was used to further Greek interest while facilitating the assimilation of many native groups. Socially, this led to the adoption of Greek practices and customs by the educated native classes in order to further themselves in public life, and at the same time the ruling Macedonian class gradually adopted some of the local traditions. By 313 BC, Hellenic ideas had begun their almost 250-year expansion into the Near East, Middle East, and Central Asian cultures. It was the empire's governmental framework to rule by establishing hundreds of cities for trade and occupational purposes. Many of the existing cities began—or were compelled by force—to adopt Hellenized philosophic thought, religious sentiments, and politics although the Seleucid rulers did incorporate Babylonian religious tenets to gain support.[33]</p><p>Synthesizing Hellenic and indigenous cultural, religious, and philosophical ideas met with varying degrees of success—resulting in times of simultaneous peace and rebellion in various parts of the empire. Such was the case with the Jewish population of the Seleucid empire; the Jews' refusal to willingly Hellenize their religious beliefs or customs posed a significant problem which eventually led to war. Contrary to the accepting nature of the Ptolemaic empire towards native religions and customs, the Seleucids gradually tried to force Hellenization upon the Jewish people in their territory by outlawing Judaism. This eventually led to the revolt of the Jews under Seleucid control, which would later lead to the Jews achieving independence from the Seleucid empire.</p><h2>List of Seleucid rulers</h2><p> Main article: List of Seleucid rulers</p><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Seleucid_Empire&amp;oldid=783362085"					
								Categories:  Hidden categories:</p><br><h1 lang="en">Kushan Empire</h1><p> From Wikipedia, the free encyclopedia</p><p>The Kushan Empire (Bactrian: ???a??, Kushano; Sanskrit: ????? ?????? Ku?a? Rajava?sa; BHS: Gu?a?a-va?sa; Chinese: ????, Parthian: Kušan-xša?r [6]) was a syncretic empire, formed by Yuezhi, in the Bactrian territories in the early 1st century. It spread to encompass much of Afghanistan,[7] and then the northern parts of the Indian subcontinent at least as far as Saketa and Sarnath near Varanasi (Benares), where inscriptions have been found dating to the era of the Kushan emperor Kanishka the Great.[8] Emperor Kanishka was a great patron of Buddhism; however, as Kushans expanded southward, the deities of their later coinage came to reflect its new Hindu majority.[9][10]</p><p>The Kushans were one of five branches of the Yuezhi confederation,[11][12] a possibly Iranic[13][14] or Tocharian,[15][16][17][18][19][20] Indo-European[19][21][22][23] nomadic people who migrated from Gansu and settled in ancient Bactria.[12] The Kushans possibly used the Greek language initially for administrative purposes, but soon began to use Bactrian language.[3] Kanishka sent his armies north of the Karakoram mountains, capturing territories as far as Kashgar, Khotan and Yarkant, in the Tarim Basin of modern-day Xinjiang, China. A direct road from Gandhara to China remained under Kushan control for more than a century, encouraging travel across the Karakoram and facilitating the spread of Mahayana Buddhism to China.</p><div class="gradientback"></div></div><div class="content"><p>The Kushan dynasty had diplomatic contacts with the Roman Empire, Sasanian Persia, Aksumite Empire and Han China. While much philosophy, art, and science was created within its borders, the only textual record of the empire's history today comes from inscriptions and accounts in other languages, particularly Chinese.[24] The Kushan empire fragmented into semi-independent kingdoms in the 3rd century AD, which fell to the Sasanians invading from the west. In the 4th century, the Guptas, an Indian dynasty also pressed from the east. The last of the Kushan and Sasanian kingdoms were eventually overwhelmed by invaders from the north, known as the Hepthalites.[5] Historian H. G. Rawlinson states that the Kushana Period is a fitting prelude to the age of Guptas[vague].[25]</p><h2>Contents</h2><h2>Origins</h2><p>Chinese sources describe the Guishuang (??), i.e. the Kushans, as one of the five aristocratic tribes of the Yuezhi, with some people claiming they were a loose confederation of Indo-European peoples,[26] though many scholars are still unconvinced that they originally spoke an Indo-European language. As the historian John E. Hill has put it: For well over a century ... there have been many arguments about the ethnic and linguistic origins of the Da Yuezhi (???), Kushans (??), and the Tochari, and still there is little consensus.[27]</p><p>The Yuezhi were described in the Records of the Great Historian and the Book of Han as living in the grasslands of Gansu, in the northwest of modern-day China, until they were driven west by the Xiongnu in 176–160&nbsp;BCE.[28] The five tribes constituting the Yuezhi are known in Chinese history as Xiumì (??), Guìshuang (??), Shuangmi (??), Xìdùn (??), and Dumì (??).</p><p>The Yuezhi reached the Hellenic kingdom of Greco-Bactria (in northern Afghanistan and Uzbekistan) around 135&nbsp;BC. The displaced Greek dynasties resettled to the southeast in areas of the Hindu Kush and the Indus basin (in present-day Afghanistan and Pakistan), occupying the western part of the Indo-Greek Kingdom.</p><h2>Early Kushans</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/6/68/KushanHead.jpg/150px-KushanHead.jpg" width="150" height="172"><p>


				Head of a Kushan prince (Khalchayan palace, Uzbekistan).


				</p><p>
					Some traces remain of the presence of the Kushans in the area of Bactria and Sogdiana. Archaeological structures are known in Takht-I-Sangin, Surkh Kotal (a monumental temple), and in the palace of Khalchayan. Various sculptures and friezes are known, representing horse-riding archers,[29] and significantly men with artificially deformed skulls, such as the Kushan prince of Khalchayan[30] (a practice well attested in nomadic Central Asia). The Chinese first referred to these people as the Yuezhi and said they established the Kushan Empire, although the relationship between the Yuezhi and the Kushans is still unclear. On the ruins of ancient Hellenistic cities such as Ai-Khanoum, the Kushans are known to have built fortresses.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/7/76/Coin_of_Heraios.jpg/220px-Coin_of_Heraios.jpg" width="220" height="100"><p>


				The first known Kushan king Heraios (1-30 CE).


				</p><p>
					The earliest documented ruler, and the first one to proclaim himself as a Kushan ruler, was Heraios. He calls himself a tyrant on his coins, and also exhibits skull deformation. He may have been an ally of the Greeks, and he shared the same style of coinage. Heraios may have been the father of the first Kushan emperor Kujula Kadphises.</p><p>Ban Gu's Book of Han tells us the Kushans (Kuei-shuang) divided up Bactria in 128&nbsp;BC. Fan Ye's Book of the Later Han relates how the chief of the Kushans, Ch'iu-shiu-ch'ueh (the Kujula Kadphises of coins), founded by means of the submission of the other Yueh-chih clans the Kushan Empire, known to the Greeks and Romans under the name of Empire of the Indo-Scythians.[31]</p><p>The Chinese Hou Hanshu chronicles gives an account of the formation of the Kushan empire based on a report made by the Chinese general Ban Yong to the Chinese Emperor c. 125&nbsp;AD:</p><p>More than a hundred years later [than the conquest of Bactria by the Da Yuezhi], the prince [xihou] of Guishuang (Badakhshan) established himself as king, and his dynasty was called that of the Guishuang (Kushan) King. He invaded Anxi (Indo-Parthia), and took the Gaofu (Kabul) region. He also defeated the whole of the kingdoms of Puda (Paktiya) and Jibin (Kapisha and Gandhara). Qiujiuque (Kujula Kadphises) was more than eighty years old when he died. His son, Yangaozhen [probably Vema Tahk (tu) or, possibly, his brother Sada?ka?a], became king in his place. He defeated Tianzhu [North-western India] and installed Generals to supervise and lead it. The Yuezhi then became extremely rich. All the kingdoms call [their king] the Guishuang [Kushan] king, but the Han call them by their original name, Da Yuezhi.|Hou Hanshu[32][33]</p><h2>Diverse cultural influences</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/e/e4/KushanDevoteeFullLength.jpg/150px-KushanDevoteeFullLength.jpg" width="150" height="329"><p>


				A Buddhist devotee in Kushan dress, Mathura, 2nd century. The Kushan dress is generally depicted as quite stiff, and it is thought it was often made of leather (Francine Tissot, "Gandhara").


				</p><p>
					In the 1st century BCE, the Guishuang (Ch: ??) gained prominence over the other Yuezhi tribes, and welded them into a tight confederation under yabgu (Commander) Kujula Kadphises. The name Guishuang was adopted in the West and modified into Kushan to designate the confederation, although the Chinese continued to call them Yuezhi.</p><div class="gradientback"></div></div><div class="content"><p>Gradually wresting control of the area from the Scythian tribes, the Kushans expanded south into the region traditionally known as Gandhara (an area primarily in Pakistan's Pothowar and Khyber Pakhtunkhwa region but going in an arc to include the Kabul valley and part of Qandahar in Afghanistan)[citation needed] and established twin capitals in Begram[34] and Peshawar, then known as Kapisa and Pushklavati respectively.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/7/7c/Sho_uc_lc.svg/100px-Sho_uc_lc.svg.png" width="100" height="67"><p>


				The Kushan writing system used the Greek alphabet, with the addition of the letter Sho.


				</p><p>
					The Kushans adopted elements of the Hellenistic culture of Bactria. They adopted the Greek alphabet to suit their own language (with the additional development of the letter Þ sh, as in Kushan) and soon began minting coinage on the Greek model. On their coins they used Greek language legends combined with Pali legends (in the Kharoshthi script), until the first few years of the reign of Kanishka. After that date,[vague][when?][dubious – discuss] they used Kushan language legends (in an adapted Greek script), combined with legends in Greek (Greek script) and legends in Prakrit (Kharoshthi script).</p><p>The Kushans adopted many local beliefs and customs, including Zoroastrianism and the two rising religions in the region, the Greek cults and Buddhism.[35] From the time of Vima Takto, many Kushans started adopting aspects of Buddhist culture, and like the Egyptians, they absorbed the strong remnants of the Greek culture of the Hellenistic Kingdoms, becoming at least partly Hellenised. The great Kushan emperor Vima Kadphises may have embraced Saivism (a sect of Hinduism), as surmised by coins minted during the period. The following Kushan emperors represented a wide variety of faiths including Zoroastrianism, Buddhism, and possibly Saivism.</p><p>The rule of the Kushans linked the seagoing trade of the Indian Ocean with the commerce of the Silk Road through the long-civilized Indus Valley. At the height of the dynasty, the Kushans loosely ruled a territory that extended to the Aral Sea through present-day Uzbekistan, Afghanistan, and Pakistan into northern India.</p><p>The loose unity and comparative peace of such a vast expanse encouraged long-distance trade, brought Chinese silks to Rome, and created strings of flourishing urban centers.</p><h2>Territorial expansion</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/e/ee/Kushan_king_or_prince.jpg/220px-Kushan_king_or_prince.jpg" width="220" height="386"><p>


				Kushan king or prince, Greco-Buddhist art of Gandhara, 2nd-3rd century CE.


				</p><p>
					Rosenfield notes that archaeological evidence of a Kushan rule of long duration is present in an area stretching from Surkh Kotal, Begram, the summer capital of the Kushans, Peshawar, the capital under Kanishka I, Taxila, and Mathura, the winter capital of the Kushans.[36]</p><p>Other areas of probable rule include Khwarezm[36] Kausambi (excavations of Allahabad University),[36] Sanchi and Sarnath (inscriptions with names and dates of Kushan kings),[36] Malwa and Maharashtra,[37] Odisha (imitation of Kushan coins, and large Kushan hoards).[36]</p><p>Kushan invasions in the 1st century CE had been given as an explanation for the migration of Indians from the Indian Subcontinent toward Southeast Asia according to proponents of a Greater India theory by 20th-century Indian nationalists. However, there is no evidence to support this hypothesis.[38]</p><p>The recently discovered Rabatak inscription confirms the account of the Hou Hanshu, Weilüe, and inscriptions dated early in the Kanishka era (incept probably 127 CE), that large Kushan dominions expanded into the heartland of northern India in the early 2nd century CE. The lines 4 to 7 of the inscription[39] describe the cities which were under the rule of Kanishka, among which six names are identifiable: Ujjain, Kundina, Saketa, Kausambi, Pataliputra, and Champa (although the text is not clear whether Champa was a possession of Kanishka or just beyond it).[40][41][42] The Kushan state was bounded to the south by the Parata state of Balochistan, western Pakistan, Afghanistan, Kyrgyzstan, Tajikistan, Uzbekistan, Turkmenistan. Turkmenistan was known for the kushan Buddhist city of Merv.[36] As late as the 3rd century AD, decorated coins of Huvishka were dedicated at Bodh Gaya together with other gold offerings under the Enlightenment Throne of the Buddha, suggesting direct Kushan influence in the area during that period.[43]</p><p>Northward, in the 2nd century AD, the Kushans under Kanishka made various forays into the Tarim Basin, where they had various contacts with the Chinese. Both archaeological findings and literary evidence suggest Kushan rule, in Kashgar, Yarkand and Khotan.[44]</p><h2>Main Kushan rulers</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/3/38/BodhGayaEnlightmentThroneOfferingAndHuvishkaCoin.jpg/220px-BodhGayaEnlightmentThroneOfferingAndHuvishkaCoin.jpg" width="220" height="230"><p>


				Offerings found in Bodh Gaya under the "Enlightenment Throne of the Buddha", with an impression of an imitation of a coin of the Kushan emperor Huvishka, 2nd century CE. British Museum.


				</p><h3>Kujula Kadphises (c. 30 – c. 80)</h3><p>
					...the prince [elavoor] of Guishuang, named thilac [Kujula Kadphises], attacked and exterminated the four other xihou. He established himself as king, and his dynasty was called that of the Guishuang [Kushan] King. He invaded Anxi [Indo-Parthia], and took the Gaofu [Kabul] region. He also defeated the whole of the kingdoms of Puda [Paktiya] and Jibin [Kapisha and Gandhara]. Qiujiuque [Kujula Kadphises] was more than eighty years old when he died.|Hou Hanshu[32]</p><div class="gradientback"></div></div><div class="content"><p>These conquests probably took place sometime between 45 and 60, and laid the basis for the Kushan Empire which was rapidly expanded by his descendants.</p><p>Kujula issued an extensive series of coins and fathered at least two sons, Sada?ka?a (who is known from only two inscriptions, especially the Rabatak inscription, and apparently never ruled), and seemingly Vima Takto.</p><p>Kujula Kadphises was the great grandfather of Kanishka.</p><h3>Vima Taktu or Sadashkana (c. 80 – c. 95)</h3><p>Vima Takto (Ancient Chinese: ??? Yangaozhen) is mentioned in the Rabatak inscription (another son, Sadashkana, is mentioned in an inscription of Senavarman, the King of Odi). He was the predecessor of Vima Kadphises, and Kanishka I. He expanded the Kushan Empire into the northwest of the South Asia. The Hou Hanshu says:</p><p>His son, Yangaozhen [probably Vema Tahk (tu) or, possibly, his brother Sada?ka?a], became king in his place. He defeated Tianzhu [North-western India] and installed Generals to supervise and lead it. The Yuezhi then became extremely rich. All the kingdoms call [their king] the Guishuang [Kushan] king, but the Han call them by their original name, Da Yuezhi.</p><h3>Vima Kadphises (c. 95 – c. 127)</h3><p>Vima Kadphises (Kushan language: ???µ? ?adf?s??) was a Kushan emperor from around 90–100 CE, the son of Sadashkana and the grandson of Kujula Kadphises, and the father of Kanishka I, as detailed by the Rabatak inscription.</p><p>Vima Kadphises added to the Kushan territory by his conquests in Afghanistan and north-west Pakistan. He issued an extensive series of coins and inscriptions. He issued gold coins in addition to the existing copper and silver coinage.</p><h3>Kanishka I (c. 127 – c. 140)</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/a/a6/Kanishka_enhanced.jpg/220px-Kanishka_enhanced.jpg" width="220" height="331"><p>


				Kanishka, Mathura art, Mathura Museum.


				</p><p>
					The rule of Kanishka the Great, fifth Kushan king, who flourished for about 13 years from c.&nbsp;127. Upon his accession, Kanishka ruled a huge territory (virtually all of northern India), south to Ujjain and Kundina and east beyond Pataliputra, according to the Rabatak inscription:</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/6/6d/Qila_Mubarak_in_Bathinda.jpg/220px-Qila_Mubarak_in_Bathinda.jpg" width="220" height="146"><p>


				The Qila Mubarak fort at Bathinda, India was built by Kanishka the Great.



				</p><p>
					In the year one, it has been proclaimed unto India, unto the whole realm of the governing class, including Koonadeano (Kaundiny, Kundina) and the city of Ozeno (Ozene, Ujjain) and the city of Zageda (Saketa) and the city of Kozambo (Kausambi) and the city of Palabotro (Pataliputra) and so long unto (i.e. as far as) the city of Ziri-tambo (Sri-Champa).</p><p>His territory was administered from two capitals: Purushapura (now Peshawar in northwestern Pakistan) and Mathura, in northern India. He is also credited (along with Raja Dab) for building the massive, ancient Fort at Bathinda (Qila Mubarak), in the modern city of Bathinda, Indian Punjab.</p><p>The Kushans also had a summer capital in Bagram (then known as Kapisa), where the Begram Treasure, comprising works of art from Greece to China, has been found. According to the Rabatak inscription, Kanishka was the son of Vima Kadphises, the grandson of Sadashkana, and the great-grandson of Kujula Kadphises. Kanishka’s era is now generally accepted to have begun in 127 on the basis of Harry Falk’s ground-breaking research.[45][46] Kanishka’s era was used as a calendar reference by the Kushans for about a century, until the decline of the Kushan realm.</p><h3>Vasishka (c. 140 – c. 160)</h3><p>Vasishka was a Kushan emperor who seems to have a 20-year reign following Kanishka. His rule is recorded as far south as Sanchi (near Vidisa), where several inscriptions in his name have been found, dated to the year 22 (The Sanchi inscription of Vaksushana – i.&nbsp;e. Vasishka Kushana) and year 28 (The Sanchi inscription of Vasaska – i.&nbsp;e. Vasishka) of the Kanishka era.</p><h3>Huvishka (c. 160 – c. 190)</h3><p>Huvishka (Kushan: ??????, Ooishki) was a Kushan emperor from about 20 years after the death of Kanishka (assumed on the best evidence available to be in 140) until the succession of Vasudeva I about thirty years later. His rule was a period of retrenchment and consolidation for the Empire. In particular he devoted time and effort early in his reign to the exertion of greater control over the city of Mathura.</p><h3>Vasudeva I (c. 190 – c. 230)</h3><p>Vasudeva I (Kushan: ?a??d?? Bazodeo, Chinese: ?? Bodiao) was the last of the Great Kushans. Named inscriptions dating from year 64 to 98 of Kanishka’s era suggest his reign extended from at least 191 to 225&nbsp;AD. He was the last great Kushan emperor, and the end of his rule coincides with the invasion of the Sasanians as far as northwestern India, and the establishment of the Indo-Sasanians or Kushanshahs in what is nowadays Afghanistan, Pakistan and northwestern India from around 240&nbsp;AD.</p><div class="gradientback"></div></div><div class="content"><h2>Kushan deities</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/6/6c/Kumara%2C_The_Divine_General_LACMA_M.85.279.3.jpg/220px-Kumara%2C_The_Divine_General_LACMA_M.85.279.3.jpg" width="220" height="328"><p>


				Kumara/Kartikeya with a Kushan devotee, 2nd century CE.



				<br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/e/ea/Gandhara%2C_omaggio_di_un_re_kushana_al_bodhisattva%2C_II-III_sec.JPG/220px-Gandhara%2C_omaggio_di_un_re_kushana_al_bodhisattva%2C_II-III_sec.JPG" width="220" height="170"><br>


				Kushan prince making a donation to a Boddhisattva.


				</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/e/ea/Gandhara%2C_omaggio_di_un_re_kushana_al_bodhisattva%2C_II-III_sec.JPG/220px-Gandhara%2C_omaggio_di_un_re_kushana_al_bodhisattva%2C_II-III_sec.JPG" width="220" height="170"><br><p>
					The Kushan religious pantheon is extremely varied, as revealed by their coins that were made in gold, silver, and copper. These coins contained more than thirty different gods, belonging mainly to their own Iranic, Greek, and Indo-Aryan worlds as well. Kushan coins had images of Kushan Kings, Buddha, and figures from the Indo-Aryan and Iranian pantheons.[47] Greek deities, with Greek names are represented on early coins. During Kanishka's reign, the language of the coinage changes to Bactrian (though it remained in Greek script for all kings). After Huvishka, only two divinities appear on the coins: Ardoxsho and Oesho (see details below).</p><p>The Iranic entities depicted on coinage include:</p><p>Representation of entities from Greek mythology and Hellenistic syncretism are:</p><p>The Indic entities represented on coinage include:</p><p>Additionally,</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/e/e0/Four_sets_of_Gold_Coins_of_Vima_Kadphises.jpg/510px-Four_sets_of_Gold_Coins_of_Vima_Kadphises.jpg" width="510" height="240"><p>


				Kushan coins showing half-length bust of Vima Kadphises in various poses, holding mace-scepter or laurel branch in right hand; flames at shoulder, tamgha to right or left. On the other side of coin is a deity with a bull. Some consider the deity as Shiva because he is in ithyphallic state, holds a trident, and the Nandi bull is his mount, as in Hindu mythology.[49][50][54] Others suggest him as Oesho, Zoroastrian Vayu.


				</p><h2>Kushans and Buddhism</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/8/8b/Kanishka-Inaugurates-Mahyana-Buddhism.jpg/170px-Kanishka-Inaugurates-Mahyana-Buddhism.jpg" width="170" height="229"><br><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/3/3c/BuddhistTriad.JPG/220px-BuddhistTriad.JPG" width="220" height="134"><br><p>
					The Kushans inherited the Greco-Buddhist traditions of the Indo-Greek Kingdom they replaced, and their patronage of Buddhist institutions allowed them to grow as a commercial power.[55] Between the mid-1st century and the mid-3rd century, Buddhism, patronized by the Kushans, extended to China and other Asian countries through the Silk Road.</p><p>Kanishka is renowned in Buddhist tradition for having convened a great Buddhist council in Kashmir. Along with his predecessor in the region the Indo-Greek king Menander I (Milinda) and the Indian emperors Ashoka and Harsha Vardhana, Kanishka is considered by Buddhism as one of its greatest benefactors.</p><p>During the 1st century AD, Buddhist books were being produced and carried by monks, and their trader patrons. Also, monasteries were being established along these land routes that went from China and other parts of Asia. With the development of Buddhist books, it caused a new written language called Gandhara. Gandhara consists of eastern Afghanistan and northern Pakistan. Scholars are said to have found many Buddhist scrolls that contained the Gandhari language.[56]</p><div class="gradientback"></div></div><div class="content"><p>The reign of Huvishka corresponds to the first known epigraphic evidence of the Buddha Amitabha, on the bottom part of a 2nd-century statue which has been found in Govindo-Nagar, and now at the Mathura Museum. The statue is dated to the 28th year of the reign of Huvishka, and dedicated to Amitabha Buddha by a family of merchants. There is also some evidence that Huvishka himself was a follower of Mahayana Buddhism. A Sanskrit manuscript fragment in the Schøyen Collection describes Huvishka as one who has set forth in the Mahayana.[57]</p><h3>Kushan art</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/7/7d/Taxila._Standing_Female._88.194.jpg/220px-Taxila._Standing_Female._88.194.jpg" width="220" height="295"><p>


				Standing Female, 1st century CE Terracotta. This lively female figure comes from an area of Pakistan where merchants from around the Mediterranean had long maintained trading posts. The area, known in antiquity as Gandhara, developed an unusual hybrid style of art and culture that was at once Hellenic and Indic. Brooklyn Museum


				</p><p>
					The art and culture of Gandhara, at the crossroads of the Kushan hegemony, continued the traditions of Greco-Buddhist art and are the best known expressions of Kushan influences to Westerners. Several direct depictions of Kushans are known from Gandhara, where they are represented with a tunic, belt and trousers and play the role of devotees to the Buddha, as well as the Bodhisattva and future Buddha Maitreya.</p><p>During the Kushan Empire, many images of Gandhara share a strong resemblance to the features of Greek, Syrian, Persian and Indian figures. These Western-looking stylistic signatures often include heavy drapery and curly hair,[58] representing a composite (the Greeks, for example, often possessed curly hair).</p><p>In the iconography, they are never associated however with the very Hellenistic Standing Buddha statues, which might therefore correspond to an earlier historical period.</p><h2>Contacts with Rome</h2><p> Main article: Roman trade with India</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/d/d8/BegramGladiator.JPG/150px-BegramGladiator.JPG" width="150" height="200"><p>


				Greco-Roman gladiator on a glass vessel, Begram, 2nd century


				</p><p>
					Several Roman sources describe the visit of ambassadors from the Kings of Bactria and India during the 2nd century, probably referring to the Kushans.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/c/ce/TrajanCoinAhinposhBuddhistMonasteryAfghanistan.jpg/130px-TrajanCoinAhinposhBuddhistMonasteryAfghanistan.jpg" width="130" height="133"><p>


				Coin of the Roman Emperor Trajan, found together with coins of Kanishka the Great at the Ahin Posh Monastery


				</p><p>
					Historia Augusta, speaking of Emperor Hadrian (117–138) tells:</p><p>Reges Bactrianorum legatos ad eum, amicitiae petendae causa, supplices miserunt</p><p>The kings of the Bactrians sent supplicant ambassadors to him, to seek his friendship.</p><p>Also in 138, according to Aurelius Victor (Epitome‚ XV, 4), and Appian (Praef., 7), Antoninus Pius, successor to Hadrian, received some Indian, Bactrian Hyrcanian ambassadors.</p><p>Precious things from Da Qin [the Roman Empire] can be found there [in Tianzhu or Northwestern India], as well as fine cotton cloths, fine wool carpets, perfumes of all sorts, sugar candy, pepper, ginger, and black salt.</p><p>The summer capital of the Kushan in Begram has yielded a considerable amount of goods imported from the Roman Empire, in particular, various types of glassware.</p><h2>Contacts with China</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/f/fc/KanishkaICoinFoundInKhotan.jpg/220px-KanishkaICoinFoundInKhotan.jpg" width="220" height="216"><p>


				A bronze coin of Kanishka the Great found in Khotan, Tarim Basin


				</p><div class="gradientback"></div></div><div class="content"><p>
					During the 1st and 2nd century, the Kushan Empire expanded militarily to the north and occupied parts of the Tarim Basin, their original grounds, putting them at the center of the profitable Central Asian commerce with the Roman Empire. They are related to have collaborated militarily with the Chinese against nomadic incursion, particularly when they collaborated with the Han Dynasty general Ban Chao against the Sogdians in 84, when the latter were trying to support a revolt by the king of Kashgar.[60] Around 85, they also assisted the Chinese general in an attack on Turpan, east of the Tarim Basin.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/d/dc/Lokaksema.jpg/140px-Lokaksema.jpg" width="140" height="237"><p>


				The Kushan Buddhist monk Lokaksema, first known translator of Buddhist Mahayana scriptures into Chinese, c. 170.


				</p><p>
					In recognition for their support to the Chinese, the Kushans requested a Han princess, but were denied,[60][61] even after they had sent presents to the Chinese court. In retaliation, they marched on Ban Chao in 86 with a force of 70,000, but were defeated by a smaller Chinese force.[60][61] The Yuezhi retreated and paid tribute to the Chinese Empire during the reign of emperor He of Han (89–106).</p><p>Later, around 116, the Kushans under Kanishka established a kingdom centered on Kashgar, also taking control of Khotan and Yarkand, which were Chinese dependencies in the Tarim Basin, modern Xinjiang. They introduced the Brahmi script, the Indian Prakrit language for administration, and expanded the influence of Greco-Buddhist art which developed into Serindian art.</p><p>The Kushans are again recorded to have sent presents to the Chinese court in 158–159 during the reign of emperor Huan of Han.</p><p>Following these interactions, cultural exchanges further increased, and Kushan Buddhist missionaries, such as Lokaksema, became active in the Chinese capital cities of Loyang and sometimes Nanjing, where they particularly distinguished themselves by their translation work. They were the first recorded promoters of Hinayana and Mahayana scriptures in China, greatly contributing to the Silk Road transmission of Buddhism.</p><h2>Decline</h2><p>After the death of Vasudeva I in 225, the Kushan empire split into western and eastern halves. The Western Kushans (in Afghanistan) were soon subjugated by the Persian Sasanian Empire and lost Bactria and other territories. In 248 they were defeated again by the Persians, who deposed the Western dynasty and replaced them with Persian vassals known as the Kushanshas (or Indo-Sasanians).</p><p>The Eastern Kushan kingdom was based in the Punjab. Around 270 their territories on the Gangetic plain became independent under local dynasties such as the Yaudheyas. Then in the mid-4th century they were subjugated by the Gupta Empire under Samudragupta.</p><p>In 360 a Kushan vassal named Kidara overthrew the old Kushan dynasty and established the Kidarite Kingdom. The Kushan style of Kidarite coins indicates they considered themselves Kushans. The Kidarite seem to have been rather prosperous, although on a smaller scale than their Kushan predecessors.</p><p>These remnants of the Kushan empire were ultimately wiped out in the 5th century by the invasions of the Hephthalites, and the rise of the Gupta empire.</p><h2>Rulers</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/5/53/KushanTamgas.gif/330px-KushanTamgas.gif" width="330" height="294"><p>


				Listing of Kushan royal tamgas.


				 

				 
				</p><h2>Notes</h2><li>^ From the dated inscription on the Rukhana reliquary</li><li>^ An Inscribed Silver Buddhist Reliquary of the Time of King Kharaosta and Prince Indravarman, Richard Salomon, Journal of the American Oriental Society, Vol. 116, No. 3 (Jul. - Sep., 1996), pp. 442 [4]</li><li>^ A Kharosthi Reliquary Inscription of the Time of the Apraca Prince Visnuvarma, by Richard Salomon, South Asian Studies 11 1995, Pages 27-32, Published online: 09 Aug 2010 [5]</li><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Kushan_Empire&amp;oldid=783229128"					
								Categories:  Hidden categories:</p><br><h1 lang="en">List of monarchs of Persia</h1><p>
					 From Wikipedia, the free encyclopedia</p><p>The following is a list of monarchs of Persia, who ruled over the area of modern-day Iran from the establishment of the Achaemenid dynasty by Cyrus the Great in 550 BC until the deposition of the Pahlavi dynasty in 1979.</p><p>Earlier monarchs in the area of modern-day Iran are listed in:</p><p>Minor dynasties and vassal monarchs can be found in:</p><h2>Contents</h2><div class="gradientback"></div></div><div class="content"><h2>Achaemenid dynasty (550–330 BC)</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/8/8a/Achaemenid_%28greatest_extent%29.svg/220px-Achaemenid_%28greatest_extent%29.svg.png" width="220" height="220"><p>


				Extent of the first Persian Empire, the Achaemenid Empire.


				 
				</p><h2>Argead (Macedonian) dynasty (330–309 BC)</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/b/bd/Macedonia_%28ancient_kingdom%2C_greatest_extent%29.svg/220px-Macedonia_%28ancient_kingdom%2C_greatest_extent%29.svg.png" width="220" height="220"><br><h2>Seleucid dynasty (311–129 BC)</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/9/91/Seleucid_Empire_%28greatest_extent%29.svg/220px-Seleucid_Empire_%28greatest_extent%29.svg.png" width="220" height="220"><br><h2>Parthian or Arsacid dynasty (247 BC – AD 228)</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/4/47/Parthian_Empire_%28greatest_extent%29.svg/220px-Parthian_Empire_%28greatest_extent%29.svg.png" width="220" height="220"><br><p>
					The Seleucid dynasty gradually lost control of Persia. In 253, the Arsacid dynasty established itself in Parthia. The Parthians gradually expanded their control, until by the mid-2nd century BC, the Seleucids had completely lost control of Persia. Control of eastern territories was permanently lost by Antiochus VII in 129 BC. For more comprehensive lists of kings, queens, sub-kings and sub-queens of this Era see:</p><h2>Sasanian dynasty (224–651)</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/3/33/Sasanian_Empire_%28greatest_extent%29.svg/220px-Sasanian_Empire_%28greatest_extent%29.svg.png" width="220" height="220"><p>


				Sasanian Empire at its greatest extent.


				 
				</p><h2>Dabuyid dynasty (642–760)</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/c/c4/Dabuyid_dynasty_%28greatest_extent%29.svg/220px-Dabuyid_dynasty_%28greatest_extent%29.svg.png" width="220" height="220"><br><p>
					beginning of Muslim conquest of Persia</p><h2>Rashidun Caliphate (642–661)</h2><div class="gradientback"></div></div><div class="content"><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/0/09/Rashidun_Caliphate_%28greatest_extent%29.svg/220px-Rashidun_Caliphate_%28greatest_extent%29.svg.png" width="220" height="220"><p>


				The Rashidun Empire reached its greatest extent under Caliph Uthman, in 654.


				</p><p>
					For more comprehensive lists of kings and sub-kings of this Era see:</p><h2>Umayyad Caliphate (661–750)</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/a/a0/Umayyad_Caliphate_%28greatest_extent%29.svg/220px-Umayyad_Caliphate_%28greatest_extent%29.svg.png" width="220" height="220"><p>


				Umayyad Caliphate at its greatest extent (AD 750).


				 
				</p><h2>Abbasid Caliphate (750–946)</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/2/21/Abbasid_Caliphate_%28greatest_extent%29.svg/220px-Abbasid_Caliphate_%28greatest_extent%29.svg.png" width="220" height="220"><br><h2>Samanid dynasty (819–999)</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/a/a6/Samanid_Empire_%28greatest_extent%29.svg/220px-Samanid_Empire_%28greatest_extent%29.svg.png" width="220" height="220"><br><h2>Saffarid dynasty (861–1003)</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/9/90/Saffarid_dynasty_%28greatest_extent%29.svg/220px-Saffarid_dynasty_%28greatest_extent%29.svg.png" width="220" height="220"><br><p>
					For more comprehensive lists of kings and sub-kings of this Era see:</p><h2>Ghurid dynasty (879–1215)</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/2/28/Ghurid_dynasty_%28greatest_extent%29.svg/220px-Ghurid_dynasty_%28greatest_extent%29.svg.png" width="220" height="220"><p>


				Map of the Ghurid dynasty at its greatest extent by the year 1202.


				</p><p>
					For more comprehensive lists of kings and sub-kings of this Era see:</p><h2>Buyid Clan and their dynasty (934–1062)</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/2/26/Buyid_Dynasty_%28greatest_extent%29.svg/220px-Buyid_Dynasty_%28greatest_extent%29.svg.png" width="220" height="220"><div class="gradientback"></div></div><div class="content"><p>


				Buyid Dynasty at its greatest extent.


				</p><p>
					The Buyid Empire was divided into a number of separate emirates, of which the most important were Fars, Ray, and Iraq. Generally, one of the emirs held a sort of primus inter pares supremacy over the rest, which would be marked by titles like Amir al-umara and Shahanshah. For more comprehensive lists of kings and sub-kings of this Era see:</p><h2>Ziyarid dynasty (928–1043)</h2><h2>Great Seljuqs and their Empire (1029–1194)</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/a/af/Seljuk_Empire_%28greatest_extent%29.svg/220px-Seljuk_Empire_%28greatest_extent%29.svg.png" width="220" height="220"><p>


				A map showing the Great Seljuk Empire at its height, upon the death of Malik Shah I in 1092.


				</p><p>
					For more comprehensive lists of kings and sub-kings of this Era see:</p><h2>Khwarezmid dynasty (1153–1231)</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/7/75/Khwarazmian_dynasty_%28greatest_extent%29.svg/220px-Khwarazmian_dynasty_%28greatest_extent%29.svg.png" width="220" height="220"><p>


				Khwarazmian Empire at its greatest extent.


				</p><p>
					An empire built from Khwarezm, covering part of Iran and neighbouring Central Asia. For more comprehensive lists of kings and sub-kings of this Era see:</p><h2>Mongol Empire and Ilkhanate (1230–1357)</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/2/2a/Mongol_Empire_%28greatest_extent%29.svg/220px-Mongol_Empire_%28greatest_extent%29.svg.png" width="220" height="220"><p>


				Mongol Empire at its greatest extent.



				<br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/f/fe/Ilkhanate_%28greatest_extent%29.svg/220px-Ilkhanate_%28greatest_extent%29.svg.png" width="220" height="220"><br>


				Ilkhanate at its greatest extent.


				</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/f/fe/Ilkhanate_%28greatest_extent%29.svg/220px-Ilkhanate_%28greatest_extent%29.svg.png" width="220" height="220"><br><p>
					For more comprehensive lists of kings and sub-kings of this Era see:</p><h2>Rival dynasties (1332–1501)</h2><p>For more comprehensive lists of kings and sub-kings of this Era see:</p><h3>Sarbadars (1332–1386)</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/0/03/Sarbadars_%28greatest_extent%29.svg/220px-Sarbadars_%28greatest_extent%29.svg.png" width="220" height="220"><p>


				Sarbadars in 1345


				 
				</p><div class="gradientback"></div></div><div class="content"><h3>Chupanids (1335–1357)</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/9/92/Chobanids.svg/220px-Chobanids.svg.png" width="220" height="220"><br><h3>Jalayirids (1335–1432)</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/0/06/Jalairid_Sultanate.svg/220px-Jalairid_Sultanate.svg.png" width="220" height="220"><br><h3>Injuids (1335–1357)</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/9/92/Injuids_%28greatest_extent%29.svg/220px-Injuids_%28greatest_extent%29.svg.png" width="220" height="220"><br><h3>Muzaffarids (1314–1393)</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/0/04/Muzaffarids_%28greatest_extent%29.svg/220px-Muzaffarids_%28greatest_extent%29.svg.png" width="220" height="220"><br><h3>Kara Koyunlu (1375–1468)</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/3/32/Qara_Qoyunlu_%28greatest_extent%29.svg/220px-Qara_Qoyunlu_%28greatest_extent%29.svg.png" width="220" height="220"><br><h3>Ak Koyunlu (1378–1497)</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/5/58/Ag_Qoyunlu_%28greatest_extent%29.svg/220px-Ag_Qoyunlu_%28greatest_extent%29.svg.png" width="220" height="220"><br><h3>Timurid dynasty (1370–1507)</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/5/51/Timurid_Empire_%28greatest_extent%29.svg/220px-Timurid_Empire_%28greatest_extent%29.svg.png" width="220" height="220">
				<div class="gradientback"></div></div><div class="content">
				<li>Mecca</li><li>Yemen</li><li>Kufa</li><li>Basra</li><li>Jazira</li><li>Fars</li><li>Azerbaijan</li><li>Khorasan</li><li>Syria</li><li>Egypt</li><li>North Africa</li><p>During Ali's reign, with the exception of Syria (which was under Muawiyah I's control) and Egypt (that he had lost during the latter years of his caliphate to the rebel troops of Amr ibn Al-A'as), the remaining ten provinces were under his control, which kept their administrative organizations as they were under Uthman.</p><p>The provinces were further divided into districts. Each of the 100 or more districts of the empire, along with the main cities, were administered by a governor (Wali). Other officers at the provincial level were:</p><li>Katib, the Chief Secretary.</li><li>Katib-ud-Diwan, the Military Secretary.</li><li>Sahib-ul-Kharaj, the Revenue Collector.</li><li>Sahib-ul-Ahdath, the Police chief.</li><li>Sahib-ul-Bait-ul-Mal, the Treasury Officer.</li><li>Qadi, the Chief Judge.</li><p>In some districts there were separate military officers, though the governor was in most cases the commander-in-chief of the army quartered in the province.</p><p>The officers were appointed by the Caliph. Every appointment was made in writing. At the time of appointment an instrument of instructions was issued with a view to regulating the conduct of Governors. On assuming office, the Governor was required to assemble the people in the main mosque, and read the instrument of instructions before them.[33]</p><p>Umar's general instructions to his officers were:</p><p>Remember, I have not appointed you as commanders and tyrants over the people. I have sent you as leaders instead, so that the people may follow your example. Give the Muslims their rights and do not beat them lest they become abused. Do not praise them unduly, lest they fall into the error of conceit. Do not keep your doors shut in their faces, lest the more powerful of them eat up the weaker ones. And do not behave as if you were superior to them, for that is tyranny over them.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/8/8f/Libya_4983_Tadrart_Acacus_Luca_Galuzzi_2007.jpg/220px-Libya_4983_Tadrart_Acacus_Luca_Galuzzi_2007.jpg" width="220" height="147"><p>


				Moving sand dunes in Tadrart Acacus


				</p><p>
					During the reign of Abu Bakr the state was economically weak, while during Umar’s reign because of increase in revenues and other sources of income, the state was on its way to economic prosperity. Hence Umar felt it necessary that the officers be treated in a strict way as to prevent the possible greed for money that may lead them to corruption. During his reign, at the time of appointment, every officer was required to make the oath:</p><li>That he would not ride a Turkic horse (which was a symbol of pride).</li><li>That he would not wear fine clothes.</li><li>That he would not eat sifted flour.</li><li>That he would not keep a porter at his door.</li><li>That he would always keep his door open to the public.</li><p>Caliph Umar himself followed the above postulates strictly. During the reign of Uthman the state become more economically prosperous than ever before; the allowance of the citizens was increased by 25% and the economical condition of the ordinary person was more stable, which lead Caliph Uthman to revoke the 2nd and 3rd postulates of the oath. At the time of appointment a complete inventory of all the possessions of the person concerned was prepared and kept in record. If there was an unusual increase in the possessions of the office holder, he was immediately called to account, and the unlawful property was confiscated by the State. The principal officers were required to come to Mecca on the occasion of the hajj, during which people were free to present any complaint against them. In order to minimize the chances of corruption, Umar made it a point to pay high salaries to the staff. Provincial governors received as much as five to seven thousand dirhams annually besides their share of the spoils of war (if they were also the commander-in-chief of the army of their sector).</p><h3>Judicial administration</h3><p>As most of the administrative structure of the Rashidun Empire was set up by Umar, the judicial administration was also established by him and the other Caliphs followed the same system without any type of basic amendment in it. In order to provide adequate and speedy justice for the people, an effective system of judicial administration was set up, hereunder justice was administered according to the principles of Islam.</p><p>Qadis (Judges) were appointed at all administrative levels for the administration of justice. The Qadis were chosen for their integrity and learning in Islamic law. High salaries were fixed for the Qadis so that there was no temptation to bribery. Wealthy men and men of high social status were appointed as Qadis so that they might not have the temptation to take bribes, or be influenced by the social position of any body. The Qadis were not allowed to engage in trade. Judges were appointed in sufficient number, and there was no district which did not have a Qadi.</p><h3>Electing or appointing a Caliph</h3><p>Fred Donner, in his book The Early Islamic Conquests (1981), argues that the standard Arabian practice during the early Caliphates was for the prominent men of a kinship group, or tribe, to gather after a leader's death and elect a leader from amongst themselves, although there was no specified procedure for this shura, or consultative assembly. Candidates were usually from the same lineage as the deceased leader, but they were not necessarily his sons. Capable men who would lead well were preferred over an ineffectual direct heir, as there was no basis in the majority Sunni view that the head of state or governor should be chosen based on lineage alone.</p><p>This argument is advanced by Sunni Muslims that Muhammad's companion Abu Bakr was elected by the community, and this was the proper procedure. They further argue that a caliph is ideally chosen by election or community consensus. The caliphate became a hereditary office or the prize of the strongest general after the Rashidun caliphate. However, Sunni Muslims believe this was after the 'rightly guided' caliphate ended (Rashidun caliphate).</p><p>Abu Bakr Al-Baqillani has said that the leader of the Muslims simply should be from the majority. Abu Hanifa an-Nu‘man also wrote that the leader must come from the majority.[34]</p><h3>Sunni belief</h3><div class="gradientback"></div></div><div class="content"><p>Following the death of Muhammad, a meeting took place at Saqifah. At that meeting, Abu Bakr was elected caliph by the Muslim community. Sunni Muslims developed the belief that the caliph is a temporal political ruler, appointed to rule within the bounds of Islamic law (The rules of life set by Allah in the Qur'an). The job of adjudicating orthodoxy and Islamic law was left to Islamic lawyers, judiciary, or specialists individually termed as Mujtahids and collectively named the Ulema. The first four caliphs are called the Rashidun, meaning the Rightly Guided Caliphs, because they are believed to have followed the Qur'an and the sunnah (example) of Muhammad in all things.</p><h3>Majlis al-Shura: Parliament</h3><p>Traditional Sunni Islamic lawyers agree that shura, loosely translated as “consultation of the people”, is a function of the caliphate. The Majlis al-Shura advise the caliph. The importance of this is premised by the following verses of the Qur'an:</p><p>... those who answer the call of their Lord and establish the prayer, and who conduct their affairs by Shura. [are loved by God][42:38]</p><p>... consult them (the people) in their affairs. Then when you have taken a decision (from them), put your trust in Allah[3:159]</p><p>The majlis is also the means to elect a new caliph. Al-Mawardi has written that members of the majlis should satisfy three conditions: they must be just, they must have enough knowledge to distinguish a good caliph from a bad one, and must have sufficient wisdom and judgment to select the best caliph. Al-Mawardi also said in emergencies when there is no caliphate and no majlis, the people themselves should create a majlis, select a list of candidates for caliph, then the majlis should select from the list of candidates.[34]</p><p>Some modern interpretations of the role of the Majlis al-Shura include those by Islamist author Sayyid Qutb and by Taqiuddin al-Nabhani, the founder of a transnational political movement devoted to the revival of the Caliphate. In an analysis of the shura chapter of the Qur'an, Qutb argued Islam requires only that the ruler consult with at least some of the ruled (usually the elite), within the general context of God-made laws that the ruler must execute. Taqiuddin al-Nabhani, writes that Shura is important and part of the ruling structure of the Islamic caliphate, but not one of its pillars, and may be neglected without the Caliphate's rule becoming unislamic. Non-Muslims may serve in the majlis, though they may not vote or serve as an official.</p><h3>Accountability of rulers</h3><p>Sunni Islamic lawyers have commented on when it is permissible to disobey, impeach or remove rulers in the Caliphate. This is usually when the rulers are not meeting public responsibilities obliged upon them under Islam.</p><p>Al-Mawardi said that if the rulers meet their Islamic responsibilities to the public, the people must obey their laws, but if they become either unjust or severely ineffective then the Caliph or ruler must be impeached via the Majlis al-Shura. Similarly Al-Baghdadi[clarification needed] believed that if the rulers do not uphold justice, the ummah via the majlis should give warning to them, and if unheeded then the Caliph can be impeached. Al-Juwayni argued that Islam is the goal of the ummah, so any ruler that deviates from this goal must be impeached. Al-Ghazali believed that oppression by a caliph is enough for impeachment. Rather than just relying on impeachment, Ibn Hajar al-Asqalani obliged rebellion upon the people if the caliph began to act with no regard for Islamic law. Ibn Hajar al-Asqalani said that to ignore such a situation is haraam, and those who cannot revolt inside the caliphate should launch a struggle from outside. Al-Asqalani used two ayahs from the Qur'an to justify this:</p><p>And they (the sinners on qiyama) will say, Our Lord! We obeyed our leaders and our chiefs, and they misled us from the right path. Our Lord! Give them (the leaders) double the punishment you give us and curse them with a very great curse ...[33:67–68]</p><p>Islamic lawyers commented that when the rulers refuse to step down via successful impeachment through the Majlis, becoming dictators through the support of a corrupt army, if the majority agree they have the option to launch a revolution against them. Many noted that this option is only exercised after factoring in the potential cost of life.[34]</p><h3>Rule of law</h3><p>The following hadith establishes the principle of rule of law in relation to nepotism and accountability[35]</p><p>Narrated ‘Aisha: The people of Quraish worried about the lady from Bani Makhzum who had committed theft. They asked, Who will intercede for her with Allah's Apostle? Some said, No one dare to do so except Usama bin Zaid the beloved one to Allah's Apostle. When Usama spoke about that to Allah's Apostle Allah's Apostle said: Do you try to intercede for somebody in a case connected with Allah’s Prescribed Punishments? Then he got up and delivered a sermon saying, What destroyed the nations preceding you, was that if a noble amongst them stole, they would forgive him, and if a poor person amongst them stole, they would inflict Allah's Legal punishment on him. By Allah, if Fatima, the daughter of Muhammad (my daughter) stole, I would cut off her hand.</p><p>Various Islamic lawyers do however place multiple conditions, and stipulations e.g. the poor cannot be penalised for stealing out of poverty, before executing such a law, making it very difficult to reach such a stage. It is well known during a time of drought in the Rashidun caliphate period, capital punishments were suspended until the effects of the drought passed.</p><p>Islamic jurists later formulated the concept of the rule of law, the equal subjection of all classes to the ordinary law of the land, where no person is above the law and where officials and pr<br>
							

											 
										

							</p><br><h1 lang="en">Abbasid Caliphate</h1><p> From Wikipedia, the free encyclopedia</p><p>The Abbasid Caliphate (/?'bæs?d/ or /'æb?s?d/ Arabic: ??????? ?????????? al-Khilafah al-‘Abbasiyah) was the third of the Islamic caliphates to succeed the Islamic prophet Muhammad. The Abbasid dynasty descended from Muhammad's youngest uncle, Al-Abbas ibn Abd al-Muttalib (566–653 CE), from whom the dynasty takes its name.[1] They ruled as caliphs, for most of their period from their capital in Baghdad in modern-day Iraq, after assuming authority over the Muslim empire from the Umayyads in 750 CE (132&nbsp;AH).</p><p>The Abbasid caliphate first centered its government in Kufa, but in 762 the caliph Al-Mansur founded the city of Baghdad, north of the Sasanian capital city of Ctesiphon. The choice of a capital so close to Persia proper reflected a growing reliance on Persian bureaucrats, most notably of the Barmakid family, to govern the territories conquered by Arab Muslims, as well as an increasing inclusion of non-Arab Muslims in the ummah. Persianate customs were broadly adopted by the Abbasid ruling elite.[2] Despite this initial cooperation, the Abbasids of the late 8th century had alienated both Arab mawali[3] and Iranian bureaucrats,[4] and were forced to cede authority over Al-Andalus and Maghreb to the Umayyads, Morocco to the Idrisid dynasty, Ifriqiya to the Aghlabids, and Egypt to the Shi'ite Caliphate of the Fatimids. The political power of the caliphs largely ended with the rise of the Buyids and the Seljuq Turks. Although Abbasid leadership over the vast Islamic empire was gradually reduced to a ceremonial religious function, the dynasty retained control over its Mesopotamian demesne. The capital city of Baghdad became a center of science, culture, philosophy and invention during the Golden Age of Islam.</p><p>This period of cultural fruition ended in 1258 with the sack of Baghdad by the Mongols under Hulagu Khan. The Abbasid line of rulers, and Muslim culture in general, recentered themselves in the Mamluk capital of Cairo in 1261. Though lacking in political power, the dynasty continued to claim authority in religious matters until after the Ottoman conquest of Egypt (1517).[5]</p><h2>Contents</h2><div class="gradientback"></div></div><div class="content"><h2>History</h2><h3>Abbasid Revolution (750–751)</h3><p> Main article: Abbasid Revolution</p><p>The Abbasid caliphs were Arabs descended from Abbas ibn Abd al-Muttalib, one of the youngest uncles of Muhammad and of the same Banu Hashim clan. The Abbasids claimed to be the true successors of Prophet Muhammad in replacing the Umayyad descendants of Banu Umayya by virtue of their closer bloodline to Muhammad.</p><p>The Abbasids also distinguished themselves from the Umayyads by attacking their moral character and administration in general. According to Ira Lapidus, The Abbasid revolt was supported largely by Arabs, mainly the aggrieved settlers of Marw with the addition of the Yemeni faction and their Mawali.[6] The Abbasids also appealed to non-Arab Muslims, known as mawali, who remained outside the kinship-based society of the Arabs and were perceived as a lower class within the Umayyad empire. Muhammad ibn 'Ali, a great-grandson of Abbas, began to campaign for the return of power to the family of Prophet Muhammad, the Hashimites, in Persia during the reign of Umar II.</p><p>During the reign of Marwan II, this opposition culminated in the rebellion of Ibrahim the Imam, the fourth in descent from Abbas. Supported by the province of Khorasan, Iran, even though the governor opposed them, and the Shi'i Arabs,[1][7] he achieved considerable success, but was captured in the year 747 and died, possibly assassinated, in prison.</p><p>On 9 June 747 (15 Ramadan AH 129), Abu Muslim successfully initiated an open revolt against Umayyad rule, which was carried out under the sign of the Black Standard. Close to 10,000 soldiers were under Abu Muslim's command when the hostilities officially began in Merv.[8] General Qahtaba followed the fleeing governor Nasr ibn Sayyar west defeating the Umayyads at the Battle of Nishapur (748), the Battle of Gorgan, the Battle of Nahavand (748) and finally in the Battle of Karbala (748).[7]</p><p>The quarrel was taken up by Ibrahim's brother Abdallah, known by the name of Abu al-'Abbas as-Saffah, who defeated the Umayyads in 750 in the Battle of the Zab near the Great Zab and was subsequently proclaimed caliph.[9] After this loss, Marwan fled to Egypt, where he was subsequently assassinated. The remainder of his family, barring one male, were also eliminated.[7]</p><p>Immediately after their victory, As-Saffah sent his forces to Central Asia, where his forces fought against Tang expansion during the Battle of Talas. Barmakids, who were instrumental in building Baghdad; introduced the world's first recorded paper mill in Baghdad, thus beginning a new era of intellectual rebirth in the Abbasid domain. As-Saffah focused on putting down numerous rebellions in Syria and Mesopotamia. The Byzantines conducted raids during these early distractions.[7]</p><h3>Power (752–775)</h3><p>The first change the Abbasids, under Al-Mansur, made was to move the empire's capital from Damascus, in Syria, to Baghdad in Iraq. This was to both appease as well to be closer to the Persian mawali support base that existed in this region more influenced by Persian history and culture, and part of the Persian mawali demand for less Arab dominance in the empire. Baghdad was established on the Tigris River in 762. A new position, that of the vizier, was also established to delegate central authority, and even greater authority was delegated to local emirs. Eventually, this meant that many Abbasid caliphs were relegated to a more ceremonial role than under the Umayyads, as the viziers began to exert greater influence, and the role of the old Arab aristocracy was slowly replaced by a Persian bureaucracy.[10] During Al-Mansur's time control of Al-Andalus was lost, and the Shiites revolted and were defeated a year later at the Battle of Bakhamra.[7]</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/e/e3/Abbasids_Baghdad_Iraq_765.jpg/170px-Abbasids_Baghdad_Iraq_765.jpg" width="170" height="175"><p>


				Coin of the Abbasids, Baghdad, Iraq, 765


				</p><p>
					The Abbasids had depended heavily on the support of Persians[1] in their overthrow of the Umayyads. Abu al-'Abbas' successor, Al-Mansur welcomed non-Arab Muslims to his court. While this helped integrate Arab and Persian cultures, it alienated many of their Arab supporters, particularly the Khorasanian Arabs who had supported them in their battles against the Umayyads.</p><p>These fissures in their support led to immediate problems. The Umayyads, while out of power, were not destroyed. The only surviving member of the Umayyad royal family, which had been all but annihilated, ultimately made his way to Spain where he established himself as an independent Emir (Abd ar-Rahman I, 756). In 929, Abd ar-Rahman III assumed the title of Caliph, establishing Al Andalus from Córdoba as a rival to Baghdad as the legitimate capital of the Islamic Empire.</p><p>In 756, the Abbasid Caliph Al-Mansur sent over 4,000 Arab mercenaries to assist the Chinese Tang dynasty in the An Shi Rebellion against An Lushan. The Abbasides or Black Flags, as they were commonly called, were known in Tang dynasty chronicles as the heiyi Dàshí,  The Black-robed Tazi, (????) (Tazi being a Tang dynasty borrowing from Persian to denote 'Arabs').[nb 1][nb 2][nb 3][nb 4][nb 5] Al-Rashid sent embassies to the Chinese Tang dynasty and established good relations with them.[16][nb 6][nb 7][19][20][21][22][23] After the war, these embassies remained in China [24][25][26][27][28] with Caliph Harun al-Rashid establishing an alliance with China.[16] Several embassies from the Abbasid Caliphs to the Chinese court have been recorded in the T'ang Annals, the most important of these being those of Abul Abbas al-Saffah, the founder of the Abbasid dynasty, Abu Jafar and Harun al-Rashid.</p><h3>Abbasid Golden Age (775–861)</h3><p>The Abbasid leadership had to work hard in the last half of the 8th century (750–800), under several competent caliphs and their viziers to overcome the political challenges created by the far flung nature of the empire, and the limited communication across it and usher in the administrative changes needed to keep order.[29] It was also during this early period of the dynasty, in particular during the governance of al-Mansur, Harun al-Rashid, and al-Ma'mun, that the reputation and power of the dynasty was created.[1] Al-Mahdi restarted the fighting with the Byzantines and his sons continued the conflict until Empress Irene pushed for peace.[7] After several years of peace, Nikephoros I broke the treaty, then fended off multiple incursions during the first decade of the 9th century. These attacks pushed into the Taurus Mountains culminating with a victory at the Battle of Krasos and the massive invasion of 806, led by Rashid himself. Rashid's navy also proved successful as he took Cyprus. Eventually, the momentum turned and much of the land gained was lost. Rashid decided to focus on the rebellion of Rafi ibn al-Layth in Khorasan and died while there.[30] While the Byzantine Empire was fighting Abbasid rule in Syria and Anatolia, military operations during this period were minimal, as the caliphate focused on internal matters, its governors exerting greater autonomy and using their increasing power to make their positions hereditary.[10]</p><p>At the same time, the Abbasids faced challenges closer to home. Harun al-Rashid turned on the Barmakids, a Persian family that had grown significantly in power within the administration of the state and killed most of the family.[31] During the same period, several factions began either to leave the empire for other lands or to take control of distant parts of the empire away from the Abbasids. The reign of al-Rashid and his sons were considered to be the apex of the Abbasids.[32] After Rashid's death, the empire was split by a civil war between the caliph al-Amin and his brother al-Ma'mun who had the support of Khorasan. This war ended with a two-year siege of Baghdad and the eventual death of al-Amin in 813.[30] Al-Ma'mun ruled for 20 years of relative calm interspersed with a rebellion supported by the Byzantines in Azerbaijan by the Khurramites. Al-Ma'mun was also responsible for the creation of an autonomous Khorasan, and the continued repulsing of Byzantine forays.[30] Al-Mu'tasim gained power in 833 and his rule marked the end of the strong caliphs. He strengthened his personal army with Turkish mercenaries and promptly restarted the war with the Byzantines. His military excursions were generally successful culminating with a resounding victory in the Sack of Amorium. His attempt at seizing Constantinople failed when his fleet was destroyed by a storm.[33] The Byzantines restarted the fighting by sacking Damietta in Egypt. Al-Mutawakkil responded by sending his troops into Anatolia again, sacking and marauding until they were eventually annihilated in 863.[34]</p><div class="gradientback"></div></div><div class="content"><h3>Fracture to autonomous dynasties (861–945)</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/4/49/TajikistanP19-100Somoni-1999%282000%29-donatedeh_f.jpg/250px-TajikistanP19-100Somoni-1999%282000%29-donatedeh_f.jpg" width="250" height="104"><p>


				Image of the Amir of Khorasan Isma'il ibn Ahmad on the Tajikistani somoni who exercised independent authority from the Abbassids


				</p><p>
					Even by 820, the Samanids had begun the process of exercising independent authority in Transoxiana and Greater Khorasan, as had the Shia Hamdanids in Northern Syria, and the succeeding Tahirid and Saffarid dynasties of Iran. The Saffarids, from Khorasan, nearly seized Baghdad in 876, and the Tulunids took control of most of Syria. The trend of weakening of the central power and strengthening of the minor caliphates on the periphery continued, except for the 10-year period of Al-Mu'tadid's rule. He brought parts of Egypt, Syria, and Khorasan back into the Abbasid's control. Especially after the Anarchy at Samarra, the Abbasid central government was weakened and centrifugal tendencies became more prominent in the Caliphate's provinces. By the early 10th century, the Abbasids almost lost control of Iraq to various amirs, and the caliph al-Radi was forced to acknowledge their power by creating the position of Prince of Princes (amir al-umara). Al-Mustakfi had a short reign from 944-946, and it was during this period that the Persian faction known as the Buyids from Daylam swept into power and assumed control over the bureaucracy in Baghdad. According to the history of Miskawayh, they began distributing iqtas (fiefs in the form of tax farms) to their supporters. This period of localized secular control was to last nearly 100 years.[1] The loss of Abbasid power to the Buyids would shift as the Seljuks would take over from the Persians.[32]</p><p>At the end of the eighth century the Abbasids found they could no longer keep a huge polity larger than that of Rome together from Baghdad. In 793 the Shi'ite dynasty of Idrisids set up a state from Fez in Morocco, while a family of governors under the Abbasids became increasingly independent until they founded the Aghlabid Emirate from the 830s. Al-Mu'tasim started the downward slide by utilizing non-Muslim mercenaries in his personal army. Also during this period officers started assassinating superiors with whom they disagreed, in particular the caliphs.[1] By the 870s Egypt became autonomous under Ahmad ibn Tulun. In the East as well, governors decreased their ties to the center. The Saffarids of Herat and the Samanids of Bukhara had broken away from the 870s, cultivating a much more Persianate culture and statecraft. By this time only the central lands of Mesopotamia were under direct Abbasid control, with Palestine and the Hijaz often managed by the Tulunids. Byzantium, for its part, had begun to push Arab Muslims farther east in Anatolia.</p><p>By the 920s, the situation had changed further, as North Africa was lost to the Abbasids. A Shi'ite sect only recognizing the first five Imams and tracing its roots to Muhammad's daughter Fatima took control of Idrisi and then Aghlabid domains.[32] Called the Fatimid dynasty, they had advanced to Egypt in 969, establishing their capital near Fustat in Cairo, which they built as a bastion of Shi'ite learning and politics. By 1000 they had become the chief political and ideological challenge to Sunni Islam in the form of the Abbasids. By this time the latter state had fragmented into several governorships that, while recognizing caliphal authority from Baghdad, did mostly as they wanted, fighting with each other. The Caliph himself was under 'protection' of the Buyid Emirs who possessed all of Iraq and western Iran, and were quietly Shi'ite in their sympathies.</p><p>Outside Iraq, all the autonomous provinces slowly took on the characteristic of de facto states with hereditary rulers, armies, and revenues and operated under only nominal caliph suzerainty, which may not necessarily be reflected by any contribution to the treasury, such as the Soomro Emirs that had gained control of Sindh and ruled the entire province from their capital of Mansura.[29] Mahmud of Ghazni took the title of sultan, as opposed to the amir that had been in more common usage, signifying the Ghaznavid Empire's independence from caliphal authority, despite Mahmud's ostentatious displays of Sunni orthodoxy and ritual submission to the caliph. In the 11th century, the loss of respect for the caliphs continued, as some Islamic rulers no longer mentioned the caliph's name in the Friday khutba, or struck it off their coinage.[29]</p><p>The Ismaili Fatimid dynasty of Cairo contested the Abbasids for even the titular authority of the Islamic ummah. They commanded some support in the Shia sections of Baghdad (such as Karkh), although Baghdad was the city most closely connected to the caliphate, even in the Buyid and Seljuq eras. The Fatimids' green banners contrasted with Abbasids' black, and the challenge of the Fatimids only ended with their downfall in the 12th century.</p><h3>Buyid and Seljuq military control (945–1118)</h3><p>Despite the power of the Buyid amirs, the Abbasids retained a highly ritualized court in Baghdad, as described by the Buyid bureaucrat Hilal al-Sabi', and they retained a certain influence over Baghdad as well as religious life. As Buyid power waned after the death of Baha' al-Daula, the caliphate was able to regain some measure of strength. The caliph al-Qadir, for example, led the ideological struggle against the Shia with writings such as the Baghdad Manifesto. The caliphs kept order in Baghdad itself, attempting to prevent the outbreak of fitnas in the capital, often contending with the ayyarun'</p><p>With the Buyid dynasty on the wane, a vacuum was created that was eventually filled by the dynasty of Oghuz Turks known as the Seljuqs. By 1055, the Seljuqs had wrested control from the Buyids and Abbasids, and took any remaining temporal power.[1] When the amir and former slave Basasiri took up the Shia Fatimid banner in Baghdad in, the caliph al-Qa'im was unable to defeat him without outside help. Toghril Beg, the Seljuq sultan, restored Baghdad to Sunni rule and took Iraq for his dynasty. Once again, the Abbasids were forced to deal with a military power that they could not match, though the Abbasid caliph remained the titular head of the Islamic community. The succeeding sultans Alp Arslan and Malikshah, as well as their vizier Nizam al-Mulk, took up residence in Persia, but held power over the Abbasids in Baghdad. When the dynasty began to weaken in the 12th century, the Abbasids gained greater independence once again.</p><h3>Revival of military strength (1118–1206)</h3><p>While the Caliph al-Mustarshid was the first caliph to build an army capable of meeting a Seljuk army in battle, he was nonetheless defeated in 1135 and assassinated. The Caliph al-Muqtafi was the first Abbasid Caliph to regain the full military independence of the Caliphate, with the help of his vizier Ibn Hubayra. After nearly 250 years of subjection to foreign dynasties, he successfully defended Baghdad against the Seljuqs in the siege of Baghdad (1157), thus securing Iraq for the Abbasids. The reign of al-Nasir (d. 1225) brought the caliphate back into power throughout Iraq, based in large part on the Sufi futuwwa organizations that the caliph headed.[32] Al-Mustansir built the Mustansiriya School, in an attempt to eclipse the Seljuq-era Nizamiyya built by Nizam al-Mulk.</p><h3>Mongol invasion (1206–1258)</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/3/3d/Baghdad_1258.jpg/220px-Baghdad_1258.jpg" width="220" height="281"><div class="gradientback"></div></div><div class="content"><p>


				Siege of Baghdad by the Mongols led by Hulagu Khan in 1258.


				</p><p>
					In 1206, Genghis Khan established a powerful dynasty among the Mongols of central Asia. During the 13th century, this Mongol Empire conquered most of the Eurasian land mass, including both China in the east and much of the old Islamic caliphate (as well as Kievan Rus') in the west. Hulagu Khan's destruction of Baghdad in 1258 is traditionally seen as the approximate end of the Golden Age.[35] Mongols feared that a supernatural disaster would strike if the blood of Al-Musta'sim, a direct descendant of Muhammad's uncle Al-‘Abbas ibn ‘Abd al-Muttalib,[36] and the last reigning Abbasid caliph in Baghdad, was spilled. The Shiites of Persia stated that no such calamity had happened after the deaths of Husayn ibn Ali; nevertheless, as a precaution and in accordance with a Mongol taboo which forbade spilling royal blood, Hulagu had Al-Musta'sim wrapped in a carpet and trampled to death by horses on 20 February 1258. The Caliph's immediate family was also executed, with the lone exceptions of his youngest son who was sent to Mongolia, and a daughter who became a slave in the harem of Hulagu.[37]</p><h3>Abbasid Caliphate of Cairo (1261–1517)</h3><p> Main article: Mamluk Sultanate (Cairo)</p><p>In the 9th century, the Abbasids created an army loyal only to their caliphate, composed of non-Arab origin people, known as Mamluks.[38][39][40][41][42] This force, created in the reign of al-Ma'mun (813–33) and his brother and successor al-Mu'tasim (833–42), prevented the further disintegration of the empire. The Mamluk army, though often viewed negatively, both helped and hurt the caliphate. Early on, it provided the government with a stable force to address domestic and foreign problems. However, creation of this foreign army and al-Mu'tasim's transfer of the capital from Baghdad to Samarra created a division between the caliphate and the peoples they claimed to rule. In addition, the power of the Mamluks steadily grew until al-Radi (934–41) was constrained to hand over most of the royal functions to Muhammad ibn Ra'iq.[9]</p><p>The Mamluks eventually came to power in Egypt. In 1261, following the devastation of Baghdad by the Mongols, the Mamluk rulers of Egypt re-established the Abbasid caliphate in Cairo. The first Abbasid caliph of Cairo was Al-Mustansir. The Abbasid caliphs in Egypt continued to maintain the presence of authority, but it was confined to religious matters.[citation needed] The Abbasid caliphate of Cairo lasted until the time of Al-Mutawakkil III, who was taken away as a prisoner by Selim I to Constantinople where he had a ceremonial role. He died in 1543, following his return to Cairo.[citation needed]</p><h2>Culture</h2><h3>Islamic Golden Age</h3><p> Main article: Islamic Golden Age</p><p> Further information: Early Islamic philosophy and Inventions in the Muslim world</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/8/8b/ManuscriptAbbasid.jpg/250px-ManuscriptAbbasid.jpg" width="250" height="180"><p>


				Manuscript from the Abbasid Era


				</p><p>
					The Abbasid historical period lasting to the Mongol conquest of Baghdad in 1258 CE is considered the Islamic Golden Age.[43] The Islamic Golden Age was inaugurated by the middle of the 8th century by the ascension of the Abbasid Caliphate and the transfer of the capital from Damascus to Baghdad.[44] The Abbassids were influenced by the Qur'anic injunctions and hadith such as the ink of a scholar is more holy than the blood of a martyr stressing the value of knowledge. During this period the Muslim world became an intellectual center for science, philosophy, medicine and education as [44] the Abbasids championed the cause of knowledge and established the House of Wisdom in Baghdad; where both Muslim and non-Muslim scholars sought to translate and gather all the world's knowledge into Arabic.[44] Many classic works of antiquity that would otherwise have been lost were translated into Arabic and Persian and later in turn translated into Turkish, Hebrew and Latin.[44] During this period the Muslim world was a cauldron of cultures which collected, synthesized and significantly advanced the knowledge gained from the ancient Roman, Chinese, Indian, Persian, Egyptian, North African, Greek and Byzantine civilizations.[44] In virtually every field of endeavor — in astronomy, alchemy, mathematics, medicine, optics and so forth — the Caliphate's scientists were in the forefront of scientific advance.[45]</p><h3>Science</h3><p> Main article: Science in the medieval Islamic world</p><p> Further information: Alchemy (Islam), Islamic astronomy, Islamic mathematics, Islamic medicine, and Timeline of science and technology in the Islamic world</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/9/9d/Mustansiriya_University_CPT.jpg/170px-Mustansiriya_University_CPT.jpg" width="170" height="227"><p>


				Mustansiriya University in Baghdad.



				<br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/0/04/Jabir_ibn_Hayyan.jpg/170px-Jabir_ibn_Hayyan.jpg" width="170" height="209"><br>


				Jabir ibn Hayyan, "the father of Chemistry".[46][47]



				<br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/6/63/Alhazen%2C_the_Persian.gif/170px-Alhazen%2C_the_Persian.gif" width="170" height="203"><br>


				Ibn al-Haytham, "the father of Optics".[48]


				</p><div class="gradientback"></div></div><div class="content"><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/0/04/Jabir_ibn_Hayyan.jpg/170px-Jabir_ibn_Hayyan.jpg" width="170" height="209"><br><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/6/63/Alhazen%2C_the_Persian.gif/170px-Alhazen%2C_the_Persian.gif" width="170" height="203"><br><p>
					The reigns of Harun al-Rashid (786–809) and his successors fostered an age of great intellectual achievement. In large part, this was the result of the schismatic forces that had undermined the Umayyad regime, which relied on the assertion of the superiority of Arab culture as part of its claim to legitimacy, and the Abbasids' welcoming of support from non-Arab Muslims. It is well established that the Abbasid caliphs modeled their administration on that of the Sassanids.[49] Harun al-Rashid's son, Al-Ma'mun (whose mother was Persian), is even quoted as saying:</p><p>The Persians ruled for a thousand years and did not need us Arabs even for a day. We have been ruling them for one or two centuries and cannot do without them for an hour.[50]</p><p>A number of medieval thinkers and scientists living under Islamic rule played a role in transmitting Islamic science to the Christian West. In addition, the period saw the recovery of much of the Alexandrian mathematical, geometric and astronomical knowledge, such as that of Euclid and Claudius Ptolemy. These recovered mathematical methods were later enhanced and developed by other Islamic scholars, notably by Persian scientists Al-Biruni and Abu Nasr Mansur.</p><p>Christians (particularly Nestorian Christians) contributed to the Arab Islamic Civilization during the Ummayads and the Abbasids by translating works of Greek philosophers to Syriac and afterwards to Arabic.[51][52] Nestorians played a prominent role in the formation of Arab culture,[53] with the Jundishapur school being prominent in the late Sassanid, Umayyad and early Abbasid periods.[54] Notably, eight generations of the Nestorian Bukhtishu family served as private doctors to caliphs and sultans between the eighth and eleventh centuries.[55][56]</p><p>Algebra was significantly developed by Persian scientist Muhammad ibn Musa al-Khwarizmi during this time in his landmark text, Kitab al-Jabr wa-l-Muqabala, from which the term algebra is derived. He is thus considered to be the father of algebra by some,[57] although the Greek mathematician Diophantus has also been given this title. The terms algorism and algorithm are derived from the name of al-Khwarizmi, who was also responsible for introducing the Arabic numerals and Hindu-Arabic numeral system beyond the Indian subcontinent.</p><p>Ibn al-Haytham (Alhazen) developed an early scientific method in his Book of Optics (1021). The most important development of the scientific method was the use of experiments to distinguish between competing scientific theories set within a generally empirical orientation, which began among Muslim scientists. Ibn al-Haytham's empirical proof of the intromission theory of light (that is, that light rays entered the eyes rather than being emitted by them) was particularly important. Alhazen was significant in the history of scientific method, particularly in his approach to experimentation,[58] and has been referred to as the world’s first true scientist.[59]</p><p>Medicine in medieval Islam was an area of science that advanced particularly during the Abbasids' reign. During the 9th century, Baghdad contained over 800 doctors, and great discoveries in the understanding of anatomy and diseases were made. The clinical distinction between measles and smallpox was described during this time. Famous Persian scientist Ibn Sina (known to the West as Avicenna) produced treatises and works that summarized the vast amount of knowledge that scientists had accumulated, and was very influential through his encyclopedias, The Canon of Medicine and The Book of Healing. The work of him and many others directly influenced the research of European scientists during the Renaissance.</p><p>Astronomy in medieval Islam was advanced by Al-Battani, who improved the precision of the measurement of the precession of the Earth's axis. The corrections made to the geocentric model by al-Battani,[citation needed] Averroes,[citation needed] Nasir al-Din al-Tusi, Mo'ayyeduddin Urdi and Ibn al-Shatir were later incorporated into the Copernican heliocentric model.[60] The astrolabe, though originally developed by the Greeks, was developed further by Islamic astronomers and engineers, and subsequently brought to medieval Europe.</p><p>Muslim alchemists influenced medieval European alchemists, particularly the writings attributed to Jabir ibn Hayyan (Geber). A number of chemical processes such as distillation techniques were developed in the Muslim world and then spread to Europe.</p><h3>Literature</h3><p> Main articles: Islamic literature, Arabic literature, Arabic epic literature, and Persian literature</p><p> Further information: Islamic poetry, Arabic poetry, Turkish poetry, and Persian poetry</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/4/44/Ali-Baba.jpg/220px-Ali-Baba.jpg" width="220" height="283"><p>


				Parrish, Maxfield, Ali Baba&nbsp;


				</p><p>
					The best known fiction from the Islamic world is The Book of One Thousand and One Nights, a collection of fantastical folk tales, legends and parables compiled primarily during the Abbassid era. The collection is recorded as having originated from an Arabic translation of a Sassanian era Persian prototype, with likely origins in Indian literary traditions. Stories from Arabic, Persian, Mesopotamian, and Egyptian folklore and literature were later incorporated. The epic is believed to have taken shape in the 10th century and reached its final form by the 14th century; the number and type of tales have varied from one manuscript to another.[61] All Arabian fantasy tales were often called Arabian Nights when translated into English, regardless of whether they appeared in The Book of One Thousand and One Nights.[61] This epic has been influential in the West since it was translated in the 18th century, first by Antoine Galland.[62] Many imitations were written, especially in France.[63] Various characters from this epic have themselves become cultural icons in Western culture, such as Aladdin, Sinbad and Ali Baba.</p><p>A famous example of Islamic poetry on romance was Layla and Majnun, which further developed mainly by Iranian, other poets in Persian,[64] dating back to the Umayyad era in the 7th century. It is a tragic story of undying love much like the later Romeo and Juliet.[citation needed]</p><div class="gradientback"></div></div><div class="content"><p>Arabic poetry reached its greatest height in the Abbasid era, especially before the loss of central authority and the rise of the Persianate dynasties. Writers like Abu Tammam and Abu Nuwas were closely connected to the caliphal court in Baghdad during the early 9th century, while others such as al-Mutanabbi received their patronage from regional courts.</p><h3>Philosophy</h3><p> Main articles: Islamic philosophy and Early Islamic philosophy</p><p> Further information: Logic in Islamic philosophy, Kalam, Avicennism, Averroism, Illuminationist philosophy, and Transcendent Theosophy</p><p>One of the common definitions for Islamic philosophy is the style of philosophy produced within the framework of Islamic culture.[65] Islamic philosophy, in this definition is neither necessarily concerned with religious issues, nor is exclusively produced by Muslims.[65] Their works on Aristotle was a key step in the transmission of learning from ancient Greeks to the Islamic world and the West. They often corrected the philosopher, encouraging a lively debate in the spirit of ijtihad. They also wrote influential original philosophical works, and their thinking was incorporated into Christian philosophy during the Middle Ages, notably by Thomas Aquinas.[citation needed]</p><p>Three speculative thinkers, al-Kindi, al-Farabi, and Avicenna, combined Aristotelianism and Neoplatonism with other ideas introduced through Islam, and Avicennism was later established as a result. Other influential Muslim philosophers in the Caliphates include al-Jahiz, and Ibn al-Haytham (Alhacen).</p><h3>Architecture</h3><p>As the power shifted from the Umayyads to the Abbasids, the architecture styles changed also. The Christian styles evolved into a style based more on the Sassanian empire utilizing mud bricks and baked bricks with carved stucco.[66] Another major development was the creation or vast enlargement of cities as they were turned into the capital of the empire. First, starting with the creation of Baghdad, starting in 762, which was planned as a walled city with a mosque and palace in the center. The walls were to have four gates to exit the city. Al-Mansur, who was responsible for the creation of Baghdad, also planned the city of Raqqa, along the Euphrates. Finally, in 836, al-Mu'tasim moved the capital to a new site that he created along the Tigris, called Samarra. This city saw 60 years of work, with race-courses and game preserves to add to the atmosphere.[66] Due to the dry remote nature of the environment, some of the palaces built in this era were isolated havens. Al-Ukhaidir Fortress is a fine example of this type of building which has stables, living quarters, and a mosque, all surrounding inner courtyards.[66] Other mosques of this era, such as the Mosque of Ibn Tulun, in Cairo, and the Great Mosque of Kairouan in Tunisia while ultimately built during the Umayyad dynasty, it was substantially renovated in the 9th century. This renovation was so extensive as to ostensibly be a rebuild, was in the furthest reaches of the Muslim world, in an area that the Aghlabids controlled; however the styles utilized were mainly of the Abbasids.[67] Mesopotamia only has one surviving mausoleum from this era, in Samarra. This octagonal dome is the final resting place of al-Muntasir.[68] Other architectural innovations and styles were few, such as the four-centered arch, and a dome erected on squinches. Unfortunately, much was lost due to the ephemeral nature of the stucco and luster tiles.[68]</p><h3>Glass and crystal</h3><p>The Near East has, since Roman times, been recognized as a center of quality glassware and crystal. 9th century finds from Samarra show styles similar to Sassanian forms. The types of objects made were bottles, flasks, vases, and cups utilized for domestic use. Decorations on these domestic items include molded flutes, honeycomb patters, and inscriptions.[69] Other styles seen that may not have come from the Sassanians were stamped items. These were typically round stamps, such as medallions or disks with animals, birds, or Kufic inscriptions. Colored lead glass, typically blue or green, have been found in Nishapur, along with prismatic perfume bottles. Finally, cut glass may have been the high point of Abbasid glass-working, decorated with floral and animal designs.[70]</p><h3>Painting</h3><p>Early Islamic painting has not survived in great quantities, and sometimes harder to differentiate; however Samarra is a good example as it was built by the Abbasids and abandoned 56 years later. The walls of the principal rooms of the palace that has been excavated show wall paintings and lively carved stucco dadoes. The style is obviously adopted with little variation from Sassanian art, as not only the styles is similar with harems, animals, and dancing people, all enclosed in scrollwork, but also the garments are Persian.[71] Nishapur had its own school of painting. Excavations at Nishapur show artwork both monochrome and polychrome from the 8th and 9th centuries. One famous piece of art consists of hunting nobles with falcons and on horseback, in full regalia, The clothing places him as Tahirid, which was again, a sub-dynasty of the Abbasids. Other styles are of vegetation, and fruit in nice colors on a four foot high dedo.[71]</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/5/5e/Bowl_with_Kufic_Inscription.jpg/220px-Bowl_with_Kufic_Inscription.jpg" width="220" height="165"><p>


				Bowl with Kufic Inscription, 9th century Brooklyn Museum


				</p><h3>Pottery</h3><p>
					Whereas painting and architecture were not areas of strength for the Abbasid dynasty, pottery was a different story. The Islamic culture as a whole and the Abbasid's, in particular, were at the forefront of new ideas and techniques. Some examples of their work were pieces engraved with decorations and then colored with yellow-brown, green, and purple glazes. Designs were diverse with geometric patterns, Kufic lettering, arabesque scrollwork, along with rosettes, animals, birds, and humans.[72] Abbasid pottery from the 8th and 9th centuries have been found throughout the region, as far as Cairo. These were generally made with a yellow clay and fired multiple times with separate glazes to produce metallic luster in shades of gold, brown, or red. By the 9th century, the potters had mastered their techniques and their decorative designs could be divided into two styles. The Persian style would show animals, birds, humans, along with Kufic lettering in gold. Pieces excavated from Samarra exceed in vibrancy and beauty any from later periods. These predominantly being made for the Caliphs use. Tiles were also made utilizing this same technique to create both monochromic and polychromic luster tiles.[73]</p><h3>Textiles</h3><p>Egypt being a center of the textile industry was part of the Abbasid cultural advancement. Copts were employed in the textile industry and produced linens and silks. Tinnis was famous for its factories and had over 5,000 looms. Kasab, a fine linen for turbans and badana for garments of the upper class to name a couple. In a town named Tuna near Tinnis, was made the kiswah for the kaaba in Mecca. Fine silk was also made in Dabik and Damietta.[74] Of particular interest is the stamped and inscribed fabrics. Not only did they utilize inks but also liquid gold. Some of the finer pieces were colored in such a manner as to require six separate stamps to achieve the proper design and color. This technology spread to Europe eventually.[75]</p><h3>Technology</h3><p> Main articles: Inventions in medieval Islam, Muslim Agricultural Revolution, and Timeline of Islamic science and technology</p><div class="gradientback"></div></div><div class="content"><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/6/6f/Abbasids_Baghdad_Iraq_1244.JPG/220px-Abbasids_Baghdad_Iraq_1244.JPG" width="220" height="224"><p>


				Coin of the Abbasids, Baghdad, Iraq, 1244


				</p><p>
					In technology, the Muslim world adopted papermaking from China.[76] The use of paper spread from China into the Muslim world in the 8th century CE, arriving in Spain (and then the rest of Europe) in the 10th century. It was easier to manufacture than parchment, less likely to crack than papyrus, and could absorb ink, making it ideal for making records and making copies of the Koran. Islamic paper makers devised assembly-line methods of hand-copying manuscripts to turn out editions far larger than any available in Europe for centuries.[77] It was from Islam that the rest of the world learned to make paper from linen.[78] The knowledge of gunpowder was also transmitted from China via Islamic countries, where the formulas for pure potassium nitrate and an explosive gunpowder effect were first developed.[79]</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/en/b/b9/Al-Mu%27tamid-coin.jpg" width="207" height="373"><p>Advances were made in irrigation and farming, using new technology such as the windmill. Crops such as almonds and citrus fruit were brought to Europe through al-Andalus, and sugar cultivation was gradually adopted by the Europeans. Apart from the Nile, Tigris and Euphrates, navigable rivers were uncommon, so transport by sea was very important. Navigational sciences were highly developed, making use of a rudimentary sextant (known as a kamal). When combined with detailed maps of the period, sailors were able to sail across oceans rather than skirt along the coast. Muslim sailors were also responsible for reintroducing large three masted merchant vessels to the Mediterranean. The name caravel may derive from an earlier Arab ship known as the qarib.[80] Arab merchants dominated trade in the Indian Ocean until the arrival of the Portuguese in the 16th century. Hormuz was an important center for this trade. There was also a dense network of trade routes in the Mediterranean, along which Muslim countries traded with each other and with European powers such as Venice, Genoa and Catalonia. The Silk Road crossing Central Asia passed through Muslim states between China and Europe.</p><p>Muslim engineers in the Islamic world made a number of innovative industrial uses of hydropower, and early industrial uses of tidal power, wind power, and petroleum (notably by distillation into kerosene). The industrial uses of watermills in the Islamic world date back to the 7th century, while horizontal-wheeled and vertical-wheeled water mills were both in widespread use since at least the 9th century. By the time of the Crusades, every province throughout the Islamic world had mills in operation, from al-Andalus and North Africa to the Middle East and Central Asia. These mills performed a variety of agricultural and industrial tasks.[76] Muslim engineers also developed machines (such as pumps) incorporating crankshafts, employed gears in mills and water-raising machines, and used dams to provide additional power to watermills and water-raising machines.[81] Such advances made it possible for many industrial tasks that were previously driven by manual labour in ancient times to be mechanized and driven by machinery instead in the medieval Islamic world. It has been argued that the industrial use of waterpower had spread from Islamic to Christian Spain, where fulling mills, paper mills, and forge mills were recorded for the first time in Catalonia.[82]</p><p>A number of industries were generated during the Arab Agricultural Revolution, including early industries for textiles, sugar, rope-making, matting, silk, and paper. Latin translations of the 12th century passed on knowledge of chemistry and instrument making in particular.[83] The agricultural and handicraft industries also experienced high levels of growth during this period.[84]</p><h3>Status of women</h3><p>In contrast to the earlier era, women in Abbasid society were absent from all arenas of the community's central affairs.[85] While their Muslim forbearers led men into battle, started rebellions, and played an active role in community life, as demonstrated in the Hadith literature, Abbasid women were ideally kept in seclusion. Conquests had brought enormous wealth and large numbers of slaves to the Muslim elite. The majority of the slaves were women and children,[86] many of whom had been dependents or harem-members of the defeated Sassanian upper classes.[87] In the wake of the conquests an elite man could potentially own a thousand slaves, and ordinary soldiers could have ten people serving them.[86]</p><p>Nabia Abbott, preeminent historian of elite women of the Abbasid Caliphate, describes the lives of harem women as follows.</p><p>The choicest women were imprisoned behind heavy curtains and locked doors, the strings and keys of which were entrusted into the hands of that pitiable creature – the eunuch. As the size of the harem grew, men indulged to satiety. Satiety within the individual harem meant boredom for the one man and neglect for the many women. Under these conditions ... satisfaction by perverse and unnatural means crept into society, particularly in its upper classes.[87]</p><p>The marketing of human beings, particularly women, as objects for sexual use meant that elite men owned the vast majority of women they interacted with, and related to them as would masters to slaves.[88] Being a slave meant relative lack of autonomy during this time period, and belonging to a harem caused a wife and her children to have little insurance of stability and continued support due to the volatile politics of harem life.</p><p>Elite men expressed in literature the horror they felt for the humiliation and degradation of their daughters and female relatives. For example, the verses addressed to Hasan ibn al-Firat on the death of his daughter read:</p><p>Even so, courtesans and princesses produced prestigious and important poetry. Enough survives to give us access to women's historical experiences, and reveals some vivacious and powerful figures, such as the Sufi mystic Raabi'a al-Adwiyya (714–801 CE), the princess and poet 'Ulayya bint al-Mahdi (777–825 CE), and the singing-girls Shariyah (c.?815-70 CE), Fadl Ashsha'ira (d. 871 CE) and Arib al-Ma'muniyya (797–890 CE).[90]</p><div class="gradientback"></div></div><div class="content"><h2>Evolution of Islamic identity</h2><p>While the Abbasids originally gained power by exploiting the social inequalities against non-Arabs in the Umayyad Empire, ironically during Abbasid rule the empire rapidly Arabized. As knowledge was shared in the Arabic language throughout the empire, people of different nationalities and religions began to speak Arabic in their everyday lives. Resources from other languages began to be translated into Arabic, and a unique Islamic identity began to form that fused previous cultures with Arab culture, creating a level of civilization and knowledge that was considered a marvel in Europe.[91]</p><h2>Decline of the empire</h2><p>Abbasids found themselves at odds with the Shia Muslims, most of whom had supported their war against the Umayyads, since the Abbasids and the Shias claimed legitimacy by their familial connection to Prophet Muhammad. Once in power, the Abbasids embraced Sunni Islam and disavowed any support for Shi'a beliefs. Shortly thereafter, Berber Kharijites set up an independent state in North Africa in 801. Within 50 years the Idrisids in the Maghreb and Aghlabids of Ifriqiya and a little later the Tulunids and Ikshidids of Misr were effectively independent in Africa. The Abbasid authority began to deteriorate during the reign of al-Radi when their Turkic Army generals, who already had de facto independence, stopped paying the Caliphate. Even provinces close to Baghdad began to seek local dynastic rule. Also, the Abbasids found themselves to often be at conflict with the Umayyads in Spain. The Abbasid financial position weakened as well, with tax revenues from the Sawad decreasing in the 9th and 10th centuries.[92]</p><h2>Separatist dynasties and their successors</h2><p>The Abbasid Caliphate differed from others in that it did not have the same borders and extent as Islam. Particularly, in the west of the Caliphate, there were multiple smaller caliphates that existed in relative peace with them.[1] This list represents the succession of Islamic dynasties that emerged from the fractured Abbasid empire by their general geographic location. Dynasties often overlap, where a vassal emir revolted from and later conquered his lord. Gaps appear during periods of contest where the dominating power was unclear. Except for the Fatimid Caliphate in Egypt, recognizing a Shi'ite succession through Ali, and the Andalusian Caliphates of the Umayyads and Almohads, every Muslim dynasty at least acknowledged the nominal suzerainty of the Abbasids as Caliph and Commander of the Faithful.</p><h2>Abbasid Khanate of Bastak</h2><p>In 656 AH/1258 CE, the year of the fall of Baghdad, and following the sack of the city, a few surviving members of the Abbasid dynastic family led by the eldest amongst them, Ismail II son of Hamza son of Ahmed son of Mohamed,[nb 8] made their way into the region of Fars in Southern Persia.[94] They settled in the city of Khonj, then a great centre for learning and scholarship. Shaikh Abdulsalam Khonji (b. 661 AH – d. 746 AH) son of Abbas son of Ismail II was born in Khonj only five years after the fall of Baghdad and the arrival of his grandfather in the city.[95][96] He became a great religious scholar and Sufi saint, held in high esteem by the local populace. His tomb still stands in Khonj and is a site visited by people from near and far.</p><p>The descendants of Shaikh Abdulsalam Khonji were religious scholars and figures of great respect and repute for generation after generation. One such scholar and direct descendant of Shaikh Abdulsalam Khonji in the male line, Shaikh Mohamed (d. around 905 AH) son of Shaikh Jaber son of Shaikh Ismail IV, moved to Bastak.[93][page&nbsp;needed] His grandson, Shaikh Mohamed the Elder (d. 950 or 975 AH) son of Shaikh Nasser al-Din Ahmed son of Shaikh Mohamed, settled in Khonj for a time. But in 938 AH, in response to growing Safavid power, Shaikh Mohamed the Elder moved permanently to Bastak as his grandfather had done.[97] His own grandson, Shaikh Hassan (d. 1084 AH) (also called Mulla Hassan) son of Shaikh Mohamed the Younger son of Shaikh Mohamed the Elder, is the common ancestor of all the Abbasids of Bastak and its neighbouring areas.[98]</p><p>Shaikh Hassan’s grandsons, Shaikh Mohamed Saeed (b. 1096 AH – d. 1152 AH) and Shaikh Mohamed Khan (b. 1113 AH – d. 1197 AH) son of Shaikh Abdulqader son of Shaikh Hassan, became the first two Abbasid rulers of the region. In 1137 AH, Shaikh Mohamed Saeed began gathering support for an armed force. Following the capture of Lar, he ruled the city and its dependencies for 12 or 14 years before dying in 1152 AH.[99]</p><p>Shaikh Mohamed Khan Bastaki, his brother, was meanwhile the ruler of Bastak and the region of Jahangiriyeh. In 1161 AH, Shaikh Mohamed Khan Bastaki departed for Didehban Fortress, leaving Bastak and its dependencies in the hands of his eldest son Shaikh Mohamed Sadeq and his cousin Agha Hassan Khan son of Mulla Ismail.[100] Shaikh Mohamed Khan ruled Jahangiriyeh from Didehban Fortress for a period of roughly 20 to 24 years, for which reason he has been referred to as Shaikh Mohamed Didehban.[101] He eventually returned to Bastak and continued to reign from there up to the time of his death. At the height of his rule, the Khanate of Bastak included not only the region of Jahangiriyeh, but its power also extended to Lar and Bandar Abbas as well as their dependencies, not to mention several islands in the Persian Gulf.[102][103][104][105][106]</p><p>Shaikh Mohamed Khan Bastaki was the first Abbasid ruler of Bastak to hold the title of Khan (Persian: ???, Arabic: ??????), meaning ruler or king, which was bestowed upon him by Karim Khan Zand.[103] The title then became that of all the subsequent Abbasid rulers of Bastak and Jahangiriyeh, and also collectively refers in plural form – i.e., Khans (Persian: ??????) - to the descendants of Shaikh Mohamed Khan Bastaki.</p><p>The last Abbasid ruler of Bastak and Jahangiriyeh was Mohamed A’zam Khan Baniabbassian son of Mohamed Reza Khan Satvat al-Mamalek Baniabbasi. He authored the book Tarikh-e Jahangiriyeh va Baniabbassian-e Bastak (1960),[107] in which is recounted the history of the region and the Abbasid family that ruled it. Mohamed A’zam Khan Baniabbassian died in 1967, a year regarded as marking the end of the Abbasid reign in Bastak.</p><h2>Footnotes</h2><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Abbasid_Caliphate&amp;oldid=784019513"					
								Categories:  Hidden categories:</p><br><h1 lang="en">Buyid dynasty</h1><p> From Wikipedia, the free encyclopedia</p><p>The Buyid dynasty or the Buyids (Persian: ?? ?????? Al-e Buye), also known as Buwaihids, Bowayhids, Buyahids, or Buyyids, was an Iranian Shia dynasty[3] of Daylamite origin.[4] Coupled with the rise of other Iranian dynasties in the region, the approximate century of Buyid rule represents the period in Iranian history sometimes called the 'Iranian Intermezzo' since, after the Muslim conquest of Persia, it was an interlude between the rule of the Abbasid Caliphate and the Seljuk Empire.[5]</p><p>The Buyid dynasty was founded by 'Ali ibn Buya, who in 934 conquered Fars and made Shiraz his capital, while his younger brother Hasan ibn Buya conquered parts of Jibal in the late 930s, and by 943 managed to capture Ray, which he made his capital. In 945, the youngest brother, Ahmad ibn Buya, conquered Iraq and made Baghdad his capital, receiving the honorific title of Mu'izz al-Dawla (Fortifier of the State), while 'Ali was given the title of 'Imad al-Dawla (Support of the State), and Hasan was given the title of Rukn al-Dawla (Pillar of the State).</p><p>As Daylamite Iranians the Buyids consciously revived symbols and practices of Persia's Sassanid dynasty.[6] In fact, beginning with 'Adud al-Dawla they used the ancient Sassanid title Shahanshah (Persian: ?????????), literally king of kings.[7][8]</p><p>At its greatest extent, the Buyid dynasty encompassed most of today's Iran, Iraq, Kuwait, and Syria, along with parts of Oman, the UAE, Turkey, Afghanistan and Pakistan. During the 10th and 11th centuries, just prior to the invasion of the Seljuq Turks, the Buyids were the most influential dynasty in the Middle East,[9] and under king 'Adud al-Dawla, became one of the most powerful Muslim dynasties.[10]</p><div class="gradientback"></div></div><div class="content"><h2>Contents</h2><h2>Origins</h2><p>The word Buya (Arabic Buwayh) is a Middle Persian name ending in the diminutive ???? (Middle Persian -oe, modern Persian -uya, Arabic -uwayh). The Buyids were descendants of Panah-Khusrau, a Zoroastrian from Daylam. He had a son named Buya, who was a fisherman from Lahijan,[11] and later left Zoroastrianism and converted to Islam.[12]:274 Buya later had three sons named Ahmad, 'Ali, and Hasan, who would later carve the Buyid kingdom together. Most historians agree that the Buyids were Daylamites.[12]:251–52[13][14][15][16][17][18][19] The Buyids claimed royal lineage from Bahram V, 15th king of the Sasanian Empire.[20]</p><h2>History</h2><h3>Rise (934-945)</h3><p>The founder of the dynasty, 'Ali ibn Buya, was originally a soldier in the service of the Daylamite warlord Makan ibn Kaki,[21] but later changed his adherence to the Iranian ruler Mardavij, who had established the Ziyarid dynasty, and was himself related to the ruling dynasty of Gilan,[22] a region bordering Dailam. 'Ali was later joined by his two younger brothers, Hasan ibn Buya and Ahmad ibn Buya. In 932, 'Ali was given Karaj as his fief, and thus was able to enlist other Daylamites into his own army. However, 'Ali's independent actions made Mardavij plan to have him killed, but fortunately for 'Ali, he was informed of Mardavij's plan by the latter's own vizier. The Buyids brother, with 400 of their Daylamite supporters, then fled to Fars,[23] where they managed to take control of Arrajan.[24] However, the Buyids and the Abbasid general Yaqut shortly came into a struggle for the control of Fars, which the Buyids eventually emerged victorious in.[21] This victory opened the way for the conquest of the capital of Fars, Shiraz.[25]</p><p>'Ali also made an alliance with the landowners of Fars, which included the Fasanjas family, which would later produce many prominent statesmen for the Buyids. Furthermore, 'Ali also to enlist more soldiers, which included the Turks, who were made part of cavalry. 'Ali then sent his brother Ahmad on an expedition to Kirman, but was forced to withdraw from them after opposition from the Baloch people and the Qafs.[26] However, Mardavij, who sought to depose the Abbasid caliph of Baghdad and recreate a Zoroastrian Iranian Empire, shortly wrested Khuzestan from the Abbasids and forced 'Ali to recognize him as his suzerain.[27]</p><p>Luckily for the Buyids, Mardavij was shortly assassinated in 935, which caused chaos in the Ziyarid territories, a perfect situation for the Buyid brothers; Ali and Ahmad conquered Khuzistan, while Hasan captured the Ziyarid capital of Isfahan, and in 943 captured Rey, which became his capital, thus conquering all of Jibal. In 945, Ahmad entered Iraq and made the Abbasid Caliph his vassal, at the same receiving the laqab Mu'izz ad-Dawla (Fortifier of the State), while 'Ali was given the laqab Imad ad-Dawla (Support of the State), and Hasan was given the laqab Rukn ad-Dawla (Pillar of the State).</p><h3>Height of power and Golden age (945-983)</h3><p>In addition to the other territories the Buyids had conquered, Kirman was conquered in 967, Oman (967), the Jazira (979), Tabaristan (980), and Gorgan (981). After this, however, the Buyids went into a slow decline, with pieces of the confederation gradually breaking off and local dynasties under their rule becoming de facto independent.</p><h3>Decline and fall (983–1048)</h3><p>The death of Adud al-Dawla is considered the starting point of the decline of the Buyid dynasty;[28] his son Abu Kalijar Marzuban, who was in Baghdad at the time of his death, first kept his death secret in order to ensure his succession and avoid civil war. When he made the death of his father public, he was given the title of Samsam al-Dawla. However, Adud's other son, Shirdil Abu'l-Fawaris, challenged the authority of Samsam al-Dawla, resulting in a civil war.[29] Meanwhile, a Marwanid chieftain named Badh, seized Diyabakr and forced Samsam al-Dawla to recognize him as the vassal ruler of the region.[29] Furthermore, Mu'ayyad al-Dawla also died during this period, and he was succeeded by Fakhr al-Dawla, who with the aid of Mu'ayyad al-Dawla's vizier Sahib ibn 'Abbad became the ruler of Mu'ayyad al-Dawla's possessions.[30] Another son of Adud al-Dawla, Abu Tahir Firuzshah, established himself as the ruler of Basra and took the title of Diya' al-Dawla, while another son, Abu'l-Husain Ahmad, established himself as the ruler of Khuzistan, taking the title of Taj al-Dawla.</p><p>Shirdil Abu'l-Fawaris (known by his title of Sharaf al-Dawla) quickly seized Oman from Samsam al-Dawla, and in 983, the Turkic troops of Samsam al-Dawla mutinied against him, and left Iraq for Fars, but most of them were persuaded by his relative Ziyar ibn Shahrakawayh to stay in Iraq. However, unfortunately for Samsam al-Dawla, Iraq was in grim affairs, and several rebellions occurred, which he however, managed to suppress, the most dangerous rebellion being under Asfar ibn Kurdawayh, who tried to make Abu Nasr Firuz Kharshadh (known by his title of Baha' al-Dawla) the ruler of Iraq. During the same period, Samsam al-Dawla also managed to seize Basra and Khuzistan, forcing his two brothers to flee to Fakhr al-Dawla's territory.</p><p>During the mid-11th century, the Buyid amirates gradually fell to the Ghaznavid and Seljuq Turks. In 1029, Majd al-Dawla, who was facing an uprising by his Dailami troops in Ray, requested assistance from Mahmud of Ghazna.[31] When Sultan Mahmud arrived, he deposed Majd al-Dawla, replaced him with a Ghaznavid governor and ended the Buyid dynasty in Ray.[32][33]</p><p>In 1055, Tughrul conquered Baghdad, the seat of the caliphate, and ousted the last of the Buyid rulers.[34] Like the Buyids, the Seljuqs kept the Abbasid caliphate as the titular ruler.[35]</p><h2>Government</h2><p>The Buyids established a confederation in Iraq and western Iran. This confederation formed three principalities - one in Fars, with Shiraz as its capital - the second one in Jibal, with Ray as its capital - and the last one in Iraq, with Baghdad as its capital. However, during their late period, more principalities formed in the Buyid confederation. Succession of power was hereditary, with fathers dividing their land among their sons.</p><p>The title used by the Buyid rulers was amir, meaning governor or prince. Generally one of the amirs would be recognized as having seniority over the others; this individual would use the title of amir al-umara,[8] or senior amir. Although the senior amir was the formal head of the Buyids, he did not usually have any significant control outside of his own personal amirate; each amir enjoyed a high degree of autonomy within his own territories. As mentioned above, some of the stronger amirs used the Sassanid title of Shahanshah. Furthermore, several other titles such as malik (king), and malik al-muluk (king of kings), were also used by the Buyids. On a smaller scale, the Buyid territory was also be ruled by princes from other families, such as the Hasanwayhids.</p><h3>Military</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/a/a1/Daylamite_infantryman.jpg/220px-Daylamite_infantryman.jpg" width="220" height="368"><div class="gradientback"></div></div><div class="content"><p>


				Artistic rendering of a Daylamite Buyid infantryman.


				</p><p>
					During the beginning of the Buyid dynasty, their army consisted mainly of their fellow Daylamites, a warlike and brave people of mostly peasant origin, who served as foot soldiers. The Daylamites had a long history of military activity dating back to the Sasanian period, and had been mercenaries in various places in Iran and Iraq, and even as far as Egypt. The Daylamites, during a battle, normally bore a sword, a shield, and three spears. Furthermore, they were also known for their formidable shield formation, which was hard to break through.[36]</p><p>But when the Buyid territories increased, they began recruiting Turks into their cavalry,[25] who had played a prominent role in the Abbasid military.[37] The Buyid army also consisted of Kurds, who, along with the Turks, were Sunnis, while the Daylamites were Shi'i Muslims.[38] However, the army of the Buyids of Jibal mainly composed of Daylamites.[39]</p><p>The Daylamites and Turks often quarreled with each other in an attempt to be the dominant force within the army.[40] To compensate their soldiers the Buyid amirs often distributed iqta?s, or the rights to a percentage of tax revenues from a province (tax farming), although the practice of payment in kind was also frequently used.[41] While the Turks were favored in Buyid Iraq, the Daylamites were favored in Buyid Iran.[42]</p><h2>Religion</h2><p>Like most Daylamites at the time, the Buyids were Shia and have been called Twelvers. However, it is more likely that they began as Zaydis.[43][44] As the reason of this turning from Zaydism to Twelverism, Moojen Momen suggests that since the Buyids were not descendants of Ali, the first Shi'i Imam, Zaydism would have urged them to install an Imam from Ali's family. For that reason Buyids tended toward Twelverism, which has an occulted Imam, which was more politically attractive to them.[43]</p><p>The Buyids rarely attempted to enforce a particular religious view upon their subjects except when in matters where it would be politically expedient. The Sunni Abbasids retained the caliphate but were deprived of all secular power.[45] In addition, in order to prevent tensions between the Shia and the Sunnis from spreading to government agencies, the Buyid amirs occasionally appointed Christians to high offices instead of Muslims from either sect.[46]</p><h2>Buyid rulers</h2><h3>Major rulers</h3><p>Generally, the three most powerful Buyid amirs at any given time were those in control of Fars, Jibal and Iraq. Sometimes a ruler would come to rule more than one region, but no Buyid rulers ever exercised direct control of all three regions.</p><p>Buyids in Fars</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/7/70/Plate_Buwayhid.JPG/250px-Plate_Buwayhid.JPG" width="250" height="261"><p>


				Buyid era art: Painted, incised, and glazed earthenware. Dated 10th century, Iran. New York Metropolitan Museum of Art.


				</p><p>
					Buyids in Ray</p><p>Buyids in Iraq</p><h3>Minor rulers</h3><p>It was not uncommon for younger sons to found collateral lines, or for individual Buyid members to take control of a province and begin ruling there. The following list is incomplete.</p><p>Buyids in Basra</p><p>Buyids in Hamadan</p><p>Buyids in Kerman</p><p>Buyids of Khuzistan</p><h2>Family tree</h2><h2>Sources</h2><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Buyid_dynasty&amp;oldid=772177233"					
								Categories:  Hidden categories:</p><br><br><img alt="This is a good article. Click here for more information." src="http://upload.wikimedia.org/wikipedia/en/thumb/9/94/Symbol_support_vote.svg/19px-Symbol_support_vote.svg.png" width="19" height="20"><h1 lang="en">Ayyubid dynasty</h1><p> From Wikipedia, the free encyclopedia</p><p>The Ayyubid dynasty (Arabic: ??????????? al-Ayyubiyun; Kurdish: ???????? ?????????? Xanedana Eyûbiyan) was a Muslim dynasty of Kurdish origin,[2][3][4] founded by Saladin and centered in Egypt. The dynasty ruled much of the Middle East during the 12th and 13th centuries. Saladin had been the vizier of Fatimid Egypt before toppling the Fatimids in 1171. Three years later, he proclaimed himself sultan following the death of his former master, the Zengid ruler Nur al-Din.[5] For the next decade, the Ayyubids launched conquests throughout the region and by 1183, they controlled Egypt, Syria, northern Mesopotamia, Hejaz, Yemen, and the North African coast up to the borders of modern-day Tunisia. Most of the Kingdom of Jerusalem fell to Saladin after his victory at the Battle of Hattin in 1187. However, the Crusaders regained control of Palestine's coastline in the 1190s.</p><p>After the death of Saladin in 1193, his sons contested control of the sultanate, but Saladin's brother al-Adil became the paramount Ayyubid sultan in 1200, and all of the later Ayyubid sultans of Egypt were his descendants. In the 1230s, the emirs of Syria attempted to assert their independence from Egypt and the Ayyubid realm remained divided until Sultan as-Salih Ayyub restored its unity by conquering most of Syria, except Aleppo, by 1247. By then, local Muslim dynasties had driven out the Ayyubids from Yemen, the Hejaz, and parts of Mesopotamia. After his death in 1249, as-Salih Ayyub was succeeded in Egypt by al-Mu'azzam Turanshah. However, the latter was soon overthrown by the Mamluk generals who had repelled a Crusader invasion of the Nile Delta. This effectively ended Ayyubid power in Egypt; attempts by the emirs of Syria, led by an-Nasir Yusuf of Aleppo, to wrest back Egypt failed. In 1260, the Mongols sacked Aleppo and conquered the Ayyubids' remaining territories soon after. The Mamluks, who expelled the Mongols, maintained the Ayyubid principality of Hama until deposing its last ruler in 1341.</p><div class="gradientback"></div></div><div class="content"><p>During their relatively short tenure, the Ayyubids ushered in an era of economic prosperity in the lands they ruled, and the facilities and patronage provided by the Ayyubids led to a resurgence in intellectual activity in the Islamic world. This period was also marked by an Ayyubid process of vigorously strengthening Sunni Muslim dominance in the region by constructing numerous madrasas (Islamic schools of law) in their major cities.</p><h2>Contents</h2><h2>History</h2><h3>Origins</h3><p>The progenitor of the Ayyubid dynasty, Najm ad-Din Ayyub ibn Shadhi, belonged to the Kurdish Rawadiya tribe, itself a branch of the Hadhabani confederation. Ayyub's ancestors settled in the town of Dvin, in northern Armenia.[2] The Rawadiya were the dominant Kurdish group in the Dvin district, forming part of the political-military elite of the town.[2]</p><p>Circumstances became unfavorable in Dvin when Turkish generals seized the town from its Kurdish prince. Shadhi left with his two sons Ayyub and Asad ad-Din Shirkuh.[2] His friend Mujahid ad-Din Bihruz—the military governor of northern Mesopotamia under the Seljuks—welcomed him and appointed him governor of Tikrit. After Shadhi's death, Ayyub succeeded him in governance of the city with the assistance of his brother Shirkuh. Together they managed the affairs of the city well, gaining them popularity from the local inhabitants.[6] In the meantime, Imad ad-Din Zangi, the ruler of Mosul, was defeated by the Abbasids under Caliph al-Mustarshid and Bihruz. In his bid to escape the battlefield to Mosul via Tikrit, Zangi took shelter with Ayyub and sought his assistance in this task. Ayyub complied and provided Zangi and his companions boats to cross the Tigris River and safely reach Mosul.[7]</p><p>As a consequence for assisting Zangi, the Abbasid authorities sought punitive measures against Ayyub. Simultaneously, in a separate incident, Shirkuh killed a close confidant of Bihruz on charges that he had sexually assaulted a woman in Tikrit. The Abbasid court issued arrest warrants for both Ayyub and Shirkuh, but before the brothers could be arrested, they departed Tikrit for Mosul in 1138.[7] When they arrived in Mosul, Zangi provided them with all the facilities they needed and he recruited the two brothers into his service. Ayyub was made commander of Ba'albek and Shirkuh entered the service of Zangi's son, Nur ad-Din. According to historian Abdul Ali, it was under the care and patronage of Zangi that the Ayyubid family rose to prominence.[7]</p><h3>Establishment in Egypt</h3><p>In 1164, Nur al-Din dispatched Shirkuh to lead an expeditionary force to prevent the Crusaders from establishing a strong presence in an increasingly anarchic Egypt. Shirkuh enlisted Ayyub's son, Saladin, as an officer under his command.[8] They successfully drove out Dirgham, the vizier of Egypt, and reinstated his predecessor Shawar. After being reinstated, Shawar ordered Shirkuh to withdraw his forces from Egypt, but Shirkuh refused, claiming it was Nur al-Din's will that he remain.[9] Over the course of several years, Shirkuh and Saladin defeated the combined forces of the Crusaders and Shawar's troops, first at Bilbais, then at a site near Giza, and in Alexandria, where Saladin would stay to protect while Shirkuh pursued Crusader forces in Lower Egypt.[10]</p><p>Shawar died in 1169 and Shirkuh became vizier, but he too died later that year.[11] After Shirkuh's death, Saladin was appointed vizier by the Fatimid caliph al-Adid because there was no one weaker or younger than Saladin, and not one of the emirs obeyed him or served him, according to medieval Muslim chronicler Ibn al-Athir.[12] Saladin soon found himself more independent than ever before in his career, much to the dismay of Nur al-Din who attempted to influence events in Egypt. He permitted Saladin's elder brother, Turan-Shah, to supervise Saladin in a bid to cause dissension within the Ayyubid family and thus undermining its position in Egypt. Nur al-Din satisfied Saladin's request that he be joined by his father Ayyub. However, Ayyub was sent primarily to ensure that Abbasid suzerainty was proclaimed in Egypt, which Saladin was reluctant to undertake due to his position as the vizier of the Fatimids. Although Nur al-Din failed to provoke the Ayyubids into rivalry, the extended Ayyubid family, particularly a number of local governors in Syria, did not entirely back Saladin.[13]</p><p>Saladin consolidated his control in Egypt after ordering Turan-Shah to put down a revolt in Cairo staged by the Fatimid army's 50,000-strong Nubian regiments. After this success, Saladin began granting his family members high-ranking positions in the country and increased Sunni Muslim influence in Shia Muslim-dominated Cairo by ordering the construction of a college for the Maliki school of jurisprudence of Sunni Islam in the city, and another for the Shafi'i school, to which he belonged, in al-Fustat.[14] In 1171, al-Adid died and Saladin took advantage of this power vacuum, effectively taking control of the country. Upon seizing power, he switched Egypt's allegiance to the Baghdad-based Abbasid Caliphate which adhered to Sunni Islam.[8]</p><h3>Expansion</h3><p>Saladin went to Alexandria in 1171–72 and found himself facing the dilemma of having many supporters in the city, but little money. A family council was held there by the Ayyubid emirs of Egypt where it was decided that al-Muzaffar Taqi al-Din Umar, Saladin's nephew, would launch an expedition against the coastal region of Barqa (Cyrenaica) west of Egypt with a force of 500 cavalry. In order to justify the raid, a letter was sent to the Bedouin tribes of Barqa, rebuking them for their robberies of travelers and ordering them to pay the alms-tax (zakat). The latter was to be collected from their livestock.[15]</p><p>In late 1172, Aswan was besieged by former Fatimid soldiers from Nubia and the governor of the city, Kanz al-Dawla—a former Fatimid loyalist—requested reinforcements from Saladin who complied. The reinforcements had come after the Nubians had already departed Aswan, but Ayyubid forces led by Turan-Shah advanced and conquered northern Nubia after capturing the town of Ibrim. Turan-Shah and his Kurdish soldiers temporarily lodged there. From Ibrim, they raided the surrounding region, halting their operations after being presented with an armistice proposal from the Dongola-based Nubian king. Although Turan-Shah's initial response was hawkish, he later sent an envoy to Dongola, who upon returning, described the poverty of the city and of Nubia in general to Turan-Shah. Consequently, the Ayyubids, like their Fatimid predecessors, were discouraged from further southward expansion into Nubia due to the poverty of the region, but required Nubia to guarantee the protection of Aswan and Upper Egypt.[16] The Ayyubid garrison in Ibrim withdrew to Egypt in 1175.[17]</p><p>In 1174, Sharaf al-Din Qaraqush, a commander under al-Muzaffar Umar, conquered Tripoli from the Normans with an army of Turks and Bedouins.[15][18]</p><p>In 1173, Saladin sent Turan-Shah to conquer Yemen and the Hejaz. Muslim writers Ibn al-Athir and later al-Maqrizi wrote that the reasoning behind the conquest of Yemen was an Ayyubid fear that should Egypt fall to Nur al-Din, they could seek refuge in a faraway territory. In May 1174, Turan-Shah conquered Zabid from a Kharijite dynasty and executed its leader Mahdi Abd al-Nabi, and later that year Aden was taken from the Shia Banu Karam tribe.[19] Aden became the principal maritime port of the dynasty in the Indian Ocean and the principal city of Yemen,[20] although the official capital of Ayyubid Yemen was Ta'iz.[21] The advent of the Ayyubids marked the beginning of a period of renewed prosperity in the city which saw the improvement of its commercial infrastructure, the establishment of new institutions, and the minting of its own coins.[20] Following this prosperity, the Ayyubids implemented a new tax which was collected by galleys.[22]</p><div class="gradientback"></div></div><div class="content"><p>Turan-Shah drove out the Hamdanid rulers of Sana'a, conquering the mountainous city in 1175.[19] With the conquest of Yemen, the Ayyubids developed a coastal fleet, al-asakir al-bahriyya, which they used to guard the sea coasts under their control and protect them from pirate raids.[23] The conquest held great significance for Yemen because the Ayyubids managed to unite the previous three independent states (Zabid, Aden, and Sana'a) under a single power. However, when Turan-Shah was transferred from his governorship in Yemen in 1176, uprisings broke out in the territory and were not quelled until 1182 when Saladin assigned his other brother Tughtekin Sayf al-Islam as governor of Yemen.[19]</p><p>From Yemen, as from Egypt, the Ayyubids aimed to dominate the Red Sea trade routes which Egypt depended on and so sought to tighten their grip over the Hejaz, where an important trade stop, Yanbu, was located.[24] To favor trade in the direction of the Red Sea, the Ayyubids built facilities along the Red Sea-Indian Ocean trade routes to accompany merchants.[25] The Ayyubids also aspired to back their claims of legitimacy within the Caliphate by having sovereignty over the Islamic holy cities of Mecca and Medina.[24] The conquests and economic advancements undertaken by Saladin effectively established Egypt's hegemony in the region.[25]</p><p>Although still nominally a vassal of Nur al-Din, Saladin adopted an increasingly independent foreign policy. This independence became more publicly pronounced after Nur al-Din's death in 1174.[8] Thereafter, Saladin set out to conquer Syria from the Zengids, and on November 23 he was welcomed in Damascus by the governor of the city. By 1175, he had taken control of Hama and Homs, but failed to take Aleppo after besieging it.[26] Control of Homs was handed to the descendants of Shirkuh in 1179 and Hama was given to Saladin's nephew, al-Muzaffar Umar.[27] Saladin's successes alarmed Emir Saif al-Din of Mosul, the head of the Zengids at the time, who regarded Syria as his family's estate and was angered that it was being usurped by a former servant of Nur al-Din. He mustered an army to confront Saladin near Hama. Although heavily outnumbered, Saladin and his veteran soldiers decisively defeated the Zengids.[26] After his victory, he proclaimed himself king and suppressed the name of as-Salih Ismail al-Malik (Nur al-Din's adolescent son) in Friday prayers and Islamic coinage, replacing it with his own name. The Abbasid caliph, al-Mustadi, graciously welcomed Saladin's assumption of power and gave him the title of Sultan of Egypt and Syria.[28]</p><p>In the spring of 1176, another major confrontation occurred between the Zengids and the Ayyubids, this time at the Sultan's Mound, 15 kilometres (9.3&nbsp;mi) from Aleppo. Saladin again emerged victorious, but Saif al-Din managed to narrowly escape. The Ayyubids proceeded to conquer other Syrian cities in the north, namely Ma'arat al-Numan, A'zaz, Buza'a, and Manbij, but failed to capture Aleppo during a second siege. An agreement was laid out, however, whereby Gumushtigin, the governor of Aleppo, and his allies at Hisn Kayfa and Mardin, would recognize Saladin as the sovereign of the Ayyubids' possessions in Syria, while Saladin allowed for Gumushtigin and as-Salih al-Malik to continue their rule over Aleppo.[29]</p><p>While Saladin was in Syria, his brother al-Adil governed Egypt,[30] and in 1174–75, Kanz al-Dawla of Aswan revolted against the Ayyubids with the intention of restoring Fatimid rule. His main backers were the local Bedouin tribes and the Nubians, but he also enjoyed the support of a multitude of other groups, including the Armenians. Coincidental or possibly in coordination, was an uprising by Abbas ibn Shadi who overran Qus along the Nile River in central Egypt. Both rebellions were crushed by al-Adil.[31] For the rest of that year and throughout early 1176, Qaraqush continued his raids in western North Africa, bringing the Ayyubids into conflict with the Almohads who ruled the Maghreb.[15]</p><p>In 1177, Saladin led a force of some 26,000 soldiers, according to Crusader chronicler William of Tyre, into southern Palestine after hearing that most of the Kingdom of Jerusalem's soldiers were besieging Harim north of Aleppo. Suddenly attacked by the Templars under Baldwin IV of Jerusalem near Ramla, the Ayyubid army was defeated at the Battle of Montgisard, with the majority of its troops killed. Saladin encamped at Homs the following year and a number of skirmishes between his forces, commanded by Farrukh Shah, and the Crusaders occurred.[32] Undeterred, Saladin invaded the Crusader states from the west and defeated Baldwin at the Battle of Marj Ayyun in 1179. The following year, he destroyed the newly built Crusader castle of Chastellet at the Battle of Jacob's Ford. In the campaign of 1182, he sparred with Baldwin again in the inconclusive Battle of Belvoir Castle in Kawkab al-Hawa.[33] The Ayyubid na'ib (deputy governor) of Yemen, Uthman al-Zandjili, conquered the greater part of Hadramaut in 1180, upon Turan-Shah's return to Yemen.[34]</p><p>In May 1182, Saladin captured Aleppo after a brief siege; the new governor of the city, Imad al-Din Zangi II, had been unpopular with his subjects and surrendered Aleppo after Saladin agreed to restore Zangi II's previous control over Sinjar, Raqqa, and Nusaybin, which would thereafter serve as vassal territories of the Ayyubids.[35] Aleppo formally entered Ayyubid hands on 12 June. The day after, Saladin marched to Harim, near the Crusader-held Antioch and captured the city when its garrison forced out their leader, Surhak, who was then briefly detained and released by al-Muzaffar Umar.[36] The surrender of Aleppo and Saladin's allegiance with Zangi II had left Izz al-Din al-Mas'ud of Mosul the only major Muslim rival of the Ayyubids. Mosul had been subjected to a short siege in the autumn of 1182, but after mediation by the Abbasid caliph an-Nasir, Saladin withdrew his forces. Mas'ud attempted to align himself with the Artuqids of Mardin, but they became allies of Saladin instead. In 1183, Irbil too switched allegiance to the Ayyubids. Mas'ud then sought the support of Pahlawan ibn Muhammad, the governor of Azerbaijan, and although he did not usually intervene in the region, the possibility of Pahlawan's intervention made Saladin cautious about launching further attacks against Mosul.[37]</p><p>An arrangement was negotiated whereby al-Adil was to administer Aleppo in the name of Saladin's son al-Afdal, while Egypt would be governed by al-Muzaffar Umar in the name of Saladin's other son Uthman. When the two sons were to come of age they would assume power in the two territories, but if any died, one of Saladin's brothers would take their place.[38] In the summer of 1183, after ravaging eastern Galilee, Saladin's raids there culminated in the Battle of al-Fule in the Jezreel Valley between him and the Crusaders under Guy of Lusignan. The mostly hand-to-hand fighting ended indecisively. The two armies withdrew to a mile from each other and while the Crusaders discussed internal matters, Saladin captured the Golan Plateau, cutting the Crusaders off from their main supplies source. In October 1183 and then on 13 August 1184, Saladin and al-Adil besieged Crusader-held Karak, but were unable to capture it. Afterward, the Ayyubids raided Samaria, burning down Nablus. Saladin returned to Damascus in September 1184 and a relative peace between the Crusader states and the Ayyubid empire subsequently ensued in 1184–1185.[39]</p><p>Saladin launched his last offensive against Mosul in late 1185, hoping for an easy victory over a presumably demoralized Mas'ud, but failed due to the city's unexpectedly stiff resistance and a serious illness which caused Saladin to withdraw to Harran. Upon Abbasid encouragement, Saladin and Mas'ud negotiated a treaty in March 1186 that left the Zengids in control of Mosul, but under the obligation to supply the Ayyubids with military support when requested.[37]</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/6/66/Hattin.jpg/220px-Hattin.jpg" width="220" height="296"><p>


				Virtually the entire Kingdom of Jerusalem passed into Ayyubid hands after their victory against the Crusaders in the Battle of Hattin in 1187; illustration from Les Passages faits Outremer par les Français contre les Turcs et autres Sarrasins et Maures outremarins, circa 1490


				</p><div class="gradientback"></div></div><div class="content"><p>
					Saladin besieged Tiberias in the eastern Galilee on 3 July 1187 and the Crusader army attempted to attack the Ayyubids by way of Kafr Kanna. After hearing of the Crusaders' march, Saladin led his guard back to their main camp at Kafr Sabt, leaving a small detachment at Tiberias. With a clear view of the Crusader army, Saladin ordered al-Muzaffar Umar to block the Crusaders' entry from Hattin by taking a position near Lubya, while Gokbori and his troops were stationed at a hill near al-Shajara. On 4 July the Crusaders advanced toward the Horns of Hattin and charged against the Muslim forces, but were overwhelmed and defeated decisively. Four days after the battle, Saladin invited al-Adil to join him in the reconquest of Palestine. On 8 July the Crusader stronghold of Acre was captured by Saladin, while his forces seized Nazareth and Saffuriya; other brigades took Haifa, Caesarea, Sebastia and Nablus, while al-Adil conquered Mirabel and Jaffa. On 26 July Saladin returned to the coast and received the surrender of Sarepta, Sidon, Beirut, and Jableh.[40] In August, the Ayyubids conquered Ramla, Darum, Gaza, Bayt Jibrin, and Latrun. Ascalon was taken on 4 September.[41] In September–October 1187, the Ayyubids besieged Jerusalem, taking possession of it on 2 October after negotiations with Balian of Ibelin.[42]</p><p>Karak and Mont Real in Transjordan soon fell, followed by Safad in the northeastern Galilee. By the end of 1187 the Ayyubids were in control of virtually the entire Crusader kingdom in the Levant with the exception of Tyre, which held out under Conrad of Montferrat. In December, an Ayyubid army consisting of the garrisons of Saladin and his brothers from Aleppo, Hama, and Egypt besieged Tyre. Half of the Muslim naval fleet was seized by Conrad's forces on 29 December, followed by an Ayyubid defeat on the shoreline of the city. On 1 January 1188, Saladin held a war council where a withdrawal from Tripoli was agreed.[43]</p><p>While they fought the Crusaders in the Levant, the Ayyubids under Sharaf al-Din wrested control of Kairouan from the Almohads in North Africa.[15]</p><p>Pope Gregory VIII called for a Third Crusade against the Muslims in early 1189. Frederick Barbarossa of the Holy Roman Empire, Philip Augustus of France, and Richard the Lionheart of England formed an alliance to reconquer Jerusalem. Meanwhile, the Crusaders and the Ayyubids fought near Acre that year and were joined by the reinforcements from Europe. From 1189 to 1191, Acre was besieged by the Crusaders, and despite initial Muslim successes, it fell to Richard's forces. A massacre of 2,700 Muslim inhabitants ensued, and the Crusaders then planned to take Ascalon in the south.[44]</p><p>The Crusaders, now under the unified command of Richard, defeated Saladin at the Battle of Arsuf, allowing for the Crusader conquest of Jaffa and much of coastal Palestine, but they were unable to recover the interior regions. Instead, Richard signed a treaty with Saladin in 1192, restoring the Kingdom of Jerusalem to a coastal strip between Jaffa and Beirut. It was the last major war effort of Saladin's career, as he died the next year, in 1193.</p><h3>Quarrels over the sultanate</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/1/1b/Ayyubid_Sultanate_1193_AD.jpg/300px-Ayyubid_Sultanate_1193_AD.jpg" width="300" height="213"><p>


				The state of the Ayyubid dynasty and its neighbors after the death of Saladin


				</p><p>
					Rather than establishing a centralized empire, Saladin had established hereditary ownership throughout his lands, dividing his empire among his kinsmen, with family members presiding over semi-autonomous fiefs and principalities.[8] Although these princes (emirs) owed allegiance to the Ayyubid sultan, they maintained relative independence in their own territories.[45] Upon Saladin's death, az-Zahir took Aleppo from al-Adil per the arrangement and al-Aziz Uthman held Cairo, while his eldest son, al-Afdal retained Damascus,[46] which also included Palestine and much of Mount Lebanon.[47] Al-Adil then acquired al-Jazira (Upper Mesopotamia), where he held the Zengids of Mosul at bay. In 1193, Mas'ud of Mosul joined forces with Zangi II of Sinjar and together the Zengid coalition moved to conquer al-Jazira. However, before any major results could be achieved, Mas'ud fell ill and returned to Mosul, and al-Adil then compelled Zangi to make a quick peace before the Zengids suffered territorial losses at the hands of the Ayyubids.[37] Al-Adil's son al-Mu'azzam took possession of Karak and Transjordan.[46]</p><p>Soon, however, Saladin's sons squabbled over the division of the empire. Saladin had appointed al-Afdal to the governorship of Damascus with the intention that his son should continue to see the city as his principal place of residence in order to emphasize the primacy of the jihad (holy struggle) against the Crusader states. Al-Afdal, however, found that his attachment to Damascus contributed to his undoing. Several of his father's subordinate emirs left the city for Cairo to lobby Uthman to oust him on claims he was inexperienced and intended to oust the Ayyubid old guard. Al-Adil further encouraged Uthman to act in order prevent al-Afdal's incompetence putting the Ayyubid empire in jeopardy. Thus, in 1194, Uthman openly demanded the sultanate. Uthman's claim to the throne was settled in a series of assaults on Damascus in 1196, forcing al-Afdal to leave for a lesser post at Salkhad. Al-Adil established himself in Damascus as a lieutenant of Uthman, but wielded great influence within the empire.[47]</p><p>When Uthman died in a hunting accident near Cairo, al-Afdal was again made sultan (although Uthman's son al-Mansur was the nominal ruler of Egypt), al-Adil having been absent in a campaign in the northeast. Al-Adil returned and managed to occupy the Citadel of Damascus, but then faced a strong assault from the combined forces of al-Afdal and his brother az-Zahir of Aleppo. These forces disintegrated under al-Afdal's leadership and in 1200, al-Adil resumed his offensive.[48] Upon Uthman's death, two clans of mamluks (slave soldiers) entered into conflict. They were the Asadiyya and Salahiyya, both of which Shirkuh and Saladin had purchased. The Salahiyya backed al-Adil in his struggles against al-Afdal. With their support, al-Adil conquered Cairo in 1200,[49] and forced al-Afdal to accept internal banishment.[48] He proclaimed himself Sultan of Egypt and Syria afterward and entrusted the governance of Damascus to al-Mu'azzam and al-Jazira to his other son al-Kamil.[49] Also around 1200, a sharif (tribal head related to the Islamic prophet Muhammad), Qatada ibn Idris, seized power in Mecca and was recognized as the emir of the city by al-Adil.[24]</p><p>Al-Afdal strove to retrieve Damascus a final time, but failed. Al-Adil entered the city in triumph in 1201.[48] Thereafter, al-Adil's line, rather than Saladin's line, dominated the next 50 years of Ayyubid rule.[48] However, az-Zahir still held Aleppo and al-Afdal was given Samosata in Anatolia.[49] Al-Adil redistributed his possessions between his sons: al-Kamil was to succeed him in Egypt, al-Ashraf received al-Jazira, and al-Awhad was given Diyar Bakr, but the latter territory shifted to al-Ashraf's domain after al-Awhad died.[49]</p><p>Al-Adil aroused open hostility from the Hanbali lobby in Damascus for largely ignoring the Crusaders, having launched only one campaign against them. Al-Adil believed that the Crusader army could not be defeated in a direct fight. Prolonged campaigns also involved the difficulties of maintaining a coherent Muslim coalition. The trend under al-Adil was the steady growth of the empire, mainly through the expansion of Ayyubid authority in al-Jazira and Armenia. The Abbasids eventually recognized al-Adil's role as sultan in 1207.[48] A Crusader military campaign was launched on 3 November 1217, beginning with an offensive towards Transjordan. Al-Mu'azzam urged al-Adil to launch a counter-attack, but he rejected his son's proposal.[50] In 1218, the fortress of Damietta in the Nile Delta was besieged by the Crusaders. After two failed attempts, the fortress eventually capitulated on 25 August. Six days later al-Adil died of apparent shock at Damietta's loss.[51]</p><div class="gradientback"></div></div><div class="content"><p>Al-Kamil proclaimed himself sultan in Cairo, while his brother al-Mu'azzam claimed the throne in Damascus. Al-Kamil attempted to retake Damietta, but was forced back by John of Brienne. After learning of a conspiracy against him, he fled, leaving the Egyptian army leaderless. Panic ensued, but with the help of al-Mu'azzam, al-Kamil regrouped his forces. By then, however, the Crusaders had seized his camp. The Ayyubids offered to negotiate for a withdrawal from Damietta, offering the restoration of Palestine to the Kingdom of Jerusalem, with the exception of the forts of Mont Real and Karak.[52] This was refused by the leader of the Fifth Crusade, Pelagius of Albano, and in 1221, the Crusaders were driven out of the Nile Delta after the Ayyubid victory at Mansura.[8]</p><h3>Disintegration</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/7/7c/Al-Kamil_Muhammad_al-Malik_and_Frederick_II_Holy_Roman_Emperor.jpg/170px-Al-Kamil_Muhammad_al-Malik_and_Frederick_II_Holy_Roman_Emperor.jpg" width="170" height="350"><p>


				Al-Kamil (right) and Frederick II signed a treaty restoring Jerusalem to the Crusaders for ten years; from Nuova Cronica, mid-14th century


				</p><p>
					In the east, the Khwarezemids under Jalal ad-Din Mingburnu captured the town of Khilat from al-Ashraf,[53] while the normally loyalist Rasulids began to encroach on Ayyubid territorial holdings in Arabia. In 1222 the Ayyubids appointed the Rasulid leader Ali Bin Rasul as governor of Mecca. Ayyubid rule in Yemen and the Hejaz was declining and the Ayyubid governor of Yemen, Mas'ud bin Kamil, was forced to leave for Egypt in 1223. He appointed Nur ad-Din Umar as his deputy governor while he was absent.[54] In 1224 the local al-Yamani dynasty gained control of Hadramaut from the Ayyubids who had held it loosely due to the troubled situation of their administration in Yemen proper.[34] Following Mas'ud bin Kamil's death in 1229, Nur ad-Din Umar declared himself the independent ruler of Yemen and discontinued the annual tribute payment to the Ayyubid sultanate in Egypt.[54]</p><p>Under Frederick II, a Sixth Crusade was launched, capitalizing on the ongoing internal strife between al-Kamil of Egypt and al-Mu'azzam of Syria.[8] Subsequently, al-Kamil offered Jerusalem to Frederick to avoid a Syrian invasion of Egypt, but the latter refused. Al-Kamil's position was strengthened when al-Mu'azzam died in 1227 and was succeeded by his son an-Nasir Dawud. Al-Kamil continued negotiations with Frederick II in Acre in 1228, leading to a truce agreement signed in February 1229. The agreement gave the Crusaders control over an unfortified Jerusalem for over ten years, but also guaranteed Muslims control over Islamic holy places in the city.[45] Although the treaty was virtually meaningless in military terms, an-Nasir Dawud used it to provoke the sentiments of Syria's inhabitants and a Friday sermon by a popular preacher at the Umayyad Mosque reduced the crowd to violent sobbing and tears.[55]</p><p>The settlement with the Crusaders was accompanied by a proposed redistribution of the Ayyubid principalities whereby Damascus and its territories would by governed by al-Ashraf, who recognized al-Kamil's sovereignty. An-Nasir Dawud resisted the settlement, incensed by the Ayyubid-Crusader truce.[55] Al-Kamil's forces reached Damascus to enforce the proposed agreement in May 1229. The siege put great pressure on the city, but the inhabitants rallied to an-Nasir Dawud, supportive of al-Mu'azzam's stable rule and angered at the treaty with Frederick. After one month, however, an-Nasir Dawud sued for a peaceful outcome and was given a new principality centered around Karak, while al-Ashraf, the governor of Diyar Bakr, assumed the governorship of Damascus.[56]</p><p>Meanwhile, the Seljuks were advancing towards al-Jazira,[57] and the descendants of Qatada ibn Idris fought with their Ayyubid overlords over control of Mecca. The conflict between them was taken advantage of by the Rasulids of Yemen who attempted to end Ayyubid suzerainty in the Hejaz and bring the region under their control which they accomplished in 1238 when Nur al-Din Umar captured Mecca.[24][54]</p><p>Al-Ashraf's rule in Damascus was stable, but he and the other emirs of Syria sought to assert their independence from Cairo. Amid these tensions, al-Ashraf died in August 1237 after a four-month illness and was succeeded by his brother as-Salih Ismail. Two months later, al-Kamil's Egyptian army arrived and besieged Damascus, but as-Salih Ismail had destroyed the suburbs of the city to deny al-Kamil's forces shelter.[58] In 1232, al-Kamil installed his eldest son as-Salih Ayyub to govern Hisn Kayfa, but upon al-Kamil's death in 1238, as-Salih Ayyub disputed the proclamation of younger brother al-Adil II as sultan in Cairo. As-Salih Ayyub eventually occupied Damascus in December 1238, but his uncle Ismail retrieved the city in September 1239. Ismail's cousin an-Nasir Dawud had Ismail detained in Karak in a move to prevent the latter's arrest by al-Adil II. Ismail entered into an alliance with Dawud who released him the following year, allowing him to proclaim himself sultan in place of al-Adil II in May 1240.</p><p>Throughout the early 1240s, as-Salih Ayyub carried out reprisals against those who supported al-Adil II, and he then quarreled with an-Nasir Dawud who had reconciled with as-Salih Ismail of Damascus. The rival sultans as-Salih Ayyub and Ismail attempted to ally with the Crusaders against the other.[59] In 1244, the breakaway Ayyubids of Syria allied with the Crusaders and confronted the coalition of as-Salih Ayyub and the Khwarizmids at Hirbiya, near Gaza. A large battle ensued, resulting in a major victory for as-Salih Ayyub and the virtual collapse of the Kingdom of Jerusalem.[60]</p><p>In 1244–1245, as-Salih Ayyub had seized the area approximate to the modern-day West Bank from an-Nasir Dawud; he gained possession of Jerusalem, then marched on to take Damascus, which fell with relative ease in October 1245.[60] Shortly afterward, Sayf al-Din Ali surrendered his exposed principality of Ajlun and its fortress to as-Salih Ayyub. The rupture of the alliance between the Khwarizmids and as-Salih Ayyub ended with the virtual destruction of the former by al-Mansur Ibrahim, the Ayyubid emir of Homs, in October 1246.[60] With the Khwarizimid defeat, as-Salih Ayyub was able to complete the conquest of southern Syria.[61] His general Fakhr ad-Din went on to subdue an-Nasir Dawud's territories. He sacked the lower town of Karak, then besieged its fortress. A stalemate followed with neither an-Nasir Dawud or Fakhr ad-Din strong enough to dislodge the other's forces. A settlement was eventually reached whereby an-Nasir Dawud would retain the fortress, but cede the remainder of his principality to as-Salih Ayyub. Having settled the situation in Palestine and Transjordan, Fakhr ad-Din moved north and marched to Bosra, the last place still held by Ismail. During the siege, Fakhr ad-Din fell ill, but his commanders continued the assault against the city, which fell in December 1246.[62]</p><p>By May 1247, as-Salih Ayyub was master of Syria south of Lake Homs, having gained control over Banyas and Salkhad. With his fellow Ayyubid opponents subdued, except for Aleppo under an-Nasir Yusuf, as-Salih Ayyub undertook a limited offensive against the Crusaders, sending Fakhr ad-Din to move against their territories in the Galilee. Tiberias fell on 16 June, followed by Mount Tabor and Kawkab al-Hawa soon thereafter. Safad with its Templar fortress seemed out of reach, so the Ayyubids marched south to Ascalon. Facing stubborn resistance from the Crusader garrison, an Egyptian flotilla was sent by as-Salih Ayyub to support the siege and on 24 October, Fakhr ad-Din's troops stormed through a breach in the walls and killed or captured the entire garrison. The city was razed and left deserted.[62]</p><div class="gradientback"></div></div><div class="content"><p>As-Salih Ayyub returned to Damascus to keep an eye on developments in northern Syria. Al-Ashraf Musa of Homs had ceded the important stronghold of Salamiyah to as-Salih Ayyub the previous winter, perhaps to underline their patron-client relationship. This troubled the Ayyubids of Aleppo who feared it would be used as a base for a military take-over of their city. An-Nasir Yusuf found this intolerable and decided to annex Homs in the winter of 1248. The city surrendered in August and an-Nasir Yusuf's terms forced al-Ashraf Musa to hand over Homs, but he was allowed to retain nearby Palmyra and Tell Bashir in the Syrian Desert. As-Salih Ayyub sent Fakhr ad-Din to recapture Homs, but Aleppo countered by sending an army to Kafr Tab, south of the city.[63] An-Nasir Dawud left Karak for Aleppo to support an-Nasir Yusuf, but in his absence, his brothers al-Amjad Hasan and az-Zahir Shadhi detained his heir al-Mu'azzam Isa and then personally went to as-Salih Ayyub's camp at al-Mansourah in Egypt to offer him control of Karak in return for holdings in Egypt. As-Salih Ayyub agreed and sent the eunuch Badr al-Din Sawabi to act as his governor in Karak.[64]</p><h3>Fall</h3><p>In 1248, a Crusader fleet of 1,800 boats and ships arrived in Cyprus with the intent of launching a Seventh Crusade against the Muslims by conquering Egypt. Their commander, Louis IX, attempted to enlist the Mongols to launch a coordinated attack on Egypt, but when this failed to materialize, the Crusader force sailed to Damietta and the local population there fled as soon as they landed. When as-Salih Ayyub, who was in Syria at the time, heard of this, he rushed back to Egypt, avoiding Damietta, instead reaching Mansurah. There, he organized an army and raised a commando force which harassed the Crusaders.[65]</p><p>As-Salih Ayyub was ill and his health deteriorated further due to the mounting pressure from the Crusader offensive. His wife Shajar al-Durr called a meeting of all the war generals and thus became commander-in-chief of the Egyptian forces. She ordered the fortification of Mansurah and then stored large quantities of provisions and concentrated her forces there. She also organized a fleet of war galleys and scattered them at various strategic points along the Nile River. Crusader attempts to capture Mansurah were thwarted and King Louis found himself in a critical position. He managed to cross the Nile to launch a surprise attack against Mansurah. Meanwhile, as-Salih Ayyub died, but Shajar al-Durr and as-Salih Ayyub's Bahri Mamluk generals, including Rukn al-Din Baybars and Aybak, countered the assault and inflicted heavy losses on the Crusaders. Simultaneously, Egyptian forces cut off the Crusader's line of supply from Damietta, preventing the arrival of reinforcements. As-Salih Ayyub's son and the newly proclaimed Ayyubid sultan al-Mu'azzam Turan-Shah reached Mansurah at this point and intensified the battle against the Crusaders. The latter ultimately surrendered at the Battle of Fariskur, and King Louis and his companions were arrested.[66]</p><p>Al-Mu'azzam Turan-Shah alienated the Mamluks soon after their victory at Mansurah and constantly threatened them and Shajar al-Durr. Fearing for their positions of power, the Bahri Mamluks revolted against the sultan and killed him in April 1250.[45] Aybak married Shajar al-Durr and subsequently took over the government in Egypt in the name of al-Ashraf II who became sultan, but only nominally.[67]</p><p>Intent on restoring the supremacy of Saladin's direct descendants within the Ayyubid family,[68] an-Nasir Yusuf was eventually able to enlist the backing of all of the Syria-based Ayyubid emirs in a common cause against Mamluk-dominated Egypt. By 1250, he took Damascus with relative ease and except for Hama and Transjordan, an-Nasir Yusuf's direct authority stood unbroken from the Khabur River in northern Mesopotamia to the Sinai Peninsula. In December 1250, he attacked Egypt after hearing of al-Mu'azzam Turan-Shah's death and the ascension of Shajar al-Durr. An-Nasir Yusuf's army was much larger and better-equipped than that of the Egyptian army, consisting of the forces of Aleppo, Homs, Hama, and those of Saladin's only surviving sons, Nusrat ad-Din and Turan-Shah ibn Salah ad-Din.[69] Nonetheless, it suffered a major defeat at the hands of Aybak's forces. An-Nasir Yusuf subsequently returned to Syria, which was slowly slipping out of his control.[68]</p><p>The Mamluks forged an alliance with the Crusaders in March 1252 and agreed to jointly launch a campaign against an-Nasir Yusuf. King Louis, who had been released after al-Mu'azzam Turan-Shah's murder, led his army to Jaffa, while Aybak intended to send his forces to Gaza. Upon hearing of the alliance, an-Nasir Yusuf immediately dispatched a force to Tell al-Ajjul, just outside Gaza, in order to prevent the junction of the Mamluk and Crusader armies. Meanwhile, the rest of the Ayyubid army was stationed in the Jordan Valley. Realizing that a war between them would greatly benefit the Crusaders, Aybak and an-Nasir Yusuf accepted Abbasid mediation via Najm ad-Din al-Badhirai. In April 1253, a treaty was signed whereby the Mamluks would retain control over all of Egypt and Palestine up to, but not including, Nablus, while an-Nasir Yusuf would be confirmed as the ruler of Muslim Syria. Thus, Ayyubid rule was officially ended in Egypt.[70] After conflict arose between the Mamluks and the Ayyubids reignited, al-Badhirai arranged another treaty, this time giving an-Nasir Yusuf control of the Mamluks' territories in Palestine and al-Arish in Sinai. Instead of placing Ayyubids in charge, however, an-Nasir Yusuf handed Jerusalem to a Mamluk named Kutuk while Nablus and Jenin were given to Baibars.[71]</p><p>For over a year after the settlement with the Mamluks, calm settled over an-Nasir Yusuf's reign, but on 11 December 1256 he sent two envoys to the Abbasids in Baghdad seeking formal investiture from the caliph, al-Musta'sim, for his role as Sultan. This request was connected to an-Nasir's rivalry with Aybak, as the title would be useful in future disputes with the Mamluks. However, the Mamluks had sent their envoys to Baghdad previously to precisely ensure that an-Nasir Yusuf would not gain the title, putting al-Musta'sim in a difficult position.[71]</p><p>In early 1257, Aybak was killed in a conspiracy, and was succeeded by his 15-year-old son, al-Mansur Ali, while Saif ad-Din Qutuz held an influential position. Soon after al-Mansur Ali's ascendancy rumors of another conspiracy to which an-Nasir Yusuf had an alleged connection emerged. The accused conspirator, al-Mansur Ali's vizier, Sharaf ad-Din al-Fa'izi, was strangled by Egyptian authorities. The Bahri Mamluks in Syria led by Baibars pressured an-Nasir Yusuf to intervene by invading Egypt, but he would not act, fearing the Bahri dynasty would usurp his throne if they gained Egypt.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/5/51/Ayyubids_1257.png/200px-Ayyubids_1257.png" width="200" height="145"><p>


				Ayyubid territories in 1257. Area in bright red controlled by an-Nasir Yusuf, while the area under dark red was under the nominal control of al-Mughith Umar of Kerak


				</p><p>
					Relations between an-Nasir Yusuf and the Bahri Mamluks grew tense after the former refused to invade Egypt. In October 1257, Baibars and his fellow Mamluks left Damascus or were expelled from the city and together they moved south to Jerusalem. When the governor Kutuk refused to aid them against an-Nasir Yusuf, Baibars deposed him and had al-Mugith Umar, the emir of Karak, pronounced in the khutba at the al-Aqsa Mosque; over the years, al-Mugith Umar had allowed the political dissidents of Cairo and Damascus, who sought protection from either the Mamluk and Ayyubid authorities, a safe haven within his territory.[72]</p><p>Soon after gaining Jerusalem, Baibars conquered Gaza and an-Nasir Yusuf sent his army to Nablus in response. A battle ensued and the Mamluks ultimately fled across the Jordan River to the Balqa area. From there they reached Zughar at the southern tip of the Dead Sea where they sent their submission to Karak. Al-Mughith Umar's new relationship with Baibars solidified his independence from an-Nasir Yusuf's Syria. To ensure his independence, al-Mughith Umar began to distribute the territories of Palestine and Transjordan among the Bahri Mamluks.[72] The new allies assembled a small army and headed for Egypt. In spite of initial gains in Palestine and al-Arish, they withdrew after seeing how overwhelmingly outnumbered they were by the Egyptian army. Al-Mughith Umar and Baibars were not discouraged, however, and launched an army 1,500 regular cavalry to Sinai at the beginning of 1258, but again were defeated by the Mamluks of Egypt.[73]</p><div class="gradientback"></div></div><div class="content"><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/1/10/Mongol_raids_in_Syria_and_Palestine_1260.svg/250px-Mongol_raids_in_Syria_and_Palestine_1260.svg.png" width="250" height="343"><p>


				The Mongol conquest of Ayyubid Syria


				</p><p>
					The Ayyubids had been under the nominal sovereignty of the Mongol Empire after a Mongol force targeted Ayyubid territories in Anatolia in 1244. An-Nasir Yusuf sent an embassy to the Mongol capital Karakorum in 1250, shortly after assuming power. These understandings did not last, however, and the Mongol Great Khan, Möngke, issued a directive to his brother Hulagu to extend the realms of the empire to the Nile River. The latter raised an army of 120,000 and in 1258, sacked Baghdad and slaughtered its inhabitants, including Caliph al-Musta'sim and most of his family after the Ayyubids failed to assemble an army to protect the city.[74] That same year the Ayyubids lost Diyar Bakr to the Mongols.[75]</p><p>An-Nasir Yusuf sent a delegation to Hulagu afterward, repeating his protestations to submission. Hulagu refused to accept the terms and so an-Nasir Yusuf called on Cairo for aid. This plea coincided with a successful coup by the Cairo-based Mamluks against the remaining symbolic Ayyubid leadership in Egypt, with strongman Qutuz officially taking power. Meanwhile, an Ayyubid army was assembled at Birzeh, just north of Damascus to defend the city against the Mongols who were now marching towards northern Syria. Aleppo was soon besieged within a week and in January 1260 it fell to the Mongols. The Great Mosque and the Citadel of Aleppo were razed and most of the inhabitants were killed or sold into slavery.[76] The destruction of Aleppo caused panic in Muslim Syria; The Ayyubid emir of Homs, al-Ashraf Musa, offered to ally with Mongols at the approach of their army and was allowed to continue governance of the city by Hulagu. Hama also capitulated without resisting, but did not join forces with the Mongols.[77] An-Nasir Yusuf opted to flee Damascus to seek protection in Gaza.[76]</p><p>Hulagu departed for Karakorum and left Kitbuqa, a Nestorian Christian general, to continue the Mongol conquest. Damascus capitulated after the arrival of the Mongol army, but was not sacked like other captured Muslim cities. However, from Gaza, an-Nasir Yusuf managed to rally the small garrison he left in the Citadel of Damascus to rebel against the Mongol occupation. The Mongols retaliated by launching a massive artillery assault on the citadel and when it became apparent that an-Nasir Yusuf was unable to relieve the city with a newly assembled army, the garrison surrendered.[76]</p><p>The Mongols proceeded by conquering Samaria, killing most of the Ayyubid garrison in Nablus, and then advanced south, as far as Gaza, unhindered. An-Nasir Yusuf was soon captured by the Mongols and used to persuade the garrison at Ajlun to capitulate. Afterward, the junior Ayyubid governor of Banyas allied with the Mongols,[77] who had now gained control of most of Syria and al-Jazira, effectively ending Ayyubid power in the region. On 3 September 1260, the Egypt-based Mamluk army led by Qutuz and Baibars challenged Mongol authority and decisively defeated their forces in the Battle of Ain Jalut, outside of Zir'in in the Jezreel Valley. Five days later, the Mamluks took Damascus and within a month, most of Syria was in Bahri Mamluk hands.[76] Meanwhile, an-Nasir Yusuf was killed in captivity.[78]</p><h3>Remnants of the dynasty</h3><p>Many of the Ayyubid emirs of Syria were discredited by Qutuz for collaborating with the Mongols, but since al-Ashraf Musa defected and fought alongside the Mamluks at Ain Jalut, he was allowed to continue his rule over Homs. Al-Mansur of Hama had fought alongside the Mamluks from the start of their conquest and because of this,[78] Hama continued to be ruled by the Ayyubid descendants of al-Muzaffar Umar. After al-Ashraf Musa's death in 1262, the new Mamluk sultan, Baibars, annexed Homs. The next year, al-Mughith Umar was tricked into surrendering Karak to Baibars and was executed soon after for having previously sided with the Mongols.[78]</p><p>The last Ayyubid ruler of Hama died in 1299 and Hama briefly passed through direct Mamluk suzerainty. However, in 1310, under the patronage of the Mamluk sultan al-Nasir Muhammad, Hama was restored to the Ayyubids under the well-known geographer and author Abu al-Fida. The latter died in 1331 and was succeeded by his son al-Afdal Muhammad, who eventually lost the favor of his Mamluk overlords. He was removed from his post in 1341 and Hama was formally placed under Mamluk rule.[79]</p><p>In southeastern Anatolia, the Ayyubids continued to rule the principality of Hisn Kayfa and managed to remain an autonomous entity, independent of the Mongol Ilkhanate, which ruled northern Mesopotamia until the 1330s. After the breakup of the Ilkhanate, their former vassals in the area, the Artuqids, waged war against the Ayyubids of Hisn Kayfa in 1334, but were decisively defeated, with the Ayyubids gaining the Artuqids' possessions on the left bank of the Tigris River.[80] In the 14th century, the Ayyubids rebuilt the castle of Hisn Kayfa which served as their stronghold. The Ayyubids of Hisn Kayfa were vassals of the Mamluks and later the Dulkadirids until being supplanted by the Ottoman Empire in the early 16th century.[81]</p><h2>Culture</h2><h3>Government</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/4/45/Ayyubid_Az_Zahir_1204_Aleppo.jpg/220px-Ayyubid_Az_Zahir_1204_Aleppo.jpg" width="220" height="219"><p>


				An Ayyubid coin minted in Aleppo bearing the name of Emir al-Zahir


				</p><p>
					Saladin structured the Ayyubid empire around the concept of collective sovereignty i.e. a confederation of principalities held together by the idea of family rule. Under this arrangement there existed numerous petty sultans while one family member, as-Sultan al-Mu'azzam, reigned supreme. After the death of Saladin, this coveted position became open to whomever was strong enough to seize it. Subsequent rivalry between the Ayyubids of Syria and Egypt reached a point where the rulers of each territory would at times collude with Crusaders against the other.[82] Ayyubid rule differed in these two regions. In Syria, each major city was ruled as a relatively independent principality under an Ayyubid family member, while in Egypt the long tradition of centralized rule enabled the Ayyubids to maintain direct control over the province from Cairo.[83] It was Baghdad, seat of the Caliphate, however, that exercised cultural and political hegemony over the Ayyubid territories, particularly those in Southwest Asia. For instance, the qadi (chief justice) of Damascus was still appointed by the Abbasids during Ayyubid rule.[82]</p><div class="gradientback"></div></div><div class="content"><p>Political power was concentrated in the Ayyubid household which was not necessarily characterized only by blood relation; slaves and intimates could acquire great, and even supreme power within it. It was a common occurrence for the mothers of young Ayyubid rulers to act as independent powers or in a few cases, rulers in their own right. Eunuchs exercised substantial power under the Ayyubids, serving as attendants and atabegs within the household or as emirs, governors, and army commanders outside the household. One of Saladin's most important supporters was the eunuch Baha ad-Din ibn Shaddad who helped him depose the Fatimids, dispossess their properties, and construct the wall of Cairo's citadel. Following the death of al-Aziz Uthman, he became the regent of his son al-Mansur and effectively ruled over Egypt for a short time before the arrival of al-Adil. Later sultans appointed eunuchs as deputy sultans and even awarded them sovereignty over certain cities, such as Shams al-Din Sawab who was given the Jaziran cities of Amid and Diyar Bakr in 1239.[84]</p><p>The Ayyubids had three principal means of recruiting the educated elites whom they needed to administer their cities and towns. Some of these local leaders, known as shaykhs, entered the service of an Ayyubid ruling household and thus their bids for power were supported from Ayyubid household revenues and influence. Others were paid directly out of revenues made from the diwan, a high governmental body of the state. The third method was assignment to the shaykhs of the revenues of charitable endowments, known as waqfs.[85] The Ayyubids, like their various predecessors in the region, had relatively few state agencies by which they could penetrate their cities and towns. To link themselves with the educated elite of their cities, they relied on the political usage of patronage practices. The assignment of waqf revenue to this elite was similar to the assignment of fiefs (iqta'at) to the commanders and generals of the army. In both cases, it enabled the Ayyubids to recruit a dependent, but not administratively subordinate elite.[86]</p><p>Following their conquest of Jerusalem in 1187, the Ayyubids under Saladin may have been the first to establish the position of amir al-hajj (commander of the pilgrimage) to protect the annual Hajj caravans leaving Damascus for Mecca with the appointment of Tughtakin ibn Ayyub to the office.[87]</p><p>The seat of Ayyubid government from Saladin's rule from the 1170s up to al-Adil's reign in 1218 had been Damascus. The city provided a strategic advantage in the constant war with the Crusaders and allowed the sultan to keep an eye on his relatively ambitious vassals in Syria and al-Jazira. Cairo was too remote to serve as a base of operations, but had always served as the economic foundation of the empire. This rendered the city a critical constituent in the repertoire of the Ayyubid possessions.[82] When Saladin was proclaimed sultan in Cairo in 1171, he chose the Fatimid-built Lesser Western Palace (part of a larger palace complex in Cairo isolated from the urban sprawl) as the seat of government. Saladin himself resided in the former Fatimid vizier palace, Turan-Shah took up a former Fatimid prince's living quarter, and their father occupied the Pearl Pavilion which was situated outside of Cairo overlooking the city's canal. The successive Ayyubid sultans of Egypt would live in the Lesser Western Palace.[88]</p><p>After al-Adil I seized the throne in Cairo and with it the sultanate of the Ayyubid oligarchy, the period of rivalry between Damascus and Cairo to become capital of the Ayyubid empire commenced. Under al-Adil and al-Kamil, Damascus continued as an autonomous province whose ruler reserved the right to designate his own heir, but during as-Salih Ayyub's rule, military campaigns against Syria reduced Damascus to a vassal of Cairo.[89] In addition, Ayyub established new rules both in administration and government in order to centralize his regime; he conferred the most prominent positions of the state to his close confidants, instead of his Ayyubid relatives. His wife Shajar al-Durr, for example, managed the affairs of Egypt while he was in Syria. Ayyub officially delegated his authority to his dead son Khalil and made al-Durr act formally on Khalil's behalf.[90]</p><h3>Demographics</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/c/c3/Minaret_of_the_Aleppo_Citadel_Mosque_Aleppo_Syria.jpg/220px-Minaret_of_the_Aleppo_Citadel_Mosque_Aleppo_Syria.jpg" width="220" height="293"><p>


				Minaret of the Great Mosque of the Aleppo Citadel, built by az-Zahir Ghazi in 1214


				</p><p>
					By the 12th century, Islam was the dominant religion in the Middle East. It is not certain, however, if it was the religion of the majority outside the Arabian Peninsula. Arabic was the language of high culture and of the urban population, although other languages dating to pre-Islamic rule were still being used to a certain extent.[91] Most Egyptians were speaking Arabic by the time the Ayyubids took power there.[92]</p><p>Kurdish was the mother tongue of the early Ayyubids, at the time of their departure from Dvin. Sultan Saladin spoke both Arabic and Kurdish, and likely Turkish as well.[93][94] According to Yasser Tabbaa, an anthropologist specializing in medieval Islamic culture,[95] the Ayyubid rulers who reigned in the late 12th-century were far removed from their Kurdish origins, and unlike their Seljuq predecessors and their Mamluk successors, they were firmly Arabized. Arabic culture and language[96] formed the main component of their identity instead of their Kurdish heritage.[97] Arabic surnames were much more prevalent among the Ayyubids, a tribe that had already been partially assimilated into the Arabic-speaking world before its members came to power, than non-Arabic names. Some exceptions included the non-Arabic surname Turan-Shah. Most of the Ayyubid rulers spoke fluent Arabic and a number of them, such as az-Zahir Ghazi, al-Mu'azzam Isa and the minor emirs of Hama, composed Arabic poetry.[98]</p><p>The Arabization of the Ayyubid ruling families differed starkly from the ranks of their armies, which lacked cultural cohesion, with Turks and Kurds dominating the cavalry and nomadic Turcomans and Arabs filling the ranks of the infantry. These groups typically settled in the pastoral areas outside of the cities, the centers of cultural life, and as such they were relatively isolated from the Arabic-dominant urban environment. This isolation allowed them to preserve their traditions.[99] It is thought that Saladin spoke Turkish to his military commanders.[94] Like their Fatimid predecessors, the Ayyubid rulers of Egypt maintained a substantial force of mamluks (military slaves). By the first half of the 13th century mamluks were mostly drawn from Kipchak Turks and Circassians and there is strong evidence that these forces continued to speak Kipchak Turkish.[100][101]</p><p>The majority of Syria's population in the 12th century consisted of Sunni Muslims, typically from Arab or Kurdish backgrounds. There were also sizable Muslim communities of Twelver Shias, Druzes, and Alawites. The Ismaili presence was small and most were of Persian origin, having migrated from Alamut. They mostly resided in the mountainous area near the northern Syrian coastline.[102] Large Christian communities existed in northern Syria, Palestine, Transjordan and Upper Mesopotamia. They were Aramaic-speaking and indigenous to the area, mostly belonging to the Syriac Orthodox Church. They lived in villages of Christian or mixed Christian and Muslim population, monasteries, and in small towns where they appear to have been on friendly terms with their Muslim neighbors. Ideologically, they were led by the Patriarch of Antioch.[103]</p><div class="gradientback"></div></div><div class="content"><p>In Yemen and Hadramaut, much of the population adhered to Shia Islam in its Zaydi form. The inhabitants of Upper Mesopotamia were made up of Sunni Muslim Kurds and Turks, although there was a significant Yazidi minority in that region as well. Jews were spread throughout the Islamic world and most Ayyubid cities had Jewish communities due to the important roles Jews played in trade, manufacture, finance, and medicine. In Yemen and some parts of Syria, Jews also lived in rural towns. The Ayyubid emir of Yemen in 1197–1202, al-Malik Mu'izz Isma'il, attempted to forcibly convert the Jews of Aden, but this process ceased after his death in 1202. Within the Jewish community, particularly in Egypt and Palestine, there existed a minority of Karaites.[91]</p><p>In Egypt, there were large communities of Coptic Christians, Melkites, Turks, Armenians, and Black Africans—the latter two groups had a large presence in Upper Egypt. Under the Fatimids, non-Muslims in Egypt generally prospered, with the exception of Caliph al-Hakim's reign. However, with Shirkuh's ascendancy to the vizier position, a number edicts were enacted against the non-Muslim population. With the advent of the Syrian expeditionary force (consisting of Oghuz Turks and Kurds) into Egypt, waves of maltreatment of minorities occurred, irrespective of religion.[104] These incidents occurred while Shirkuh and Saladin were viziers to the Fatimid caliph.[104]</p><p>At the beginning of Saladin's reign as sultan in Egypt, upon the encouragement of his adviser, Qadi al-Fadil, Christians were prohibited from employment in the fiscal administration, but various Ayyubid emirs continued to allow Christians to serve in their posts. A number of other regulations were imposed, including the bans on alcohol consumption, religious processions, and the ringing of church bells. Conversion of formerly high-ranking Christians and their families to Islam took place throughout the early period of Ayyubid rule.[105] According to historian Yaakov Lev, the persecution of non-Muslims had some permanent effects on them, but nonetheless, the effects were local and contained.[104] To manage Mediterranean trade, the Ayyubids permitted Europeans—mainly Italians, but also French and Catalans—to settle in Alexandria in large numbers. However, in the aftermath of the Fifth Crusade, 3,000 merchants from the area were arrested or expelled.[85]</p><p>The Ayyubids generally employed Kurds, Turks, and people from the Caucasus for the higher-ranking posts of the military and bureaucratic fields. Not much is known about the foot soldiers of the Ayyubid army, but the numbers of cavalrymen are known to have fluctuated between 8,500 and 12,000. The cavalry was largely composed of free-born Kurds, Turks, and Turkomans whom Ayyubid emirs and sultans purchased as slaves (mamluks). In addition, there existed Arab auxiliaries, former Fatimid units such as the Nubians, and separate Arab contingents—notably from the Kinaniyya tribe, who were largely devoted to the defense of Egypt. Rivalry between Kurdish and Turkish troops occurred occasionally when leading positions were at stake and towards the end of Ayyubid rule, Turks outnumbered Kurds in the army. Despite their Kurdish background, the sultans remained impartial to both groups.[106]</p><p>There is no accurate figure for the population of the various territories under Ayyubid rule. Colin McEvedy and Richard Jones suggest that in the 12th century, Syria had a population of 2.7 million, Palestine and Transjordan had 500,000 inhabitants, and Egypt had a population of under 5 million.[107] Josiah C. Russel <br>
							

											 
										

							</p><br><h1 lang="en">20th-century history of Iraq</h1><p> From Wikipedia, the free encyclopedia</p><p>After World War I, Iraq passed from the failing Ottoman Empire to British control. Britain established the Kingdom of Iraq in 1932. In the 14 July Revolution of 1958, the king was deposed and the Republic of Iraq was declared. In 1963, the Ba'ath Party staged a coup d'état and was in turn toppled by another coup in the same year, but managed to retake power in 1968. Saddam Hussein took power in 1979 and ruled Iraq for the remainder of the century, during the Iran–Iraq War of the 1980s, the Invasion of Kuwait and the Gulf War of 1990 to 1991 and the UN sanction during the 1990s. Saddam was removed from power in the 2003 invasion of Iraq.</p><h2>Contents</h2><h2>British Mandate of Mesopotamia</h2><p> Main article: British Mandate of Mesopotamia</p><p> Further information: Iraqi revolt against the British</p><p>Ottoman rule over Iraq lasted until the World War I when the Ottomans sided with Germany and the Central Powers. In the Mesopotamian campaign against the Central Powers, British forces invaded the country and suffered a major defeat at the hands of the Turkish army during the Siege of Kut (1915–16). British forces regrouped and captured Baghdad in 1917. An armistice was signed in 1918.</p><br><img alt="LittleIraq.png" src="http://upload.wikimedia.org/wikipedia/commons/9/97/LittleIraq.png" width="165" height="178"><p>Iraq was carved out of the Ottoman Empire by the French and British as agreed in the Sykes-Picot Agreement. The Sykes-Picot agreement was a secret agreement between UK and France with the assent of Imperial Russia, defining their respective sphere of influence and control in West Asia after the expected downfall of the Ottoman Empire during World War I. The Agreement was concluded on 16 May 1916.[1] On 11 November 1920 it became a League of Nations mandate under British control with the name State of Iraq.</p><p>Britain imposed a Hashimite monarchy on Iraq and defined the territorial limits of Iraq without taking into account the politics of the different ethnic and religious groups in the country, in particular those of the Kurds and the Assyrians to the north. During the British occupation, the Shi'ites and Kurds fought for independence.</p><p>Faced with spiralling costs and influenced by the public protestations of war hero T. E. Lawrence in The Times, Britain replaced Arnold Wilson in October 1920 with new Civil Commissioner Sir Percy Cox. Cox managed to quell the rebellion, yet was also responsible for implementing the fateful policy of close cooperation with Iraq's Sunni minority.[2][3]</p><p>In the Mandate period and beyond, the British supported the traditional, Sunni leadership (such as the tribal shaykhs) over the growing, urban-based nationalist movement. The Land Settlement Act gave the tribal shaykhs the right to register the communal tribal lands in their own name. The Tribal Disputes Regulations gave them judiciary rights, whereas the Peasants' Rights and Duties Act of 1933 severely reduced the tenants', forbidding them to leave the land unless all their debts to the landlord had been settled. The British resorted to military force when their interests were threatened, as in the 1941 Rashid `Ali al-Gaylani coup. This coup led to a British invasion of Iraq using forces from the British Indian Army and the Arab Legion from Jordan.</p><h2>Kingdom of Iraq</h2><p> Further information: Kingdom of Iraq and List of Kings of Iraq</p><p>Emir Faisal, leader of the Arab revolt against the Ottoman sultan during the Great War, and member of the Sunni Hashimite family from Mecca, became the first king of the new state. He obtained the throne partly by the influence of T. E. Lawrence. Although the monarch was legitimized and proclaimed King by a plebiscite in 1921, nominal independence was only achieved in 1932, when the British Mandate officially ended.</p><div class="gradientback"></div></div><div class="content"><p>In 1927, huge oil fields were discovered near Kirkuk and brought economic improvement. Exploration rights were granted to the Iraqi Petroleum Company, which despite the name, was a British oil company. King Faisal I was succeeded by his son Ghazi in December 1933. King Ghazi's reign lasted five and a half years. He claimed Iraqi sovereignty over Kuwait. An avid amateur racer, the king drove his car into a lamppost and died 3 April 1939. His son Faisal followed him to the throne.</p><p>King Faisal II (1935–1958) was the only son of King Ghazi I and Queen `Aliyah. The new king was four when his father died. His uncle 'Abd al-Ilah became regent (April 1939 – May 1953). Abd al-llah's appointment changed the delicate balance between the palace, the officer corps, the civilian political elite and the British. Abd al-llah differed from his late brother-in-law in that he was more tolerant of the continued British presence in Iraq. Indeed, he was in some respect positively enthusiastic about the link with Great Britain, seeing it as one of the principal guarantors of the Hashemite dynasty. This meant that he had little in common with the Arab nationalist army officers whom he tended to regard as social upstarts, unworthy of his cultivation.[4]</p><p>In 1945, Iraq joined the United Nations and became a founding member of the Arab League. At the same time, the Kurdish leader Mustafa Barzani led a rebellion against the central government in Baghdad. After the failure of the uprising Barzani and his followers fled to the Soviet Union.</p><p>In 1948, Iraq entered the 1948 Arab-Israeli War along with other members of the Arab League in order to defend Palestinian rights. Iraq was not a party to the cease-fire agreement signed in May 1949. The war had a negative impact on Iraq's economy. The government had to allocate 40 percent of available funds to the army and for the Palestinian refugees. Oil royalties paid to Iraq were halved when the pipeline to Haifa was cut.</p><p>Iraq signed the Baghdad Pact in 1956. It allied Iraq, Turkey, Iran, Pakistan, and the United Kingdom. Its headquarters were in Baghdad. The Pact constituted a direct challenge to Egyptian president Gamal Abdal Nasser. In response, Nasser launched a media campaign that challenged the legitimacy of the Iraqi monarchy.</p><p>In February 1958, King Hussein of Jordan and `Abd al-Ilah proposed a union of Hashimite monarchies to counter the recently formed Egyptian-Syrian union. The prime minister Nuri as-Said wanted Kuwait to be part of the proposed Arab-Hashimite Union. Shaykh `Abd-Allah as-Salim, the ruler of Kuwait, was invited to Baghdad to discuss Kuwait's future. This policy brought the government of Iraq into direct conflict with Britain, which did not want to grant independence to Kuwait. At that point, the monarchy found itself completely isolated. Nuri as-Said was able to contain the rising discontent only by resorting to ever greater political oppression.</p><h2>Republic of Iraq</h2><h3>Formation</h3><p>Inspired by Nasser, officers from the Nineteenth Brigade known as Free Officers, under the leadership of Brigadier Abd al-Karim Qasim (known as az-Za`im, 'the leader') and Colonel Abdul Salam Arif overthrew the Hashimite monarchy on 14 July 1958. King Faisal II and `Abd al-Ilah were executed in the gardens of ar-Rihab Palace. Their bodies (and those of many others in the royal family) were displayed in public. Nuri as-Said evaded capture for one day, but after attempting to escape disguised as a veiled woman, he was caught and shot.</p><p>The new government proclaimed Iraq to be a republic and rejected the idea of a union with Jordan. Iraq's activity in the Baghdad Pact ceased.</p><p>When Qasim distanced himself from `Abd an-Nasir, he faced growing opposition from pro-Egypt officers in the Iraqi army. `Arif, who wanted closer cooperation with Egypt, was stripped of his responsibilities and thrown in prison.</p><p>When the garrison in Mosul rebelled against Qasim's policies, he allowed the Kurdish leader Barzani to return from exile in the Soviet Union to help suppress the pro-Nasir rebels.</p><h3>1960s</h3><p>In 1961, Kuwait gained independence from Britain and Iraq claimed sovereignty over Kuwait. As in the 1930s, Qasim based Iraq's claim on the assertion that Kuwait had been a district of the Ottoman province of Basra, unjustly severed by the British from the main body of Iraqi state when it had been created in the 1920s.[5] Britain reacted strongly to Iraq's claim and sent troops to Kuwait to deter Iraq. Qasim was forced to back down and in October 1963, Iraq recognized the sovereignty of Kuwait.</p><p>A period of considerable instability followed. Qasim was assassinated in February 1963, when the Ba'ath Party took power under the leadership of General Ahmed Hasan al-Bakr (prime minister) and Colonel Abdul Salam Arif (president). Nine months later `Abd as-Salam Muhammad `Arif led a successful coup against the Ba'ath government. On 13 April 1966, President Abdul Salam Arif died in a helicopter crash and was succeeded by his brother, General Abdul Rahman Arif. Following the Six Day War of 1967, the Ba'ath Party felt strong enough to retake power (17 July 1968). Ahmad Hasan al-Bakr became president and chairman of the Revolutionary Command Council (RCC).</p><p>In 1967-1968 Iraqi communists launched an insurgency in southern Iraq.[6]</p><p>Barzani and the Kurds who had begun a rebellion in 1961 were still causing problems in 1969. The secretary-general of the Ba`ath party, Saddam Hussein, was given responsibility to find a solution. It was clear that it was impossible to defeat the Kurds by military means and in 1970 a political agreement was reached between the rebels and the Iraqi government.</p><p>Iraq's economy recovered sharply after the 1968 revolution. The Arif brothers had spent close to 90% of the national budget on the army but the Ba'ath government gave priority to agriculture and industry. The British Iraq Petroleum Company monopoly was broken when a new contract was signed with ERAP, a major French oil company. Later the IPC was nationalized. As a result of these policies Iraq experienced rapid economic growth.</p><h3>1970s</h3><p>During the 1970s, border disputes with Iraq and Kuwait caused many problems. Kuwait's refusal to allow Iraq to build a harbor in the Shatt al-Arab delta strengthened Iraq's belief that foreign powers in the region were trying to control the Persian Gulf. Iran's occupation of numerous islands in the Strait of Hormuz didn't help alter Iraq's fears. The border disputes between Iraq and Iran were temporarily resolved with the signing of the Algiers Accord on 6 March 1975.</p><p>In 1972 an Iraqi delegation visited Moscow. The same year diplomatic relations with the US were restored. Relations with Jordan and Syria were good. Iraqi troops were stationed in both countries. During the 1973 October War, Iraqi divisions engaged Israeli forces.</p><p>In retrospect, the 1970s can be seen as a high point in Iraq's modern history. A new, young, technocratic elite was governing the country and the fast-growing economy brought prosperity and stability. Many Arabs outside Iraq considered it an example. However, the following decades would not be as favorable for the fledgling country.</p><h3>Rise to power of Saddam Hussein</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/a/a2/Saddam1970s.jpg/220px-Saddam1970s.jpg" width="220" height="163"><div class="gradientback"></div></div><div class="content"><p>


				Promoting women's education in the 1970s.


				</p><p>
					In July 1979, President Ahmed Hassan al-Bakr resigned, and his chosen successor, Saddam Hussein, assumed the offices of both President and Chairman of the Revolutionary Command Council. He was the de facto ruler of Iraq for some years before he formally came to power. The Baath Party was now a country wide organisation, reaching down to the smallest village and most modest neighbourhood in an unprecedented way. In addition, the Popular army and the youth organisation brought ever larger numbers into the paramilitary formations established by the regime. Finally, Saddam Hussein established a National Assembly in March 1980, setting up the first parliament since the overthrow of the Monarchy in 1958. It was meant to create the impression of national unity and to give Saddam Hussain another forum for presenting himself as the national leader.[7]</p><p>The new regime modernized the countryside and rural areas of Iraq, mechanizing agriculture and establishing farm cooperatives.[8]</p><p>Saddam's organizational prowess was credited with Iraq's rapid pace of development in the 1970s; development went forward at such a fevered pitch that two million persons from other Arab countries and even Yugoslavia worked in Iraq to meet the growing demand for labor.</p><p>However, Hussein's ambition soon led him to be involved in various conflicts, with disastrous results to the infrastructure of Iraq.</p><h3>Iran-Iraq war</h3><p> Main article: Iran–Iraq War</p><p>Territorial disputes with Iran led to an inconclusive and costly eight-year war, the Iran–Iraq War (1980–1988, termed Qadisiyyat-Saddam – 'Saddam's Qadisiyyah'), which devastated the economy. Iraq declared victory in 1988 but actually achieved a weary return to the status quo ante bellum. The war left Iraq with the largest military establishment in the Persian Gulf region but with huge debts and an ongoing rebellion by Kurdish elements in the northern mountains. The government suppressed the rebellion using chemical weapons on the rebels. Eight years of war had taken a terrible toll of the Iraqi population: the war had cost Iraq an estimated quarter of those had been victims of the Iraqi Kurds; over 60,000 Iraqis remained prisoners of the Iranians; nearly one million Iraqis now served in the armed forces.[9]</p><p>Between 1986 and 1989, Hussein's Al-Anfal Campaign is alleged to have killed an estimated 100,000 to 200,000 Kurdish civilians.[10][11]</p><p>A mass chemical weapons attack on the city of Halabja in March 1988 during the Iran–Iraq War is usually attributed to Saddam's regime, although responsibility for the attack is a matter of some dispute.[12] Saddam maintained his innocence in this matter up to his execution in December 2006. Almost all current accounts, influenced by special interests, of the incident regard the Iraqi regime as the party responsible for the gas attack (as opposed to Iran), and the event has become iconic in depictions of Saddam's cruelty. Estimates of casualties range from several hundred to at least 7,000 people. The Iraqi government continued to be supported by a broad international community including most of the West, the Soviet Union, and the People's Republic of China, which continued sending arms shipments to combat Iran. Indeed, shipments from the US (though always a minority) increased after this date, and the UK awarded £400 million in trade credits to Iraq ten days after condemning the massacre [3].</p><p>In the late 1970s, Iraq purchased a French nuclear reactor, dubbed Osirak or Tammuz 1. Construction began in 1979. In 1980, the reactor site suffered minor damage due to an Iranian air strike, and in 1981, before the reactor could be completed, it was, in violation of International Laws[citation needed], destroyed by the Israeli Air Force (see Operation Opera).</p><h3>1990 Invasion of Kuwait and the Gulf War</h3><p> Main articles: Invasion of Kuwait and Gulf War</p><p>A long-standing territorial dispute led to the invasion of Kuwait in 1990. Iraq accused Kuwait of violating the Iraqi border to secure oil resources, and demanded that its debt repayments should be waived. Direct negotiations began in July 1990, but they soon failed. Saddam Hussein had an emergency meeting with April Glaspie, the United States Ambassador to Iraq, on 25 July 1990, airing his concerns but stating his intention to continue talks. April Glaspie informed Saddam that the United States had no interest in border disputes between Iraq and Kuwait, as was the U.S. government's official tone on the subject at the time. Subsequent events would prove otherwise, however this was said to Saddam in hopes that it would prevent him from attacking.</p><p>Arab mediators convinced Iraq and Kuwait to negotiate their differences in Jiddah, Saudi Arabia, on 1 August 1990, but that session resulted only in charges and counter-charges. A second session was scheduled to take place in Baghdad, but Iraq invaded Kuwait the following day. Iraqi troops overran the country shortly after midnight on 2 August 1990. The United Nations Security Council and the Arab League immediately condemned the Iraqi invasion. Four days later, the Security Council imposed an economic embargo on Iraq that prohibited nearly all trade with Iraq.</p><p>Iraq responded to the sanctions by annexing Kuwait as the 19th Province of Iraq on 8 August, prompting the exiled Sabah family to call for a stronger international response. Over the ensuing months, the United Nations Security Council passed a series of resolutions that condemned the Iraqi occupation of Kuwait and implemented total mandatory economic sanctions against Iraq. Other countries subsequently provided support for Operation Desert Shield. Acting on the policy of the Carter Doctrine, and out of fear the Iraqi Army cauld launch an invasion of Saudi Arabia, U.S. President George H. W. Bush quickly announced that the U.S. would launch a wholly defensive mission to prevent Iraq from invading Saudi Arabia. Operation Desert Shield was when U.S. troops were moved into Saudi Arabia on 7 August 1990.[13] In November 1990, the UN Security Council adopted Resolution 678, permitting member states to use all necessary means, authorizing military action against the Iraqi forces occupying Kuwait and demanded a complete withdrawal by 15 January 1991.</p><p>When Saddam Hussein failed to comply with this demand, the Gulf War (Operation Desert Storm) ensued on 17 January 1991 (3am Iraqi time), with allied troops of 28 countries, led by the US launching an aerial bombardment on Baghdad. The war, which proved disastrous for Iraq, lasted only six weeks. One hundred and forty-thousand tons of munitions had showered down on the country, the equivalent of seven Hiroshima bombs. Probably as many as 30,000 Iraqi soldiers and a few thousand of civilians were killed.</p><p>Allied air raids destroyed roads, bridges, factories, and oil-industry facilities (shutting down the national refining and distribution system) and disrupted electric, telephone, and water service. On 13 February 1991, hundreds of Iraqis were killed in the attack on the Al-Amiriyah bomb shelter. Diseases spread through contaminated drinking water because water purification and sewage treatment facilities could not operate without electricity.</p><p>A cease-fire was announced by the US on 28 February 1991. UN Secretary-General Javier Pérez de Cuéllar met with Saddam Hussein to discuss the Security Council timetable for the withdraw of troops from Kuwait. Iraq agreed to UN terms for a permanent cease-fire in April 1991, and strict conditions were imposed, demanding the disclosure and destruction of all stockpiles of weapons.</p><p>In March 1991 revolts in the Shia-dominated southern Iraq started involving demoralized Iraqi Army troops and the anti-government Shia parties. Another wave of insurgency broke out shortly afterwards in the Kurdish populated northern Iraq (see 1991 uprisings in Iraq). Although they presented a serious threat to the Iraqi Ba'ath Party regime, Saddam Hussein managed to suppress the rebellions with massive and indiscriminate force and maintained power. They were ruthlessly crushed by the loyalist forces spearheaded by the Iraqi Republican Guard and the population was successfully terrorized. During the few weeks of unrest tens of thousands of people were killed. Many more died during the following months, while nearly two million Iraqis fled for their lives. In the aftermath, the government intensified the forced relocating of Marsh Arabs and the draining of the Iraqi marshlands, while the Allies established the Iraqi no-fly zones.</p><div class="gradientback"></div></div><div class="content"><h3>Iraq under UN Sanction</h3><p>On 6 August 1990, after the Iraqi invasion of Kuwait, the U.N. Security Council adopted Resolution 661 which imposed economic sanctions on Iraq, providing for a full trade embargo, excluding medical supplies, food and other items of humanitarian necessity, these to be determined by the Security Council sanctions committee. After the end of the Gulf War and after the Iraqi withdrawal from Kuwait, the sanctions were linked to removal of weapons of mass destruction by Resolution 687 [4]. From 1991 until 2003 the effects of government policy and sanctions regime led to hyperinflation, widespread poverty and malnutrition. The historically generous state welfare provision that had been central to the regime's governing strategy disappeared overnight. The large and well-educated middle class that had grown in the years of plenty to form the bedrock of Iraqi society was impoverished. The story of Iraq from 1991 until 2003 is of a country suffering a profound macroeconomic shock.[14]</p><p>The United States, citing a need to prevent the genocide of the Marsh Arabs in southern Iraq and the Kurds to the north, declared air exclusion zones north of the 36th parallel and south of the 32nd parallel. The Clinton administration judged an alleged assassination attempt on former President George H. W. Bush by Iraqi secret agents to be worthy of a military response on 27 June 1993. The Iraqi Intelligence Headquarters in Baghdad was targeted by Tomahawk cruise missiles.</p><p>During the time of the UN sanctions, internal and external opposition to the Ba'ath government was weak and divided. In May 1995, Saddam sacked his half-brother, Wathban, as Interior Minister and in July demoted his Defense Minister, Ali Hassan al-Majid. These personnel changes were the result of the growth in power of Saddam Hussein's two sons, Uday Hussein and Qusay Hussein, who were given effective vice-presidential authority in May 1995. In August Major General Husayn Kamil Hasan al-Majid, Minister of Military Industries and a political ally of Saddam, defected to Jordan, together with his wife (one of Saddam's daughters) and his brother, Saddam, who was married to another of the president's daughters; both called for the overthrow of the Iraqi government. After a few weeks in Jordan, being given promises for their safety, the two brothers returned to Iraq where they were killed.</p><p>During the latter part of the 1990s the UN considered relaxing the sanctions imposed because of the hardships suffered by ordinary Iraqis. According to UN estimates, between 500,000 and 1.2 million children died [5] during the years of the sanctions. The United States used its veto in the UN Security Council to block the proposal to lift the sanctions because of the continued failure of Iraq to verify disarmament. However, an oil for food program was established in 1996 to ease the effects of sanctions. The cause of excess deaths is disputed.</p><p>Iraqi cooperation with UN weapons inspection teams was questioned on several occasions during the 1990s. UNSCOM chief weapons inspector Richard Butler withdrew his team from Iraq in November 1998 because of Iraq's lack of cooperation. The team returned in December.[15] Butler prepared a report for the UN Security Council afterwards in which he expressed dissatisfaction with the level of compliance [6]. The same month, US President Bill Clinton authorized air strikes on government targets and military facilities. Air strikes against military facilities and alleged WMD sites continued into 2002.</p><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=20th-century_history_of_Iraq&amp;oldid=781768516"					
								Categories:  Hidden categories:</p><br><h1 lang="en">Kingdom of Iraq</h1><p> From Wikipedia, the free encyclopedia</p><p>The Hashemite Kingdom of Iraq (Arabic: ??????? ???????? ?????????? al-Mamlakah al-‘Iraqiyyah Al-Hashimiyah) was founded on 23 August 1921 under British administration following the defeat of the Ottoman Empire in the Mesopotamian campaign of World War I. Although a League of Nations mandate was awarded to Britain in 1920, the 1920 Iraqi revolt resulted in the scrapping of the original mandate plan in favor of a British administered semi-independent kingdom, under the Hashemite allies of Britain, via the Anglo-Iraqi Treaty. The kingdom of Iraq was granted full independence in 1932,[1] following the Anglo-Iraqi Treaty (1930). The independent Iraqi Kingdom under the Hashemite rulers underwent a period of turbulence through its entire existence. Establishment of Sunni religious domination in Iraq was followed by Assyrian, Yazidi and Shi'a unrests, which were all brutally suppressed.[citation needed] In 1936, the first military coup took place in the Kingdom of Iraq, as Bakr Sidqi succeeded in replacing the acting Prime Minister with his associate. Multiple coups followed in a period of political instability, peaking in 1941.</p><p>During World War II, the Iraqi regime of Regent 'Abd al-Ilah was overthrown in 1941 by the Golden Square officers, headed by Rashid Ali. The short-lived pro-Nazi government of Iraq was defeated in May 1941 by the allied forces in the Anglo-Iraqi War. Iraq was later used as a base for allied attacks on the Vichy-French-held Mandate of Syria and support for the Anglo-Soviet invasion of Iran. At the same time, the Kurdish leader Mustafa Barzani led a rebellion against the central government in Baghdad. After the failure of the uprising Barzani and his followers fled to the Soviet Union.</p><p>In 1945, during the final stages of World War II, Iraq joined the United Nations and became a founding member of the Arab League. In 1948, massive violent protests, known as the Al-Wathbah uprising broke out across Baghdad as a popular demand against the government treaty with the British, and with communist party support. More protests continued in spring, but were interrupted in May, with the martial law, when Iraq entered the 1948 Arab-Israeli War along with other members of the Arab League.</p><p>In February 1958, King Hussein of Jordan and `Abd al-Ilah proposed a union of Hashimite monarchies to counter the recently formed Egyptian-Syrian union.[citation needed] The resulting Arab Federation, formed on 14 February 1958 was short-lived. It ended in 1958, when the monarchy was overthrown in a military coup, led by Abd al-Karim Qasim.</p><h2>Contents</h2><h2>Prior to independence - British administration</h2><p> Main article: Mandatory Iraq</p><p>The territory of Iraq was under Ottoman dominance until the end of World War I, becoming an occupied territory under British military from 1918. In order to transform the region to civil rule, Mandatory Mesopotamia was proposed as a League of Nations Class A mandate under Article 22 and entrusted to Britain, when the former territories Ottoman Empire were divided in August 1920 by the Treaty of Sèvres. However, the 1920 Iraqi revolt resulted in the scrapping of the original mandate plan in favor of British administered semi-independent kingdom, under the Hashemite allies of Britain, via the Anglo-Iraqi Treaty.</p><p>Faisal ibn Husayn, who had previously been proclaimed King of Syria by a Syrian National Congress in Damascus in March 1920, was ejected by the French in July of the same year. Faisal was then granted the territory of Iraq, to rule it as a protected kingdom, with the British RAF retaining certain military control, though de facto, the territory remained under British administration until 1932.</p><p>The civil government of postwar Iraq was headed originally by the High Commissioner, Sir Percy Cox, and his deputy, Colonel Arnold Wilson. British reprisals after the murder of a British officer in Najaf failed to restore order. British administration had yet to be established in the mountains of north Iraq. The most striking problem facing the British was the growing anger of the nationalists.</p><h2>History</h2><h3>Independence</h3><div class="gradientback"></div></div><div class="content"><p>With the signing of the Anglo-Iraqi Treaty and the settling of the Mosul Question, Iraqi politics took on a new dynamic. The emerging class of Sunni and Shia landowning tribal sheikhs vied for positions of power with wealthy and prestigious urban-based Sunni families and with Ottoman-trained army officers and bureaucrats. Because Iraq's newly established political institutions were the creation of a foreign power, and because the concept of democratic government had no precedent in Iraqi history, the politicians in Baghdad lacked legitimacy and never developed deeply rooted constituencies. Thus, despite a constitution and an elected assembly, Iraqi politics was more a shifting alliance of important personalities and cliques than a democracy in the Western sense. The absence of broadly based political institutions inhibited the early nationalist movement's ability to make deep inroads into Iraq's diverse social structure.</p><p>The new Anglo-Iraqi Treaty was signed in June 1930. It provided for a close alliance, for full and frank consultations between the two countries in all matters of foreign policy, and for mutual assistance in case of war. Iraq granted the British the use of air bases near Basra and at Al Habbaniyah and the right to move troops across the country. The treaty, of twenty-five years' duration, was to come into force upon Iraq's admission to the League of Nations. This occurred on October 3, 1932.</p><p>In 1932, the Kingdom of Iraq was granted independence under King Faisal I. However the British retained military bases in the country. Iraq was granted official independence on October 3, 1932 in accordance with an agreement signed by the United Kingdom in 1930, whereby the United Kingdom would end its effective mandate on the condition that the Iraqi government would allow British advisers to take part in government affairs, allow British military bases to remain, and a requirement that Iraq assist the United Kingdom in wartime.[2] Strong political tensions existed between Iraq and the United Kingdom even upon gaining independence. After gaining independence in 1932, the Iraqi government immediately declared that Kuwait was rightfully a territory of Iraq, as loosely been under the authority of the Ottoman vilâyet of Basra for centuries until the British had formally severed Kuwait from the Ottoman influence after World War I and thus stated that Kuwait was a British imperialist invention.[3]</p><h3>Political instability and army coups, 1933–1941</h3><p>After Faisal died in 1933, King Ghazi reigned as a figurehead from 1933 to 1939, when he was killed in a motor accident. Pressure from Arab nationalists and Iraqi nationalists demanded that the British leave Iraq, but their demands were ignored by the United Kingdom.</p><p>Upon achieving independence in 1932, political tensions arose over the continued British presence in Iraq, with Iraq's government and politicians split between those considered pro-British politicians such as Nuri as-Said, who did not oppose a continued British presence and anti-British politicians, such as Rashid Ali al-Gaylani, who demanded that remaining British influence in the country be removed.[4]</p><p>Various ethnic and religious factions tried to gain political accomplishments during this period, often resulting in violent revolts and a brutal suppression by the Iraqi military, led by Bakr Sidqi. In 1933, thousands of Assyrians were killed in Simele massacre, in 1935–1936 a series of Shi'a uprisings were brutally suppressed in mid-Euphrates region of Iraq,[5] and in parallel an anti-conscription Kurdish uprising in the north and a Yazidi revolt in Jabal Sinjar were crushed in 1935. Throughout the period political instability led to an exchange of numerous governments. Bakr Sidqi himself ascended to power in 1936, following a successful coup d'état.</p><p>From 1917 to 1946, five coups by the Iraqi Army occurred, led by the chief officers of the army against the government to pressure the government to concede to army demands.[4]</p><h3>Anglo-Iraqi War and Second British Occupation</h3><p>The 1941 Iraqi coup d'état overthrew Nuri as-Said and placed Rashid Ali al-Gaylani as prime minister of a pro-Nazi government. Ali did not overthrow the monarchy, but installed a more compliant Regent, and attempted to restrict the rights of the British under the treaty from 1930. Rashid Ali's attempted to secure control over Iraq asking assistance of Nazi Germany, Fascist Italy and Imperial Japan.</p><p>On April 20 the Iraqi Army established itself on the high ground to the south of the Habbaniya air force base. An Iraqi envoy was sent to demand that no movements, either ground or air, were to take place from the base. The British refused the demand and then themselves demanded that the Iraqi army leave the area at once. After a further ultimatum given in the early hours of May 2 expired, at 0500 hours the British began bombing the Iraqi troops threatening the base, marking the beginning of the Anglo-Iraqi War.</p><p>Hostilities lasted from May 2 to May 31, 1941 between Iraqis and the British and their indigenous Assyrian Levies. The British would continue to occupy Iraq for many years afterwards.</p><p>In the aftermath of the Iraqi defeat, a bloody Farhud massacre broke out in Baghdad on June 2, initiated by the Futuwwa youth and Rashid Ali's supporters, resulting in deaths of some 180 Jews and heavy damage to the Jewish community.</p><h3>1941–1958</h3><p>After the Anglo-Iraqi War ended, Nuri as-Said returned as Prime Minister and dominated the politics of Iraq until the overthrow of the monarchy and his assassination in 1958. Nuri as-Said pursued a largely pro-western policy during this period.[6]</p><h2>Republic declared</h2><p>The Hashemite monarchy lasted until 1958, when it was overthrown through a coup d'état by the Iraqi Army, known as the 14 July Revolution. King Faisal II along with members of the royal family were executed. The coup brought Abd al-Karim Qasim to power. He withdrew from the Baghdad Pact and established friendly relations with the Soviet Union.</p><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Kingdom_of_Iraq&amp;oldid=783214096"					
								Categories:  Hidden categories:</p><br><h1 lang="en">History of Iraq (2011–present)</h1><p> From Wikipedia, the free encyclopedia</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/6/61/Syria_and_Iraq_2014-onward_War_map.png/260px-Syria_and_Iraq_2014-onward_War_map.png" width="260" height="199"><p>


				000000002017-03-10-0000March 10, 2017 military situation in Iraq and Syria:
				&nbsp;&nbsp;Controlled by Iraqi government
				&nbsp;&nbsp;Controlled by the Islamic State in Iraq and Syria (ISIS/ISIL)
				&nbsp;&nbsp;Controlled by Iraqi Kurds
				&nbsp;&nbsp;Controlled by Syrian government
				&nbsp;&nbsp;Controlled by Syrian rebels
				&nbsp;&nbsp;Controlled by Syrian Kurds



				 
				</p><p>
					The departure of US troops from Iraq in 2011 ended the period of occupation that had begun with the U.S.-led invasion in March 2003. The time since U.S. withdrawal has been marked by a renewed Iraqi insurgency and by a spillover of the Syrian civil war into Iraq. By 2013, the insurgency escalated into a renewed civil war, the central government of Iraq being opposed by various factions, primarily radical Sunni forces.</p><div class="gradientback"></div></div><div class="content"><p>ISIS forces have seized the majority of Anbar province,[1] including the cities of Fallujah,[2] Al Qaim,[3] Abu Ghraib[4] and (in May 2015) Ramadi,[5] leaving them in control of 90% of Anbar.[6][7] Tikrit, Mosul and most of the Nineveh province, along with parts of Salahuddin, Kirkuk and Diyala provinces, were seized by insurgent forces in the June 2014 offensive.[8] ISIS captured Sinjar and a number of other towns in the August 2014 offensive, but Sinjar became a contested city in December 2014.</p><h2>Contents</h2><h2>Insurgency (2011–2013)</h2><p> Main article: Iraqi insurgency (2011–2013)</p><p>Sectarian violence continued in the first half of 2013 with at least 56 people killed in April when a Sunni protest in Hawija was interrupted by a government-supported helicopter raid. On 20 May 2013, at least 95 people died in a wave of car bomb attacks that was preceded by a car bombing on 15 May that led to 33 deaths; also, on 18 May, 76 people were killed in the Sunni areas of Baghdad.[9][10] On 22 July 2013, at least five hundred convicts, most of whom were senior members of al-Qaida who had received death sentences, broke out of Iraq's Abu Ghraib jail when comrades launched a military-style assault to free them. The attack began when a suicide bomber drove a car packed with explosives into prison gates.[11] James F. Jeffrey, the United States ambassador in Baghdad when the last American troops exited, said the assault and resulting escape will provide seasoned leadership and a morale boost to Al Qaeda and its allies in both Iraq and Syria ... it is likely to have an electrifying impact on the Sunni population in Iraq, which has been sitting on the fence.[12]</p><h2>Civil war (2014–present)</h2><p> Main article: Iraq War (2014–present)</p><p>By mid-2014 the country was in chaos with a new government yet to be formed following national elections, and the insurgency reaching new heights. In early June 2014 the Islamic State in Iraq and the Levant (ISIS) took over the cities of Mosul and Tikrit and said it was ready to march on Baghdad, while Iraqi Kurdish forces took control of key military installations in the major oil city of Kirkuk. Prime Minister Nouri al-Maliki asked his parliament to declare a state of emergency that would give him increased powers, but the lawmakers refused.[13]</p><p>In the summer of 2014 U.S. President Obama announced a renewed military intervention in the form of aerial support, with the aim of halting the advance of ISIS forces and rendering humanitarian aid to stranded refugees and stabilize the political situation.[14]</p><p>Since June 2014, al-Maliki had faced growing pressure to resign, including from the United States.[15] In July 2014, the Kurdish Regional Government demanded his resignation,[16] and his own party (the Islamic Dawa Party) began looking for a new leader.[17]</p><p>On 14 August 2014, Prime Minister Nouri al-Maliki succumbed to the pressure at home and abroad to step down. Iraq's new president, Fuad Masum, appointed a new prime minister, Haider al-Abadi on 19 August 2014.[18] However, for the appointment to take effect, al-Abadi needed to form a government and be confirmed by Parliament, within 30 days.[19] After initially expressing opposition to al-Abadi's selection, al-Maliki endorsed al-Abadi and said he would not stand in the way.[20]</p><p>In what was claimed to be revenge for the aerial bombing ordered by President Obama, ISIS, which by this time had changed their name to the Islamic State, beheaded an American journalist, James Foley, who had been kidnapped two years previously. Despite U.S. bombings and breakthroughs on the political front, Iraq remained in chaos with the Islamic State consolidating its gains, and sectarian violence continuing unabated. On 22 August 2014, suspected Shia militants opened fire on a Sunni mosque during Friday prayers, killing 70 worshippers. Separately, Iraqi forces in helicopters killed 30 Sunni fighters in the town of Dhuluiya.[21] A day later, apparently in retaliation for the attack on the mosque, three bombings across Iraq killed 35 people.[22]</p><p>The Kurdish Regional Government has participated in fighting ISIL, while also taking other territory (such as Kirkuk).[23] Since August 2014, the U.S. has also been bombing ISIL positions.[24] In late January 2015, Iraqi forces recaptured the entire province of Diyala from the Islamic State.[25] On 2 March, Second Battle of Tikrit began.[26] and after more than a month of hard fighting, Iranians, Iraqis and Shiite militia overcame ISIL fighters and took Tikrit. This success was off-set in late May, by ISIL's capture of the provincial capital of Ramadi in Anbar province.</p><li>^ John Kerry holds talks in Iraq as more cities fall to ISIS militants. CNN. 23 June 2014.&nbsp;</li><li>^ Al Qaeda-linked militants capture Fallujah during violent outbreak. Fox News Channel. 4 January 2014.&nbsp;</li><li>^ Militants kill 21 Iraqi leaders, capture 2 border crossings. NY Daily News. Retrieved 14 October 2014.&nbsp;</li><li>^ Iraq Update #42: Al-Qaeda in Iraq Patrols Fallujah; Aims for Ramadi, Mosul, Baghdad. Institute for the Study of War. Retrieved 5 January 2014.&nbsp;</li><li>^ Isis seizes Ramadi. The Independent. May 18, 2015.&nbsp;</li><li>^ Iraq: Shiite Gov't faces Mammoth Task in taking Sunni al-Anbar from ISIL. Informed Comment. Retrieved 11 June 2015.&nbsp;</li><li>^ Islamic State overruns Camp Speicher, routs Iraqi forces. Retrieved 14 October 2014.&nbsp;</li><li>^ Reuters (2014-06-09). Insurgents in Iraq Overrun Mosul Provincial Government Headquarters. Voanews.com. Retrieved 2014-07-31.&nbsp; Iraqi city of Mosul falls to jihadists. CBS. 10 June 2014.&nbsp;</li><li>^ Keith Wagstaff (27 May 2013). Is Iraq heading toward civil war?. The Week. THE WEEK PUBLICATIONS, INC. Retrieved 28 May 2013.&nbsp;</li><li>^ Sinan Salaheddin (20 May 2013). ATTACKS KILL 95 IN IRAQ, HINT OF SYRIAN SPILLOVER. Associated Press. Retrieved 28 May 2013.&nbsp;</li><li>^ Associated Press in Baghdad (22 July 2013). Iraq: hundreds escape from Abu Ghraib jail. London: Guardian. Retrieved 19 January 2014.&nbsp;</li><li>^ Brazen Attacks at Prisons Raise Worries of Al Qaeda's Strength in Iraq, New York Times, By MICHAEL R. GORDON and DURAID ADNAN Published: 23 July 2013</li><li>^ Iraq crisis: Isis gains strength near Baghdad as Kurdish forces seize Kirkuk. The Guardian. Retrieved 12 June 2014.&nbsp;</li><li>^ Obama Authorizes Air Strikes in Iraq. The New York Times. 8 August 2014. Retrieved 22 August 2014.&nbsp;</li><li>^ Solomon, Jay and Carol E. Lee (June 19, 2014). U.S. Signals Iraq's Maliki Should Go. The Wall Street Journal. Retrieved 2014-08-12.&nbsp;</li><li>^ Rubin, Alissa J. and Alan Cowell (July 10, 2014). Kurdish Government Calls on Maliki to Quit as Iraqi Premier. The New York Times. Retrieved 2014-08-12.&nbsp;</li><li>^ Morris, Loveday (July 28, 2014). Maliki's party in search of alternative candidate to lead Iraq. Pittsburgh Post-Gazette. The Washington Post. Retrieved 2014-08-12.&nbsp;</li><li>^ Madi, Mohamed (11 August 2014). Profile: Haider al-Abadi, Iraqi PM in waiting. BBC. Retrieved 2014-08-12.&nbsp;</li><li>^ Ashton, Adam (August 11, 2014). Haider al Abadi named to replace Maliki as troops take to Baghdad's streets. McClatchyDC. Retrieved 2014-08-12.&nbsp;</li><li>^ Al Jazeera English (14 August 2014). Maliki steps down as Iraqi prime minister. Al Jazeera English. Retrieved 14 August 2014.&nbsp;</li><li>^ Attack on Sunni Mosque in Iraq kills dozens. Al Jazeera. 22 August 2014. Retrieved 23 August 2014.&nbsp;</li><li>^ UN calls for immediate action to prevent new ISIS massacre in Iraq. Reuters. 23 August 2014. Retrieved 23 August 2014.&nbsp;</li><li>^ Kurds take oil-rich Kirkuk amid advance of ISIL insurgency in Iraq. Al Jazeera America. Al Jazeera. 12 June 2014. Retrieved 14 June 2014.&nbsp;</li><li>^ Nissenbaum, Dion and Julian E. Barnes (August 8, 2014). U.S. Launches Airstrikes in Iraq. Wall Street Journal. Retrieved 2014-08-12.&nbsp;</li><div class="gradientback"></div></div><div class="content"><li>^ Iraq forces 'liberate' Diyala province from IS. Yahoo News. 26 January 2015. Retrieved 11 June 2015.&nbsp;</li><li>^ Iraq 'seizes districts from IS' in Tikrit advance. BBC News. Retrieved 11 June 2015.&nbsp;</li><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=History_of_Iraq_(2011–present)&amp;oldid=770104115"					
								Categories:  Hidden categories:</p><br><h1 lang="en">Template:History of Iraq</h1><p> From Wikipedia, the free encyclopedia</p><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Template:History_of_Iraq&amp;oldid=672294473"					
								Categories:  				
											
						<br>
							

											 
										
				<br><img alt="This is a featured article. Click here for more information." src="http://upload.wikimedia.org/wikipedia/en/thumb/e/e7/Cscr-featured.svg/20px-Cscr-featured.svg.png" width="20" height="19">

							</p><br><br><img alt="This is a featured article. Click here for more information." src="http://upload.wikimedia.org/wikipedia/en/thumb/e/e7/Cscr-featured.svg/20px-Cscr-featured.svg.png" width="20" height="19"><h1 lang="en">Parthian Empire</h1><p> From Wikipedia, the free encyclopedia</p><p>The Parthian Empire (/'p??r?i?n/; 247&nbsp;BC – 224&nbsp;AD), also known as the Arsacid Empire (/'??rs?s?d/),[9] was a major Iranian political and cultural power in ancient Iran and Iraq.[10] Its latter name comes from Arsaces I of Parthia[11] who, as leader of the Parni tribe, founded it in the mid-3rd century BC when he conquered the region of Parthia[12] in Iran's northeast, then a satrapy (province) in rebellion against the Seleucid Empire. Mithridates I of Parthia (r.&nbsp;c.&nbsp;171–138&nbsp;BC) greatly expanded the empire by seizing Media and Mesopotamia from the Seleucids. At its height, the Parthian Empire stretched from the northern reaches of the Euphrates, in what is now central-eastern Turkey, to eastern Iran. The empire, located on the Silk Road trade route between the Roman Empire in the Mediterranean Basin and the Han Empire of China, became a center of trade and commerce.</p><p>The Parthians largely adopted the art, architecture, religious beliefs, and royal insignia of their culturally heterogeneous empire, which encompassed Persian, Hellenistic, and regional cultures. For about the first half of its existence, the Arsacid court adopted elements of Greek culture, though it eventually saw a gradual revival of Iranian traditions. The Arsacid rulers were titled the King of Kings, as a claim to be the heirs to the Achaemenid Empire; indeed, they accepted many local kings as vassals where the Achaemenids would have had centrally appointed, albeit largely autonomous, satraps. The court did appoint a small number of satraps, largely outside Iran, but these satrapies were smaller and less powerful than the Achaemenid potentates. With the expansion of Arsacid power, the seat of central government shifted from Nisa to Ctesiphon along the Tigris (south of modern Baghdad, Iraq), although several other sites also served as capitals.</p><p>The earliest enemies of the Parthians were the Seleucids in the west and the Scythians in the east. However, as Parthia expanded westward, they came into conflict with the Kingdom of Armenia, and eventually the late Roman Republic. Rome and Parthia competed with each other to establish the kings of Armenia as their subordinate clients. The Parthians soundly defeated Marcus Licinius Crassus at the Battle of Carrhae in 53&nbsp;BC, and in 40–39&nbsp;BC, Parthian forces captured the whole of the Levant except Tyre from the Romans. However, Mark Antony led a counterattack against Parthia, although his successes were generally achieved in his absence, under the leadership of his lieutenant Ventidius. Also, various Roman emperors or their appointed generals invaded Mesopotamia in the course of the several Roman-Parthian Wars which ensued during the next few centuries. The Romans captured the cities of Seleucia and Ctesiphon on multiple occasions during these conflicts, but were never able to hold on to them.</p><p>Frequent civil wars between Parthian contenders to the throne proved more dangerous to the Empire's stability than foreign invasion, and Parthian power evaporated when Ardashir I, ruler of Estakhr in Fars, revolted against the Arsacids and killed their last ruler, Artabanus V, in 224&nbsp;AD. Ardashir established the Sassanid Empire, which ruled Iran and much of the Near East until the Muslim conquests of the 7th century AD, although the Arsacid dynasty lived on through the Arsacid Dynasty of Armenia, the Arsacid dynasty of Iberia, and the Arsacid Dynasty of Caucasian Albania; all eponymous branches of the Parthian Arsacids.</p><p>Native Parthian sources, written in Parthian, Greek and other languages, are scarce when compared to Sassanid and even earlier Achaemenid sources. Aside from scattered cuneiform tablets, fragmentary ostraca, rock inscriptions, drachma coins, and the chance survival of some parchment documents, much of Parthian history is only known through external sources. These include mainly Greek and Roman histories, but also Chinese histories, prompted by the Han Chinese desire to form alliances against the Xiongnu.[13] Parthian artwork is viewed by historians as a valid source for understanding aspects of society and culture that are otherwise absent in textual sources.</p><h2>Contents</h2><h2>History</h2><h3>Origins and establishment</h3><br><img alt="Two sides of a silver coin. The one on the left bears the imprint of a man's head, while the one on the right a sitting individual." src="http://upload.wikimedia.org/wikipedia/commons/thumb/1/14/Pdc_24586.jpg/220px-Pdc_24586.jpg" width="220" height="108"><p>


				The silver drachma of Arsaces I of Parthia (r. c.&nbsp;247–211&nbsp;BC) with a Greek-alphabet inscription of his name (??S????)



				</p><p> Further information: Parni conquest of Parthia</p><p>
					Before Arsaces I of Parthia founded the Arsacid Dynasty, he was chieftain of the Parni, an ancient Central-Asian tribe of Iranian peoples and one of several nomadic tribes within the confederation of the Dahae.[14] The Parni most likely spoke an eastern Iranian language, in contrast to the northwestern Iranian language spoken at the time in Parthia.[15] The latter was a northeastern province, first under the Achaemenid, and then the Seleucid empires.[16] After conquering the region, the Parni adopted Parthian as the official court language, speaking it alongside Middle Persian, Aramaic, Greek, Babylonian, Sogdian and other languages in the multilingual territories they would conquer.[17]</p><p>Why the Arsacid court retroactively chose 247&nbsp;BC as the first year of the Arsacid era is uncertain. A.D.H. Bivar concludes that this was the year the Seleucids lost control of Parthia to Andragoras, the appointed satrap who rebelled against them. Hence, Arsaces I backdated his regnal years to the moment when Seleucid control over Parthia ceased.[18] However, Vesta Sarkhosh Curtis asserts that this was simply the year Arsaces was made chief of the Parni tribe.[19] Homa Katouzian[20] and Gene Ralph Garthwaite[21] claim it was the year Arsaces conquered Parthia and expelled the Seleucid authorities, yet Curtis[19] and Maria Brosius[22] state that Andragoras was not overthrown by the Arsacids until 238&nbsp;BC.</p><p>It is unclear who immediately succeeded Arsaces I. Bivar[23] and Katouzian[20] affirm that it was his brother Tiridates I of Parthia, who in turn was succeeded by his son Arsaces II of Parthia in 211&nbsp;BC. Yet Curtis[24] and Brosius[25] state that Arsaces II was the immediate successor of Arsaces I, with Curtis claiming the succession took place in 211&nbsp;BC, and Brosius in 217&nbsp;BC. Bivar insists that 138&nbsp;BC, the last regnal year of Mithridates I, is the first precisely established regnal date of Parthian history.[26] Due to these and other discrepancies, Bivar outlines two distinct royal chronologies accepted by historians.[27] Later on, some of the Parthian Kings would claim Achaemenid descent. The claim has recently received support from numismatic and other written evidence suggesting that both Achaemenid and Parthian kings suffered from the hereditary disease neurofibromatosis.[28]</p><div class="gradientback"></div></div><div class="content"><br><img alt="A map centered on the Mediterranean and Middle East showing the extent of the Roman Republic (Purple), Selucid Empire (Blue), and Parthia (Yellow) around 200&nbsp;BC." src="http://upload.wikimedia.org/wikipedia/commons/thumb/3/31/Rome-Seleucia-Parthia_200bc.jpg/300px-Rome-Seleucia-Parthia_200bc.jpg" width="300" height="141"><p>


				Parthia, shaded yellow, alongside the Seleucid Empire (blue) and the Roman Republic (purple) around 200&nbsp;BC


				</p><p>
					For a time, Arsaces consolidated his position in Parthia and Hyrcania by taking advantage of the invasion of Seleucid territory in the west by Ptolemy III Euergetes (r.&nbsp;246–222&nbsp;BC) of Egypt. This conflict with Ptolemy, the Third Syrian War (246–241&nbsp;BC), also allowed Diodotus I to rebel and form the Greco-Bactrian Kingdom in Central Asia.[22] The latter's successor, Diodotus II, formed an alliance with Arsaces against the Seleucids, but Arsaces was temporarily driven from Parthia by the forces of Seleucus II Callinicus (r.&nbsp;246–225&nbsp;BC).[29] After spending some time in exile among the nomadic Apasiacae tribe, Arsaces led a counterattack and recaptured Parthia. Seleucus II's successor, Antiochus III the Great (r.&nbsp;222–187&nbsp;BC), was unable to immediately retaliate because his troops were engaged in putting down the rebellion of Molon in Media.[29]</p><p>Antiochus III launched a massive campaign to retake Parthia and Bactria in 210 or 209&nbsp;BC. He was unsuccessful, but did negotiate a peace settlement with Arsaces II. The latter was granted the title of king (Greek: basileus) in return for his submission to Antiochus III as his superior.[30] The Seleucids were unable to further intervene in Parthian affairs following increasing encroachment by the Roman Republic and the Seleucid defeat at Magnesia in 190&nbsp;BC.[30] Phriapatius of Parthia (r. c.&nbsp;191–176&nbsp;BC) succeeded Arsaces II, and Phraates I of Parthia (r. c.&nbsp;176–171&nbsp;BC) eventually ascended the throne. Phraates I ruled Parthia without further Seleucid interference.[31]</p><h3>Expansion and consolidation</h3><p> Main article: Seleucid–Parthian wars</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/2/26/Parthian_Empire.gif/300px-Parthian_Empire.gif" width="300" height="228"><p>


				Parthian Empire timeline including important events and territorial evolution.



				<br><img alt="Faded relief carved into the side of a rock. The scene portrays a man on horseback as well as several other characters." src="http://upload.wikimedia.org/wikipedia/commons/thumb/7/76/Xong-e_Ashdar_Parthian_relief.jpg/220px-Xong-e_Ashdar_Parthian_relief.jpg" width="220" height="165"><br>


				A rock-carved relief of Mithridates I of Parthia (r. c.&nbsp;171–138&nbsp;BC), seen riding on horseback, at Kong-e Aždar, city of Izeh, Khuzestan Province, Iran


				</p><br><img alt="Faded relief carved into the side of a rock. The scene portrays a man on horseback as well as several other characters." src="http://upload.wikimedia.org/wikipedia/commons/thumb/7/76/Xong-e_Ashdar_Parthian_relief.jpg/220px-Xong-e_Ashdar_Parthian_relief.jpg" width="220" height="165"><br><p>
					Phraates I is recorded as expanding Parthia's control past the Gates of Alexander and occupied Apamea Ragiana, the locations of which are unknown.[32] Yet the greatest expansion of Parthian power and territory took place during the reign of his brother and successor Mithridates I of Parthia (r. c.&nbsp;171–138 BC),[25] whom Katouzian compares to Cyrus the Great (d. 530 BC), founder of the Achaemenid Empire.[20]</p><p>Relations between Parthia and Greco-Bactria deteriorated after the death of Diodotus II, when Mithridates' forces captured two eparchies of the latter kingdom, then under Eucratides I (r. c.&nbsp;170–145&nbsp;BC).[33] Turning his sights on the Seleucid realm, Mithridates invaded Media and occupied Ecbatana in 148 or 147&nbsp;BC; the region had been destabilized by a recent Seleucid suppression of a rebellion there led by Timarchus.[34] This victory was followed by the Parthian conquest of Babylonia in Mesopotamia, where Mithridates had coins minted at Seleucia in 141&nbsp;BC and held an official investiture ceremony.[35] While Mithridates retired to Hyrcania, his forces subdued the kingdoms of Elymais and Characene and occupied Susa.[35] By this time, Parthian authority extended as far east as the Indus River.[36]</p><p>Whereas Hecatompylos had served as the first Parthian capital, Mithridates established royal residences at Seleucia, Ecbatana, Ctesiphon and his newly founded city, Mithradatkert (Nisa, Turkmenistan), where the tombs of the Arsacid kings were built and maintained.[37] Ecbatana became the main summertime residence for the Arsacid royalty.[38] Ctesiphon may not have become the official capital until the reign of Gotarzes I of Parthia (r. c.&nbsp;90–80&nbsp;BC).[39] It became the site of the royal coronation ceremony and the representational city of the Arsacids, according to Brosius.[40]</p><p>The Seleucids were unable to retaliate immediately as general Diodotus Tryphon led a rebellion at the capital Antioch in 142 BC.[41] However, by 140&nbsp;BC Demetrius II Nicator was able to launch a counter-invasion against the Parthians in Mesopotamia. Despite early successes, the Seleucids were defeated and Demetrius himself was captured by Parthian forces and taken to Hyrcania. There Mithridates treated his captive with great hospitality; he even married his daughter Rhodogune of Parthia to Demetrius.[42]</p><br><img alt="Two sides of a coin. The side on the left showing the head of a bearded man, while the right a standing individual." src="http://upload.wikimedia.org/wikipedia/commons/thumb/7/7f/Mithradatesi.jpg/220px-Mithradatesi.jpg" width="220" height="108"><p>


				Drachma of Mithridates I of Parthia, showing him wearing a beard and a royal diadem on his head


				</p><p>
					Antiochus VII Sidetes (r.&nbsp;138–129&nbsp;BC), a brother of Demetrius, assumed the Seleucid throne and married the latter's wife Cleopatra Thea. After defeating Diodotus Tryphon, Antiochus initiated a campaign in 130&nbsp;BC to retake Mesopotamia, now under the rule of Phraates II of Parthia (r.&nbsp;c.&nbsp;138–128&nbsp;BC). The Parthian general Indates was defeated along the Great Zab, followed by a local uprising where the Parthian governor of Babylonia was killed. Antiochus conquered Babylonia and occupied Susa, where he minted coins.[43] After advancing his army into Media, the Parthians pushed for peace, which Antiochus refused to accept unless the Arsacids relinquished all lands to him except Parthia proper, paid heavy tribute, and released Demetrius from captivity. Arsaces released Demetrius and sent him to Syria, but refused the other demands.[44] By Spring 129&nbsp;BC, the Medes were in open revolt against Antiochus, whose army had exhausted the resources of the countryside during winter. While attempting to put down the revolts, the main Parthian force swept into the region and killed Antiochus in battle. His body was sent back to Syria in a silver coffin; his son Seleucus was made a Parthian hostage[45] and a daughter joined Phraates' harem.[46]</p><div class="gradientback"></div></div><div class="content"><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/4/44/Mithridatesiiyoung.jpg/220px-Mithridatesiiyoung.jpg" width="220" height="114"><p>


				Drachma of Mithridates II of Parthia (r.&nbsp;c.&nbsp;124–90&nbsp;BC)


				</p><p>
					While the Parthians regained the territories lost in the west, another threat arose in the east. In 177–176&nbsp;BC the nomadic confederation of the Xiongnu dislodged the nomadic Yuezhi from their homelands in what is now Gansu province in Northwest China;[47] the Yuezhi then migrated west into Bactria and displaced the Saka (Scythian) tribes. The Saka were forced to move further west, where they invaded the Parthian Empire's northeastern borders.[48] Mithridates was thus forced to retire to Hyrcania after his conquest of Mesopotamia.[49]</p><p>Some of the Saka were enlisted in Phraates' forces against Antiochus. However, they arrived too late to engage in the conflict. When Phraates refused to pay their wages, the Saka revolted, which he tried to put down with the aid of former Seleucid soldiers, yet they too abandoned Phraates and joined sides with the Saka.[50] Phraates II marched against this combined force, but he was killed in battle.[51] The Roman historian Justin reports that his successor Artabanus I of Parthia (r. c.&nbsp;128–124&nbsp;BC) shared a similar fate fighting nomads in the east. He claims Artabanus was killed by the Tokhari (identified as the Yuezhi), although Bivar believes Justin conflated them with the Saka.[52] Mithridates II of Parthia (r. c.&nbsp;124–90&nbsp;BC) later recovered the lands lost to the Saka in Sistan.[53]</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/c/c1/Silk_from_Mawangdui_2.jpg/220px-Silk_from_Mawangdui_2.jpg" width="220" height="165"><p>


				Chinese silk from Mawangdui, 2nd century BC, silk from China was perhaps the most lucrative luxury item the Parthians traded at the western end of the Silk Road.[54]


				</p><p>
					Following the Seleucid withdrawal from Mesopotamia, the Parthian governor of Babylonia, Himerus, was ordered by the Arsacid court to conquer Characene, then ruled by Hyspaosines from Charax Spasinu. When this failed, Hyspaosines invaded Babylonia in 127&nbsp;BC and occupied Seleucia. Yet by 122&nbsp;BC, Mithridates II forced Hyspaosines out of Babylonia and made the kings of Characene vassals under Parthian suzerainty.[55] After Mithridates extended Parthian control further west, occupying Dura-Europos in 113&nbsp;BC, he became embroiled in a conflict with the Kingdom of Armenia.[56] His forces defeated and deposed Artavasdes I of Armenia in 97&nbsp;BC, taking his son Tigranes hostage, who would later become Tigranes II the Great of Armenia (r. c.&nbsp;95–55&nbsp;BC).[57]</p><p>The Indo-Parthian Kingdom, located in modern-day Afghanistan and Pakistan made an alliance with the Parthian Empire in the 1st century BC.[58] Bivar claims that these two states considered each other political equals.[59] After the Greek philosopher Apollonius of Tyana visited the court of Vardanes I of Parthia (r. c.&nbsp;40–47&nbsp;AD) in 42&nbsp;AD, Vardanes provided him with the protection of a caravan as he traveled to Indo-Parthia. When Apollonius reached Indo-Parthia's capital Taxila, his caravan leader read Vardanes' official letter, perhaps written in Parthian, to an Indian official who treated Apollonius with great hospitality.[58]</p><p>Following the diplomatic venture of Zhang Qian into Central Asia during the reign of Emperor Wu of Han (r.&nbsp;141–87&nbsp;BC), the Han Empire of China sent a delegation to Mithridates II's court in 121&nbsp;BC. The Han embassy opened official trade relations with Parthia via the Silk Road yet did not achieve a desired military alliance against the confederation of the Xiongnu.[60] The Parthian Empire was enriched by taxing the Eurasian caravan trade in silk, the most highly priced luxury good imported by the Romans.[61] Pearls were also a highly valued import from China, while the Chinese purchased Parthian spices, perfumes, and fruits.[62] Exotic animals were also given as gifts from the Arsacid to Han courts; in 87 AD Pacorus II of Parthia sent lions and Persian gazelles to Emperor Zhang of Han (r.&nbsp;75–88&nbsp;AD).[63] Besides silk, Parthian goods purchased by Roman merchants included iron from India, spices, and fine leather.[64] Caravans traveling through the Parthian Empire brought West Asian and sometimes Roman luxury glasswares to China.[65] The merchants of Sogdia, speaking an Eastern Iranian language, served as the primary middlemen of this vital silk trade between Parthia and Han China.[66]</p><h3>Rome and Armenia</h3><p> Main articles: Roman–Persian relations and Roman–Parthian Wars</p><p>The Yuezhi Kushan Empire in northern India largely guaranteed the security of Parthia's eastern border.[67] Thus, from the mid-1st century BC onwards, the Arsacid court focused on securing the western border, primarily against Rome.[67] A year following Mithridates II's subjugation of Armenia, Lucius Cornelius Sulla, the Roman proconsul of Cilicia, convened with the Parthian diplomat Orobazus at the Euphrates river. The two agreed that the river would serve as the border between Parthia and Rome, although several historians have argued that Sulla only had authority to communicate these terms back to Rome.[68]</p><p>Despite this agreement, in 93 or 92&nbsp;BC Parthia fought a war in Syria against the tribal leader Laodice and her Seleucid ally Antiochus X Eusebes (r.&nbsp;95–92?&nbsp;BC), killing the latter.[69] When one of the last Seleucid monarchs, Demetrius III Eucaerus, attempted to besiege Beroea (modern Aleppo), Parthia sent military aid to the inhabitants and Demetrius was defeated.[69]</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/8/84/Orodesi.jpg/220px-Orodesi.jpg" width="220" height="99"><p>


				Drachma of Orodes I of Parthia (r.&nbsp;c.&nbsp;90–80&nbsp;BC)


				</p><p>
					Following the rule of Mithridates II, Gotarzes I ruled Babylonia, while Orodes I (r. c.&nbsp;90–80&nbsp;BC) ruled Parthia separately.[70] This system of split monarchy weakened Parthia, allowing Tigranes II of Armenia to annex Parthian territory in western Mesopotamia. This land would not be restored to Parthia until the reign of Sanatruces of Parthia (r. c.&nbsp;78–71&nbsp;BC).[71] Following the outbreak of the Third Mithridatic War, Mithridates VI of Pontus (r.&nbsp;119–63&nbsp;BC), an ally of Tigranes II of Armenia, requested aid from Parthia against Rome, but Sanatruces refused help.[72] When the Roman commander Lucullus marched against the Armenian capital Tigranocerta in 69&nbsp;BC, Mithridates VI and Tigranes II requested the aid of Phraates III of Parthia (r. c.&nbsp;71–58). Phraates did not send aid either, and after the fall of Tigranocerta he reaffirmed with Lucullus the Euphrates as the boundary between Parthia and Rome.[73]</p><p>Tigranes the Younger, son of Tigranes II of Armenia, failed to usurp the Armenian throne from his father. He fled to Phraates III and convinced him to march against Armenia's new capital at Artaxarta. When this siege failed, Tigranes the Younger once again fled, this time to the Roman commander Pompey. He promised Pompey that he would act as a guide through Armenia, but, when Tigranes II submitted to Rome as a client king, Tigranes the Younger was brought to Rome as a hostage.[74] Phraates demanded Pompey return Tigranes the Younger to him, but Pompey refused. In retaliation, Phraates launched an invasion into Corduene (southeastern Turkey) where, according to two conflicting Roman accounts, the Roman consul Lucius Afranius forced the Parthians out by either military or diplomatic means.[75]</p><div class="gradientback"></div></div><div class="content"><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/c/cc/Marcus_Licinius_Crassus_Louvre.jpg/170px-Marcus_Licinius_Crassus_Louvre.jpg" width="170" height="276"><p>


				A Roman marble head of the triumvir Marcus Licinius Crassus, who was defeated at Carrhae by Surena


				</p><p>
					Phraates III was assassinated by his sons Orodes II of Parthia and Mithridates III of Parthia, after which Orodes turned on Mithridates, forcing him to flee from Media to Roman Syria.[76] Aulus Gabinius, the Roman proconsul of Syria, marched in support of Mithridates to the Euphrates, but had to turn back to aid Ptolemy XII Auletes (r.&nbsp;80–58; 55–51&nbsp;BC) against a rebellion in Egypt.[77] Despite losing his Roman support, Mithridates managed to conquer Babylonia, and minted coins at Seleucia until 54&nbsp;BC. In that year, Orodes' general, known only as Surena after his noble family's clan name, recaptured Seleucia, and Mithridates was executed.[78]</p><p>Marcus Licinius Crassus, one of the triumvirs who was now proconsul of Syria, launched an invasion into Parthia in 53&nbsp;BC in belated support of Mithridates.[79] As his army marched to Carrhae (modern Harran, southeastern Turkey), Orodes II invaded Armenia, cutting off support from Rome's ally Artavasdes II of Armenia (r.&nbsp;53–34&nbsp;BC). Orodes persuaded Artavasdes to a marriage alliance between the crown prince Pacorus I of Parthia (d.&nbsp;38&nbsp;BC) and Artavasdes' sister.[80]</p><p>Surena, with an army entirely on horseback, rode to meet Crassus.[81] Surena's 1,000 cataphracts, armed with lances, and 9,000 horse archers were outnumbered roughly four to one by Crassus' army, comprising seven Roman legions and auxiliaries including mounted Gauls and light infantry.[82] Relying on a baggage train of about 1,000 camels, the Parthian horse archers were given constant supplies of arrows.[82] The horse archers employed the Parthian shot tactic, where they would fake a retreat, only to turn and fire upon their opponents. This tactic, combined with the use of heavy composite bows on flat plain devastated Crassus' infantry.[83] With some 20,000 Romans dead, approximately 10,000 captured, and roughly another 10,000 escaping west, Crassus fled into the Armenian countryside.[84] At the head of his army, Surena approached Crassus, offering a parley, which Crassus accepted. However, he was killed when one of his junior officers, suspecting a trap, attempted to stop him from riding into Surena's camp.[85]</p><p>Crassus' defeat at Carrhae was one of the worst military defeats of Roman history.[86] Parthia's victory cemented its reputation as a formidable if not equal power with Rome.[87] With his camp followers, war captives, and precious Roman booty, Surena traveled some 700&nbsp;km (430&nbsp;mi) back to Seleucia where his victory was celebrated. However, fearing his ambitions even for the Arsacid throne, Orodes had Surena executed shortly thereafter.[86]</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/8/8b/Antony_with_Octavian_aureus.jpg/220px-Antony_with_Octavian_aureus.jpg" width="220" height="111"><p>


				Roman aurei bearing the portraits of Mark Antony (left) and Octavian (right), issued in 41&nbsp;BC to celebrate the establishment of the Second Triumvirate by Octavian, Antony and Marcus Lepidus in 43&nbsp;BC


				</p><p>
					Emboldened by the victory over Crassus, the Parthians attempted to capture Roman-held territories in Western Asia.[88] Crown prince Pacorus I and his commander Osaces raided Syria as far as Antioch in 51 BC, but were repulsed by Gaius Cassius Longinus, who ambushed and killed Osaces.[89] The Arsacids sided with Pompey in his civil war against Julius Caesar and even sent troops to support the anti-Caesarian forces at the Battle of Philippi in 42&nbsp;BC.[90] Quintus Labienus, a general loyal to Cassius and Brutus, sided with Parthia against the Second Triumvirate in 40 BC; the following year he invaded Syria alongside Pacorus I.[91] The triumvir Mark Antony was unable to lead the Roman defense against Parthia due to his departure to Italy, where he amassed his forces to confront his rival Octavian and eventually conducted negotiations with him at Brundisium.[92] After Syria was occupied by Pacorus' army, Labienus split from the main Parthian force to invade Anatolia while Pacorus and his commander Barzapharnes invaded the Roman Levant.[91] They subdued all settlements along the Mediterranean coast as far south as Ptolemais (modern Acre, Israel), with the lone exception of Tyre.[93] In Judea, the pro-Roman Jewish forces of high priest Hyrcanus II, Phasael, and Herod were defeated by the Parthians and their Jewish ally Antigonus II Mattathias (r.&nbsp;40–37&nbsp;BC); the latter was made king of Judea while Herod fled to his fort at Masada.[91]</p><p>Despite these successes, the Parthians were soon driven out of the Levant by a Roman counteroffensive. Publius Ventidius Bassus, an officer under Mark Antony, defeated and then executed Labienus at the Battle of the Cilician Gates (in modern Mersin Province, Turkey) in 39 BC.[94] Shortly afterward, a Parthian force in Syria led by general Pharnapates was defeated by Ventidius at the Battle of Amanus Pass.[94] As a result, Pacorus I temporarily withdrew from Syria. When he returned in the spring of 38&nbsp;BC, he faced Ventidius at the Battle of Mount Gindarus, northeast of Antioch. Pacorus was killed during the battle, and his forces retreated across the Euphrates. His death spurred a succession crisis in which Orodes II chose Phraates IV of Parthia (r. c.&nbsp;38–2&nbsp;BC) as his new heir.[95]</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/f/ff/Phraatesiv.jpg/220px-Phraatesiv.jpg" width="220" height="106"><p>


				Drachma of Phraates IV of Parthia (r.&nbsp;c.&nbsp;38–2&nbsp;BC)


				</p><p>
					Upon assuming the throne, Phraates IV eliminated rival claimants by killing and exiling his own brothers.[96] One of them, Monaeses, fled to Antony and convinced him to invade Parthia.[97] Antony defeated Parthia's Judaean ally Antigonus in 37&nbsp;BC, installing Herod as a client king in his place. The following year, when Antony marched to Erzurum, Artavasdes II of Armenia once again switched alliances by sending Antony additional troops. Antony invaded Media Atropatene (modern Iranian Azerbaijan), then ruled by Parthia's ally Artavasdes I of Media Atropatene, with the intention of seizing the capital Praaspa, the location of which is now unknown. However, Phraates IV ambushed Antony's rear detachment, destroying a giant battering ram meant for the siege of Praaspa; after this, Artavasdes abandoned Antony's forces.[98] The Parthians pursued and harassed Antony's army as they fled to Armenia. Eventually, the greatly weakened force reached Syria.[99] After this, Antony lured Artavasdes II into a trap with the promise of a marriage alliance. He was taken captive in 34 BC, sent back to Rome, and executed.[100] Antony attempted to strike an alliance with Artavasdes I of Media Atropatene, whose relations with Phraates IV had recently soured. This was abandoned when Antony and his forces withdrew from Armenia in 33&nbsp;BC; they escaped a Parthian invasion while Antony's rival Octavian attacked his forces to the west.[100] Following Antony's suicide in Egypt, the Parthian ally Artaxias II reassumed the throne of Armenia.</p><div class="gradientback"></div></div><div class="content"><h3>Peace with Rome, court intrigue and contact with Chinese generals</h3><p> Further information: Pax Romana</p><p>Following the defeat of Antony at the Battle of Actium in 31&nbsp;BC, Octavian consolidated his political power and in 27&nbsp;BC was named Augustus by the Roman Senate, becoming the first Roman emperor. Around this time, Tiridates II of Parthia briefly overthrew Phraates IV, who was able to quickly reestablish his rule with the aid of Scythian nomads.[101] Tiridates fled to the Romans, taking one of Phraates' sons with him. In negotiations conducted in 20&nbsp;BC, Phraates arranged for the release of his kidnapped son. In return, the Romans received the lost legionary standards taken at Carrhae in 53&nbsp;BC, as well as any surviving prisoners of war.[102] The Parthians viewed this exchange as a small price to pay to regain the prince.[103] Augustus hailed the return of the standards as a political victory over Parthia; this propaganda was celebrated in the minting of new coins, the building of a new temple to house the standards, and even in fine art such as the breastplate scene on his statue Augustus of Prima Porta.[104]</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/2/22/Augustus_Prima_Porta_%28detail%29.PNG/220px-Augustus_Prima_Porta_%28detail%29.PNG" width="220" height="216"><p>


				A close-up view of the breastplate on the statue of Augustus of Prima Porta, showing a Parthian man returning to Augustus the legionary standards lost by Marcus Licinius Crassus at Carrhae


				</p><p>
					Along with the prince, Augustus also gave Phraates IV an Italian slave-girl, who later became Queen Musa of Parthia. To ensure that her child Phraataces would inherit the throne without incident, Musa convinced Phraates IV to give his other sons to Augustus as hostages. Again, Augustus used this as propaganda depicting the submission of Parthia to Rome, listing it as a great accomplishment in his Res Gestae Divi Augusti.[105] When Phraataces took the throne as Phraates V of Parthia (r. c.&nbsp;2&nbsp;BC – 4&nbsp;AD), Musa married her own son and ruled alongside him. The Parthian nobility, disapproving of both the incestuous relationship and the notion of a king with non-Arsacid blood, forced the pair into exile in Roman territory.[106] Phraates' successor Orodes III of Parthia lasted just two years on the throne, and was followed by Vonones I of Parthia, who had adopted many Roman mannerisms during time in Rome. The Parthian nobility, angered by Vonones' sympathies for the Romans, backed a rival claimant, Artabanus III of Parthia (r. c.&nbsp;10–38&nbsp;AD), who eventually defeated Vonones and drove him into exile in Roman Syria.[107]</p><p>During the reign of Artabanus III, two Jewish commoners and brothers, Anilai and Asinai from Nehardea (near modern Fallujah, Iraq),[108] led a revolt against the Parthian governor of Babylonia. After defeating the latter, the two were granted the right to govern the region by Artabanus III, who feared further rebellion elsewhere.[109] Anilai's Parthian wife poisoned Asinai out of fear he would attack Anilai over his marriage to a gentile. Following this, Anilai became embroiled in an armed conflict with a son-in-law of Artabanus, who eventually defeated him.[110] With the Jewish regime removed, the native Babylonians began to harass the local Jewish community, forcing them to emigrate to Seleucia. When that city rebelled against Parthian rule in 35–36&nbsp;AD, the Jews were expelled again, this time by the local Greeks and Aramaeans. The exiled Jews fled to Ctesiphon, Nehardea, and Nisibis.[111]</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/a/af/Augustus_Denarius_19_BC_2230399.jpg/220px-Augustus_Denarius_19_BC_2230399.jpg" width="220" height="108"><p>


				A denarius struck in 19&nbsp;BC during the reign of Augustus, with the goddess Feronia depicted on the obverse, and on the reverse a Parthian man kneeling in submission while offering the Roman military standards taken at the Battle of Carrhae[112]


				</p><p>
					Although at peace with Parthia, Rome still interfered in its affairs. The Roman emperor Tiberius (r.&nbsp;14–37&nbsp;AD) became involved in a plot by Pharasmanes I of Iberia to place his brother Mithridates on the throne of Armenia by assassinating the Parthian ally King Arsaces of Armenia.[113] Artabanus III tried and failed to restore Parthian control of Armenia, prompting an aristocratic revolt that forced him to flee to Scythia. The Romans released a hostage prince, Tiridates III of Parthia, to rule the region as an ally of Rome. Shortly before his death, Artabanus managed to force Tiridates from the throne using troops from Hyrcania.[114] After Artabanus' death in 38&nbsp;AD, a long civil war ensued between the rightful successor Vardanes I of Parthia and his brother Gotarzes II of Parthia.[115] After Vardanes was assassinated during a hunting expedition, the Parthian nobility appealed to Roman emperor Claudius (r. 41–54&nbsp;AD) in 49&nbsp;AD to release the hostage prince Meherdates to challenge Gotarzes. This backfired when Meherdates was betrayed by the governor of Edessa and Izates bar Monobaz of Adiabene; he was captured and sent to Gotarzes, where he was allowed to live after having his ears mutilated, an act that disqualified him from inheriting the throne.[116]</p><p>In 97&nbsp;AD, the Chinese general Ban Chao, the Protector-General of the Western Regions, sent his emissary Gan Ying on a diplomatic mission to reach the Roman Empire. Gan visited the court of Pacorus II of Parthia at Hecatompylos before departing towards Rome.[117] He traveled as far west as the Persian Gulf, where Parthian authorities convinced him that an arduous sea voyage around the Arabian Peninsula was the only means to reach Rome.[118] Discouraged by this, Gan Ying returned to the Han court and provided Emperor He of Han (r.&nbsp;88–105&nbsp;AD) with a detailed report on the Roman Empire based on oral accounts of his Parthian hosts.[119] William Watson speculates that the Parthians would have been relieved at the failed efforts by the Han Empire to open diplomatic relations with Rome, especially after Ban Chao's military victories against the Xiongnu in eastern Central Asia.[117] However, Chinese records maintain that a Roman embassy, perhaps only a group of Roman merchants, arrived at the Han capital Luoyang by way of Jiaozhi (northern Vietnam) in 166&nbsp;AD, during the reigns of Marcus Aurelius (r. 161–180&nbsp;AD) and Emperor Huan of Han (r. 146–168&nbsp;AD).[120] Although it could be coincidental, Antonine Roman golden medallions dated to the reigns of Marcus Aurelius and his predecessor Antoninus Pius have been discovered at Oc Eo, Vietnam (among other Roman artefacts in the Mekong Delta), a site that is one of the suggested locations for the port city of Cattigara along the Magnus Sinus (i.e. Gulf of Thailand and South China Sea) in Ptolemy's Geography.[121]</p><h3>Continuation of Roman hostilities and Parthian decline</h3><p> Main articles: Roman–Parthian War of 58–63, Trajan's Parthian campaign, Roman–Parthian War of 161–166, and Parthian war of Caracalla</p><p> Further information: Roman Armenia</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/e/e1/Roman-Parthian_War_58-60.svg/300px-Roman-Parthian_War_58-60.svg.png" width="300" height="181"><div class="gradientback"></div></div><div class="content"><p>


				Map of the troop movements during the first two years of the Roman–Parthian War of 58–63 AD over the Kingdom of Armenia, detailing the Roman offensive into Armenia and capture of the country by Gnaeus Domitius Corbulo


				</p><p>
					After the Iberian king Pharasmanes I had his son Rhadamistus (r.&nbsp;51–55&nbsp;AD) invade Armenia to depose the Roman client king Mithridates, Vologeses I of Parthia (r. c.&nbsp;51–77&nbsp;AD) planned to invade and place his brother, the later Tiridates I of Armenia, on the throne.[122] Rhadamistus was eventually driven from power, and, beginning with the reign of Tiridates, Parthia would retain firm control over Armenia—with brief interruptions—through the Arsacid Dynasty of Armenia.[123] Even after the fall of the Parthian Empire, the Arsacid line lived on through the Armenian kings.[124] However, not only did the Arsacid line continue through the Armenians, it as well continued through the Georgian kings with the Arsacid dynasty of Iberia, and for many centuries afterwards in Caucasian Albania through the Arsacid Dynasty of Caucasian Albania.[125]</p><p>When Vardanes II of Parthia rebelled against his father Vologeses I in 55&nbsp;AD, Vologeses withdrew his forces from Armenia. Rome quickly attempted to fill the political vacuum left behind.[126] In the Roman–Parthian War of 58–63&nbsp;AD, the commander Gnaeus Domitius Corbulo achieved some military successes against the Parthians while installing Tigranes VI of Armenia as a Roman client.[127] However, Corbulo's successor Lucius Caesennius Paetus was soundly defeated by Parthian forces and fled Armenia.[128] Following a peace treaty, Tiridates I traveled to Naples and Rome in 63 AD. At both sites the Roman emperor Nero (r.&nbsp;54–68&nbsp;AD) ceremoniously crowned him king of Armenia by placing the royal diadem on his head.[129]</p><p>A long period of peace between Parthia and Rome ensued, with only the invasion of Alans into Parthia's eastern territories around 72&nbsp;AD mentioned by Roman historians.[130] Whereas Augustus and Nero had chosen a cautious military policy when confronting Parthia, later Roman emperors invaded and attempted to conquer the eastern Fertile Crescent, the heart of the Parthian Empire along the Tigris and Euphrates. The heightened aggression can be explained in part by Rome's military reforms.[131] To match Parthia's strength in missile troops and mounted warriors, the Romans at first used foreign allies (especially Nabataeans), but later established a permanent auxilia force to complement their heavy legionary infantry.[132] The Romans eventually maintained regiments of horse archers (sagittarii) and even mail-armored cataphracts in their eastern provinces.[133] Yet the Romans had no discernible grand strategy in dealing with Parthia and gained very little territory from these invasions.[134] The primary motivations for war were the advancement of the personal glory and political position of the emperor, as well as defending Roman honor against perceived slights such as Parthian interference in the affairs of Rome's client states.[135]</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/1/15/ParthianInChains.jpg/220px-ParthianInChains.jpg" width="220" height="300"><p>


				A Parthian (right) wearing a Phrygian cap, depicted as a prisoner of war in chains held by a Roman (left); Arch of Septimius Severus, Rome, 203&nbsp;AD


				</p><p>
					Hostilities between Rome and Parthia were renewed when Osroes I of Parthia (r. c.&nbsp;109–128&nbsp;AD) deposed the Armenian king Tiridates and replaced him with Axidares, son of Pacorus II, without consulting Rome.[136] The Roman emperor Trajan (r.&nbsp;98–117&nbsp;AD) had the next Parthian nominee for the throne, Parthamasiris, killed in 114&nbsp;AD, instead making Armenia a Roman province.[137] His forces, led by Lusius Quietus, also captured Nisibis; its occupation was essential to securing all the major routes across the northern Mesopotamian plain.[138] The following year, Trajan invaded Mesopotamia and met little resistance from only Meharaspes of Adiabene, since Osroes was engaged in a civil war to the east with Vologases III of Parthia.[139] Trajan spent the winter of 115–116 at Antioch, but resumed his campaign in the spring. Marching down the Euphrates, he captured Dura-Europos, the capital Ctesiphon[140] and Seleucia, and even subjugated Characene, where he watched ships depart to India from the Persian Gulf.[141]</p><p>In the last months of 116&nbsp;AD, Trajan captured the Persian city of Susa. When Sanatruces II of Parthia gathered forces in eastern Parthia to challenge the Romans, his cousin Parthamaspates of Parthia betrayed and killed him: Trajan crowned him the new king of Parthia.[142] Never again would the Roman Empire advance so far to the east.</p><p>On Trajan's return north, the Babylonian settlements revolted against the Roman garrisons.[143] Trajan was forced to retreat from Mesopotamia in 117&nbsp;AD, overseeing a failed siege of Hatra during his withdrawal.[144] His retreat was—in his intentions—temporary, because he wanted to renew the attack on Parthia in 118 AD and make the subjection of the Parthians a reality,[145] but Trajan died suddenly in August 117&nbsp;AD.</p><p>During his campaign, Trajan was granted the title Parthicus by the Senate and coins were minted proclaiming the conquest of Parthia.[146] However, only the 4th-century AD historians Eutropius and Festus allege that he attempted to establish a Roman province in lower Mesopotamia.[147]</p><p>Trajan's successor Hadrian (r.&nbsp;117–138&nbsp;AD) reaffirmed the Roman-Parthian border at the Euphrates, choosing not to invade Mesopotamia due to Rome's now limited military resources.[148] Parthamaspates fled after the Parthians revolted against him, yet the Romans made him king of Osroene. Osroes I died during his conflict with Vologases III, the latter succeeded by Vologases IV of Parthia (r. c.&nbsp;147–191&nbsp;AD) who ushered in a period of peace and stability.[149] However, the Roman–Parthian War of 161–166&nbsp;AD began when Vologases invaded Armenia and Syria, retaking Edessa. Roman emperor Marcus Aurelius (r.&nbsp;161–180&nbsp;AD) had co-ruler Lucius Verus (r.&nbsp;161–169&nbsp;AD) guard Syria while Marcus Statius Priscus invaded Armenia in 163&nbsp;AD, followed by the invasion of Mesopotamia by Avidius Cassius in 164&nbsp;AD.[150]</p><p>The Romans captured and burnt Seleucia and Ctesiphon to the ground, yet they were forced to retreat once the Roman soldiers contracted a deadly disease (possibly smallpox) that soon ravaged the Roman world.[151] Although they withdrew, from this point forward the city of Dura-Europos remained in Roman hands.[152]</p><p>When Roman emperor Septimius Severus (r.&nbsp;193–211&nbsp;AD) invaded Mesopotamia in 197&nbsp;AD during the reign of Vologases V of Parthia (r. c.&nbsp;191–208&nbsp;AD), the Romans once again marched down the Euphrates and captured Seleucia and Ctesiphon. After assuming the title Parthicus Maximus, he retreated in late 198&nbsp;AD, failing as Trajan once did to capture Hatra during a siege.[153]</p><p>Around 212&nbsp;AD, soon after Vologases VI of Parthia (r. c.&nbsp;208–222&nbsp;AD) took the throne, his brother Artabanus V of Parthia (d.&nbsp;224&nbsp;AD) rebelled against him and gained control over a greater part of the empire.[154] Meanwhile, the Roman emperor Caracalla (r.&nbsp;211–217&nbsp;AD) deposed the kings of Osroene and Armenia to make them Roman provinces once more. He marched into Mesopotamia under the pretext of marrying one of Artabanus' daughters, but—because the marriage was not allowed—made war on Parthia and conquered Arbil east of the Tigris river.</p><div class="gradientback"></div></div><div class="content"><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/f/fb/Bas_relief_nagsh-e-rostam_couronnement.jpg/220px-Bas_relief_nagsh-e-rostam_couronnement.jpg" width="220" height="165"><p>


				The Sassanid relief at Naqsh-e Rustam showing the investiture of Ardashir I


				</p><p>
					Caracalla was assassinated the next year on the road to Carrhae by his soldiers.[154] After this debacle, the Parthians made a settlement with Macrinus (r.&nbsp;217–218) where the Romans paid Parthia over two-hundred million denarii with additional gifts.[155]</p><p>But the Parthian Empire, weakened by internal strife and wars with Rome, was soon to be followed by the Sassanid Empire. Indeed, shortly afterward, Ardashir I, the local Iranian ruler of Persis (modern Fars Province, Iran) from Estakhr began subjugating the surrounding territories in defiance of Arsacid rule.[156] He confronted Artabanus V at the Battle of Hormozdgan on 28 April 224&nbsp;AD, perhaps at a site near Isfahan, defeating him and establishing the Sassanid Empire.[156] There is evidence, however, that suggests Vologases VI continued to mint coins at Seleucia as late as 228&nbsp;AD.[157]</p><p>The Sasanians would not only assume Parthia's legacy as Rome's Persian nemesis, but they would also attempt to restore the boundaries of the Achaemenid Empire by briefly conquering the Levant, Anatolia, and Egypt from the Eastern Roman Empire during the reign of Khosrau II (r.&nbsp;590–628&nbsp;AD).[158] However, they would lose these territories to Heraclius—the last Roman emperor before the Arab conquests. Nevertheless, for a period of more than 400 years, they succeeded the Parthian realm as Rome's principal rival.[159][160][161]</p><h3>Native and external sources</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/7/72/Parthian_gold_funerary_objects_by_Nickmard_Khoey.jpg/126px-Parthian_gold_funerary_objects_by_Nickmard_Khoey.jpg" width="126" height="165"><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/6/63/Parthian_jewelry_from_Nineveh_by_Nickmard_Khoey.jpg/174px-Parthian_jewelry_from_Nineveh_by_Nickmard_Khoey.jpg" width="174" height="164"><p>Local and foreign written accounts, as well as non-textual artifacts have been used to reconstruct Parthian history.[162] Although the Parthian court maintained records, the Parthians had no formal study of history; the earliest universal history of Iran, the Khwaday-Namag, was not compiled until the reign of the last Sassanid ruler Yazdegerd III (r. 632–651&nbsp;AD).[163] Indigenous sources on Parthian history remain scarce, with fewer of them available than for any other period of Iranian history.[164] Most contemporary written records on Parthia contain Greek as well as Parthian and Aramaic inscriptions.[165] The Parthian language was written in a distinct script derived from the Imperial Aramaic chancellery script of the Achaemenids, and later developed into the Pahlavi writing system.[166]</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/8/83/Samartian-Persian_necklace_and_amulet.png/220px-Samartian-Persian_necklace_and_amulet.png" width="220" height="163"><p>


				A Sarmatian-Parthian gold necklace and amulet, 2nd century AD. Located in Tamoikin Art Fund


				</p><p>
					The most valuable indigenous sources for reconstructing an accurate chronology of Arsacid rulers are the metal drachma coins issued by each ruler.[167] These represent a transition from non-textual to textual remains, according to historian Geo Widengren.[168] Other Parthian sources used for reconstructing chronology include cuneiform astronomical tablets and colophons discovered in Babylonia.[169] Indigenous textual sources also include stone inscriptions, parchment and papyri documents, and pottery ostraca.[168] For example, at the early Parthian capital of Mithradatkert/Nisa in Turkmenistan, large caches of pottery ostraca have been found yielding information on the sale and storage of items like wine.[170] Along with parchment documents found at sites like Dura-Europos, these also provide valuable information on Parthian governmental administration, covering issues such as taxation, military titles, and provincial organization.[171]</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/6/6a/Golden_Necklace_-_Parthian_Empire_2nd_AD.JPG/220px-Golden_Necklace_-_Parthian_Empire_2nd_AD.JPG" width="220" height="179"><p>


				Parthian golden necklace, 2nd century A.D., Iran, Reza Abbasi Museum



				<br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/c/c6/Iran-bastan-32.jpg/220px-Iran-bastan-32.jpg" width="220" height="157"><br>


				A Parthian ceramic oil lamp, Khuzestan Province, Iran, National Museum of Iran


				</p><div class="gradientback"></div></div><div class="content"><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/c/c6/Iran-bastan-32.jpg/220px-Iran-bastan-32.jpg" width="220" height="157"><br><p>
					The Greek and Latin histories, which represent the majority of materials covering Parthian history, are not considered entirely reliable since they were written from the perspective of rivals and wartime enemies.[172] These external sources generally concern major military and political events, and often ignore social and cultural aspects of Parthian history.[173] The Romans usually depicted the Parthians as fierce warriors but also as a culturally refined people; recipes for Parthian dishes in the cookbook Apicius exemplifies their admiration for Parthian cuisine.[174] Apollodorus of Artemita and Arrian wrote histories focusing on Parthia, which are now lost and survive only as quoted extracts in other histories.[175] Isidore of Charax, who lived during the reign of Augustus, provides an account of Parthian territories, perhaps from a Parthian government survey.[176] To a lesser extent, people and events of Parthian history were also included in the histories of Justin, Strabo, Diodorus Siculus, Plutarch, Cassius Dio, Appian, Josephus, Pliny the Elder, and Herodian.[177]</p><p>Parthian history can also be reconstructed via the Chinese historical records of events.[178] In contrast to Greek and Roman histories, the early Chinese histories maintained a more neutral view when describing Parthia,[179] although the habit of Chinese chroniclers to copy material for their accounts from older works (of undetermined origin) makes it difficult to establish a chronological order of events.[180] The Chinese called Parthia Anxi (Chinese: ??, Old Chinese pronunciation: 'ansj?k), perhaps after the Greek name for the Parthian city Antiochia in Margiana (Greek: ??t???e?a t?? ?a???a??s).[181] However, this could also have been a transliteration of Arsaces, after the dynasty's eponymous founder.[182] The works and historical authors include the Shiji (also known as the Records of the Grand Historian) by Sima Qian, the Han shu (Book of Han) by Ban Biao, Ban Gu, and Ban Zhao, and the Hou Han shu (Book of Later Han) by Fan Ye.[183] They provide information on the nomadic migrations leading up to the early Saka invasion of Parthia and valuable political and geographical information.[178] For example, the Shiji (ch. 123) describes diplomatic exchanges, exotic gifts given by Mithridates II to the Han court, types of agricultural crops grown in Parthia, production of wine using grapes, itinerant merchants, and the size and location of Parthian territory.[184] The Shiji also mentions that the Parthians kept records by writing horizontally on strips of leather, that is, parchment.[185]</p><h2>Government and administration</h2><h3>Central authority and semi-autonomous kings</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/f/fd/650521.jpg/220px-650521.jpg" width="220" height="102"><p>


				Coin of Kamnaskires III, king of Elymais (modern Khuzestan Province), and his wife Queen Anzaze, 1st century BC


				</p><p>
					Compared with the earlier Achaemenid Empire, the Parthian government was notably decentralized.[186] An indigenous historical source reveals that territories overseen by the central government were organized in a similar manner to the Seleucid Empire. They both had a threefold division for their provincial hierarchies: the Parthian marzban, xšatrap, and dizpat, similar to the Seleucid satrapy, eparchy, and hyparchy.[187] The Parthian Empire also contained several subordinate semi-autonomous kingdoms, including the states of Caucasian Iberia, Armenia, Atropatene, Gordyene, Adiabene, Edessa, Hatra, Mesene, Elymais, and Persis.[188] The state rulers governed their own territories and minted their own coinage distinct from the royal coinage produced at the imperial mints.[189] This was not unlike the earlier Achaemenid Empire, which also had some city-states, and even distant satrapies who were semi-independent but recognised the supremacy of the king, paid tribute and provided military support, according to Brosius.[190] However, the satraps of Parthian times governed smaller territories, and perhaps had less prestige and influence than their Achaemenid predecessors.[191] During the Seleucid period, the trend of local ruling dynasties with semi-autonomous rule, and sometimes outright rebellious rule, became commonplace, a fact reflected in the later Parthian style of governance.[192]</p><h3>Nobility</h3><p> Further information: Seven Parthian clans</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/b/b8/Arm_less_man_edit_3.jpg/220px-Arm_less_man_edit_3.jpg" width="220" height="255"><p>


				A bronze statue of a Parthian nobleman from the sanctuary at Shami in Elymais (modern-day Khuzestan Province, Iran, along the Persian Gulf), now located at the National Museum of Iran.


				</p><p>
					The King of Kings headed the Parthian government. He maintained polygamous relations, and was usually succeeded by his first-born son.[193] Like the Ptolemies of Egypt, there is also record of Arsacid kings marrying their nieces and perhaps even half-sisters; Queen Musa married her own son, though this was an extreme and isolated case.[193] Brosius provides an extract from a letter written in Greek by King Artabanus II in 21&nbsp;AD, which addresses the governor (titled archon) and citizens of the city of Susa. Specific government offices of Preferred Friend, Bodyguard and Treasurer are mentioned and the document also proves that while there were local jurisdictions and proceedings to appointment to high office, the king could intervene on behalf of an individual, review a case and amend the local ruling if he considered it appropriate.[194]</p><p>The hereditary titles of the hierarchic nobility recorded during the reign of the first Sassanid monarch Ardashir I most likely reflect the titles already in use during the Parthian era.[195] There were three distinct tiers of nobility, the highest being the regional kings directly below the King of Kings, the second being those related to the King of Kings only through marriage, and the lowest order being heads of local clans and small territories.[196]</p><p>By the 1st century AD, the Parthian nobility had assumed great power and influence in the succession and deposition of Arsacid kings.[197] Some of the nobility functioned as court advisers to the king, as well as holy priests.[198] Of the great noble Parthian families listed at the beginning of the Sasanian period, only two are explicitly mentioned in earlier Parthian documents: the House of Suren and the House of Karen.[199] The historian Plutarch noted that members of the Suren family, the first among the nobility, were given the privilege of crowning each new Arsacid King of Kings during their coronations.[200] Later on, some of the Parthian kings would claim Achaemenid descent. This has recently been corroborated via the possibility of an inherited disease (neurofibromatosis) demonstrated by the physical descriptions of rulers and from evidence of familial disease on ancient coinage.[201]</p><h3>Military</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/3/3f/Zahhak_castle_stucco_2.JPG/220px-Zahhak_castle_stucco_2.JPG" width="220" height="310"><div class="gradientback"></div></div><div class="content"><p>


				A Parthian stucco relief of an infantryman, from the walls of Zahhak Castle, East Azarbaijan Province, Iran


				</p><p>
					The Parthian Empire had no standing army, yet were able to quickly recruit troops in the event of local crises.[202] There was a permanent armed guard attached to the person of the king, comprising nobles, serfs and mercenaries, but this royal retinue was small.[203] Garrisons were also permanently maintained at border forts; Parthian inscriptions reveal some of the military titles granted to the commanders of these locations.[203] Military forces could also be used in diplomatic gestures. For example, when Chinese envoys visited Parthia in the late 2nd century BC, the Shiji maintains that 20,000 horsemen were sent to the eastern borders to serve as escorts for the embassy, although this figure is perhaps an exaggeration.[204]</p><p>The main striking force of the Parthian army was its cataphracts, heavy cavalry with man and horse decked in mailed armor.[205] The cataphracts were equipped with a lance for chargin<br>
							

											 
										

							</p><br><h1 lang="en">Prehistory</h1><p> From Wikipedia, the free encyclopedia</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/d/d5/G%C3%B6bekli_Tepe%2C_Urfa.jpg/300px-G%C3%B6bekli_Tepe%2C_Urfa.jpg" width="300" height="199"><p>


				Massive stone pillars at Göbekli Tepe, in southeast Turkey, erected for ritual use by early Neolithic people 11,000 years ago.


				 
				</p><p>
					Prehistory is the period of human activity between the use of the first stone tools ~3.3 million years ago and the invention of writing systems, the earliest of which appeared ~5300 years ago.</p><p>Sumer in Mesopotamia, the Indus valley civilisation and ancient Egypt were the first civilisations to develop their own scripts, and to keep historical records; this took place already during the early Bronze Age. Neighbouring civilizations were the first to follow. Most other civilizations reached the end of prehistory during the Iron Age. The three-age system of division of prehistory into the Stone Age, followed by the Bronze Age and Iron Age, remains in use for much of Eurasia and North Africa, but is not generally used in those parts of the world where the working of hard metals arrived abruptly with contact with Eurasian cultures, such as the Americas, Oceania, Australasia and much of Sub-Saharan Africa. These areas also, with some exceptions in Pre-Columbian civilizations in the Americas, did not develop complex writing systems before the arrival of Eurasians, and their prehistory reaches into relatively recent periods.</p><p>The beginning of written materials (and so the beginning of local historic times) varies; in many cultures, especially outside Eurasia, it follows conquest by a culture with writing, and often the earliest written sources on pre-literate cultures come from their literate neighbours. The period when a culture is written about by others, but has not developed its own writing is often known as the protohistory of the culture. By definition, there are no written records from human prehistory, so dating of prehistoric materials is crucial. Clear techniques for dating were not well-developed until the 19th century.[1]</p><p>This article is concerned with human prehistory as defined here above. There are separate articles for the overall history of the Earth and the history of life before humans. However, for the human race as a whole, prehistory ends when recorded history begins with the accounts of the ancient world around the 4th millennium BC, and coincides with the invention of writing.</p><h2>Contents</h2><h2>Definition</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/f/f0/Caveman_6.jpg/220px-Caveman_6.jpg" width="220" height="300"><p>


				A prehistoric man and boy.



				<br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/3/3d/Prehistoric_man.jpg/300px-Prehistoric_man.jpg" width="300" height="204"><br>


				man in wilderness



				Beginning

				</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/3/3d/Prehistoric_man.jpg/300px-Prehistoric_man.jpg" width="300" height="204"><br><p>
					The term prehistory can refer to the vast span of time since the beginning of the Universe or the Earth, but more often it refers to the period since life appeared on Earth, or even more specifically to the time since human-like beings appeared.[2][3]</p><div class="gradientback"></div></div><div class="content"><p>The date marking the end of prehistory in a particular culture or region, that is, the date when relevant written historical records become a useful academic resource, varies enormously from region to region. For example, in Egypt it is generally accepted that prehistory ended around 3200 BC, whereas in New Guinea the end of the prehistoric era is set much more recently, at around 1900 AD. In Europe the relatively well-documented classical cultures of Ancient Greece and Ancient Rome had neighbouring cultures, including the Celts and to a lesser extent the Etruscans, with little or no writing, and historians must decide how much weight to give to the often highly prejudiced accounts of these prehistoric cultures in Greek and Roman literature.</p><p>In dividing up human prehistory, historians typically use the three-age system, whereas scholars of pre-human time periods typically use the well-defined geologic record and its internationally defined stratum base within the geologic time scale. The three-age system is the periodization of human prehistory into three consecutive time periods, named for their respective predominant tool-making technologies:</p><h3>History of the term</h3><p>The notion of prehistory began to surface during the Enlightenment in the work of antiquarians who used the word 'primitive' to describe societies that existed before written records.[5] The first use of the word prehistory in English, however, occurred in the Foreign Quarterly Review in 1836.[6]</p><p>The use of the geologic time scale for pre-human time periods, and of the three-age system for human prehistory, is a system that emerged during the late nineteenth century in the work of British, German and Scandinavian archeologists, antiquarians and anthropologists.[4]</p><h2>Means of research</h2><p>The main source for prehistory is archaeology, but some scholars are beginning to make more use of evidence from the natural and social sciences.[7][8][9] This view has been articulated by advocates of deep history.</p><p>The primary researchers into human prehistory are archaeologists and physical anthropologists who use excavation, geologic and geographic surveys, and other scientific analysis to reveal and interpret the nature and behavior of pre-literate and non-literate peoples.[2] Human population geneticists and historical linguists are also providing valuable insight for these questions.[3] Cultural anthropologists help provide context for societal interactions, by which objects of human origin pass among people, allowing an analysis of any article that arises in a human prehistoric context.[3] Therefore, data about prehistory is provided by a wide variety of natural and social sciences, such as paleontology, biology, archaeology, palynology, geology, archaeoastronomy, comparative linguistics, anthropology, molecular genetics and many others.</p><p>Human prehistory differs from history not only in terms of its chronology but in the way it deals with the activities of archaeological cultures rather than named nations or individuals. Restricted to material processes, remains and artifacts rather than written records, prehistory is anonymous. Because of this, reference terms that prehistorians use, such as Neanderthal or Iron Age are modern labels with definitions sometimes subject to debate.</p><h2>Stone Age</h2><h3>Palaeolithic</h3><p> Main article: Paleolithic</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/c/c8/Map-of-human-migrations.svg/400px-Map-of-human-migrations.svg.png" width="400" height="286"><p>


				Map of early human migrations, according to mitochondrial population genetics. Numbers are millennia before the present (accuracy disputed).


				</p><p>
					Palaeolithic means Old Stone Age, and begins with the first use of stone tools. The Paleolithic is the earliest period of the Stone Age.</p><p>The early part of the Palaeolithic is called the Lower Palaeolithic, which predates Homo sapiens, beginning with Homo habilis (and related species) and with the earliest stone tools, dated to around 2.5 million years ago.[10] Evidence of control of fire by early humans during the Lower Palaeolithic Era is uncertain and has at best limited scholarly support. The most widely accepted claim is that H. erectus or H. ergaster made fires between 790,000 and 690,000&nbsp;BP (before the present period) in a site at Bnot Ya'akov Bridge, Israel. The use of fire enabled early humans to cook food, provide warmth, and have a light source at night.</p><p>Early Homo sapiens originated some 200,000 years ago, ushering in the Middle Palaeolithic. Anatomic changes indicating modern language capacity also arise during the Middle Palaeolithic.[11] During the Middle Palaeolithic Era, there is the first definitive evidence of human use of fire. Sites in Zambia have charred bone and wood that have been dated to 61,000 B.P. The systematic burial of the dead, music, early art, and the use of increasingly sophisticated multi-part tools are highlights of the Middle Paleolithic.</p><p>Throughout the Palaeolithic, humans generally lived as nomadic hunter-gatherers. Hunter-gatherer societies tended to be very small and egalitarian,[12] though hunter-gatherer societies with abundant resources or advanced food-storage techniques sometimes developed sedentary lifestyles with complex social structures such as chiefdoms[citation needed], and social stratification. Long-distance contacts may have been established, as in the case of Indigenous Australian highways known as songlines.[citation needed]</p><h3>Mesolithic</h3><p> Main article: Mesolithic</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/f/fa/Dugout_boats_Kierikki_Centre_Oulu_20130526.JPG/260px-Dugout_boats_Kierikki_Centre_Oulu_20130526.JPG" width="260" height="172"><div class="gradientback"></div></div><div class="content"><p>


				Dugout canoe


				</p><p>
					The Mesolithic, or Middle Stone Age (from the Greek mesos, middle, and lithos, stone) was a period in the development of human technology between the Palaeolithic and Neolithic periods of the Stone Age.</p><p>The Mesolithic period began at the end of the Pleistocene epoch, some 10,000 BP, and ended with the introduction of agriculture, the date of which varied by geographic region. In some areas, such as the Near East, agriculture was already underway by the end of the Pleistocene, and there the Mesolithic is short and poorly defined. In areas with limited glacial impact, the term Epipalaeolithic is sometimes preferred.</p><p>Regions that experienced greater environmental effects as the last ice age ended have a much more evident Mesolithic era, lasting millennia. In Northern Europe, societies were able to live well on rich food supplies from the marshlands fostered by the warmer climate. Such conditions produced distinctive human behaviours that are preserved in the material record, such as the Maglemosian and Azilian cultures. These conditions also delayed the coming of the Neolithic until as late as 4000 BC (6,000 BP) in northern Europe.</p><p>Remains from this period are few and far between, often limited to middens. In forested areas, the first signs of deforestation have been found, although this would only begin in earnest during the Neolithic, when more space was needed for agriculture.</p><p>The Mesolithic is characterized in most areas by small composite flint tools — microliths and microburins. Fishing tackle, stone adzes and wooden objects, e.g. canoes and bows, have been found at some sites. These technologies first occur in Africa, associated with the Azilian cultures, before spreading to Europe through the Ibero-Maurusian culture of Northern Africa and the Kebaran culture of the Levant. Independent discovery is not always ruled out.</p><h3>Neolithic</h3><p> Main article: Neolithic</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/0/09/Malta_Hagar_Qim_BW_2011-10-04_16-39-32.JPG/220px-Malta_Hagar_Qim_BW_2011-10-04_16-39-32.JPG" width="220" height="147"><p>


				Entrance to the Ggantija phase temple complex of Hagar Qim, Malta, 3900 BC.[13]



				<br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/6/6b/N%C3%A9olithique_0001.jpg/200px-N%C3%A9olithique_0001.jpg" width="200" height="133"><br>


				An array of Neolithic artifacts, including bracelets, axe heads, chisels, and polishing tools. Neolithic stone artifacts are by definition polished and, except for specialty items, not chipped.


				</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/6/6b/N%C3%A9olithique_0001.jpg/200px-N%C3%A9olithique_0001.jpg" width="200" height="133"><br><p>
					Neolithic means New Stone Age. Although there were several species of human beings during the Paleolithic, by the Neolithic only Homo sapiens sapiens remained.[14] (Homo floresiensis may have survived right up to the very dawn of the Neolithic, about 12,200 years ago.)[15] This was a period of primitive technological and social development. It began about 10,200 BC in some parts of the Middle East, and later in other parts of the world[16] and ended between 4,500 and 2,000 BC. The Neolithic is a progression of behavioral and cultural characteristics and changes, including the use of wild and domestic crops and of domesticated animals.</p><p>Early Neolithic farming was limited to a narrow range of plants, both wild and domesticated, which included einkorn wheat, millet and spelt, and the keeping of dogs, sheep and goats. By about 6,900–6,400 BC, it included domesticated cattle and pigs, the establishment of permanently or seasonally inhabited settlements, and the use of pottery. The Neolithic period saw the development of early villages, agriculture, animal domestication, tools and the onset of the earliest recorded incidents of warfare.[17] The Neolithic era commenced with the beginning of farming, which produced the Neolithic Revolution. It ended when metal tools became widespread (in the Copper Age or Bronze Age; or, in some geographical regions, in the Iron Age).The term Neolithic is commonly used in the Old World, as its application to cultures in the Americas and Oceania that did not fully develop metal-working technology raises problems.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/8/8b/Luni_sul_Mignone_monumental_building.jpg/200px-Luni_sul_Mignone_monumental_building.jpg" width="200" height="134"><p>


				The monumental building at Luni sul Mignone in Blera, Italy, 3500 BC.


				</p><p>
					Settlements became more permanent with some having circular houses with single rooms made of mudbrick. Settlements might have a surrounding stone wall to keep domesticated animals in and protect the inhabitants from other tribes. Later settlements have rectangular mud-brick houses where the family lived together in single or multiple rooms. Burial findings suggest an ancestor cult where people preserved skulls of the dead. The Vinca culture may have created the earliest system of writing.[18] The megalithic temple complexes of Ggantija are notable for their gigantic structures. Although some late Eurasian Neolithic societies formed complex stratified chiefdoms or even states, states evolved in Eurasia only with the rise of metallurgy, and most Neolithic societies on the whole were relatively simple and egalitarian.[19] Most clothing appears to have been made of animal skins, as indicated by finds of large numbers of bone and antler pins which are ideal for fastening leather. Wool cloth and linen might have become available during the later Neolithic,[20][21] as suggested by finds of perforated stones that (depending on size) may have served as spindle whorls or loom weights.[22][23][24]</p><h3>Chalcolithic</h3><p> Main article: Chalcolithic</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/1/1c/Los_Millares_recreacion_cuadro.jpg/220px-Los_Millares_recreacion_cuadro.jpg" width="220" height="159"><div class="gradientback"></div></div><div class="content"><p>


				Artist's impression of a Copper Age walled city, Los Millares, Iberia


				</p><p>
					In Old World archaeology, the Chalcolithic, Eneolithic or Copper Age refers to a transitional period where early copper metallurgy appeared alongside the widespread use of stone tools. During this period, some weapons and tools were made of copper. This period was still largely Neolithic in character. It is a phase of the Bronze Age before it was discovered that adding tin to copper formed the harder bronze. The Copper Age was originally defined as a transition between the Neolithic and the Bronze Age. However, because it is characterized by the use of metals, the Copper Age is considered a part of the Bronze Age rather than the Stone Age.</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/a/a5/TimnaChalcolithicMine.JPG/200px-TimnaChalcolithicMine.JPG" width="200" height="150"><p>


				Chalcolithic copper mine in Timna Valley, Negev Desert, Israel


				</p><p>
					An archaeological site in Serbia contains the oldest securely dated evidence of copper making at high temperature, from 7,500 years ago. The find in June 2010 extends the known record of copper smelting by about 800 years, and suggests that copper smelting may have been invented in separate parts of Asia and Europe at that time rather than spreading from a single source.[25] The emergence of metallurgy may have occurred first in the Fertile Crescent, where it gave rise to the Bronze Age in the 4th millennium BC (the traditional view), though finds from the Vinca culture in Europe have now been securely dated to slightly earlier than those of the Fertile Crescent. Timna Valley contains evidence of copper mining 9,000 to 7,000 years ago. The process of transition from Neolithic to Chalcolithic in the Middle East is characterized in archaeological stone tool assemblages by a decline in high quality raw material procurement and use. North Africa and the Nile Valley imported its iron technology from the Near East and followed the Near Eastern course of Bronze Age and Iron Age development. However the Iron Age and Bronze Age occurred simultaneously in much of Africa.</p><h2>Bronze Age</h2><p> Main article: Bronze Age</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/9/91/Maler_der_Grabkammer_des_Sennudem_001.jpg/220px-Maler_der_Grabkammer_des_Sennudem_001.jpg" width="220" height="144"><p>


				Ox-drawn plow, Egypt, ca. 1200 BCE.


				</p><p>
					The Bronze Age is the earliest period in which some civilizations have reached the end of prehistory, by introducing written records. The Bronze Age or parts thereof are thus considered to be part of prehistory only for the regions and civilizations who adopted or developed a system of keeping written records during later periods. The invention of writing coincides in some areas with the early beginnings of the Bronze Age. Soon after the appearance of writing, people started creating texts including written accounts of events and records of administrative matters.</p><p>The term Bronze Age refers to a period in human cultural development when the most advanced metalworking (at least in systematic and widespread use) included techniques for smelting copper and tin from naturally occurring outcroppings of ores, and then combining them to cast bronze. These naturally occurring ores typically included arsenic as a common impurity. Copper/tin ores are rare, as reflected in the fact that there were no tin bronzes in Western Asia before 3000 BC. The Bronze Age forms part of the three-age system for prehistoric societies. In this system, it follows the Neolithic in some areas of the world.</p><p>While copper is a common ore, deposits of tin are rare in the Old World, and often had to be traded or carried considerable distances from the few mines, stimulating the creation of extensive trading routes. In many areas as far apart as China and England, the valuable new material was used for weapons but for a long time apparently not available for agricultural tools. Much of it seems to have been hoarded by social elites, and sometimes deposited in extravagant quantities, from Chinese ritual bronzes and Indian copper hoards to European hoards of unused axe-heads.</p><p>By the end of the Bronze Age large states, which are often called empires, had arisen in Egypt, China, Anatolia (the Hittites) and Mesopotamia, all of them literate.</p><h2>Iron Age</h2><p> Main articles: Iron Age and Classical antiquity</p><p>The Iron Age is not part of prehistory for all civilizations who had introduced written records during the Bronze Age. Most remaining civilizations did so during the Iron Age, often through conquest by the empires, which continued to expand during this period. For example, in most of Europe conquest by the Roman Empire means that the term Iron Age is replaced by Roman, Gallo-Roman and similar terms after the conquest.</p><p>In archaeology, the Iron Age refers to the advent of ferrous metallurgy. The adoption of iron coincided with other changes in some past cultures, often including more sophisticated agricultural practices, religious beliefs and artistic styles, which makes the archaeological Iron Age coincide with the Axial Age in the history of philosophy. Although iron ore is common, the metalworking techniques necessary to use iron are very different from those needed for the metal used earlier, and iron was slow-spreading and for long mainly used for weapons, while bronze remained typical for tools, as well as art.</p><h2>Timeline</h2><p> Further information: Timeline of human evolution, Timeline of the Stone Age, and Timeline of human prehistory</p><p>All dates are approximate and conjectural, obtained through research in the fields of anthropology, archaeology, genetics, geology, or linguistics. They are all subject to revision due to new discoveries or improved calculations. BP stands for Before Present (1950). BCE stands for Before Common Era.</p><h2>By region</h2><div class="gradientback"></div></div><div class="content"><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Prehistory&amp;oldid=783519853"					
								Categories:  Hidden categories:</p><br><h1 lang="en">Canaan</h1><p> From Wikipedia, the free encyclopedia</p><p>Canaan (/'ke?n?n/; Northwest Semitic: kna?n; Phoenician: ????????????????; Biblical Hebrew/ Masoretic: ???????? [K?na‘an; ??na‘an]) was a Semitic-speaking region in the Ancient Near East during the late 2nd millennium BC. In the Bible it corresponds to the Levant, in particular to the areas of the Southern Levant that provide the main setting of the narrative of the Hebrew Bible, i.e., the area of Israel, Philistia, Phoenicia, and other nations.</p><p>The name Canaan occurs commonly in the Hebrew Bible. In particular, the references in Genesis 10 and Numbers 34 define the Land of Canaan as extending from Lebanon southward to the Brook of Egypt and eastward to the Jordan River Valley. References to Canaan in the Bible are usually backward-looking, referring to a region that had become something else (i.e., the Land of Israel).</p><p>The term Canaanites serves as an ethnic catch-all term covering various indigenous populations—both settled and nomadic-pastoral groups—throughout the regions of the southern Levant or Canaan.[1] It is by far the most frequently used ethnic term in the Bible,[2] which commonly describes Canaanites as a people which, in the Book of Joshua are marked down on a list as one of the nations to be exterminated,[3] and later as a group which the Israelites had annihilated.[4]</p><p>Archaeological attestation of the name Canaan in Ancient Near Eastern sources relates almost exclusively to the period in which the region operated as a colony of the New Kingdom of Egypt (16th–11th centuries BC), with usage of the name almost disappearing following the Late Bronze Age collapse (c. 1206–1150 BC).[5] The references suggest that during this period the term was familiar to the region's neighbors on all sides, although scholars have disputed to what extent such references provide a coherent description of its location and boundaries, and regarding whether the inhabitants used the term to describe themselves.[6] The Amarna Letters and other cuneiform documents use Kina??u [Kinakh'khu], while other sources of the Egyptian New Kingdom mention numerous military campaigns conducted in Ka-na-na.[7]</p><p>The name Canaanites (???????????? kana‘anim, ?????????? kana‘ani) is attested, many centuries later, as the endonym of the people later known to the Ancient Greeks from c. 500 BC as Phoenicians,[4] and following the emigration of Canaanite speakers to Carthage, was also used as a self-designation by the Punics (chanani) during Late Antiquity. This mirrors later usage in later books of the Hebrew Bible, such as at the end of the Book of Zechariah, where it is thought[by whom?] to refer to a class of merchants or to non-monotheistic worshippers in Israel or neighbouring Sidon and Tyre, as well as in its single independent usage in the New Testament, where it is alternated for Syrophoenician in two parallel passages.</p><p>Canaan had significant geopolitical importance in the Late Bronze Age Amarna period (14th century BC) as the area where the spheres of interest of the Egyptian, Hittite, Mitanni and Assyrian Empires converged. Much of the modern knowledge about Canaan stems from archaeological excavation in this area at sites such as Tel Hazor, Tel Megiddo, and Gezer.</p><h2>Contents</h2><h2>Etymology</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/2/26/Middle_East_by_Robert_de_Vaugondy.jpg/250px-Middle_East_by_Robert_de_Vaugondy.jpg" width="250" height="247"><p>


				Map of the Near East by Robert de Vaugondy (1762), indicating Canaan as limited to the Holy Land, to the exclusion of Lebanon and Syria


				</p><p>
					The English term Canaan (pronounced /'ke?n?n/ since c. AD 1500, due to the Great Vowel Shift) comes from the Hebrew ????? (kn?n), via Greek ?a?a?? Khanaan and Latin Canaan. It appears as KUR ki-na-ah-na in the Amarna letters (14th century BC), and kn?n is found on coins from Phoenicia in the last half of the 1st millennium. It first occurs in Greek in the writings of Hecataeus as Khna (???).[8] Scholars connect the name Canaan with kn?n, Kana'an, the general Northwest Semitic name for this region.</p><p>The etymology is uncertain. An early explanation derives the term from the Semitic root kn? to be low, humble, subjugated.[9] Some scholars have suggested that this implies an original meaning of lowlands, in contrast with Aram, which would then mean highlands,[10] whereas others have suggested it meant the subjugated as the name of Egypt's province in the Levant, and evolved into the proper name in a similar fashion to Provincia Nostra (the first Roman colony north of the Alps, which became Provence).[11]</p><p>An alternative suggestion put forward by Ephraim Avigdor Speiser in 1936 derives the term from Hurrian Kinahhu, purportedly referring to the colour purple, so that Canaan and Phoenicia would be synonyms (Land of Purple). Tablets found in the Hurrian city of Nuzi in the early 20th century appear to use the term Kinahnu as a synonym for red or purple dye, laboriously produced by the Kassite rulers of Babylon from murex shells as early as 1600&nbsp;BC, and on the Mediterranean coast by the Phoenicians from a byproduct of glassmaking. Purple cloth became a renowned Canaanite export commodity which is mentioned in Exodus. The dyes may have been named after their place of origin. The name 'Phoenicia' is connected with the Greek word for purple, apparently referring to the same product, but it is difficult to state with certainty whether the Greek word came from the name, or vice versa. The purple cloth of Tyre in Phoenicia was well known far and wide and was associated by the Romans with nobility and royalty. However, according to Robert Drews, Speiser's proposal has generally been abandoned.[12][13]</p><h2>Archaeology</h2><h3>Origins</h3><p>Canaanite culture apparently developed in situ from the earlier Ghassulian chalcolithic culture, which pioneered the Mediterranean agricultural system typical of the Canaanite region, which comprised intensive subsistence horticulture, extensive grain growing, commercial wine and olive cultivation and transhumance pastoralism. Ghassulian itself developed from the Circum-Arabian Nomadic Pastoral Complex, which in turn developed from a fusion of their ancestral Natufian and Harifian cultures with Pre-Pottery Neolithic B (PPNB) farming cultures, practicing animal domestication, during the 6200&nbsp;BC climatic crisis which led to the Agricultural Revolution/Neolithic Revolution in the Levant.[14] The Late Bronze Age state of Ugarit (at Ras Shamra in Syria) is considered quintessentially Canaanite archaeologically,[15] even though its Ugaritic language does not belong to the Canaanite language group proper.[16][17][18]</p><div class="gradientback"></div></div><div class="content"><h3>Middle Bronze Age</h3><p>Ebla tablets (ca. 2500–2200 BC)</p><p>A disputed reference to Lord of ga-na-na in the Semitic Eblaite tablets (dated 2350&nbsp;BC) from the archive of Tell Mardikh has been interpreted by some scholars to mention the deity Dagon by the title Lord of Canaan[19] If correct, this would suggest that Eblaites were conscious of Canaan as an entity by 2500 BC.[20] Jonathan Tubb states that the term ga-na-na may provide a third millennium reference to Canaanite while at the same time stating that the first certain reference is in the 18th century BC.[21] See Ebla-Biblical controversy for further details.</p><p>Mari letters (ca. 2000 BC)</p><p>A letter from Mutu-bisir to Shamshi-Adad I (c. 1809&nbsp;– 1776 BC) of the Old Assyrian Empire (2025–1750 BC) has been translated: It is in Rahisum that the brigands (habbatum) and the Canaanites (Kinahnum) are situated. It was found in 1973 in the ruins of Mari, an Assyrian outpost at that time in Syria.[15][22] Additional unpublished references to Kinahnum in the Mari letters refer to the same episode.[23] Whether the term Kinahnum refers to people from a specific region or rather people of foreign origin has been disputed,[24][25] such that Robert Drews states that the ?rst certain cuneiform reference to Canaan is found on the Alalakh statue of King Idrimi (below).[26]</p><h3>Late Bronze Age cuneiform (1500–1000 BC)</h3><p>Alalakh texts[23]</p><p>A reference to Ammiya being in the land of Canaan is found on the Statue of Idrimi (16th century BC) from Alalakh in modern Syria. After a popular uprising against his rule, Idrimi was forced into exile with his mother's relatives to seek refuge in the land of Canaan, where he prepared for an eventual attack to recover his city. The other references in the Alalakh texts are:[23]</p><p>Amarna letters</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/4/4e/BM_29785_EA_9_Reverse_v2.jpg/220px-BM_29785_EA_9_Reverse_v2.jpg" width="220" height="206"><p>


				Amarna tablet EA 9


				</p><p>
					References to Canaanites are also found throughout the Amarna letters of Pharaoh Akenaton circa 1350&nbsp;BC. In the Amarna letters (circa 1350&nbsp;BC), some of which were sent by governors and princes of Canaan to their Egyptian overlord Akhenaten (Amenhotep IV) in the 14th century BC, are found, beside Amar and Amurru (Amorites), the two forms Kinahhi and Kinahni, corresponding to Kena and Kena'an respectively, and including Syria in its widest extent, as Eduard Meyer has shown. The letters are written in the official and diplomatic East Semitic Akkadian language of Assyria and Babylonia, though Canaanitish words and idioms are also in evidence. The known references are:[23]</p><p>Ugarit texts</p><p>Text RS 20.182 from Ugarit is a copy of a letter of the king of Ugarit to Ramesses II concerning money paid by the sons of the land of Ugarit to the foreman of the sons of the land of Canaan (*kn'ny) According to Jonathan Tubb, this suggests that the Semitic people of Ugarit, contrary to much modern opinion, considered themselves to be non-Canaanite.[27]</p><p>The other Ugarit reference, KTU 4.96, shows a list of traders assigned to royal estates, of which one of the estates had three Ugaritans, an Ashdadite, an Egyptian and a Canaanite.[23]</p><p>Ashur tablets</p><p>A Middle Assyrian letter during the reign of Shalmaneser I includes a reference to the travel to Canaan of an Assyrian official.[23]</p><p>Hattusa letters</p><p>Four references are known from Hattusa:[23]</p><h3>Late Bronze Age Hieroglyphic and Hieratic (1500–1000 BC)</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/d/d4/KAnana.gif/150px-KAnana.gif" width="150" height="90"><p>


				The name Canaan occurs in hieroglyphs as k3n?n? on the Merneptah Stele in the 13th century BC


				</p><p>
					During the 2nd millennium BC, Ancient Egyptian texts use the term Canaan to refer to an Egyptian-ruled colony, whose boundaries generally corroborate the definition of Canaan found in the Hebrew Bible, bounded to the west by the Mediterranean Sea, to the north in the vicinity of Hamath in Syria, to the east by the Jordan Valley, and to the south by a line extended from the Dead Sea to around Gaza. Nevertheless, the Egyptian and Hebrew uses of the term are not identical: the Egyptian texts also identify the coastal city of Qadesh in north west Syria near Turkey as part of the Land of Canaan, so that the Egyptian usage seems to refer to the entire Levantine coast of the Mediterranean Sea, making it a synonym of another Egyptian term for this coastland, Retenu or rather Retjenu.</p><p>Lebanon, in northern Canaan, bordered by the Litani river to the watershed of the Orontes River, was known by the Egyptians as upper Retjenu.[28] In Egyptian campaign accounts, the term Djahi was used to refer to the watershed of the Jordan river. Many earlier Egyptian sources also mention numerous military campaigns conducted in Ka-na-na, just inside Asia.[7]</p><p>16 references are known in Egyptian sources, from the Eighteenth Dynasty of Egypt onwards.[23]</p><h3>Later sources</h3><p>Padiiset's Statue is the last known Egyptian reference to Canaan, a small statuette labelled Envoy of the Canaan and of Peleset, Pa-di-Eset, the son of Apy. The inscription is dated to 900–850 BC, more than 300 years after the preceding known inscription.[31]</p><p>During the period from c. 900–330 BC, the dominant empires of the Neo-Assyrians and Achaemenid Persians make no mention of Canaan.[32]</p><div class="gradientback"></div></div><div class="content"><h2>Greco-Roman historiography</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/6/67/Laodikeia_Canaan.png/220px-Laodikeia_Canaan.png" width="220" height="103"><p>


				Coin of Alexander II Zabinas with the inscription "Laodikeia, metropole of Canaan"[33]



				</p><p> Further information: Syria Phoenicia and Palestine</p><p>
					The Greek term Phoenicia is first attested in the first two works of Western literature, Homer's Iliad and Odyssey. It does not occur in the Hebrew Bible, but occurs three times in the New Testament in the Book of Acts.[34] In the 6th century BC, Hecataeus of Miletus affirms that Phoenicia was formerly called ??a, a name that Philo of Byblos subsequently adopted into his mythology as his eponym for the Phoenicians: Khna who was afterwards called Phoinix. Quoting fragments attributed to Sanchuniathon, he relates that Byblos, Berytus and Tyre were among the first cities ever built, under the rule of the mythical Cronus, and credits the inhabitants with developing fishing, hunting, agriculture, shipbuilding and writing.</p><p>Coins of the city of Beirut / Laodicea bear the legend, Of Laodicea, a metropolis in Canaan; these coins are dated to the reign of Antiochus IV (175–164 BC) and his successors until 123 BC.[33]</p><p>Saint Augustine also mentions that one of the terms the seafaring Phoenicians called their homeland was Canaan. Augustine also records that the rustic people of Hippo in North Africa retained the Punic self-designation Chanani.[35][36] Since 'punic' in Latin also meant 'non-Roman', some scholars however argue that the language referred to as Punic in Augustine may have been Libyan.[37]</p><p>The Greeks also popularized the term Palestine, named after the Greek Philistines or the Aegean Pelasgians, for roughly the region of Canaan, excluding Phoenicia, with Herodotus' first recorded use of Palaistinê, ca. 480 BC. From 110 BC, the Hasmoneans extended their authority over much of the region, creating a Judean-Samaritan-Idumaean-Ituraean-Galilean alliance. The Judean (Jewish, see Ioudaioi) control over the wider area resulted in it also becoming known as Judaea, a term that had previously only referred to the smaller region of the Judean Mountains, the allotment of the Tribe of Judah and heartland of the former Kingdom of Judah.[38][39] Between 73–63 BC, the Roman Republic extended its influence into the region in the Third Mithridatic War, conquering Judea in 63 BC, and splitting the former Hasmonean Kingdom into five districts. Around 130–135 AD, as a result of the suppression of the Bar Kochba revolt, the province of Iudaea was joined with Galilee to form new province of Syria Palaestina. There is circumstantial evidence linking Hadrian with the name change,[40] although the precise date is not certain,[40] and the interpretation of some scholars that the name change may have been intended to complete the dissociation with Judaea[41][42] is disputed.[43]</p><h2>History</h2><h3>Overview</h3><p>After the Iron Age the periods are named after the various empires that ruled the region: Assyrian, Babylonian, Persian, Greek (Hellenistic) and Roman.[44]</p><h3>Prehistory</h3><p> Main article: Prehistory of the Southern Levant</p><p>One of the earliest settlements in the region was at Jericho in Canaan. The earliest settlements were seasonal, but, by the Bronze Age, had developed into large urban centres.</p><h3>Early Bronze Age (3500–2000)</h3><p>By the Early Bronze Age other sites had developed, such as Ebla (where an East Semitic language, Eblaite, was spoken), which by c. 2300&nbsp;BC was incorporated into the Mesopotamia-based Akkadian Empire of Sargon the Great and Naram-Sin of Akkad (biblical Accad). Sumerian references to the Mar.tu (tent dwellers, later Amurru, i.e. Amorite) country West of the Euphrates date from even earlier than Sargon, at least to the reign of the Sumerian king, Enshakushanna of Uruk, and one tablet credits the early Sumerian king Lugal-anne-mundu with holding sway in the region, although this tablet is considered less credible because it was produced centuries later.</p><p>The archives of Ebla show reference to a number of biblical sites, including Hazor, Jerusalem, and as a number of people have claimed, to Sodom and Gomorrah mentioned in Genesis as well. Ebla and Amorites at Hazor, Kadesh (Qadesh-on-the-Orontes), and elsewhere in Amurru (Syria) bordered Canaan in the north and northeast. (Ugarit may be included among these Amoritic entities.[45]) The collapse of the Akkadian Empire in 2154&nbsp;BC saw the arrival of peoples using Khirbet Kerak Ware pottery,[46] coming originally from the Zagros Mountains (in modern Iran) east of the Tigris.</p><p>The first cities in the southern Levant arose during this period.[47] These proto-Canaanites were in regular contact with the other peoples to their south such as Egypt, and to the north Asia Minor (Hurrians, Hattians, Hittites, Luwians) and Mesopotamia (Sumer, Akkad, Assyria), a trend that continued through the Iron Age.[47] The end of the period is marked by the abandonment of the cities and a return to lifestyles based on farming villages and semi-nomadic herding, although specialised craft production continued and trade routes remained open.[47]</p><h3>Middle Bronze Age (2000–1550)</h3><p>Urbanism returned and the region was divided among small city-states, the most important of which seems to have been Hazor.[48] Many aspects of Canaanite material culture now reflected a Mesopotamian influence, and the entire region became more tightly integrated into a vast international trading network.[48]</p><p>As early as Naram-Sin of Akkad's reign (c. 2240&nbsp;BC), Amurru was called one of the four quarters surrounding Sumer, along with Subartu/Assyria, Akkad, and Elam.</p><p>Amorite dynasties also came to dominate in much of Mesopotamia, including in Larsa, Isin and founding the state of Babylon in 1894&nbsp;BC. Later on, Amurru became the Assyrian/Akkadian term for the interior of south as well as for northerly Canaan. At this time the Canaanite area seemed divided between two confederacies, one centred upon Megiddo in the Jezreel Valley, the second on the more northerly city of Kadesh on the Orontes River.</p><p>An Amorite chieftain named Sumu-abum founded Babylon as an independent city-state in 1894 BC. One Amorite king of Babylonia, Hammurabi (1792–1750&nbsp;BC) founded the first Babylonian Empire, which lasted only as long as his lifetime. Upon his death, the Amorites were driven from Assyria, but remained masters of Babylonia until 1595&nbsp;BC, when they were ejected by the Hittites.</p><p>The semi-fictional Story of Sinuhe describes an Egyptian officer, Sinuhe conducting military activities in the area of Upper Retchenu and Finqu during the reign of Senusret I (ca. 1950 BC). The earliest bonafide Egyptian report of a campaign to Mentu, Retchenu and Sekmem (Shechem) is the Sebek-khu Stele dated to the reign of Senusret III (c. 1862 BC).</p><p>Around 1650 BC, Canaanites invaded the eastern Delta of Egypt, where, known as the Hyksos, they became the dominant power.[49] In Egyptian inscriptions, Amar and Amurru (Amorites) are applied strictly to the more northerly mountain region east of Phoenicia, extending to the Orontes.</p><div class="gradientback"></div></div><div class="content"><p>Archaeological excavations of a number of sites, later identified as Canaanite, show that prosperity of the region reached its apogee during this Middle Bronze Age period, under leadership of the city of Hazor, at least nominally tributary to Egypt for much of the period. In the north, the cities of Yamkhad and Qatna were hegemons of important confederacies, and it would appear that biblical Hazor was the chief city of another important coalition in the south.</p><h3>Late Bronze Age (1550–1200)</h3><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/9/98/14_century_BC_Eastern.png/350px-14_century_BC_Eastern.png" width="350" height="194"><p>


				Map of the Ancient Near East during the Amarna Period, showing the great powers of the day: Egypt (orange), Hatti (blue), the Kassite kingdom of Babylon (black), Middle Assyrian Empire (yellow), and Mitanni (brown). The extent of the Achaean/Mycenaean civilization is shown in purple.


				</p><p>
					In the early Late Bronze Age, Canaanite confederacies were centered on Megiddo and Kadesh, before again being brought into the Egyptian Empire and Hittite Empire. Later still, the region was assimilated into the Neo Assyrian Empire.</p><p>Among the migrant ancient Semitic-speaking peoples who appear to have settled in the region were the Amorites, who had earlier controlled Babylonia. In the Hebrew Bible, the Amorites are mentioned in the Table of Peoples (Gen. 10:16–18a). Evidently, the Amorites played a significant role in the early history of Canaan. In Gen. 14:7 f., Josh. 10:5 f., Deut. 1:19 f., 27, 44, we find them located in the southern mountain country, while in Num. 21:13, Josh. 9:10, 24:8, 12, etc., we are told of two great Amorite kings residing at Heshbon and Ashteroth, east of the Jordan. However, in other passages such as Gen. 15:16, 48:22, Josh. 24:15, Judg. 1:34, etc., the name Amorite is regarded as synonymous with Canaanite; however Amorite is never used for the population on the coast.</p><p>In the centuries preceding the appearance of the biblical Hebrews, parts of Canaan and southwestern Syria became tributary to the Egyptian Pharaohs, although domination by the Egyptians was sporadic, and not strong enough to prevent frequent local rebellions and inter-city struggles. Other areas such as northern Canaan and northern Syria came to be ruled by the Assyrians during this period.</p><p>Under Thutmose III (1479–1426&nbsp;BC) and Amenhotep II (1427–1400&nbsp;BC), the regular presence of the strong hand of the Egyptian ruler and his armies kept the Amorites and Canaanites sufficiently loyal. Nevertheless, Thutmose III reported a new and troubling element in the population. Habiru or (in Egyptian) 'Apiru, are reported for the first time. These seem to have been mercenaries, brigands or outlaws, who may have at one time led a settled life, but with bad-luck or due to the force of circumstances, contributed a rootless element of the population, prepared to hire themselves to whichever local mayor, king or princeling prepared to undertake their support.</p><p>Although Habiru SA-GAZ (a Sumerian ideogram glossed as brigand in Akkadian), and sometimes Habiri (an Akkadian word) had been reported in Mesopotamia from the reign of the Sumerian king, Shulgi of Ur III, their appearance in Canaan appears to have been due to the arrival of a new state based in Asia Minor to the north of Assyria based upon Maryannu aristocracy of horse-drawn charioteers, associated with the Indo-Aryan rulers of the Hurrians, known as Mitanni.</p><p>The Habiru seem to have been more a social class than an ethnic group. One analysis shows that the majority were, however, Hurrian (a non-Semitic-speaking group from Asia Minor who spoke a language isolate), though there were a number of Semites and even some Kassite and Luwian adventurers amongst their number. The reign of Amenhotep III, as a result was not quite so tranquil for the Asiatic province, as Habiru/'Apiru contributed to greater political instability. It is believed[by whom?] that turbulent chiefs began to seek their opportunities, though as a rule could not find them without the help of a neighbouring king. The boldest of the disaffected nobles was Aziru, son of Abdi-Ashirta, a prince of Amurru, who even before the death of Amenhotep III, endeavoured to extend his power into the plain of Damascus. Akizzi, governor of Katna (Qatna?) (near Hamath), reported this to the Pharaoh, who seems to have sought to frustrate his attempts. In the next reign, however, both father and son caused infinite trouble to loyal servants of Egypt like Rib-Hadda, governor of Gubla (Gebal), not the least through transferring loyalty from the Egyptian crown to that of the expanding neighbouring Asia Minor based Hittite Empire under Suppiluliuma I.[50]</p><p>Egyptian power in Canaan thus suffered a major setback when the Hittites (or Hatti) advanced into Syria in the reign of Amenhotep III, and became even more threatening in that of his successor, displacing the Amorites and prompting a resumption of Semitic migration. Abd-Ashirta and his son Aziru, at first afraid of the Hittites, afterwards made a treaty with their king, and joining with the Hittites, attacked and conquered the districts remaining loyal to Egypt. In vain did Rib-Hadda send touching appeals for aid to the distant Pharaoh, who was far too engaged in his religious innovations to attend to such messages.</p><p>In the Amarna letters, we meet with the Habiri in northern Syria. Etakkama wrote thus to the Pharaoh,</p><p>Similarly, Zimrida, king of Sidon (named 'Siduna'), declared, All my cities which the king has given into my hand, have come into the hand of the Habiri. The king of Jerusalem, Abdi-Heba, reported to the Pharaoh,</p><p>Abdi-heba's principal trouble arose from persons called Iilkili and the sons of Labaya, who are said to have entered into a treasonable league with the Habiri. Apparently this restless warrior found his death at the siege of Gina. All these princes, however, maligned each other in their letters to the Pharaoh, and protested their own innocence of traitorous intentions. Namyawaza, for instance, whom Itakkama (see above) accused of disloyalty, wrote thus to the Pharaoh,</p><p>From the mid 14th century BC through to the 11th century BC, much of Canaan (particularly the north, central and eastern regions of Syria and the north western Mediterranean coastal regions) fell to the Middle Assyrian Empire, and both Egyptian and Hittite influence waned as a result. Powerful Assyrian kings forced tribute on Canaanite states and cities from north, east and central Syria as far as the Mediterranean.[52] Arik-den-ili (c. 1307–1296&nbsp;BC), consolidated Assyrian power in the Levant, he defeated and conquered ancient Semitic-speaking peoples of the so-called Ahlamu group. He was followed by Adad-nirari I (1295–1275&nbsp;BC) who continued expansion to the northwest, mainly at the expense of the Hittites and Hurrians, conquering Hittite territories such as Carchemish and beyond. In 1274&nbsp;BC Shalmaneser I ascended the throne, a powerful warrior king, he annexed territories in Syria and Canaan previously under Egyptian or Hittite influence, and the growing power of Assyria was perhaps the reason why these two states made peace with one another.[52] This trend continued under Tukulti-Ninurta I (1244–1208&nbsp;BC) and after a hiatus, Tiglath-Pileser I (1115–1077&nbsp;BC) who conquered the Arameans of northern Syria, and thence he proceeded to conquer Damascus and the Canaanite/Phoenician cities of (Byblos), Sidon, Tyre and finally Arvad.[52]</p><h3>Bronze Age collapse</h3><div class="gradientback"></div></div><div class="content"><p>Ann Killebrew has shown that cities such as Jerusalem were large and important walled settlements in the 'Pre-Israelite' Middle Bronze IIB and the Israelite Iron Age IIC period (c. 1800–1550 and 720–586&nbsp;BC), but that during the intervening Late Bronze (LB) and Iron Age I and IIA/B Ages sites like Jerusalem were small and relatively insignificant and unfortified towns.[53]</p><p>Just after the Amarna period a new problem arose which was to trouble the Egyptian control of southern Canaan (the rest of the region now being under Assyrian control). Pharaoh Horemhab campaigned against Shasu (Egyptian = wanderers) or living in nomadic pastoralist tribes, who had moved across the Jordan to threaten Egyptian trade through Galilee and Jezreel. Seti I (ca. 1290&nbsp;BC) is said to have conquered these Shasu, Semitic-speaking nomads living just south and east of the Dead Sea, from the fortress of Taru (Shtir?) to Ka-n-'-na. After the near collapse of the Battle of Kadesh, Rameses II had to campaign vigorously in Canaan to maintain Egyptian power. Egyptian forces penetrated into Moab and Ammon, where a permanent fortress garrison (Called simply Rameses) was established.</p><p>Some believe the Habiru signified generally all the nomadic tribes known as Hebrews, and particularly the early Israelites of the period of the judges, who sought to appropriate the fertile region for themselves.[54] However, the term was rarely used to describe the Shasu. Whether the term may also include other related ancient Semitic-speaking peoples such as the Moabites, Ammonites and Edomites is uncertain. It may not be an ethnonym at all; see the article Habiru for details.</p><h3>Iron Age</h3><p> Main articles: Phoenicia and History of ancient Israel and Judah</p><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/e/e8/Levant_830.svg/300px-Levant_830.svg.png" width="300" height="325"><p>


				Map of the southern Levant,[original research?] c.830s&nbsp;BC.
				&nbsp;&nbsp;Kingdom of Judah
				&nbsp;&nbsp;Kingdom of Israel
				&nbsp;&nbsp;Philistine city-states
				&nbsp;&nbsp;Phoenician states
				&nbsp;&nbsp;Kingdom of Ammon
				&nbsp;&nbsp;Kingdom of Edom
				&nbsp;&nbsp;Kingdom of Aram-Damascus
				&nbsp;&nbsp;Aramean tribes
				&nbsp;&nbsp;Arubu tribes
				&nbsp;&nbsp;Nabatu tribes
				&nbsp;&nbsp;Assyrian Empire
				&nbsp;&nbsp;Kingdom of Moab



				: Archaeology of Israel and History of ancient Israel and Judah
				</p><p>
					By the Early Iron Age, the southern Levant came to be dominated by the kingdoms of Israel and Judah, besides the Philistine city-states on the Mediterranean coast, and the kingdoms of Moab, Ammon and Aram-Damascus east of the Jordan River, and Edom to the south. The northern Levant was divided into various petty kingdoms, the so-called Syro-Hittite states and the Phoenician city-states.</p><p>The entire region (including all Phoenician/Canaanite and Aramean states, together with Israel, Philistia and Samarra) was conquered by the Neo-Assyrian Empire during the 10th and 9th centuries BC, and would remain so for three hundred years until the end of the 7th century BC. Assyrian emperor-kings such as Ashurnasirpal, Adad-nirari II, Sargon II, Tiglath-Pileser III, Esarhaddon, Sennacherib and Ashurbanipal came to dominate Canaanite affairs. The Egyptians, then under a Nubian Dynasty, made a failed attempt to regain a foothold in the region, but were vanquished by the Assyrians, leading to an Assyrian invasion and conquest of Egypt and the destruction of the Kushite Empire. The Kingdom of Judah was forced to pay tribute to Assyria. Between 616 and 605 BC the Assyrian Empire collapsed due to a series of bitter internal civil wars, followed by an attack by an alliance of Babylonians, Medes and Persians and the Scythians. The Babylonians inherited the western part of the empire of their Assyrian brethren, including all the lands in Canaan and Syria, together with Israel and Judah. They successfully defeated the Egyptians, who had belatedly attempted to aid their former masters, the Assyrians, and then remained in the region in an attempt to regain a foothold in the Near East. The Babylonian Empire itself collapsed in 539 BC, and Canaan fell to the Persians and became a part of the Achaemenid Empire. It remained so until in 332 BC it was conquered by the Greeks under Alexander the Great, later to fall to Rome in the late 2nd century BC, and then Byzantium, until the Arab Islamic invasion and conquest of the 7th century AD.[52]</p><h2>Culture</h2><p>Canaan included what today are Lebanon, Israel, Palestine, northwestern Jordan, and some western areas of Syria.[55] According to archaeologist Jonathan N. Tubb, Ammonites, Moabites, Israelites and Phoenicians undoubtedly achieved their own cultural identities, and yet ethnically they were all Canaanites, the same people who settled in farming villages in the region in the 8th millennium BC.[56]</p><p>There is uncertainty about whether the name Canaan refers to a specific Semitic-speaking ethnic group wherever they live, the homeland of this ethnic group, or a region under the control of this ethnic group, or perhaps any combination of the three.</p><p>Canaanite civilization was a response to long periods of stable climate interrupted by short periods of climate change. During these periods, Canaanites profited from their intermediary position between the ancient civilizations of the Middle East—Ancient Egypt, Mesopotamia (Sumer, Akkad, Assyria, Babylonia), the Hittites, and Minoan Crete—to become city states of merchant princes along the coast, with small kingdoms specializing in agricultural products in the interior. This polarity, between coastal towns and agrarian hinterland, was illustrated in Canaanite mythology by the struggle between the storm god, variously called Teshub (Hurrian) or Ba'al Hadad (Semitic Amorite/Aramean) and Ya'a, Yaw, Yahu or Yam, god of the sea and rivers. Early Canaanite civilization was characterized by small walled market towns, surrounded by peasant farmers growing a range of local horticultural products, along with commercial growing of olives, grapes for wine, and pistachios, surrounded by extensive grain cropping, predominantly wheat and barley. Harvest in early summer was a season when transhumance nomadism was practiced—shepherds staying with their flocks during the wet season and returning to graze them on the harvested stubble, closer to water supplies in the summer. Evidence of this cycle of agriculture is found in the Gezer calendar and in the biblical cycle of the year.</p><p>Periods of rapid climate change generally saw a collapse of this mixed Mediterranean farming system; commercial production was replaced with subsistence agricultural foodstuffs; and transhumance pastoralism became a year-round nomadic pastoral activity, whilst tribal groups wandered in a circular pattern north to the Euphrates, or south to the Egyptian delta with their flocks. Occasionally, tribal chieftains would emerge, raiding enemy settlements and rewarding loyal followers from the spoils or by tariffs levied on merchants. Should the cities band together and retaliate, a neighbouring state intervene or should the chieftain suffer a reversal of fortune, allies would fall away or intertribal feuding would return. It has been suggested that the Patriarchal tales of the Bible reflect such social forms.[57] During the periods of the collapse of Akkadian Empire in Mesopotamia and the First Intermediate Period of Egypt, the Hyksos invasions and the end of the Middle Bronze Age in Assyria and Babylonia, and the Late Bronze Age collapse, trade through the Canaanite area would dwindle, as Egypt, Babylonia, and to a lesser degree Assyria, withdrew into their isolation. When the climates stabilized, trade would resume firstly along the coast in the area of the Philistine and Phoenician cities. As markets redeveloped, new trade routes that would avoid the heavy tariffs of the coast would develop from Kadesh Barnea, through Hebron, Lachish, Jerusalem, Bethel, Samaria, Shechem, Shiloh through Galilee to Jezreel, Hazor and Megiddo. Secondary Canaanite cities would develop in this region. Further economic development would see the creation of a third trade route from Eilath, Timna, Edom (Seir), Moab, Ammon and thence to the Aramean states of Damascus and Palmyra. Earlier states (for example the Philistines and Tyrians in the case of Judah and Samaria, for the second route, and Judah and Israel for the third route) tried generally unsuccessfully to control the interior trade.[58]</p><div class="gradientback"></div></div><div class="content"><p>Eventually, the prosperity of this trade would attract more powerful regional neighbours, such as Ancient Egypt, Assyria, the Babylonians, Persians, Ancient Greeks and Romans, who would control the Canaanites politically, levying tribute, taxes and tariffs. Often in such periods, thorough overgrazing would result in a climatic collapse and a repeat of the cycle (e.g., PPNB, Ghassulian, Uruk, and the Bronze Age cycles already mentioned). The fall of later Canaanite civilization occurred with the incorporation of the area into the Greco-Roman world (as Iudaea province), and after Byzantine times, into the Muslim Arab and proto-Muslim Umayyad Caliphate. Western Aramaic, one of the two lingua francas of Canaanite civilization, is still spoken in a number of small Syrian villages, whilst Phoenician Canaanite disappeared as a spoken language in about 100&nbsp;AD. A separate Akkadian-infused Eastern Aramaic is still spoken by the existing Assyrians of Iraq, Iran, northeast Syria and southeast Turkey.</p><p>Tel Kabri contains the remains of a Canaanite city from the Middle Bronze Age (2000–1550 BC). The city, the most important of the cities in the Western Galilee during that period, had a palace at its center. Tel Kabri is the only Canaanite city that can be excavated in its entirety because after the city was abandoned, no other city was built over its remains. It is notable because the predominant extra-Canaanite cultural influence is Minoan; Minoan-style frescoes decorate the palace.[59]</p><h2>Legacy</h2><p>Canaan is used as a synonym of the Promised Land; for instance, it is used in this sense in the hymn, Canaan's Happy Shore, with the lines: Oh, brothers, will you meet me, (3x)/On Canaan's happy shore, a hymn set to the tune later used in The Battle Hymn of the Republic.</p><h2>List of Canaan's rulers</h2><p> Further information: kings of Ugarit</p><p>Names of Canaanite kings or other figures mentioned in historiography or known through archaeology</p><h2>In Scripture</h2><br><img alt="" src="http://upload.wikimedia.org/wikipedia/commons/thumb/c/cd/Map_Land_of_Israel.jpg/250px-Map_Land_of_Israel.jpg" width="250" height="350"><p>


				Map of Canaan, with the border defined by Numbers 34:1–12 shown in red.


				</p><h3>Hebrew Bible</h3><p>
					In Biblical usage, the name was confined to the country west of the Jordan River. Canaanites were described as living by the sea, and along by the side of the Jordan (Book of Numbers 33:51; Book of Joshua 22:9). Canaan was especially identified with Phoenicia (Book of Isaiah 23:11).[60] The Philistines, while an integral part of the Canaanite milieu, do not seem to have been ethnic Canaanites, and were listed in the Table of Nations as descendants of Mizraim; the Arameans, Moabites, Ammonites, Midianites and Edomites were also considered fellow descendants of Shem or Abraham, and distinct from generic Canaanites/Amorites. Heth, representing the Hittites, is a son of Canaan. The later Hittites spoke an Indo-European language (called Nesili), but their predecessors the Hattians had spoken a little-known language (Hattili), of uncertain affinities.[citation needed]</p><p>The Horites, formerly of Mount Seir, were implied to be Canaanite (Hivite), although unusually there is no direct confirmation of this in the narrative. The Hurrians, based in Upper Mesopotamia, spoke the Hurrian language. Their language was a language isolate. They were initially regarded by Bible scholars as akin to the Horites, though this is no longer the case.[citation needed][why?]</p><p>In the Bible, the renaming of the Land of Canaan as the Land of Israel marks the Israelite conquest of the Promised Land.[61]</p><p>Canaan and the Canaanites are mentioned some 160 times in the Hebrew Bible, mostly in the Pentateuch and the books of Joshua and Judges.[62]</p><p>An eponymous ancestor called Canaan first appears as one of Noah's grandsons. He appears during the narrative known as the Curse of Ham, in which Canaan is cursed with perpetual slavery because his father Ham had looked upon the drunk and naked Noah.[citation needed]</p><p>God later promises the land of Canaan to Abraham, and eventually delivers it to descendants of Abraham, the Israelites.[62] The biblical history has become increasingly problematic as the archaeological and textual evidence supports the idea that the early Israelites were in fact themselves Canaanites.[62]</p><p>The Hebrew Bible lists borders for the land of Canaan. The Book of Numbers, 34:2, includes the phrase the land of Canaan as defined by its borders. The borders are then delineated in Numbers 34:3–12. The term Canaanites in biblical Hebrew is applied especially to the inhabitants of the lower regions, along the sea coast and on the shores of the Jordan River, as opposed to the inhabitants of the mountainous regions. By the Second Temple period (530 BC–70 AD),[63] Canaanite in the Hebrew language had come to be not an ethnic designation, so much as a general synonym for merchant, as it is interpreted in, for example, Book of Job 40:30, or Book of Proverbs 31:24.[64]</p><p>John N. Oswalt notes that Canaan consists of the land west of the Jordan and is distinguished from the area east of the Jordan. Oswalt then goes on to say that in Scripture, Canaan takes on a theological character as the land which is God's gift and the place of abundance.[65]</p><p>The Hebrew Bible describes the Israelite conquest of Canaan in the Former Prophets (Nevi'im Rishonim [?????? ???????] ), viz. the books of Joshua, Judges, Samuel, and Kings. These books of the Old Testament canon give the narrative of the Israelites after the death of Moses and their entry into Canaan under the leadership of Joshua.[66] In 586&nbsp;BC, the Kingdom of Judah was annexed into the Neo-Babylonian Empire. The city of Jerusalem fell after a siege which lasted either eighteen or thirty months.[67] By 586 BC, much of Judah was devastated, and the former kingdom suffered a steep decline of both economy and population.[68] The descendants of the Israelites thus lost control of the land.[citation needed] These narratives of the Former Prophets are also part of a larger work, called the Deuteronomistic History.[69]</p><p>The passage in the Book of Genesis often called the Table of Nations presents the Canaanites as descendants of an eponymous ancestor called Canaan, the son of Ham and grandson of Noah (Hebrew: ??????????, Knaan). (Genesis 10:15–19) states:</p><div class="gradientback"></div></div><div class="content"><p>Canaan is the father of Sidon, his firstborn; and of the Hittites, Jebusites, Amorites, Girgashites, Hivites, Arkites, Sinites, Arvadites, Zemarites, and Hamathites. Later the Canaanite clans scattered, and the borders of Canaan reached [across the Mediterranean coast] from Sidon toward Gerar as far as Gaza, and then [inland around the Jordan Valley ] toward Sodom, Gomorrah, Admah and Zeboiim, as far as Lasha.</p><p>The Sidon whom the Table identifies as the firstborn son of Canaan has the same name as that of the coastal city of Sidon in Lebanon. This city dominated the Phoenician coast, and may have enjoyed hegemony over a number of ethnic groups, who are said to belong to the Land of Canaan.[citation needed]</p><p>Similarly, Canaanite populations are said to have inhabited:</p><p>The Canaanites (Hebrew: ??????, Modern&nbsp;Kna'anim, Tiberian&nbsp;K?na?anîm) are said to have been one of seven regional ethnic divisions or nations driven out by the Israelites following the Exodus. Specifically, the other nations include the Hittites, the Girgashites, the Amorites, the Perizzites, the Hivites, and the Jebusites (Deuteronomy 7:1).</p><p>According to the Book of Jubilees, the Israelite conquest of Canaan is attributed to Canaan's steadfast refusal to join his elder brothers in Ham's allotment beyond the Nile, and instead squatting on the eastern shores of the Mediterranean Sea, within the inheritance delineated for Shem. Canaan thus incurs a further curse from Noah for disobeying the agreed apportionment of land.[citation needed]</p><p>One of the 613 commandments (precisely n. 596) prescribes that no inhabitants of the cities of six Canaanite nations, the same as mentioned in 7:1, minus the Girgashites, were to be left alive.[citation needed]</p><p>While the Hebrew Bible distinguishes the Canaanites ethnically from the ancient Israelites, modern scholars Jonathan Tubb and Mark S. Smith have theorized—based on their archaeological and linguistic interpretations—that the Kingdom of Israel and the Kingdom of Judah represented a subset of Canaanite culture.[27][70]</p><h3>New Testament</h3><p>Canaan (Greek: ?a?a??, Chanaán) is used only three times in the New Testament: twice in Acts of the Apostles when paraphrasing Old Testament stories,[71] and once in the exorcism of the Syrophoenician woman's daughter. The latter story is told by both the Gospel of Matthew and the Gospel of Mark; Matthew uses the term Chananaia (Greek: ?a?a?a?a), where Mark calls the woman Syrophoenician (Greek: S???f??????ssa). Strong's Concordance describes the term Chananaia as in Christ's time equivalent to Phoenician.[72]</p><h2>Black Africans as descendants of Canaan</h2><p> Further information: Curse of Ham and Book of Abraham</p><p>During the Atlantic slave trade, many Christians began teaching that black Africans were descendants of Canaan and used the Curse of Ham to justify enslaving black Africans.[73][74] This belief was especially strong in the Church of Jesus Christ of Latter-day Saints, who canonized the Book of Abraham, which teaches that Canaan was a descendant of Cain, that his descendants settled Africa, and that they were cursed. Joseph Smith and Brigham Young both used the Curse of Ham to justify slavery in Mormonism.[75][76] This was also their rationale in denying Africans access to their priesthood until June 1978, at which point their prophet at the time, President Spencer W. Kimball, announced that as far as priesthood was concerned, the curse was lifted.[77]</p><p>Modern scholars do not believe that black Africans are related to the Canaanites based upon race as depicted throughout local and Egyptian arts and Genetics and Physical Anthropology.[78]</p><h2>Notes</h2><p>Coordinates: 32°46'00?N 35°20'00?E? / ?32.7667°N 35.3333°E? / 32.7667; 35.3333</p><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Canaan&amp;oldid=783622759"					
								Categories:  Hidden categories:</p><br><h1 lang="en">Ba'athist Iraq</h1><p> From Wikipedia, the free encyclopedia</p><p>Ba'athist Iraq, formally the Iraqi Republic, covers the history of Iraq between 1968 and 2003, during the period of the Arab Socialist Ba'ath Party's rule. This period began with high economic growth and soaring prosperity, but ended with Iraq facing social, political, and economic stagnation. The average annual income decreased because of several external factors, and several internal policies of the regime.</p><p>Iraqi President Abdul Rahman Arif, and Iraqi Prime Minister Tahir Yahya, were ousted during the 17 July coup d'état led by Ahmed Hassan al-Bakr of the Ba'ath Party, which had previously held power in 1963 and was led primarily by al-Bakr, its leader, and Saddam Hussein.[1] Saddam through his post as de facto chief of the party's intelligence services, became the country's de facto leader by the mid-1970s, and became de jure leader in 1979 when he succeeded al-Bakr in office as President. During al-Bakr's de jure rule, the country's economy grew, and Iraq's standing within the Arab world increased. However, several internal factors were threatening the country's stability, among them the country's conflict with Iran and factions within Iraq's own Shia Muslim community. An external problem was the border conflict with Iran, which would contribute to the Iran–Iraq War.</p><p>Saddam became President of Iraq, Chairman of the Revolutionary Command Council, Prime Minister and General Secretary of the Regional Command of the Ba'ath Party in 1979, during a wave of anti-government protests in Iraq led by Shias. The Ba'ath Party, which was secular in nature, harshly repressed the protests. Another policy change was Iraq's foreign policy towards Iran, a Shia Muslim country. Deteriorating relations eventually led to the Iran–Iraq War, which started in 1980 when Iraq launched a full-scale invasion of Iran. Following the 1979 Iranian revolution, the Iraqis believed the Iranians to be weak, and thus an easy target for their military. This notion proved to be incorrect, and the war lasted for eight years. Iraq's economy deteriorated during the war, and the country became dependent on foreign donations to fund their war effort. The war ended in a stalemate when a ceasefire was reached in 1988, which resulted in a status quo ante bellum.</p><p>When the war ended, Iraq found itself in the midst of an economic depression, owed millions of dollars to foreign countries, and was unable to repay its creditors. Kuwait, which had deliberately increased oil output following the war, reducing international oil prices, further weakened the Iraqi economy. In response to this, Saddam threatened Kuwait that, unless it reduced its oil output, Iraq would invade. Negotiations broke down, and on 2 August 1990, Iraq launched an invasion of Kuwait. The resulting international response led to the Persian Gulf War, which Iraq lost. The United Nations (U.N.) initiated economic sanctions in the war's aftermath to weaken the Ba'athist Iraqi government. The country's economic conditions worsened during the 1990s, and at the turn of the 21st century, Iraq's economy started to grow again as several states ignored U.N. sanctions. In the aftermath of the September 11 attacks of 2001, the United States initiated a Global War on Terrorism, and labelled Iraq as a part of an Axis of Evil. In 2003, U.S. coalition forces invaded Iraq, and the Ba'athist Iraqi government was deposed less than a month later.</p><h2>Contents</h2><h2>History</h2><h3>1968 coup</h3><p> Main article: 17 July Revolution</p><p>In contrast to previous coups d'état in Iraq's history, the 1968 coup, referred to as the 17 July Revolution, was, according to Con Coughlin, a relatively civil affair. The coup started in the early hours of 17 July, when a number of military units and civilian ba'athists seized several key government and military buildings; these included the Ministry of Defence, the electricity station, radio stations, all the city's bridges and a number of military bases. All telephone lines were cut at 03:00, by which time several tanks had been commanded to halt in front of the Presidential Palace. Abdul Rahman Arif, the then-President of Iraq, first knew of the coup when jubilant members of the Republican Guard started shooting into the air in a premature triumph. Ahmed Hassan al-Bakr, the leader of the operation, told Arif about his situation through military communication hardware at the base of operations. Arif asked for more time, during which he contacted other military units to seek support. As he soon found out, the odds were against him, and he surrendered. Arif telephoned al-Bakr and told him that he was willing to resign; to show his gratitude, al-Bakr guaranteed his safety. al-Bakr's deputies, Hardan al-Tikriti and Saleh Omar al-Ali, were ordered to give Arif this message in person.[2] Arif and his wife and son were quickly sent on the first available flight to London, UK. Later that morning, a ba'athist broadcast announced that a new government had been established. The coup was carried out with such ease that no lives were lost.[3]</p><div class="gradientback"></div></div><div class="content"><p>The coup succeeded because of contributions made by the military; the Arab Socialist Ba'ath Party was not strong enough to take power by itself. The Ba'ath Party managed to make a deal with Abd ar-Razzaq an-Naif, the deputy head of military intelligence, and Ibrahim Daud, the head of the Republican Guard. Both Naif and Daud knew that the long-term survival of Arif's and Tahir Yahya's government looked bleak, but also knew that the ba'athists needed them if the coup was to be successful. For his participation in the coup, Naif demanded to be given the post of Prime Minister after the coup as a reward, and a symbol for his strength. Daud was also rewarded with a post; he became Minister of Defence. However, not everything was going according to Naif's and Daud's plan; al-Bakr had told the Ba'ath leadership in a secret meeting that the two would be liquidated either during, or after, the revolution.[4]</p><p>al-Bakr, as the leader of the coup's military operation, retained his position as Regional Secretary of the Ba'ath Party, and was elected to the posts of Chairman of the Revolutionary Command Council, President and Prime Minister. In the immediate aftermath of the coup, a power struggle developed between al-Bakr and Naif. In all practicality, Naif should have had the upper hand; he was a respected officer and was supported by the common soldier. al-Bakr, however, proved to be more cunning, persuasive and organised than Naif, Daud and their supporters.[5] One of al-Bakr's first decisions in office was to appoint over 100 new officers to the Republican Guard. Saddam Hussein worked, in the meantime, to establish the party's security and intelligence organisation to combat its enemies. On 29 July, Daud left for a tour to Jordan to inspect the Iraqi troops located there following the Six Day War with Israel. The following day, Naif was invited to eat lunch at the Presidential Palace with al-Bakr, during which Saddam burst into the room with three accomplices and threatened Naif with death. Naif responded by crying out; I have four children. Saddam ordered Naif to leave Iraq immediately if he wanted to live.[6] Naif complied, was exiled to Morocco. An assassination attempt in 1973 was unsuccessful, but he was assassinated in London on the orders of Saddam in 1978. Daud shared a similar fate, and was exiled to Saudi Arabia. The Ba'athist were by no means ensured of victory; if any of Naif's supporters had known of the operation against him, Baghdad could have become the centre, in the words of historian Con Coughlin, of an ugly bloodbath.[7]</p><h3>Al-Bakr's rule and Saddam's rise to power (1968–1979)</h3><br><img alt="Black-and-white photo of middle-aged, mustachioed man in suit" src="http://upload.wikimedia.org/wikipedia/commons/thumb/3/3f/Ahmad_Hassan_el_Bakr.jpg/220px-Ahmad_Hassan_el_Bakr.jpg" width="220" height="290"><p>


				Ahmed Hassan al-Bakr was de jure leader of Iraq from 1968 to 1979.


				</p><p>
					al-Bakr strengthened his position in the party with the help of Saddam's newly established party security apparatus and the intelligence services. Most of 1968 was used to repress non-Ba'athist thought and groups; for instance, a campaign against Nasserists and communists was initiated under Saddam's command.[8] Several spy plots were created by the government; spies who were caught were accused of being a part of a Zionist plot against the state.[9] The Iraqi Communist Party (ICP) was skeptical of the new Ba'athist government, as many of its members remembered the anti-communist campaign launched against them by the Ba'athist government of 1963. After taking power, al-Bakr offered the ICP cabinet positions in the new government; the ICP rejected this offer. al-Bakr responded by initiating a systematic campaign against the ICP and communist sympathisers. However, as historian Charles Tripp notes in A History of Iraq, the campaign started a curious game whereby the government alternately persecuted and courted the party until 1972–1973, when the ICP was offered, and accepted, membership in the National Progressive Front (NPF). The reason for this curious game was the Ba'ath Party's belief that the ICP was more dangerous than it really was. When Aziz al-Haji broke away from the ICP, established the Iraqi Communist Party (Central Command) and initiated a popular revolutionary war against the government, it was duly crushed. By April 1969 the popular revolutionary uprising had been crushed, and al-Haji recanted his beliefs publicly.[10] Another reason for this anti-communist policy was that many Ba'ath Party members openly sympathised with communists or other socialist forces. However, at this stage, neither al-Bakr nor Saddam had enough support within the party to initiate a policy unpopular within it; at the Seventh Regional Congress of the Ba'ath Party, both al-Bakr and other leading Ba'athists expressed their support for radical socialism.[11]</p><p>By the mid-to-late 1970s, Saddam's power within the Ba'ath Party and the government grew; he became de facto leader of the country, although al-Bakr remained as president, Ba'ath Party leader and Revolutionary Command Council chairman. In 1977, following a wave of protests by Shi'ites against the government, al-Bakr relinquished his control over the Ministry of Defence; Adnan Khairallah Tulfah, Saddam's brother-in-law, was appointed defence minister. This appointment underscored the clannish character of the Ba'ath Party and the government. In contrast to Saddam's fortunes, those of al-Bakr's were on the wane. Rumours of al-Bakr's bad health began to circulate in the country. By the end of 1977, al-Bakr had little control over the country through his office as president. The reason Saddam did not become president until 1979 may be explained by Saddam's own insecurity.[12] Before making himself de jure head of state, Saddam initiated an anti-communist campaign; the ICP had no real power, and most of its leading officials had left the country or been imprisoned or executed by the Ba'ath government. The campaign was not centered on the ICP, but also Ba'athists who did not support Saddam. Saddam had initiated a similar campaign in 1978, that time to check where the loyalties of certain left-wingers were: Ba'athism or socialism. Following the campaign, Saddam entered the Arab-world stage for the first time under the banner of Nasserism and Gamal Abdel Nasser by criticising the Camp David Accords between Anwar Sadat of Egypt and the state of Israel.[13]</p><p>In response to the Iranian Revolution, several Iraqi Shi'ites revolted against what they saw as a Sunni-led government, which led to the collapse of the Ba'ath Party in certain areas of the country. It was in this situation that Saddam took over the offices of president, Ba'ath Party leader and Revolutionary Command Council chairman.[14] Izzat Ibrahim al-Duri was promoted to the office of vice-chairman (equivalent to the post of vice-president in the West). There were also rumours within the top echelons of power that al-Bakr (with the assistance of Iraqi Ba'athists who opposed Saddam) was planning to designate Hafez al-Assad as his successor. Immediately after Saddam seized power, over 60 members of the Ba'ath Party and the government leadership were charged with fomenting an anti-Iraqi Ba'athist plot in collaboration with al-Assad and the Damascus-based Ba'ath Party.[15]</p><h3>Early years, Iran-Iraq War and aftermath (1979–1990)</h3><br><img alt="Prisoners of war walking through desert-war devastation" src="http://upload.wikimedia.org/wikipedia/commons/thumb/8/82/Khorramshahr_POWs_crop.jpg/220px-Khorramshahr_POWs_crop.jpg" width="220" height="126"><div class="gradientback"></div></div><div class="content"><p>


				Demoralized Iraqi POWs at Khorramshahr.


				</p><p>
					Once he assumed the presidency, a cult of personality was created around Saddam. He was represented as the father of the nation and, by extension, of the Iraqi people. National institutions (such as the National Assembly) were established to strengthen the image of him fostered by the Iraqi propaganda machine.[16] The Ba'ath Party also contributed to the cult of personality; by 1979 it was a nationwide organisation, and became a propaganda center for pro-Saddam literature.[17] The propaganda campaign (at least in the beginning) created a common sense of nationhood for many Iraqis.[18] The Shi'ite protests were not quelled by these propaganda campaigns, and the establishment of an Islamic Republic in Iran influenced many Shi'ites to stand up against the Sunni-dominated government. At first relations between Iran and Iraq were fairly good, but ideological differences could not remain concealed forever. The new Iranian leadership was composed of Shia Islamists, while the Iraqi Ba'athists were secular. Iran has become concerned about the Iraqi government's continued repression against the Iraqi Islamist Shi'ites.[19] At the beginning of 1980, several border clashes took place between the two countries. Iraq considered the newly established Iran to be weak; the country was in a state of continued civil unrest, and the Iranian leaders had purged thousands of officers and soldiers because of their political views.[20]</p><p>It has been presumed that the Iran–Iraq War would result in a quick Iraqi victory. Saddam's plan was to strengthen Iraq's position in the Persian Gulf and on the Arab-world stage. A quick victory would restore Iraq's control over all of Shatt al-Arab, an area which Iraq had lost to Iran in 1975.[21] Saddam abrogated the treaty of 1975 in a meeting of the National Assembly on 17 September 1980. This abrogation was followed shortly afterwards by several preemptive strikes on Iran and by the invasion of Iran. Saddam believed that the Iranian government would have to disengage in order to survive. Not only was this view faulty, but it overestimated the strength of the Iraqi military; the Iranian government saw the invasion as a test of the revolution itself and all its achievements.[21] The military plan proved to be elusive; Iraq believed that the Iranian government would quickly disintegrate during the Iraqi invasion, this did not happen. Saddam, in a rare moment of frankness, [...] admitted as much.[22] While the war was not going as planned, Iraq reasserted its view of the situation, and claimed that winning the war was a matter of national honour. The majority of the Ba'athist leadership (and Saddam himself) still believed that Iran would collapse under the weight of Iraqi force.[23]</p><br><img alt="File:Shakinghands high.ogv" style="width:220px;height:165px" src="http://upload.wikimedia.org/wikipedia/commons/thumb/3/38/Shakinghands_high.ogv/220px-seek%3D5-Shakinghands_high.ogv.jpg"><p>In 1982, Iran counter-attacked and was successful in driving the Iraqis back into Iraq. That year alone, an estimated 40,000 Iraqis were taken prisoner. The defeats of 1982 were a blow to Iraq. With the economic situation worsening because of falling oil prices (and the rising military budget), the Iraqi standard of living worsened. The Revolutionary Command Council and the Ba'ath Military Command, Regional Command and National Command met in an extraordinary session in 1982 (with Saddam absent), to discuss the possibility of a ceasefire proposal to the Iranian government. The ceasefire proposal made at the meeting was rejected by the Iranian government. If the proposal had been accepted Saddam would have not have survived politically, since it was supported by all members of the Regional Command, National Command and the Revolutionary Command Council. It was at this time that rumours started circulating that Hussein would step down as president to make way for al-Bakr, the former president. As events proved, this did not happen and al-Bakr died in 1982 under mysterious circumstances.[24] Bloodshed during the conflict[25] nearly led to a mutiny led by Maher Abd al-Rashid, father-in-law of Saddam's second son.[26] Rashid began public criticism, and claimed that loss of life could have been averted if not for Saddam's meddling into military affairs.[27] This confrontation with the military led to the greater independence of military planning from Ba'athist-leadership interference. Shortly afterwards, the Iraqi Air Force once again established air superiority.[28] The turn of events caused the Iraqi government to focus on Iraqi Kurdistan which had revolted. Saddam appointed his cousin Ali Hasan al-Majid as military chief in Kurdistan. al-Majid initiated the al-Anfal campaign; chemical weapons were used against civilians.[29] In April 1988, after a series of Iraqi military victories, a ceasefire was agreed between Iraq and Iran; the war is commonly considered status quo ante bellum.[30]</p><h3>Persian Gulf War, the 1990s and the Iraq War (1990–2003)</h3><br><img alt="Huge oil fire, with two soldiers in foreground" src="http://upload.wikimedia.org/wikipedia/commons/thumb/7/78/Kuwait_burn_oilfield.png/220px-Kuwait_burn_oilfield.png" width="220" height="124"><p>


				Retreating Iraqi forces sabotaged Kuwaiti oil wells, causing massive fires across Kuwait's oil fields.


				</p><p>
					In the aftermath of the Iran–Iraq War, Kuwait intentionally increased the country's oil output; this led to an international price decrease in oil. Saddam reacted by threatening to invade Kuwait if it continued to increase its oil output (which Kuwait did nevertheless). Saudi Arabia, frightened by Saddam's military strength, then persuaded Kuwait to lower its oil output. However, when Kuwait lowered its oil output Venezuela increased its output. Saddam then ordered the invasion of Kuwait to solve the country's economic problems, with the professed goal of uniting Iraq; Kuwait was considered by many Iraqis as part of Iraq.[31] On 18 July 1990 Saddam demanded that Kuwait repay Iraq for the oil it had (according to Saddam) stolen, and nullified Iraq's debt to Kuwait. The Kuwaiti leadership failed to respond, and on 2 August 1990 the Iraqi military began the invasion of Kuwait. The invasion led to an international outcry; the United Nations, United States and the United Kingdom condemned the invasion and introduced sanctions against Iraq, and the Soviet Union and several Arab states also condemned the invasion. George H. W. Bush, President of the United States, demanded the immediate withdrawal of Iraqi troops from Kuwait and restoration of the Kuwaiti government; Saddam responded by making Kuwait an Iraqi province.[32] The Gulf War was initiated by a United States-led coalition, which succeeded in winning the war in less than a year.[33]</p><p>On the evening of 24 February, several days before the Gulf War ceasefire was signed in Safwan, the Saudi Arabia-based radio station Voice of Free Iraq (funded and operated by the Central Intelligence Agency) broadcast a message to the Iraqis to rise up and overthrow Saddam. The speaker on the radio was Salah Omar al-Ali, a former member of the Ba'ath Party and the ruling Revolutionary Command Council. Al-Ali's message urged the Iraqis to overthrow the criminal tyrant of Iraq. Al-Ali's radio broadcast encouraged Iraqis to stage a revolution and claimed that [Saddam] will flee the battlefield when he becomes certain that the catastrophe has engulfed every street, every house and every family in Iraq.[34] Believing that the United States was on its side, a nationwide uprising against Saddam's rule began in March 1991[35] which was repressed by Saddam's loyalist forces. The United Nations successfully established a no-fly zone to halt the advance of Saddam's forces. Instead of occupying Iraqi Kurdistan, the Kurdish Autonomous Republic was established, with thousands of Iraqi troops stationed at the Iraqi-Kurdish border.[36] The suppression of the rebellion led thousands of people to flee their homes, most to Turkey or Iran. On 2 and 3 April 1991 Turkey and Iran, respectively, raised the issue at the UN Security Council. The Security Council adopted Resolution 688, which stated that Iraq had to allow access for international humanitarian organisations and report openly about government repression.[37]</p><div class="gradientback"></div></div><div class="content"><p>Iraq experienced another period of unrest in early 1999 following the killing of Mohammad Mohammad Sadeq al-Sadr by Iraqi security forces.[38]</p><p>In the aftermath of the September 11 attacks, U.S. president George W. Bush included Saddam in his Axis of Evil. In 2002 the UN Security Council adopted Resolution 1441, which stated that Iraq had failed to fulfill its obligations demanded by the UN. The United States and the United Kingdom would use Resolution 1441 as a pretext for war. The 2003 US-led invasion of the country forced the Ba'ath Party and Saddam to go underground.[39] Saddam was captured later that year, and was executed in 2006.[40]</p><h2>Politics</h2><h3>Political system</h3><br><img alt="Black-and-white photo of two men in suits, shaking hands" src="http://upload.wikimedia.org/wikipedia/commons/thumb/b/b9/Baath_Party_founder_Michel_Aflaq_with_Iraqi_President_Ahmad_Hasan_al-Bakr_in_Baghdad_in_1968.jpg/220px-Baath_Party_founder_Michel_Aflaq_with_Iraqi_President_Ahmad_Hasan_al-Bakr_in_Baghdad_in_1968.jpg" width="220" height="159"><p>


				Ahmed Hassan al-Bakr (left), the Regional Secretary of the Iraqi Ba'ath, shaking hands with Michel Aflaq, principal founder of Ba'athist thought, in 1968.



				</p><p> Further information: Regional Command of the Arab Socialist Ba'ath Party – Iraq Region</p><p>
					The 1970 Iraqi Constitution stated that Iraq was in a transitional phase of development; in Ba'athist ideology, the transitional stage is the time when the Arab people unite to establish one Arab nation. The end of the transitional era would be marked by a permanent constitution; the 1970 constitution was only temporary. The Ba'ath Party dominated all government institutions, and the top decision-making body in the country was the Revolutionary Command Council (RCC). The RCC was controlled by the Ba'ath Party; RCC members had to be members of the Ba'ath Party's Regional Command. Saddam Hussein, as President of Iraq, was also RCC chairman and General Secretary of the Ba'ath Party's Regional (and National) Command.[41] All decisions within the RCC had to be decided by vote; a proposition could only be enacted if two-thirds of RCC members voted in favour of it. A Council of Ministers, the cabinet, was established on the orders of the RCC to execute RCC orders submitted to it. A National Assembly existed, which was (in theory) democratically elected by the Iraqi people; the problem was that the RCC had the authority to decide how much (or little) power the National Assembly should have.[42]</p><p>The constitution of 1970 proclaimed Ba'athist Iraq as a sovereign people's democratic republic dedicated to the establishment of a Ba'athist socialist society. Although the state was officially secular, Islam was proclaimed the country's state religion (although freedom of religion was tolerated). Natural resources and the principal means of production were defined as belonging to the Iraqi people. The Iraqi government was responsible for directing and planning the national economy.[43] If the RCC chairman died or was incapacitated, first in the line of succession was the RCC deputy chairman. There were only two RCC deputy chairmen under Ba'athist rule: Saddam (1968–1979) and Izzat Ibrahim ad-Douri (1979–2003).[44]</p><br><img alt="Saddam Hussein in uniform and man in suit, seated at opposite ends of a sofa and talking" src="http://upload.wikimedia.org/wikipedia/commons/thumb/a/a0/Baath_Party_founder_Michel_Aflaq_with_Iraqi_President_Saddam_Hussein_in_1988.jpg/300px-Baath_Party_founder_Michel_Aflaq_with_Iraqi_President_Saddam_Hussein_in_1988.jpg" width="300" height="201"><p>


				Saddam Hussein (right) talking with founder of Ba'athism and Ba'ath Party leader Michel Aflaq in 1988.



				</p><p>
					 Main articles: Ba'ath Party (Iraqi-dominated faction) and Arab Socialist Ba'ath Party – Iraq Region</p><p> Further information: Regional Command of the Arab Socialist Ba'ath Party – Iraq Region</p><p>Iraq, under the rule of the Iraqi-led Arab Socialist Ba'ath Party, was a one-party state.[45] The Regional Command (RC, the leading organ of the Iraqi Regional Branch of the Ba'ath Party) was the party's top decision-making body; Regional Command members were elected for five-year terms at the party's regional congress. The Regional Secretary (commonly referred to as the General Secretary) was the head of the Regional Command, chaired its sessions and was leader of the Ba'ath Party Regional Branch in Iraq. In theory members of the Regional Command were responsible to the party congress, but in practice they controlled the congress, and the leadership often decided results beforehand. The party's National Command was, in theory, the highest decision-making body. It was responsible for coordinating the pan-Arab Ba'ath movement. All National Command members came from their distinct regional (meaning country in Ba'athist etymology) branch; for instance, there was always a member who represented the Ba'ath Party's Jordanese Regional Branch.[46] Because of the 1966 Ba'ath Party schism (which split the Ba'ath movement into an Iraqi-led branch and a Syrian-led branch), the National Command never controlled the whole Ba'ath movement; there was a National Command headquartered in Syria, which commanded another Ba'ath movement. Another problem was the fact that the National Commands in Iraq and Syria were under the control of the country's respective regional commands.[47]</p><p> Main article: National Progressive Front (Iraq)</p><p>The National Progressive Front (NPF) was a popular front led by the Iraqi Ba'ath Party, established on 17 July 1973 (the fifth anniversary of the 17 July Revolution). The NPF charter was signed by Ahmed Hassan al-Bakr (representing the Ba'ath Party) and Aziz Muhammad (First Secretary of the Iraqi Communist Party, or ICP). In Al-Thawrah, a Ba'athist newspaper, the charter was hailed as a success for the revolution.[48] The ICP was the most prominent party to join; however, it left the NPF in March 1979. While officially an independent organisation (and the only non-Ba'athist political forum), the NPF's leadership consisted entirely of Ba'athist members or Ba'athist loyalists. The organisation's purpose was to give the Ba'athist regime a semblance of popular support.[49] Throughout the NPF's existence, Naim Haddad was its general secretary.[50]</p><h3>Opposition</h3><br><img alt="Group of about 20 Iraqi soldiers, posing with guns" src="http://upload.wikimedia.org/wikipedia/commons/thumb/b/b5/Ansar4.jpg/220px-Ansar4.jpg" width="220" height="155"><div class="gradientback"></div></div><div class="content"><p>


				Iraqi partisans (opposition forces) in northern Iraq during the Iran–Iraq War.



				</p><p>
					 Main article: Iraqi opposition (pre-2003)</p><p>The Iraqi opposition manifested itself in three forms: guerilla warfare against the regime, acts of sabotage, terrorism and desertion from the Iraqi Army or the country's paramilitary forces; the Popular Army; and Fedayeen Saddam. The largest opposition forces were headquartered in Iraqi Kurdistan, represented by the Kurdish Democratic Party (KDP) and the Patriotic Union of Kurdistan. Other organisations who opposed the regime were the Iraqi Communist Party (ICP), the al-Da'wa Party (headquartered in Teheran) and the Umma Party (based in London). One problem with the Iraqi opposition was the lack of alliances between opposition groups (although some alliances did exist—for instance, that between the ICP and the KDP). This alliance led the ICP to move its headquarters to Iraqi Kurdistan, since their activities in other areas of Iraq were routinely repressed. The Ba'athist regime was never able to take full control of the situation in Iraqi Kurdistan, with the exception of an interregnum between the end of the Iran–Iraq War and the 1991 uprising.[51] Another problem was that the Iraqi opposition had frequent problems with internal strife; for instance, the ICP was forced to hold a party congress in 1985 to stabilise the party. A more immediate problem was the strength of Iraq's secret services, renowned in the Arab world as the most efficient.[52]</p><p>In contrast to the secular opposition, the religious opposition was better organised and stronger. Several religious opposition groups could appeal to Iraqis, because of the secular nature of the Ba'athist government. During the Iran–Iraq War the government allowed some degree of religious freedom, but only to win support from the populace.[53]</p><h3>State ideology</h3><p>The Ba'ath Party was based on the ideology of Ba'athism, a Syrian ideology conceived by Zaki al-Arsuzi, Michel Aflaq and Salah al-Din al-Bitar, but evolved into neo-Ba'athism. Clause six of the Ba'ath Party's Permanent Principles stated The Ba'ath is a revolutionary party. It believes that its principal aims in [the process of] realising an Arab national renaissance and of building socialism will not be attained except by revolution and struggle. Revolution was not the key aspect of Ba'ath Party ideology; it was its clear ideological platform.[54] Ba'athism was by nature secular, even if its ideological founders had borrowed elements from Islam. The Ba'ath Party first began to talk openly of Islam during the 1990s. Considering that the term ba'ath comes from Islamic scriptures, the Ba'ath Party claimed that all Muslims were Ba'athists even if they were not party members.[55] As with the original Ba'ath Party, the Iraqi-led Ba'ath Party's key slogans were A single Arab nation with an eternal message and Unity, freedom, socialism.[56] The first slogan refers to pan-Arabism and Arab nationalism.[57] Al-Arsuzi believed that unity of the Arab people, and the establishment of an Arab nation, would lead to its becoming as strong as (or stronger than) the Soviet Union and the United States.[58] Liberty, in the Ba'athist sense of the word, does not mean political liberty for the individual. Instead, when Ba'athists use the term liberty they refer to national independence from imperialism.[59] Socialism in Ba'athist parlance means Arab socialism. Arab socialism is distinct from the international socialist movement, opposing Marx's rejection of nationalism. According to Aflaq, socialism is a means to modernise the Arab world but not a system (as generally considered in the West) which opposes private property or supports economic equality.[60]</p><p>Saddamism (Saddamiyya) is a political ideology based on the politics related to (and pursued by) Saddam Hussein.[61] It has also been referred to by Iraqi politicians as Saddamist Ba'athism (Al-Ba'athiyya Al-Saddamiyya).[62] It is officially described as a distinct variation of Ba'athism.[61] It espouses Iraqi nationalism and an Iraq-centred Arab world that calls upon Arab countries to adopt Saddamist Iraqi political discourse, and reject the Nasserite discourse which it claims collapsed after 1967.[61] It is militarist, viewing political disputes and conflict from a military standpoint as battles requiring fighting, mobilization, battlefields, bastions and trenches.[63] Saddamism was officially supported by Saddam Hussein's government and promoted by the Iraqi daily newspaper Babil, which was owned by Saddam's son Uday Hussein.[61]</p><br><img alt="Saddam Hussein and Michel Aflaq seated, talking. Both wear suits." src="http://upload.wikimedia.org/wikipedia/commons/thumb/4/46/Iraqi_President_Saddam_Hussein_with_Baath_Party_founder_Michel_Aflaq_in_1979.jpg/300px-Iraqi_President_Saddam_Hussein_with_Baath_Party_founder_Michel_Aflaq_in_1979.jpg" width="300" height="182"><p>


				Saddam Hussein (left) talking with Michel Aflaq in 1979.


				</p><p>
					Saddam Hussein and his ideologists sought to fuse a connection between the ancient Babylonian and Assyrian civilizations in Iraq to Arab nationalism by claiming that the Babylonians and ancient Assyrians are the ancestors of the Arabs. Thus, Saddam Hussein and his supporters claim that there is no conflict between Mesopotamian heritage and Arab nationalism.[64]</p><p>Saddam Hussein based his political views and ideology upon the views of Aflaq, Ba'athism's key founder. Saddam was also an avid reader of topics on moral and material forces in international politics.[64] His government was critical of orthodox Marxism, opposing the orthodox Marxist concepts of class conflict, the dictatorship of the proletariat and atheism; it opposed Marxism–Leninism's claim that non-Marxist–Leninist parties are automatically bourgeois in nature, claiming that the Ba'ath Party was a popular revolutionary movement and the people rejected petit bourgeois politics.[65] Saddam claimed that the Arab nation did not have the class structure of other nations, and class division was more along national lines (between Arabs and non-Arabs) than within the Arab community.[66] However, he spoke fondly of Vladimir Lenin and commended Lenin for giving Russian Marxism a uniquely Russian specificity which Marx alone was incapable of doing. He also expressed admiration for other communist leaders (such as Fidel Castro, Kim Il-sung, Ho Chi Minh and Josip Broz Tito) for their spirit of asserting national independence, rather than for their communism.[67]</p><p> Main article: Faith campaign</p><p>In 1993, the Iraqi regime embarked on the Return to Faith Campaign (al-Hamlah al-Imaniyyah), under the supervision of Izzat Ibrahim al-Douri. The ultimate aim of this new policy was to encourage popular devotion to Islam within Iraqi society.[68]</p><p>Up until the invasion of Kuwait in 1991, the Iraqi regime had espoused the secular ideology of Ba'athism. This started to change when Saddam, who wished to bolster the Iraqi government's Islamic credentials, implemented a variety of reforms. The Iraqi flag had the takbir added on to it. The Ministry of Endowments and Religious Affairs appointed clergy, approved the building and repair of mosques and approved the publication of Islamic literature. The Faith Campaign allowed Sunni mosques more freedom in practicing religious ceremonies and rites, which reduced substantially the opposition to the regime among Sunni Islamists.[69]</p><p>Saddam coordinated the media and educational system to put heavy emphasis on Islamic identity. Religious academic institutions were opening up across the country, and Qu'ranic and Islamic studies were introduced into the curriculum at all school levels. A religious radio station, al-Qu'ran al-Karim Radio was set up to expand and promote Islam in Iraqi life. Aspects of the Shari'ah were adopted into the Iraqi judicial system. Judges were required to study courses on Islamic jurisprudence. The selling and consumption of alcohol was curtailed by the state. Establishments which involved the vices of gambling or alcohol were restricted or closed.[70] Prostitution was deemed illegal and punishable by death. The Fedayeen Saddam, the paramilitary force loyal to the regime were well known for beheading suspected prostitutes. Thieves were punished with amputation.[71] Saddam Hussein introduced in a new penal code article 111, exempting from punishment a man who kills a woman in defense of the honour of his family.[72]</p><div class="gradientback"></div></div><div class="content"><p>This new influx of religious involvement into the government had sectarian undertones. The regimes attempt to cloak itself in Islamic conservatism saw it launch attacks on Iran, which were perceived by Shia Iraqis as being veiled attacks on their community, due to the shared faith between them and Iran. Sunni rhetoric emitting from the Iraqi government sought to discredit Iran, with scathing criticism stating that they were subscribing to a  foreign and heretical form of religion. While daily newspaper Babil, owned by Saddam's eldest son Uday Hussein, once was considered a staunch opponent of the campaign, arguing that it would undermine Iraq's religiously pluralistic society and encourage sectarian division,[73] at another point it railed against Shi'ites, referring to them as rafidah, a hateful epithet normally used by ultraconservative Salafis only.[74]</p><h2>Foreign policy</h2><h3>Relations with the Soviet Union</h3><br><img alt="Two men signing an agreement, with other men standing behind them" src="http://upload.wikimedia.org/wikipedia/commons/thumb/b/b6/Freundschaftsvertrag_Kossygin_al-Bakr_1972.jpg/220px-Freundschaftsvertrag_Kossygin_al-Bakr_1972.jpg" width="220" height="141"><p>


				Alexei Kosygin (left) and Ahmed Hassan al-Bakr signing the Iraqi–Soviet Treaty of Friendship and Co-operation in 1972.


				</p><p>
					The Ba'ath Party policy towards the Soviet Union was, at first, one of neutrality and the party's seizure of power in 1968 was not considered an important event in Moscow. The Soviet Union (which remembered the Ba'ath Party's anti-communist purge during its 1963 stint in power) gradually improved its relations with Iraq; in 1969, it guaranteed Iraq a sizable amount of modern arms and technical aid.[75] Relations improved during the nationalisation drive of the Iraqi Petroleum Company (IPC) (see Economic growth section). Saddam Hussein visited the Soviet Union in the early 1970s, and the visit led to the signing of the Iraqi–Soviet Treaty of Friendship and Co-operation and the establishment of trade relations.[76] In April 1972 Alexei Kosygin, Chairman of the Council of Ministers, visited Iraq and met with high-ranking officials. Kosygin's visit forced the Iraqi Communist Party (ICP) to improve its relations with the Ba'ath Party; two ICP members were given cabinet positions and repression of the ICP ended.[77] Relations between Iraq and the Soviet Union were at its zenith during al-Bakr's rule.[78] Iraq became a member of the Comecon (the Eastern Bloc trading organisation) as an observer in 1975.[79]</p><p>During the early years of al-Bakr's rule, the Soviet Union became a strategic ally. However, with the increase in oil revenues relations between Iraq and the Soviet Union weakened. The Iraqi regime was given more freedom of choice, and lost its dependence on Soviet investments. The Soviet Union, during this period, retained its role as Iraq's largest arms supplier. With Iraq's foreign-policy priorities changing, repression against the ICP was reintroduced. The Soviet Union tried to act as a mediator between the two parties, but Soviet involvement was considered by the Ba'athist government as Soviet interference in Iraq's internal affairs.[80] During the Iran–Iraq War Leonid Brezhnev, General Secretary of the Central Committee of the Communist Party of the Soviet Union, called the war absolutely senseless because the conflict only benefited imperialism.[81] However, Soviet relations deteriorated during the war due to Iran's support for anti-communist forces in the Democratic Republic of Afghanistan.[82] During Yuri Andropov's rule of the Soviet Union, there were rumours that the USSR was increasing its shipments of modern arms to Iraq during its war with Iran. This proved to be wrong, and Saddam openly complained that the Treaty of Friendship signed with the Soviet Union has not worked.[83] During the rule of Konstantin Chernenko, the Soviet Union's relations with Iran further deteriorated as the Soviet leadership began to criticise Islamic fundamentalism.[84] In 1986, under Mikhail Gorbachev, the Soviet Union officially changed its position from neutral to that of active containment of Iran. This policy lasted until the war with Iran ended in 1988.[85] During the Iraqi invasion of Kuwait and the following Gulf War, the Soviet Union was officially neutral.[86] Shortly after, on 26 December 1991, the Soviet Union was officially dissolved.[87]</p><h3>Relations with the United States</h3><p> Main article: Iraq–United States relations</p><p>According to historian Charles R. H. Tripp, the Iraqi–Soviet Treaty of Friendship and Co-operation upset the U.S.-sponsored security system established as part of the Cold War in the Middle East. It appeared that any enemy of the Baghdad regime was a potential ally of the United States.[88] In response, the U.S. covertly financed Kurdish rebels led by Mustafa Barzani during the Second Iraqi–Kurdish War.[88] The U.S. disliked Iraqi support for many Arab and Palestinian militant groups such as Abu Nidal, which led to Iraq's inclusion on the developing U.S. list of State Sponsors of Terrorism on 29 December 1979. The U.S. remained officially neutral after Iraq's invasion of Iran in 1980. In March 1982, however, Iran began a successful counter-offensive, and the U.S. increased its support for Iraq to prevent Iran from forcing a surrender. In a U.S. bid to open full diplomatic relations with Iraq, the country was removed from the U.S. list of State Sponsors of Terrorism. Ostensibly this was because of improvement in the regime’s record, although former U.S. Assistant Defense Secretary Noel Koch later stated, No one had any doubts about [the Iraqis'] continued involvement in terrorism. ... The real reason was to help them succeed in the war against Iran.[89]</p><h2>Economy</h2><h3>Planning system</h3><p>Since it did not have an economic policy of its own, the Ba'ath Party, when it took power in 1968, allowed the Five-Year Plan set up by the previous regime in 1965 to continue until its end date in 1969.[90] The Revolutionary Command Council (RCC) decided by the mid-1970s to alter the planning system; instead of creating stable Five-Year Plans (as had been done earlier), an annual investment plan was to be created. Every year, the RCC convened to create an investment for the year to come; for example, there were separate investment plans for 1976 and 1977. Another change is that the plan's final draft was not accepted by the highest economic elite but by the RCC, the political elite.[91] In 1976 (as a break with the new trend) the RCC introduced the National Development Plan, which was set to last from 1976 to 1980. Unlike the previous plans, the sectoral investment-allocation figures were not made public.[92]</p><h3>Economic growth</h3><p>The Iraq Petroleum Company (IPC), the largest oil company in Iraq, was a private company. In March 1970, the IPC was forced to concede 20 percent of the company's share to the government.[93] The full nationalisation of the IPC occurred when the company cut its oil production by half in March 1971; the decision would hamper Iraq's economic growth. The company was nationalised in June 1971. The nationalisation removed the last remaining element of foreign control over Iraq, and was popular with the Iraqi people. The government anticipated a loss of revenue, and therefore sent Saddam Hussein to the Soviet Union to negotiate a treaty. The visit was a success, and ended with the signing of the Iraqi–Soviet Treaty of Friendship and Co-operation and the establishment of a trade agreement. The trade agreement stated that the Soviet Union would buy some of Iraq's oil to soften the anticipated blow it would have on Iraq's oil exports. The signing of a treaty with the Soviet Union led to a visit by Alexei Kosygin (Chairman of the Council of Ministers) and the appointment of two cabinet ministers from the Iraqi Communist Party.[76]</p><div class="gradientback"></div></div><div class="content"><p>After the nationalisation of the IPC, Iraq's oil revenue increased from 219&nbsp;million ID in 1972 to 1.7&nbsp;billion ID in 1974, 3.7&nbsp;billion ID in 1978 and 8.9&nbsp;billion ID in 1980: by over 40 times in less than a decade. With the success of the Iranian revolution, Iraq became the second-largest oil exporter in the world. The increase in oil exports rejuvenated the country's economy; nearly all economic indices increased to unprecedented levels. From 1970 to 1980, Iraq's economy grew by 11.7 percent. During the Iran–Iraq War Iraq's oil-exporting capabilities decreased, and the price for oil decreased simultaneously. The growth of the 1970s was not sustainable. The economy was dependent on high oil prices and Iraq's oil-exporting capabilities; once oil was out of the picture, Iraq's growth would decrease dramatically (even more so during a war).[94]</p><p>The National Development Plan (1976–1980) ended with an 11-percent increase in GNP. The Iran–Iraq War would halt Iraq's economic development and lead to the economic stagnation seen during Saddam's later rule.[95] When Iraq implemented its plans to bomb Iran, Iran retaliated by bombing Iraq's oil facilities. By the end of the year, Iraq's oil exports had decreased by 72 percent because of Iran's bombing strategy.[96] In terms of actual income, oil exports as government revenue decreased from 26.1&nbsp;billion ID in 1980 to 10.4&nbsp;billion in 1981. With oil facilities in the Persian Gulf destroyed the Iraqi regime had no choice but to export oil overland, which was far more expensive. Other problems were the gradual erosion of the government's hard currency and its steadily increasing foreign debt.[94]</p><h3>Demise of development</h3><p>At the beginning of the war the Iraqi government had a monetary reserve of 35&nbsp;billion ID, and the annual growth rate was 27.9 percent. During the early war years, ambitious development plans were followed; because of high military spending (approaching 50 percent of GNP in 1982), the Iraqi economy began showing signs of bankruptcy in the mid-to-late 1980s. The war had cost the Iraqi government 226&nbsp;billion dollars, which in turn had led to a staggering foreign debt of between 80 and 100&nbsp;billion dollars. The rate of debt increase was estimated to be 10&nbsp;billion a year. Another problem facing the regime was in agriculture; manpower had been depleted during the war years, and agricultural production plummeted. The situation became even bleaker after the war. Minister of Foreign Affairs Tariq Aziz acknowledged that the situation had become so bad that the Iraqi government could not afford to pay for the food it had imported. Former foreign creditors were reluctant to loan money to Iraq because of the economy's near-bankruptcy.[97]</p><br><img alt="Graph of Iraqi GNP, showing highest GNP in 1980" src="http://upload.wikimedia.org/wikipedia/commons/thumb/8/8d/Iraq_GDP_per_capita_1950-2008.png/220px-Iraq_GDP_per_capita_1950-2008.png" width="220" height="168"><p>


				GNP per capita in Iraq from 1950 to 2008.


				</p><p>
					When the war started, Saddam was widely quoted as saying that Iraq faced the war with a two-year supply of all key commodities.; this proved true. Beginning in October 1982, Iraq's foreign assets began to dwindle as the government failed to repay its loans. At the end of the war, Iraq's monetary reserve had been depleted and international oil prices were not as stable (high) as they had been during the 1970s.[98] The economy was still healthy in late 1982, due to government expenditure on large development programmes.[99] Before the war, Iraq's workforce stood at five million. During the war, one million were mobilised in the war against Iran. Of the million sent to war, 100,000 died. The labour shortage led to stagnation; to fill the gap, an increasing number of women were hired.[100] There was a shift in industrial production during the war from consumer to military goods. Social programmes that had been established in the previous decade began to deteriorate, and the average standard of living decreased.[101]</p><p>During the mid-to-late 1980s, international oil prices collapsed. The Organisation for Petroleum Exporting Countries (OPEC) established a quota system in which the international oil price (for its members) was set at USD$18 per barrel. This system did not work, as Kuwait and the United Arab Emirate (UAE) did not follow OPEC policy and continued to flood the market with their oil. The result was that international oil prices were still at the 1970s level. In October 1988, because of Kuwait and the UAE, international oil prices had fallen to US$12 per barrel.[102] The policy which the UAE (and especially Kuwait) followed hampered Iraq's economic growth. In the Iran–Iraq War's aftermath, Iraq had grown more dependent on oil prices.[103] The result of Kuwait and the UAE's oil policies could be felt in 1990, when international oil prices decreased to US$13.67 per barrel. This time, the sudden fall in oil prices triggered reactions in Iraq; in Al-Thawra, the Ba'ath Party newspaper, Foreign Minister Aziz criticised Kuwait and the UAE's oil policies.[104] Because of the sudden slump, Saddam claimed at an Arab League conference that international oil prices could increase to US$25 per barrel without hurting exports. Saddam also claimed that the abrupt fall in oil prices decreased Iraq's oil revenue by one billion dollars. Iraq was not the only member criticising Kuwait and the UAE; several other members also criticised their oil-production policy.[103] Kuwait would not budge, continuing its oil-production strategy even when threatened by Iraq. This, coupled with foreign loans Iraq owned to Kuwait, was the main reason for the Iraqi invasion of Kuwait.[105]</p><h3>UN sanctions</h3><p> Main article: Sanctions against Iraq</p><p>Following Iraq's defeat in the Gulf War, the United Nations Security Council introduced Resolution 661, which imposed sanctions against Iraq. At the beginning, most American observers believed the sanctions would lead to Saddam's downfall. U.S. President George H. W. Bush said, Economic sanctions in this instance if fully enforced can be very, very effective, [...] There are some indications that that he's [Saddam] already beginning to feel the pinch and nobody can stand up forever to total economic deprivation.[106] In theory (and practice), Iraq was very vulnerable to sanctions during this time. Thirty percent of its GNP before the Gulf War was used to import food, and 95 percent of Iraq's export earnings came from oil; oil production was 40 percent of GNP. The country was also reliant on foreign trade (35–50 percent of GNP for exported and imported goods). Iraq was also an easy country to blockade economically; its oil exports could be blockaded by closing its pipelines (which ran through Turkey, Jordan and Syria). While sanctions were successful from an economic point of view, politically they failed; Saddam would rule Iraq until 2003.[107]</p><p>Throughout the Ba'ath Party's rule over Iraq, the agricultural sector had been under-performing. Those in the United States who supported sanctions believed that low agricultural production in Iraq (coupled with sanctions) would lead to a hungry population, and a hungry population was an unruly one.[108] The Iraqi government, which understood the serious effects the sanctions could have on Iraq, were able to increase agricultural output by 24 percent from 1990 to 1991. During the sanction years, the agricultural sector witnessed a boom of unprecedented proportions. The Revolutionary Command Council (RCC) introduced several decrees during this period to increase agricultural performance. These decrees may be separated into three categories:</p><p>The RCC introduced Decree No. 367 in 1990, which stated that all lands which were not under production by their owners would be taken over by the state; if the owner could not use all the land he owned, he would lose it. However, the RCC's policy was not all stick and no carrot. The government made it easier for farmers and landowners to receive credit. On 30 September 1990, the Ministry of Agriculture announced that it would increase loans to farmers by 100&nbsp;percent, and would subsidise machinery and tools. In October 1990, the RCC stated it was planning to utilize and exploit every inch of Iraqi arable land. While official statistics cannot be trusted entirely,[why?] they showed massive growth in arable land: from 16,446 donums in 1980 to 45,046 in 1990.[110] The increase in agricultural output does not mean that hunger was not widespread; prices of foodstuffs increased dramatically during this period. However, overall the sanctions failed and (indirectly) led to an unprecedented improvement in agriculture.[111]</p><p>While the agricultural sector improved, most other economic indicators deteriorated. Transport (which had been bombed during the Gulf War) further deteriorated due to the government's neglect. The economy suffered from chronic inflation and currency depreciation; the sanctions exacerbated the structural problems in Iraq's economic system. Iraq was, on balance, a planned economy with market-economy characteristics.[112]</p><div class="gradientback"></div></div><div class="content"><h3>Modest growth</h3><p>By the late 1990s, the Iraqi economy showed signs of modest growth. These would continue until 2003 when the government was toppled. The gross domestic product increased from 10.8 billion in 1996 to 30.8 billion in 2000. The major factor in this growth was the UN-initiated Oil-for-Food Programme (OFFP). Saddam was originally opposed to the OFFP. The OFFP led to the inflow of hard currency, which helped reduce the country's chronic inflation and reopened old trade routes with foreign countries.[112] It was around this time, when many countries started to ignore the UN sanctions.[113] While internal and external trade was revitalised, this did not lead to a significant increase in the standard of living; on the contrary, the government tried to prevent an increase in Shia areas to persuade more countries to oppose the sanctions. In 2000 the standard of living was estimated to be US$1,000, less than half of what it was in 1990.[114]</p><h2>Military</h2><p> Main article: Military history of Iraq</p><h3>Expenditure</h3><p>The Ba'ath regime, like its predecessors, came to power by military force. From Abd al-Karim Qasim until the Ba'athist seizure of power in 1968, the Iraqi government had followed a policy of the militarisation of society. This led to the expansion of the old military elite, which had existed under the Hashemite monarchy. The military elite gradually also evolved into an economic elite, since Iraq was a planned economy; for instance, the government appointed military personnel to senior positions in factories and companies. While the period from 1960 to 1980 was peaceful, expenditure on the military trebled and in 1981 it stood at US$4.3&nbsp;billion.[115] The government placed more importance on military development than on the civilian sector. In 1981, Iraq's military expenditure nearly equaled the national incomes of Jordan and Yemen combined.[116] The military buildup was made possible because of Iraq's oil production and the high international price for oil. Per capita military spending in 1981 was 370 percent higher than that for education. During the Iran–Iraq War military expenditures increased dramatically (while economic growth was shrinking) and the number of people employed in the military increased fivefold, to one million.[117]</p><h3>Size</h3><br><img alt="Six uniformed soldiers waving from an armoured vehicle on a highway" src="http://upload.wikimedia.org/wikipedia/commons/thumb/b/b2/Iraqi_military_men_riding_on_tank.jpg/220px-Iraqi_military_men_riding_on_tank.jpg" width="220" height="157"><p>


				28 February 2003: Iraqi soldiers ride an MT-LB armored vehicle on an Iraqi highway, one month before the start of the Iraq War.


				</p><p>
					In 1967, the Iraqi army consisted of 50,000 men on two-year service; the Iraqi Air Force had 170 aircraft. In 1980, these numbers had increased to a standing army of 200,000, 250,000 reserves and 250,000 paramilitary troops in the Ba'ath Party-led Popular Army. The army had 2,500 tanks, 335 combat aircraft and 40 combat helicopters. In 1988, at the end of the Iran–Iraq War, Iraq fielded the fourth largest army in the world; the army consisted of 955,000 standing soldiers and 650,000 paramilitary forces in the Popular Army. The army could field 4,500 tanks, 484 combat aircraft and 232 combat helicopters.[118] According to Michael Knights, the Iraqi army fielded one million men and 850,000 reservists; there were 53 divisions, 20 special-forces brigades, and several regional militias. The Iraqi military was able to field 5,500 tanks, 3,000 artillery pieces, the country had a strong air defence and could employ 700 combat aircraft and helicopters.[119] By 1990 (according to Keith Shimko) the Iraqi army fielded nearly one million men, 5,700 tanks, 3,700 artillery pieces and 950 combat aircraft. During the Gulf War the most optimistic military analysis believed that, during an all-out war with the Iraqi military, the United States military would suffer between 17,000 and 30,000 casualties.[120] In the aftermath of the Gulf War the size of the Iraqi military was reduced to an estimated 350,000 standing troops; it could deploy 2,300 main battle tanks, had about 260 combat aircraft and could deploy up to 120 combat helicopters.[118] In 2002, one year before the 2003 invasion, the Iraqi army could deploy 375,000 men. According to the United States Central Command, Iraq's army (standing and reserves) stood at 700,000 men.[121]</p><h2>Demographics</h2><h3>Culture</h3><br><img alt="Black-and-white photo of Saddam Hussein, in a suit, with a group of women students" src="http://upload.wikimedia.org/wikipedia/commons/thumb/a/a2/Saddam1970s.jpg/200px-Saddam1970s.jpg" width="200" height="149"><p>


				Saddam Hussein and women students. Ba'athism promoted greater participation of women in Iraqi society.


				</p><p>
					The Ba'athist era was a period of secularisation in Iraq. The government included people from multiple religious affiliations (including Sunni Muslims, Shiite Muslims and Christians). However, the period was marked (especially under Saddam Hussein) by sectarian, religious and political strife between the government and other groups: Shiite Muslims (mainly drawn from Arabs, this religious group formed an absolute majority) who sought to create an Iraqi theocracy; ethnic Kurds, who sought independence for their region; Sunnis with an Islamist ideology, and non-Ba'athists (such as the Iraqi communists who were heavily suppressed in 1978). The Iraqi government promoted women's rights to a degree, allowing them education and service in the armed forces, but—despite the Ba'ath's avowed radicalism—its changes to family law were considerably less radical than&nbsp;... the Shah's family reforms, to say nothing of Ataturk's radical break with Islamic family law in 1926.[122] The government sought restoration of Iraqi cultural heritage, such as rebuilding replicas of parts of the ancient city of Babylon. Under Saddam Hussein, the glorification of Saddam and the Ba'athist government was common in state-sponsored artwork. The Ba'ath Party dominated the political life of the country, although a National Progressive Front was proclaimed in 1974 to allow for the (mostly nominal) participation of non-Ba'athist figures and parties in Iraqi politics.</p><p>During the Persian Gulf War, Saddam Hussein sought to gain support from the Muslim religious community for the government, adding the Takbir to the flag, coat of arms and motto of Iraq.</p><p>Retrieved from "https://en.wikipedia.org/w/index.php?title=Sumer&amp;oldid=782306911"					
								Categories:  Hidden categories:</p><br><h1 lang="en">Elam</h1><p> From Wikipedia, the free encyclopedia</p><div class="gradientback"></div></div>


		

	</div> <!-- End of Main -->

	<div class="scrollbarContainer">
		<div>
			<Center>
				<div id="scroll2" class="iconContainer" >
					<div id="secondScrollIndex" >
					</div>
				</div>
			</Center>
		</div>
	</div>
	
	
	
	
	
	
	
	
	
	
	
	
</body>
</html>